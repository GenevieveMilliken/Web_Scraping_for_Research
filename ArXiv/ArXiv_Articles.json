[
  {
    "Article_Url": "https://arxiv.org/abs/1910.03867",
    "DOI": "arXiv:1910.03867v1",
    "Article_Title": "Loss Surface Sightseeing by Multi-Point Optimization",
    "Article_Abstract": "We present multi-point optimization: an optimization technique that allows totrain several models simultaneously without the need to keep the parameters ofeach one individually. The proposed method is used for a thorough empiricalanalysis of the loss landscape of neural networks. By extensive experiments onFashionMNIST and CIFAR10 datasets we demonstrate two things: 1) loss surface issurprisingly diverse and intricate in terms of landscape patterns it contains,and 2) adding batch normalization makes it more smooth. Source code toreproduce all the reported results is available on GitHub:https://github.com/universome/loss-patterns.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/10/09",
    "Article_PDF": "https://arxiv.org/pdf/1910.03867"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.02513",
    "DOI": "arXiv:1910.02513v1",
    "Article_Title": "Automated Isolation for White-box Test Generation",
    "Article_Abstract": "Context. White-box test generation is a technique used for automaticallyselecting test inputs using only the source or binary code. However, suchtechniques encounter challenges when applying them to complex programs. One ofthe main challenges is handling the dependencies of the unit under test.  Objective. Without proper actions, generated tests cannot cover all parts ofthe source code, or calling the dependencies may cause unexpected side effects(e.g., file system or network access). These issues should be tackled whilemaintaining the advantages of white-box test generation.  Method. In this paper, we present an automated source code transformationapproach tackling the dependency issue for white-box test generation. Thistechnique isolates the test execution by creating a parameterized sandboxwrapped around the transformed unit. We implemented the approach in aready-to-use tool using Microsoft Pex as a test generator, and evaluated it on10 open-source projects from GitHub having more than 38.000 lines of code intotal.  Results. The results from the evaluation indicate that if the lack ofisolation hinders white-box test generation, then our approach is able to help:it increases the code coverage reached by the automatically generated test,while it reduces unwanted side effects. Also, our results act as a uniquebaseline for the test generation performance of Microsoft Pex on open-sourceprojects.  Conclusion. Based on the results, our source code transformations might servewell for alleviating the isolation problem in white-box test generation as itincreases the coverage reached in such situations, while maintaining thepractical applicability of the tests generated on the isolated code.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/10/06",
    "Article_PDF": "https://arxiv.org/pdf/1910.02513"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01750",
    "DOI": "arXiv:1910.01750v2",
    "Article_Title": "PEXO: a global modeling framework for nanosecond timing, microsecond astrometry, and {\\mu}m/s radial velocities",
    "Article_Abstract": "The ability to make independent detections of the signatures of exoplanetswith complementary telescopes and instruments brings a new potential for robustidentification of exoplanets and precision characterization. We introduce PEXO,a package for Precise EXOplanetology to facilitate the efficient modeling oftiming, astrometry, and radial velocity data, which will benefit not onlyexoplanet science but also various astrophysical studies in general. PEXO isgeneral enough to account for binary motion and stellar reflex motions inducedby planetary companions and is precise enough to treat various relativisticeffects both in the solar system and in the target system. We also model thepost-Newtonian barycentric motion for future tests of general relativity inextrasolar systems. We benchmark PEXO with the pulsar timing package TEMPO2 andfind that PEXO produces numerically similar results with timing precision ofabout 1 ns, space-based astrometry to a precision of 1\u03bcas, and radialvelocity of 1 \u03bcm/s and improves on TEMPO2 for decade-long timing data ofnearby targets, due to its consideration of third-order terms of Roemer delay.PEXO is able to avoid the bias introduced by decoupling the target system andthe solar system and to account for the atmospheric effects which set apractical limit for ground-based radial velocities close to 1 cm/s. Consideringthe various caveats in barycentric correction and ancillary data required torealize cm/s modeling, we recommend the preservation of original observationaldata. The PEXO modeling package is available at GitHub(https://github.com/phillippro/pexo).",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM); Solar and Stellar Astrophysics (astro-ph.SR)",
    "Article_Date": "2019/10/03",
    "Article_PDF": "https://arxiv.org/pdf/1910.01750"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01321",
    "DOI": "arXiv:1910.01321v1",
    "Article_Title": "An Empirical Study of C++ Vulnerabilities in Crowd-Sourced Code Examples",
    "Article_Abstract": "Software developers share programming solutions in Q&A sites like StackOverflow. The reuse of crowd-sourced code snippets can facilitate rapidprototyping. However, recent research shows that the shared code snippets maybe of low quality and can even contain vulnerabilities. This paper aims tounderstand the nature and the prevalence of security vulnerabilities incrowd-sourced code examples. To achieve this goal, we investigate securityvulnerabilities in the C++ code snippets shared on Stack Overflow over a periodof 10 years. In collaborative sessions involving multiple human coders, wemanually assessed each code snippet for security vulnerabilities following CWE(Common Weakness Enumeration) guidelines. From the 72,483 reviewed codesnippets used in at least one project hosted on GitHub, we found a total of 69vulnerable code snippets categorized into 29 types. Many of the investigatedcode snippets are still not corrected on Stack Overflow. The 69 vulnerable codesnippets found in Stack Overflow were reused in a total of 2859 GitHubprojects. To help improve the quality of code snippets shared on StackOverflow, we developed a browser extension that allow Stack Overflow users tocheck for vulnerabilities in code snippets when they upload them on theplatform.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/10/03",
    "Article_PDF": "https://arxiv.org/pdf/1910.01321"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01212",
    "DOI": "arXiv:1910.01212v1",
    "Article_Title": "Social Influence and Radicalization: A Social Data Analytics Study",
    "Article_Abstract": "The confluence of technological and societal advances is changing the natureof global terrorism. For example, engagement with Web, social media, and smartdevices has the potential to affect the mental behavior of the individuals andinfluence extremist and criminal behaviors such as Radicalization. In thiscontext, social data analytics (i.e., the discovery, interpretation, andcommunication of meaningful patterns in social data) and influence maximization(i.e., the problem of finding a small subset of nodes in a social network whichcan maximize the propagation of influence) has the potential to become a vitalasset to explore the factors involved in influencing people to participate inextremist activities.  To address this challenge, we study and analyze the recent work done ininfluence maximization and social data analytics from effectiveness, efficiencyand scalability viewpoints. We introduce a social data analytics pipeline,namely iRadical, to enable analysts engage with social data to explore thepotential for online radicalization. In iRadical, we present algorithms toanalyse the social data as well as the user activity patterns to learn howinfluence flows in social networks. We implement iRadical as an extensiblearchitecture that is publicly available on GitHub and present the evaluationresults.",
    "Article_Subject": "Computers and Society (cs.CY); Machine Learning (cs.LG)",
    "Article_Date": "2019/09/04",
    "Article_PDF": "https://arxiv.org/pdf/1910.01212"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01078",
    "DOI": "arXiv:1910.01078v1",
    "Article_Title": "ROS Rescue : Fault Tolerance System for Robot Operating System",
    "Article_Abstract": "In this chapter we discuss the problem of master failure in ROS1.0 and itsimpact on robotic deployments in the real world. We address this issue in thistutorial chapter where we outline, design and demonstrate a fault tolerantmechanism associated with ROS master failure. Unlike previous solutions whichuse primary backup replication and external checkpointing libraries which areprocess heavy, our mechanism adds a lightweight functionality to the ROS masterto enable it to recover from failure.  We present a modified version of ROS master which is equipped with a loggingmechanism to record the meta information and network state of ROS nodes as wellas a recovery mechanism to go back to the previous state without having toabort or restart all the nodes. We also implement an additional master monitornode responsible for failure detection on the master by polling it for itsavailability. Our code is implemented in python and preliminary tests wereconducted successfully on a variety of land, aerial and underwater robots and atele-operating computer running ROS Kinetic on Ubuntu 16.04. The code ispublicly available under a creative commons license on github athttps://github.com/PushyamiKaveti/fault-tolerant-ros-master",
    "Article_Subject": "Robotics (cs.RO)",
    "Article_Date": "2019/10/02",
    "Article_PDF": "https://arxiv.org/pdf/1910.01078"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00725",
    "DOI": "arXiv:1910.00725v1",
    "Article_Title": "Cosmic Microwave Background Anisotropy numerical solution (CMBAns) I: An introduction to $C_l$ calculation",
    "Article_Abstract": "Cosmological Boltzmann codes are often used by researchers for calculatingthe CMB angular power spectra from different theoretical models, forcosmological parameter estimation, etc. Therefore, the accuracy of a Boltzmanncode is of utmost importance. Different Markov Chain Monte Carlo basedparameter estimation algorithms typically require 10^3 - 10^4 iterations ofBoltzmann code. This makes the time complexity of such codes another criticalfactor. In the last two decades, several Boltzmann packages, such as CMBFAST,CAMB, CMBEasy, CLASS etc., have been developed. In this paper, we present a newcosmological Boltzmann code, CMBAns, that can be used for accurate calculationof the CMB power spectrum. At present, CMBAns is developed for a flatbackground matrix. It is mostly written in the C language. However, we borrowedthe concept of class from C++. This gives researchers the flexibility todevelop their own independent package based on CMBAns, without an in-depthunderstanding of the source code. We also develop multiple stand-alonefacilities which can be directly compiled and run on a given parameter set. Inthis paper, we discuss all the mathematical formulation, approximation schemes,integration methods etc., that are used in CMBAns. The package will be madeavailable through github for public use in the near future.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); Instrumentation and Methods for Astrophysics (astro-ph.IM); General Relativity and Quantum Cosmology (gr-qc)",
    "Article_Date": "2019/10/02",
    "Article_PDF": "https://arxiv.org/pdf/1910.00725"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00536",
    "DOI": "arXiv:1910.00536v1",
    "Article_Title": "Scalable String Reconciliation by Recursive Content-Dependent Shingling",
    "Article_Abstract": "We consider the problem of reconciling similar, but remote, strings withminimum communication complexity. This \"string reconciliation\" problem is afundamental building block for a variety of networking applications, includingthose that maintain large-scale distributed networks and perform remote filesynchronization. We present the novel Recursive Content-Dependent Shingling(RCDS) protocol that is computationally practical for large strings and scaleslinearly with the edit distance between the remote strings. We providecomparisons to the performance of Rsync, one of the most popular filesynchronization tools in active use. Our experiments show that, with minimalengineering, RCDS outperforms the heavily optimized Rsync in reconcilingrelease revisions for about 51% of the 5000 top starred git repositories onGitHub. The improvement is particularly evident for repositories that seefrequent, but small, updates.",
    "Article_Subject": "Information Theory (cs.IT)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00536"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00286",
    "DOI": "arXiv:1910.00286v1",
    "Article_Title": "Ransomware Analysis using Feature Engineering and Deep Neural Networks",
    "Article_Abstract": "Detection and Analysis of a potential malware specifically, used for ransomis a challenging task. Recently, intruders are utilizing advance cryptographictechniques to get hold of digital assets and then demand ransom. It is believedthat generally, the files comprise of some attributes, states, and patternsthat can be recognized by a machine learning technique. This work thus focuseson detection of Ransomware by performing feature engineering, which helps inanalyzing vital attributes and behaviors of the malware. The main contributionof this work is the identification of important and distinct characteristics ofRansomware that can help in detecting them. Finally, based on the selectedfeatures, both conventional machine learning techniques and Transfer Learningbased Deep Convolutional Neural Networks have been used to detect Ransomware.In order to perform feature engineering and analysis, two separate datasets(static and dynamic) were generated. The static dataset has 3646 samples (1700Ransomware and 1946 Goodware). On the other hand, the dynamic dataset comprisedof 3444 samples (1455 Ransomware and 1989 Goodware). Through variousexperiments, it is observed that the Registry changes, API calls, and DLLs arethe most important features for Ransomware detection. Additionally, importantsequences are found with the help of N Gram technique. It is also observed thatin case of Registry Delete operation, if a malicious file tries to deleteregistries, it follows a specific and repeated sequence. However for the benignfile, it doesnt follow any specific sequence or repetition. Similarly, aninteresting observation made through this study is that there is no commonRegistry deleted sequence between malicious and benign file. And thus thisdiscernible fact can be readily exploited for Ransomware detection. Therelevant Python code and dataset are available at github.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00286"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00199",
    "DOI": "arXiv:1910.00199v1",
    "Article_Title": "Underwhelming Generalization Improvements From Controlling Feature Attribution",
    "Article_Abstract": "Overfitting is a common issue in machine learning, which can arise when themodel learns to predict class membership using convenient butspuriously-correlated image features instead of the true image features thatdenote a class. These are typically visualized using saliency maps. In someobject classification tasks such as for medical images, one may have someimages with masks, indicating a region of interest, i.e., which part of theimage contains the most relevant information for the classification. Wedescribe a simple method for taking advantage of such auxiliary labels, bytraining networks to ignore the distracting features which may be extractedoutside of the region of interest, on the training images for which such masksare available. This mask information is only used during training and has animpact on generalization accuracy in a dataset-dependent way. We observe anunderwhelming relationship between controlling saliency maps and improvinggeneralization performance.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00199"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00188",
    "DOI": "arXiv:1910.00188v1",
    "Article_Title": "Beyond Textual Issues: Understanding the Usage and Impact of GitHub Reactions",
    "Article_Abstract": "Recently, GitHub introduced a new social feature, named reactions, which are\"pictorial characters\" similar to emoji symbols widely used nowadays intext-based communications. Particularly, GitHub users can use a pre-defined setof such symbols to react to issues and pull requests. However, little is knownabout the real usage and impact of GitHub reactions. In this paper, we analyzethe reactions provided by developers to more than 2.5 million issues and 9.7million issue comments, in order to answer an extensive list of nine researchquestions about the usage and adoption of reactions. We show that reactions arebeing increasingly used by open source developers. Moreover, we also found thatissues with reactions usually take more time to be handled and have longerdiscussions.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00188"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00024",
    "DOI": "arXiv:1910.00024v1",
    "Article_Title": "Neural Canonical Transformation with Symplectic Flows",
    "Article_Abstract": "Canonical transformation plays a fundamental role in simplifying and solvingclassical Hamiltonian systems. We construct flexible and powerful canonicaltransformations as generative models using symplectic neural networks. Themodel transforms physical variables towards a latent representation with anindependent harmonic oscillator Hamiltonian. Correspondingly, the phase spacedensity of the physical system flows towards a factorized Gaussian distributionin the latent space. Since the canonical transformation preserves theHamiltonian evolution, the model captures nonlinear collective modes in thelearned latent representation. We present an efficient implementation ofsymplectic neural coordinate transformations and two ways to train the model.The variational free energy calculation is based on the analytical form ofphysical Hamiltonian. While the phase space density estimation only requiressamples in the coordinate space for separable Hamiltonians. We demonstrateappealing features of neural canonical transformation using toy problemsincluding two-dimensional ring potential and harmonic chain. Finally, we applythe approach to real-world problems such as identifying slow collective modesin alanine dipeptide and conceptual compression of the MNIST dataset.",
    "Article_Subject": "Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG); Computational Physics (physics.comp-ph); Machine Learning (stat.ML)",
    "Article_Date": "2019/09/30",
    "Article_PDF": "https://arxiv.org/pdf/1910.00024"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.13589",
    "DOI": "arXiv:1909.13589v1",
    "Article_Title": "Domain Adaptation for Semantic Segmentation with Maximum Squares Loss",
    "Article_Abstract": "Deep neural networks for semantic segmentation always require a large numberof samples with pixel-level labels, which becomes the major difficulty in theirreal-world applications. To reduce the labeling cost, unsupervised domainadaptation (UDA) approaches are proposed to transfer knowledge from labeledsynthesized datasets to unlabeled real-world datasets. Recently, somesemi-supervised learning methods have been applied to UDA and achievedstate-of-the-art performance. One of the most popular approaches insemi-supervised learning is the entropy minimization method. However, whenapplying the entropy minimization to UDA for semantic segmentation, thegradient of the entropy is biased towards samples that are easy to transfer. Tobalance the gradient of well-classified target samples, we propose the maximumsquares loss. Our maximum squares loss prevents the training process beingdominated by easy-to-transfer samples in the target domain. Besides, weintroduce the image-wise weighting ratio to alleviate the class imbalance inthe unlabeled target domain. Both synthetic-to-real and cross-city adaptationexperiments demonstrate the effectiveness of our proposed approach. The code isreleased at https://github. com/ZJULearning/MaxSquareLoss.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/30",
    "Article_PDF": "https://arxiv.org/pdf/1909.13589"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.13092",
    "DOI": "arXiv:1909.13092v1",
    "Article_Title": "GLA-Net: An Attention Network with Guided Loss for Mismatch Removal",
    "Article_Abstract": "Mismatch removal is a critical prerequisite in many feature-based tasks.Recent attempts cast the mismatch removal task as a binary classificationproblem and solve it through deep learning based methods. In these methods, theimbalance between positive and negative classes is important, which affectsnetwork performance, i.e., Fn-score. To establish the link between Fn-score andloss, we propose to guide the loss with the Fn-score directly. We theoreticallydemonstrate the direct link between our Guided Loss and Fn-score duringtraining. Moreover, we discover that outliers often impair global context inmismatch removal networks. To address this issue, we introduce the attentionmechanism to mismatch removal task and propose a novel Inlier Attention Block(IA Block). To evaluate the effectiveness of our loss and IA Block, we designan end-to-end network for mismatch removal, called GLA-Net \\footnote{Our codewill be available in Github later.}. Experiments have shown that our networkachieves the state-of-the-art performance on benchmark datasets.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/28",
    "Article_PDF": "https://arxiv.org/pdf/1909.13092"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.11977",
    "DOI": "arXiv:1909.11977v1",
    "Article_Title": "Stochastic Weight Matrix-based Regularization Methods for Deep Neural Networks",
    "Article_Abstract": "The aim of this paper is to introduce two widely applicable regularizationmethods based on the direct modification of weight matrices. The first method,Weight Reinitialization, utilizes a simplified Bayesian assumption withpartially resetting a sparse subset of the parameters. The second one, WeightShuffling, introduces an entropy- and weight distribution-invariant non-whitenoise to the parameters. The latter can also be interpreted as an ensembleapproach. The proposed methods are evaluated on benchmark datasets, such asMNIST, CIFAR-10 or the JSB Chorales database, and also on time series modelingtasks. We report gains both regarding performance and entropy of the analyzednetworks. We also made our code available as a GitHub repository(https://github.com/rpatrik96/lod-wmm-2019).",
    "Article_Subject": "Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)",
    "Article_Date": "2019/09/26",
    "Article_PDF": "https://arxiv.org/pdf/1909.11977"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.11811",
    "DOI": "arXiv:1909.11811v1",
    "Article_Title": "A fast, complete, point cloud based loop closure for LiDAR odometry and mapping",
    "Article_Abstract": "This paper presents a loop closure method to correct the long-term drift inLiDAR odometry and mapping (LOAM). Our proposed method computes the 2Dhistogram of keyframes, a local map patch, and uses the normalizedcross-correlation of the 2D histograms as the similarity metric between thecurrent keyframe and those in the map. We show that this method is fast,invariant to rotation, and produces reliable and accurate loop detection. Theproposed method is implemented with careful engineering and integrated into theLOAM algorithm, forming a complete and practical system ready to use. Tobenefit the community by serving a benchmark for loop closure, the entiresystem is made open source on Github",
    "Article_Subject": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/25",
    "Article_PDF": "https://arxiv.org/pdf/1909.11811"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.11544",
    "DOI": "arXiv:1909.11544v1",
    "Article_Title": "PyDEns: a Python Framework for Solving Differential Equations with Neural Networks",
    "Article_Abstract": "Recently, a lot of papers proposed to use neural networks to approximatelysolve partial differential equations (PDEs). Yet, there has been a lack offlexible framework for convenient experimentation. In an attempt to fill thegap, we introduce a PyDEns-module open-sourced on GitHub. Coupled withcapabilities of BatchFlow, open-source framework for convenient andreproducible deep learning, PyDEns-module allows to 1) solve partialdifferential equations from a large family, including heat equation and waveequation 2) easily search for the best neural-network architecture among thezoo, that includes ResNet and DenseNet 3) fully control the process ofmodel-training by testing different point-sampling schemes. With that in mind,our main contribution goes as follows: implementation of a ready-to-use andopen-source numerical solver of PDEs of a novel format, based on neuralnetworks.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/09/25",
    "Article_PDF": "https://arxiv.org/pdf/1909.11544"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.10051",
    "DOI": "arXiv:1909.10051v1",
    "Article_Title": "PyIT2FLS: A New Python Toolkit for Interval Type 2 Fuzzy Logic Systems",
    "Article_Abstract": "Fuzzy logic is an accepted and well-developed approach for constructingverbal models. Fuzzy based methods are getting more popular, while theengineers deal with more daily life tasks. This paper presents a new Pythontoolkit for Interval Type 2 Fuzzy Logic Systems (IT2FLS). Developing softwaretools is an important issue for facilitating the practical use of theoreticalresults. There are limited tools for implementing IT2FLSs in Python. Thedeveloped PyIT2FLS is providing a set of tools for fast and easy modeling offuzzy systems. This paper includes a brief description of how developed toolkitcan be used. Also, three examples are given showing the usage of the developedtoolkit for simulating IT2FLSs. First, a simple rule-based system is developedand it's codes are presented in the paper. The second example is the predictionof the Mackey-Glass chaotic time series using IT2FLS. In this example, theParticle Swarm Optimization (PSO) algorithm is used for determining systemparameters while minimizing the mean square error. In the last example, anIT2FPID is used in a linear time-delay system. The code for the examples areavailable on toolkit's GitHub page: https://github.com/Haghrah/PyIT2FLS. Thesimulations and their results confirm the ability of the developed toolkit tobe used in a wide range of the applications.",
    "Article_Subject": "Systems and Control (eess.SY); Mathematical Software (cs.MS)",
    "Article_Date": "2019/09/22",
    "Article_PDF": "https://arxiv.org/pdf/1909.10051"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.09029",
    "DOI": "arXiv:1909.09029v2",
    "Article_Title": "DIRE: A Neural Approach to Decompiled Identifier Naming",
    "Article_Abstract": "The decompiler is one of the most common tools for examining binaries withoutcorresponding source code. It transforms binaries into high-level code,reversing the compilation process. Decompilers can reconstruct much of theinformation that is lost during the compilation process (e.g., structure andtype information). Unfortunately, they do not reconstruct semanticallymeaningful variable names, which are known to increase code understandability.We propose the Decompiled Identifier Renaming Engine (DIRE), a novelprobabilistic technique for variable name recovery that uses both lexical andstructural information recovered by the decompiler. We also present a techniquefor generating corpora suitable for training and evaluating models ofdecompiled code renaming, which we use to create a corpus of 164,632 uniquex86-64 binaries generated from C projects mined from GitHub. Our results showthat on this corpus DIRE can predict variable names identical to the names inthe original source code up to 74.3% of the time.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/09/19",
    "Article_PDF": "https://arxiv.org/pdf/1909.09029"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.08766",
    "DOI": "arXiv:1909.08766v1",
    "Article_Title": "A High-Fidelity Open Embodied Avatar with Lip Syncing and Expression Capabilities",
    "Article_Abstract": "Embodied avatars as virtual agents have many applications and providebenefits over disembodied agents, allowing non-verbal social and interactionalcues to be leveraged, in a similar manner to how humans interact with eachother. We present an open embodied avatar built upon the Unreal Engine that canbe controlled via a simple python programming interface. The avatar has lipsyncing (phoneme control), head gesture and facial expression (using eitherfacial action units or cardinal emotion categories) capabilities. We releasecode and models to illustrate how the avatar can be controlled like a puppet orused to create a simple conversational agent using public applicationprogramming interfaces (APIs). GITHUB link:https://github.com/danmcduff/AvatarSim",
    "Article_Subject": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)",
    "Article_Date": "2019/09/19",
    "Article_PDF": "https://arxiv.org/pdf/1909.08766"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.06700",
    "DOI": "arXiv:1909.06700v1",
    "Article_Title": "Loam_livox: A fast, robust, high-precision LiDAR odometry and mapping package for LiDARs of small FoV",
    "Article_Abstract": "LiDAR odometry and mapping (LOAM) has been playing an important role inautonomous vehicles, due to its ability to simultaneously localize the robot'spose and build high-precision, high-resolution maps of the surroundingenvironment. This enables autonomous navigation and safe path planning ofautonomous vehicles. In this paper, we present a robust, real-time LOAMalgorithm for LiDARs with small FoV and irregular samplings. By taking efforton both front-end and back-end, we address several fundamental challengesarising from such LiDARs, and achieve better performance in both precision andefficiency compared to existing baselines. To share our findings and to makecontributions to the community, we open source our codes on Github",
    "Article_Subject": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/09/15",
    "Article_PDF": "https://arxiv.org/pdf/1909.06700"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.05983",
    "DOI": "arXiv:1909.05983v1",
    "Article_Title": "Content-Aware Unsupervised Deep Homography Estimation",
    "Article_Abstract": "Robust homography estimation between two images is a fundamental task whichhas been widely applied to various vision applications. Traditional featurebased methods often detect image features and fit a homography according tomatched features with RANSAC outlier removal. However, the quality ofhomography heavily relies on the quality of image features, which are prone toerrors with respect to low light and low texture images. On the other hand,previous deep homography approaches either synthesize images for supervisedlearning or adopt aerial images for unsupervised learning, both ignoring theimportance of depth disparities in homography estimation. Moreover, they treatthe image content equally, including regions of dynamic objects and near-rangeforegrounds, which further decreases the quality of estimation. In this work,to overcome such problems, we propose an unsupervised deep homography methodwith a new architecture design. We learn a mask during the estimation to rejectoutlier regions. In addition, we calculate loss with respect to our learneddeep features instead of directly comparing the image contents as didpreviously. Moreover, a comprehensive dataset is presented, covering bothregular and challenging cases, such as poor textures and non-planarinterferences. The effectiveness of our method is validated through comparisonswith both feature-based and previous deep-based methods. Code will be soonavailable at Github.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/12",
    "Article_PDF": "https://arxiv.org/pdf/1909.05983"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.05090",
    "DOI": "arXiv:1909.05090v1",
    "Article_Title": "DNANet: De-Normalized Attention Based Multi-Resolution Network for Human Pose Estimation",
    "Article_Abstract": "Recently, multi-resolution networks (such as Hourglass, CPN, HRNet, etc.)have achieved significant performance on the task of human pose estimation bycombining features from various resolutions. In this paper, we propose a noveltype of attention module, namely De-Normalized Attention (DNA) to deal with thefeature attenuations of conventional attention modules. Our method extends theoriginal HRNet with spatial, channel-wise and resolution-wise DNAs, which aimsat evaluating the importance of features from different locations, channels andresolutions to enhance the network capability for feature representation. Wealso propose to add fine-to-coarse connections across high-to-low resolutionsin-side each layer of HRNet to increase the maximum depth of network topology.In addition, we propose to modify the keypoint regressor at the end of HRNetfor accurate keypoint heatmap prediction. The effectiveness of our proposednetwork is demonstrated on COCO keypoint detection dataset, achievingstate-of-the-art performance at 76.9 AP score on COCO val2017 dataset withoutusing extra keypoint training data. Our paper will be accompanied with publiclyavailable codes at GitHub.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/09/11",
    "Article_PDF": "https://arxiv.org/pdf/1909.05090"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.04556",
    "DOI": "arXiv:1909.04556v1",
    "Article_Title": "Human Languages in Source Code: Auto-Translation for Localized Instruction",
    "Article_Abstract": "Computer science education has promised open access around the world, butaccess is largely determined by what human language you speak. As youngerstudents learn computer science it is less appropriate to assume that theyshould learn English beforehand. To that end we present CodeInternational, thefirst tool to translate code between human languages. To develop a theory ofnon-English code, and inform our translation decisions, we conduct a study ofpublic code repositories on GitHub. The study is to the best of our knowledgethe first on human-language in code and covers 2.9 million Java repositories.To demonstrate CodeInternational's educational utility, we build an interactiveversion of the popular English-language Karel reader and translate it into 100spoken languages. Our translations have already been used in classrooms aroundthe world, and represent a first step in an important open CS-educationproblem.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/09/10",
    "Article_PDF": "https://arxiv.org/pdf/1909.04556"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.04301",
    "DOI": "arXiv:1909.04301v1",
    "Article_Title": "Frequency domain variant of Velvet noise and its application to acoustic measurements",
    "Article_Abstract": "We propose a new family of test signals for acoustic measurements such asimpulse response, nonlinearity, and the effects of background noise. Theproposed family complements difficulties in existing families, the Swept-Sine(SS), pseudo-random noise such as the maximum length sequence (MLS). Theproposed family uses the frequency domain variant of the Velvet noise (FVN) asits building block. An FVN is an impulse response of an all-pass filter andyields the unit impulse when convolved with the time-reversed version ofitself. In this respect, FVN is a member of the time-stretched pulse (TSP) inthe broadest sense. The high degree of freedom in designing an FVN opens a vastrange of applications in acoustic measurement. We introduce the followingapplications and their specific procedures, among other possibilities. They areas follows. a) Spectrum shaping adaptive to background noise. b) Simultaneousmeasurement of impulse responses of multiple acoustic paths. d) Simultaneousmeasurement of linear and nonlinear components of an acoustic path. e)Automatic procedure for time axis alignment of the source and the receiver whenthey are using independent clocks in acoustic impulse response measurement. Weimplemented a reference measurement tool equipped with all these procedures.The MATLAB source code and related materials are open-sourced and placed in aGitHub repository.",
    "Article_Subject": "Audio and Speech Processing (eess.AS); Sound (cs.SD); Signal Processing (eess.SP)",
    "Article_Date": "2019/09/10",
    "Article_PDF": "https://arxiv.org/pdf/1909.04301"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.03650",
    "DOI": "arXiv:1909.03650v1",
    "Article_Title": "Real-time and interactive tools for vocal training based on an analytic signal with a cosine series envelope",
    "Article_Abstract": "We introduce real-time and interactive tools for assisting vocal training. Inthis presentation, we demonstrate mainly a tool based on real-time visualizerof fundamental frequency candidates to provide information-rich feedback tolearners. The visualizer uses an efficient algorithm using analytic signals forderiving phase-based attributes. We start using these tools in vocal trainingfor assisting learners to acquire the awareness of appropriate vocalization.The first author made the MATLAB implementation of the tools open-source. Thecode and associated video materials are accessible in the first author's GitHubrepository.",
    "Article_Subject": "Sound (cs.SD); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)",
    "Article_Date": "2019/09/09",
    "Article_PDF": "https://arxiv.org/pdf/1909.03650"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.03181",
    "DOI": "arXiv:1909.03181v2",
    "Article_Title": "Receding Horizon Control for Drinking Water Networks: The Case for Geometric Programming",
    "Article_Abstract": "Optimal, network-driven control of Water Distribution Network (WDN) is verydifficult: valve and pump models form non-trivial, combinatorial logic,hydraulic models are nonconvex, water demand patterns are uncertain, and WDNsare naturally large-scale. Prior research on control of WDNs addressed majorresearch challenges, yet mostly adopted simplified hydraulic models, WDNtopologies, and rudimentary valve/pump modeling.  The objective of this paper is to develop tractable computational algorithmsto manage WDN operation, while considering arbitrary topology, flow direction,an abundance of valve types, control objectives, hydraulic models, andoperational constraints. Specifically, we propose new Geometric Programming(GP)-based Model Predictive Control (MPC) algorithms, designed to solve thewater flow equations and obtain WDN controls---pump/valve schedules alongsideheads and flows. The proposed approach amounts to solving a series of convexoptimization problems that graciously scale to large networks. Under demanduncertainty, the proposed approach is tested using a 126-node network with manyvalves and pumps. The developed GP-based MPC algorithms, as well as thenumerical test results are all included on Github.",
    "Article_Subject": "Systems and Control (eess.SY); Optimization and Control (math.OC)",
    "Article_Date": "2019/09/07",
    "Article_PDF": "https://arxiv.org/pdf/1909.03181"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.03147",
    "DOI": "arXiv:1909.03147v1",
    "Article_Title": "Self Learning from Large Scale Code Corpus to Infer Structure of Method Invocations",
    "Article_Abstract": "Automatically generating code from a textual description of method invocationconfronts challenges. There were two current research directions for thisproblem. One direction focuses on considering a textual description of methodinvocations as a separate Natural Language query and do not consider thesurrounding context of the code. Another direction takes advantage of apractical large scale code corpus for providing a Machine Translation model togenerate code. However, this direction got very low accuracy. In this work, wetried to improve these drawbacks by proposing MethodInfoToCode, an approachthat embeds context information and optimizes the ability of learning oforiginal Phrase-based Statistical Machine Translation (PBMT) in NLP to inferimplementation of method invocation given method name and other contextinformation. We conduct an expression prediction models learned from 2.86million method invocations from the practical data of high qualities corpus onGithub that used 6 popular libraries: JDK, Android, GWT, Joda-Time, Hibernate,and Xstream. By the evaluation, we show that if the developers only write themethod name of a method invocation in a body of a method, MethodInfoToCode canpredict the generated expression correctly at 73% in F1 score.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/09/06",
    "Article_PDF": "https://arxiv.org/pdf/1909.03147"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.02548",
    "DOI": "arXiv:1909.02548v1",
    "Article_Title": "Explanation based Handwriting Verification",
    "Article_Abstract": "Deep learning system have drawback that their output is not accompanied withex-planation. In a domain such as forensic handwriting verification it isessential to provideexplanation to jurors. The goal of handwriting verificationis to find a measure of confi-dence whether the given handwritten samples arewritten by the same or different writer.We propose a method to generateexplanations for the confidence provided by convolu-tional neural network (CNN)which maps the input image to 15 annotations (features)provided by experts. Oursystem comprises of: (1) Feature learning network (FLN),a differentiablesystem, (2) Inference module for providing explanations. Furthermore,inferencemodule provides two types of explanations: (a) Based on cosinesimilaritybetween categorical probabilities of each feature, (b) Based onLog-Likelihood Ratio(LLR) using directed probabilistic graphical model. Weperform experiments using acombination of feature learning network (FLN) andeach inference module. We evaluateour system using XAI-AND dataset, containing13700 handwritten samples and 15 cor-responding expert examined features foreach sample. The dataset is released for publicuse and the methods can beextended to provide explanations on other verification taskslike faceverification and bio-medical comparison. This dataset can serve as the basisand benchmark for future research in explanation based handwritingverification. The code is available on github.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
    "Article_Date": "2019/08/14",
    "Article_PDF": "https://arxiv.org/pdf/1909.02548"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.02218",
    "DOI": "arXiv:1909.02218v1",
    "Article_Title": "A Better Way to Attend: Attention with Trees for Video Question Answering",
    "Article_Abstract": "We propose a new attention model for video question answering. The main ideaof the attention models is to locate on the most informative parts of thevisual data. The attention mechanisms are quite popular these days. However,most existing visual attention mechanisms regard the question as a whole. Theyignore the word-level semantics where each word can have different attentionsand some words need no attention. Neither do they consider the semanticstructure of the sentences. Although the Extended Soft Attention (E-SA) modelfor video question answering leverages the word-level attention, it performspoorly on long question sentences. In this paper, we propose the heterogeneoustree-structured memory network (HTreeMN) for video question answering. Ourproposed approach is based upon the syntax parse trees of the questionsentences. The HTreeMN treats the words differently where the \\textit{visual}words are processed with an attention module and the \\textit{verbal} ones not.It also utilizes the semantic structure of the sentences by combining theneighbors based on the recursive structure of the parse trees. Theunderstandings of the words and the videos are propagated and merged fromleaves to the root. Furthermore, we build a hierarchical attention mechanism todistill the attended features. We evaluate our approach on two datasets. Theexperimental results show the superiority of our HTreeMN model over the otherattention models especially on complex questions. Our code is available ongithub.  Our code is available at https://github.com/ZJULearning/TreeAttention",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Machine Learning (cs.LG)",
    "Article_Date": "2019/09/05",
    "Article_PDF": "https://arxiv.org/pdf/1909.02218"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.02203",
    "DOI": "arXiv:1909.02203v2",
    "Article_Title": "Elastic_HH: Tailored Elastic for Finding Heavy Hitters",
    "Article_Abstract": "Finding heavy hitters has been of vital importance in network measurement.Among all the recent works in finding heavy hitters, the Elastic sketchachieves the highest accuracy and fastest speed. However, we find that there isstill room for improvement of the Elastic sketch in finding heavy hitters. Inthis paper, we propose a tailored Elastic to enhance the sketch only forfinding heavy hitters at the cost of losing the generality of Elastic. Totailor Elastic, we abandon the light part, and improve the eviction strategy.Our experimental results show that compared with the standard Elastic, ourtailored Elastic reduces the error rate to 5.7~8.1 times and increases thespeed to 2.5 times. All the related source codes and datasets are available atGithub.",
    "Article_Subject": "Networking and Internet Architecture (cs.NI)",
    "Article_Date": "2019/09/05",
    "Article_PDF": "https://arxiv.org/pdf/1909.02203"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.01441",
    "DOI": "arXiv:1909.01441v1",
    "Article_Title": "CrossWeigh: Training Named Entity Tagger from Imperfect Annotations",
    "Article_Abstract": "Everyone makes mistakes. So do human annotators when curating labels fornamed entity recognition (NER). Such label mistakes might hurt model trainingand interfere model comparison. In this study, we dive deep into one of thewidely-adopted NER benchmark datasets, CoNLL03 NER. We are able to identifylabel mistakes in about 5.38% test sentences, which is a significant ratioconsidering that the state-of-the-art test F1 score is already around 93%.Therefore, we manually correct these label mistakes and form a cleaner testset. Our re-evaluation of popular models on this corrected test set leads tomore accurate assessments, compared to those on the original test set. Moreimportantly, we propose a simple yet effective framework, CrossWeigh, to handlelabel mistakes during NER model training. Specifically, it partitions thetraining data into several folds and train independent NER models to identifypotential mistakes in each fold. Then it adjusts the weights of training dataaccordingly to train the final NER model. Extensive experiments demonstratesignificant improvements of plugging various NER models into our proposedframework on three datasets. All implementations and corrected test set areavailable at our Github repo: https://github.com/ZihanWangKi/CrossWeigh.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/09/03",
    "Article_PDF": "https://arxiv.org/pdf/1909.01441"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.01377",
    "DOI": "arXiv:1909.01377v1",
    "Article_Title": "Deep Equilibrium Models",
    "Article_Abstract": "We present a new approach to modeling sequential data: the deep equilibriummodel (DEQ). Motivated by an observation that the hidden layers of manyexisting deep sequence models converge towards some fixed point, we propose theDEQ approach that directly finds these equilibrium points via root-finding.Such a method is equivalent to running an infinite depth (weight-tied)feedforward network, but has the notable advantage that we can analyticallybackpropagate through the equilibrium point using implicit differentiation.Using this approach, training and prediction in these networks require onlyconstant memory, regardless of the effective \"depth\" of the network. Wedemonstrate how DEQs can be applied to two state-of-the-art deep sequencemodels: self-attention transformers and trellis networks. On large-scalelanguage modeling tasks, such as the WikiText-103 benchmark, we show that DEQs1) often improve performance over these state-of-the-art models (for similarparameter counts); 2) have similar computational requirements as existingmodels; and 3) vastly reduce memory consumption (often the bottleneck fortraining large sequence models), demonstrating an up-to 88% memory reduction inour experiments. The code is available at https://github. com/locuslab/deq .",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/09/03",
    "Article_PDF": "https://arxiv.org/pdf/1909.01377"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.11527",
    "DOI": "arXiv:1908.11527v2",
    "Article_Title": "Implicit Deep Latent Variable Models for Text Generation",
    "Article_Abstract": "Deep latent variable models (LVM) such as variational auto-encoder (VAE) haverecently played an important role in text generation. One key factor is theexploitation of smooth latent structures to guide the generation. However, therepresentation power of VAEs is limited due to two reasons: (1) the Gaussianassumption is often made on the variational posteriors; and meanwhile (2) anotorious \"posterior collapse\" issue occurs. In this paper, we advocatesample-based representations of variational distributions for natural language,leading to implicit latent features, which can provide flexible representationpower compared with Gaussian-based posteriors. We further develop an LVM todirectly match the aggregated posterior to the prior. It can be viewed as anatural extension of VAEs with a regularization of maximizing mutualinformation, mitigating the \"posterior collapse\" issue. We demonstrate theeffectiveness and versatility of our models in various text generationscenarios, including language modeling, unaligned style transfer, and dialogresponse generation. The source code to reproduce our experimental results isavailable on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/30",
    "Article_PDF": "https://arxiv.org/pdf/1908.11527"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.10267",
    "DOI": "arXiv:1908.10267v2",
    "Article_Title": "DRD-Net: Detail-recovery Image Deraining via Context Aggregation Networks",
    "Article_Abstract": "Image deraining is a fundamental, yet not well-solved problem in computervision and graphics. The traditional image deraining approaches commonly behaveineffectively in medium and heavy rain removal, while the learning-based oneslead to image degradations such as the loss of image details, halo artifactsand/or color distortion. Unlike existing image deraining approaches that lackthe detail-recovery mechanism, we propose an end-to-end detail-recovery imagederaining network (termed a DRD-Net) for single images. We for the first timeintroduce two sub-networks with a comprehensive loss function which synergizeto derain and recover the lost details caused by deraining. We have three keycontributions. First, we present a rain residual network to remove rain streaksfrom the rainy images, which combines the squeeze-and-excitation (SE) operationwith residual blocks to make full advantage of spatial contextual information.Second, we design a new connection style block, named structure detail contextaggregation block (SDCAB), which aggregates context feature information and hasa large reception field. Third, benefiting from the SDCAB, we construct adetail repair network to encourage the lost details to return for eliminatingimage degradations. We have validated our approach on four recognized datasets(three synthetic and one real-world). Both quantitative and qualitativecomparisons show that our approach outperforms the state-of-the-art derainingmethods in terms of the deraining robustness and detail accuracy. The sourcecode has been available for public evaluation and use on GitHub.",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/27",
    "Article_PDF": "https://arxiv.org/pdf/1908.10267"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.09195",
    "DOI": "arXiv:1908.09195v1",
    "Article_Title": "Scalable Modeling of Spatiotemporal Data using the Variational Autoencoder: an Application in Glaucoma",
    "Article_Abstract": "As big spatial data becomes increasingly prevalent, classical spatiotemporal(ST) methods often do not scale well. While methods have been developed toaccount for high-dimensional spatial objects, the setting where there areexceedingly large samples of spatial observations has had less attention. Thevariational autoencoder (VAE), an unsupervised generative model based on deeplearning and approximate Bayesian inference, fills this void using a latentvariable specification that is inferred jointly across the large number ofsamples. In this manuscript, we compare the performance of the VAE with a moreclassical ST method when analyzing longitudinal visual fields from a largecohort of patients in a prospective glaucoma study. Through simulation and acase study, we demonstrate that the VAE is a scalable method for analyzing STdata, when the goal is to obtain accurate predictions. R code to implement theVAE can be found on GitHub: https://github.com/berchuck/vaeST.",
    "Article_Subject": "Applications (stat.AP); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/24",
    "Article_PDF": "https://arxiv.org/pdf/1908.09195"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08856",
    "DOI": "arXiv:1908.08856v1",
    "Article_Title": "Assessing Knee OA Severity with CNN attention-based end-to-end architectures",
    "Article_Abstract": "This work proposes a novel end-to-end convolutional neural network (CNN)architecture to automatically quantify the severity of knee osteoarthritis (OA)using X-Ray images, which incorporates trainable attention modules acting asunsupervised fine-grained detectors of the region of interest (ROI). Theproposed attention modules can be applied at different levels and scales acrossany CNN pipeline helping the network to learn relevant attention patterns overthe most informative parts of the image at different resolutions. We test theproposed attention mechanism on existing state-of-the-art CNN architectures asour base models, achieving promising results on the benchmark knee OA datasetsfrom the osteoarthritis initiative (OAI) and multicenter osteoarthritis study(MOST). All code from our experiments will be publicly available on the githubrepository: https://github.com/marc-gorriz/KneeOA-CNNAttention",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
    "Article_Date": "2019/08/23",
    "Article_PDF": "https://arxiv.org/pdf/1908.08856"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08584",
    "DOI": "arXiv:1908.08584v1",
    "Article_Title": "Feedbackward Decoding for Semantic Segmentation",
    "Article_Abstract": "We propose a novel approach for semantic segmentation that uses an encoder inthe reverse direction to decode. Many semantic segmentation networks adopt afeedforward encoder-decoder architecture. Typically, an input is firstdownsampled by the encoder to extract high-level semantic features andcontinues to be fed forward through the decoder module to recover low-levelspatial clues. Our method works in an alternative direction that letsinformation flow backward from the last layer of the encoder towards the first.The encoder performs encoding in the forward pass and the same network performsdecoding in the backward pass. Therefore, the encoder itself is also thedecoder. Compared to conventional encoder-decoder architectures, ours doesn'trequire additional layers for decoding and further reuses the encoder weightsthereby reducing the total number of parameters required for processing. Weshow by using only the 13 convolutional layers from VGG-16 plus one tinyclassification layer, our model significantly outperforms other frequentlycited models that are also adapted from VGG-16. On the Cityscapes semanticsegmentation benchmark, our model uses 50.0% less parameters than SegNet andachieves an 18.1% higher \"IoU class\" score; it uses 28.3% less parameters thanDeepLab LargeFOV and the achieved \"IoU class\" score is 3.9% higher; it uses89.1% fewer parameters than FCN-8s and the achieved \"IoU class\" score is 3.1%higher. Our code will be publicly available on Github later.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Image and Video Processing (eess.IV); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/22",
    "Article_PDF": "https://arxiv.org/pdf/1908.08584"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08196",
    "DOI": "arXiv:1908.08196v1",
    "Article_Title": "Unveiling Elite Developers' Activities in Open Source Projects",
    "Article_Abstract": "Open-source developers, particularly the elite developers, maintain a diverseportfolio of contributing activities. They do not only commit source code butalso spend a significant amount of effort on other communicative,organizational, and supportive activities. However, almost all prior researchfocuses on a limited number of specific activities and fails to analyze elitedevelopers' activities in a comprehensive way. To bridge this gap, we conductan empirical study with fine-grained event data from 20 large open-sourceprojects hosted on GitHub. Thus, we investigate elite developers' contributingactivities and their impacts on project outcomes. Our analyses reveal three keyfindings: (1) they participate in a variety of activities while technicalcontributions (e.g., coding) accounting for a small proportion only; (2) theytend to put more effort into supportive and communicative activities and lesseffort into coding as the project grows; (3) their participation innon-technical activities is negatively associated with the project's outcomesin term of productivity and software quality. These results provide a panoramicview of elite developers' activities and can inform an individual's decisionmaking about effort allocation, thus leading to finer project outcomes. Theresults also provide implications for supporting these elite developers.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/22",
    "Article_PDF": "https://arxiv.org/pdf/1908.08196"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08123",
    "DOI": "arXiv:1908.08123v3",
    "Article_Title": "Computing System Congestion Management Using Exponential Smoothing Forecasting",
    "Article_Abstract": "An overloaded computer must finish what it starts and not start what willfail or hang. A congestion management algorithm the author developed, andSiemens Corporation patented for telecom products, effectively manages trafficoverload with its unique formulation of Exponential Smoothing forecasting.Siemens filed for exclusive rights to this technique in 2003 and obtained USpatent US7301903B2 in 2007 with this author, an employee at the time of thefiling, the sole inventor. A computer program, written in C language, whichexercises the methodology is listed at the end of this document and availableon GitHub.",
    "Article_Subject": "Performance (cs.PF)",
    "Article_Date": "2019/08/21",
    "Article_PDF": "https://arxiv.org/pdf/1908.08123"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.07984",
    "DOI": "arXiv:1908.07984v1",
    "Article_Title": "Minimal residual multistep methods for large stiff non-autonomous linear problems",
    "Article_Abstract": "The purpose of this work is to introduce a new idea of how to avoid thefactorization of large matrices during the solution of stiff systems of ODEs.Starting from the general form of an explicit linear multistep method wesuggest to adaptively choose its coefficients on each integration step in orderto minimize the norm of the residual of an implicit BDF formula. Thereby wereduce the number of unknowns on each step from $n$ to $O(1)$, where $n$ is thedimension of the ODE system. We call this type of methods Minimal ResidualMultistep (MRMS) methods. In the case of linear non-autonomous problem, besidesthe evaluations of the right-hand side of ODE, the resulting numerical schemeadditionally requires one solution of a linear least-squares problem with athin matrix per step. We show that the order of the method and itszero-stability properties coincide with those of the used underlying BDFformula. For the simplest analog of the implicit Euler method the properties oflinear stability are investigated. Though the classical absolute stabilityanalysis is not fully relevant to the MRMS methods, it is shown that thisone-step method is applicable in stiff case. In the numerical experimentsection we consider the fixed-step integration of a two-dimensionalnon-autonomous heat equation using the MRMS methods and their classical BDFcounterparts. The starting values are taken from a preset slowly-varying exactsolution. The comparison showed that both methods give similar numericalsolutions, but in the case of large systems the MRMS methods are faster, andtheir advantage considerably increases with the growth of dimension. Pythoncode with the experimantal code can be downloaded from the GitHub repositoryhttps://github.com/bfaleichik/mrms.",
    "Article_Subject": "Numerical Analysis (math.NA)",
    "Article_Date": "2019/08/21",
    "Article_PDF": "https://arxiv.org/pdf/1908.07984"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.07883",
    "DOI": "arXiv:1908.07883v3",
    "Article_Title": "Scala Implicits are Everywhere: A large-scale study of the use of Implicits in the wild",
    "Article_Abstract": "The Scala programming language offers two distinctive language featuresimplicit parameters and implicit conversions, often referred together asimplicits. Announced without fanfare in 2004, implicits have quickly grown tobecome a widely and pervasively used feature of the language. They provide away to reduce the boilerplate code in Scala programs. They are also used toimplement certain language features without having to modify the compiler. Wereport on a large-scale study of the use of implicits in the wild. For this, weanalyzed 7,280 Scala projects hosted on GitHub, spanning over 8.1M call sitesinvolving implicits and 370.7K implicit declarations across 18.7M lines ofScala code.",
    "Article_Subject": "Programming Languages (cs.PL); Software Engineering (cs.SE)",
    "Article_Date": "2019/08/21",
    "Article_PDF": "https://arxiv.org/pdf/1908.07883"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.06473",
    "DOI": "arXiv:1908.06473v1",
    "Article_Title": "From Open Set to Closed Set: Counting Objects by Spatial Divide-and-Conquer",
    "Article_Abstract": "Visual counting, a task that predicts the number of objects from animage/video, is an open-set problem by nature, i.e., the number of populationcan vary in $[0,+\\infty)$ in theory. However, the collected images and labeledcount values are limited in reality, which means only a small closed set isobserved. Existing methods typically model this task in a regression manner,while they are likely to suffer from an unseen scene with counts out of thescope of the closed set. In fact, counting is decomposable. A dense region canalways be divided until sub-region counts are within the previously observedclosed set. Inspired by this idea, we propose a simple but effective approach,Spatial Divide-and- Conquer Network (S-DCNet). S-DCNet only learns from aclosed set but can generalize well to open-set scenarios via S-DC. S-DCNet isalso efficient. To avoid repeatedly computing sub-region convolutionalfeatures, S-DC is executed on the feature map instead of on the input image.S-DCNet achieves the state-of-the-art performance on three crowd countingdatasets (ShanghaiTech, UCF_CC_50 and UCF-QNRF), a vehicle counting dataset(TRANCOS) and a plant counting dataset (MTC). Compared to the previous bestmethods, S-DCNet brings a 20.2% relative improvement on the ShanghaiTech PartB, 20.9% on the UCF-QNRF, 22.5% on the TRANCOS and 15.1% on the MTC. Code hasbeen made available at: https://github. com/xhp-hust-2018-2011/S-DCNet.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/15",
    "Article_PDF": "https://arxiv.org/pdf/1908.06473"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.06412",
    "DOI": "arXiv:1908.06412v1",
    "Article_Title": "Characterizing the transition to Kotlin of Android apps: a study on F-Droid, Play Store and GitHub",
    "Article_Abstract": "Kotlin is a novel language that represents an alternative to Java, and hasbeen recently adopted as a first-class programming language for Androidapplications. Kotlin is achieving a significant diffusion among developers, andseveral studies have highlighted various advantages of the language whencompared to Java.  The objective of this paper is to analyze a set of open-source Android apps,to evaluate their transition to the Kotlin programming language throughouttheir lifespan and understand whether the adoption of Kotlin has impacts on thesuccess of Android apps.  We mined all the projects from the F-Droid repository of Android open-sourceapplications, and we found the corresponding projects on the official GooglePlay Store and on the GitHub platform. We defined a set of eight metrics toquantify the relevance of Kotlin code in the latest update and through allreleases of an application. Then, we statistically analyzed the correlationbetween the presence of Kotlin code in a project and popularity metrics minedfrom the platforms where the apps were released.  Of a set of 1232 projects that were updated after October 2017, near 20%adopted Kotlin and about 12% had more Kotlin code than Java; most of theprojects that adopted Kotlin quickly transitioned from Java to the newlanguage. The projects featuring Kotlin had on average higher popularitymetrics; a statistically significant correlation has been found between thepresence of Kotlin and the number of stars on the GitHub repository.  The Kotlin language seems able to guarantee a seamless migration from Javafor Android developers. With an inspection on a large set of open-sourceAndroid apps, we observed that the adoption of the Kotlin language is rapid(when compared to the average lifespan of an Android project) and seems to comeat no cost in terms of popularity among the users and other developers.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/18",
    "Article_PDF": "https://arxiv.org/pdf/1908.06412"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.06309",
    "DOI": "arXiv:1908.06309v1",
    "Article_Title": "ED2: Two-stage Active Learning for Error Detection -- Technical Report",
    "Article_Abstract": "Traditional error detection approaches require user-defined parameters andrules. Thus, the user has to know both the error detection system and the data.However, we can also formulate error detection as a semi-supervisedclassification problem that only requires domain expertise. The challenges forsuch an approach are twofold: (1) to represent the data in a way that enables aclassification model to identify various kinds of data errors, and (2) to pickthe most promising data values for learning. In this paper, we address thesechallenges with ED2, our new example-driven error detection method. First, wepresent a new two-dimensional multi-classifier sampling strategy for activelearning. Second, we propose novel multi-column features. The combinedapplication of these techniques provides fast convergence of the classificationtask with high detection accuracy. On several real-world datasets, ED2requires, on average, less than 1% labels to outperform existing errordetection approaches. This report extends the peer-reviewed paper \"ED2: A Casefor Active Learning in Error Detection\". All source code related to thisproject is available on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Databases (cs.DB); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/17",
    "Article_PDF": "https://arxiv.org/pdf/1908.06309"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05541",
    "DOI": "arXiv:1908.05541v1",
    "Article_Title": "Hamming Sentence Embeddings for Information Retrieval",
    "Article_Abstract": "In retrieval applications, binary hashes are known to offer significantimprovements in terms of both memory and speed. We investigate the compressionof sentence embeddings using a neural encoder-decoder architecture, which istrained by minimizing reconstruction error. Instead of employing the originalreal-valued embeddings, we use latent representations in Hamming space producedby the encoder for similarity calculations.  In quantitative experiments on several benchmarks for semantic similaritytasks, we show that our compressed hamming embeddings yield a comparableperformance to uncompressed embeddings (Sent2Vec, InferSent, Glove-BoW), atcompression ratios of up to 256:1. We further demonstrate that our modelstrongly decorrelates input features, and that the compressor generalizes wellwhen pre-trained on Wikipedia sentences. We publish the source code on Githuband all experimental results.",
    "Article_Subject": "Information Retrieval (cs.IR); Computation and Language (cs.CL); Machine Learning (cs.LG)",
    "Article_Date": "2019/08/15",
    "Article_PDF": "https://arxiv.org/pdf/1908.05541"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05437",
    "DOI": "arXiv:1908.05437v1",
    "Article_Title": "Massive Multi-Agent Data-Driven Simulations of the GitHub Ecosystem",
    "Article_Abstract": "Simulating and predicting planetary-scale techno-social systems poses heavycomputational and modeling challenges. The DARPA SocialSim program set thechallenge to model the evolution of GitHub, a large collaborativesoftware-development ecosystem, using massive multi-agent simulations. Wedescribe our best performing models and our agent-based simulation framework,which we are currently extending to allow simulating other planetary-scaletechno-social systems. The challenge problem measured participant's ability,given 30 months of meta-data on user activity on GitHub, to predict the nextmonths' activity as measured by a broad range of metrics applied to groundtruth, using agent-based simulation. The challenge required scaling to asimulation of roughly 3 million agents producing a combined 30 million actions,acting on 6 million repositories with commodity hardware. It was also importantto use the data optimally to predict the agent's next moves. We describe theagent framework and the data analysis employed by one of the winning teams inthe challenge. Six different agent models were tested based on a variety ofmachine learning and statistical methods. While no single method proved themost accurate on every metric, the broadly most successful sampled from astationary probability distribution of actions and repositories for each agent.Two reasons for the success of these agents were their use of a distinctcharacterization of each agent, and that GitHub users change their behaviorrelatively slowly.",
    "Article_Subject": "Multiagent Systems (cs.MA); Social and Information Networks (cs.SI)",
    "Article_Date": "2019/08/15",
    "Article_PDF": "https://arxiv.org/pdf/1908.05437"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05354",
    "DOI": "arXiv:1908.05354v2",
    "Article_Title": "Large-Scale-Exploit of GitHub Repository Metadata and Preventive Measures",
    "Article_Abstract": "When working with Git, a popular version-control system, email addresses arepart of the metadata for each individual commit. When those commits are pushedto remote hosting services like GitHub, those email addresses become visiblenot only to fellow developers, but also to malicious actors aiming to exploitthem.  As a part of our research we created a tool that leverages the publiclyavailable GitHub API to collect user data. Analysis of this data not only givesaccess to millions of email addresses in very little time, but is also powerfuland dense enough to create targeted phishing attacks posing a great threat toall GitHub users and their private, potentially sensitive data. Even worse,existing countermeasures fail to effectively protect against such exploits.  As a consequence and main conclusion of this paper, we suggest multiplepreventive measures that should be implemented as soon as possible. We alsoconsider it the duty of both companies like GitHub and well informed softwareengineers to inform fellow developers about the risk of exposing private emailaddresses in Git commits published publicly.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/08/14",
    "Article_PDF": "https://arxiv.org/pdf/1908.05354"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05097",
    "DOI": "arXiv:1908.05097v1",
    "Article_Title": "Causal discovery in heavy-tailed models",
    "Article_Abstract": "Causal questions are omnipresent in many scientific problems. While muchprogress has been made in the analysis of causal relationships between randomvariables, these methods are not well suited if the causal mechanisms manifestthemselves only in extremes. This work aims to connect the two fields of causalinference and extreme value theory. We define the causal tail coefficient thatcaptures asymmetries in the extremal dependence of two random variables. In thepopulation case, the causal tail coefficient is shown to reveal the causalstructure if the distribution follows a linear structural causal model. Thisholds even in the presence of latent common causes that have the same tailindex as the observed variables. Based on a consistent estimator of the causaltail coefficient, we propose a computationally highly efficient algorithm thatinfers causal structure from finitely many data. We prove that our methodconsistently estimates the causal order and compare it to otherwell-established and non-extremal approaches in causal discovery on syntheticdata. The code is available as an open-access R package on Github.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/08/14",
    "Article_PDF": "https://arxiv.org/pdf/1908.05097"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.04710",
    "DOI": "arXiv:1908.04710v1",
    "Article_Title": "metric-learn: Metric Learning Algorithms in Python",
    "Article_Abstract": "metric-learn is an open source Python package implementing supervised andweakly-supervised distance metric learning algorithms. As part ofscikit-learn-contrib, it provides a unified interface compatible withscikit-learn which allows to easily perform cross-validation, model selection,and pipelining with other machine learning estimators. metric-learn isthoroughly tested and available on PyPi under the MIT licence.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/13",
    "Article_PDF": "https://arxiv.org/pdf/1908.04710"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.04219",
    "DOI": "arXiv:1908.04219v1",
    "Article_Title": "How do Developers Promote Open Source Projects?",
    "Article_Abstract": "Open source projects have an increasing importance on modern softwaredevelopment. For this reason, these projects, as usual with commercial softwareprojects, should make use of promotion channels to communicate and establishcontact with users and contributors. In this article, we study the channelsused to promote a set of 100 popular GitHub projects. First, we reveal thatTwitter, user meetings, and blogs are the most common promotion channels usedby the studied projects. Second, we report a major difference between thestudied projects and a random sample of projects, regarding the use of theinvestigated promotion channels. Third, we show the importance of a popularnews aggregation site (Hacker News) on the promotion of open source. Weconclude by presenting a set of practical recommendation to open source projectmanagers and leaders, regarding the promotion of their projects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/12",
    "Article_PDF": "https://arxiv.org/pdf/1908.04219"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.03952",
    "DOI": "arXiv:1908.03952v2",
    "Article_Title": "Constraining new physics from Higgs measurements with Lilith: update to LHC Run 2 results",
    "Article_Abstract": "Lilith is a public Python library for constraining new physics from Higgssignal strength measurements. We here present version 2.0 of Lilith togetherwith an updated XML database which includes the current ATLAS and CMS Run 2Higgs results for 36/fb. Both the code and the database were extended from theordinary Gaussian approximation employed in Lilith-1.1 to using variableGaussian and Poisson likelihoods. Moreover, Lilith can now make use ofcorrelation matrices of arbitrary dimension. We provide detailed validations ofthe implemented experimental results as well as a status of global fits forreduced Higgs couplings, Two-Higgs-doublet models of Type I and Type II, andinvisible Higgs decays. Lilith-2.0 is available on GitHub and ready to be usedto constrain a wide class of new physics scenarios.",
    "Article_Subject": "High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Experiment (hep-ex)",
    "Article_Date": "2019/08/11",
    "Article_PDF": "https://arxiv.org/pdf/1908.03952"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.02320",
    "DOI": "arXiv:1908.02320v1",
    "Article_Title": "Do as I Do, Not as I Say: Do Contribution Guidelines Match the GitHub Contribution Process?",
    "Article_Abstract": "Developer contribution guidelines are used in social coding sites like GitHubto explain and shape the process a project expects contributors to follow. Theyset standards for all participants and \"save time and hassle caused byimproperly created pull requests or issues that have to be rejected andresubmitted\" (GitHub). Yet, we lack a systematic understanding of the contentof a typical contribution guideline, as well as the extent to which theseguidelines are followed in practice. Additionally, understanding how guidelinesmay impact projects that use Continuous Integration as part of the contributionprocess is of particular interest. To address this knowledge gap, we conducteda mixed-methods study of 53 GitHub projects with explicit contributionguidelines and coded the guidelines to extract key themes. We then created aprocess model using GitHub activity data (e.g., commit, new issue, new pullrequest) to compare the actual activity with the prescribed contributionguidelines. We show that approximately 68% of these projects divergesignificantly from the expected process.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/06",
    "Article_PDF": "https://arxiv.org/pdf/1908.02320"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.02116",
    "DOI": "arXiv:1908.02116v3",
    "Article_Title": "Teacher Supervises Students How to Learn From Partially Labeled Images for Facial Landmark Detection",
    "Article_Abstract": "Facial landmark detection aims to localize the anatomically defined points ofhuman faces. In this paper, we study facial landmark detection from partiallylabeled facial images. A typical approach is to (1) train a detector on thelabeled images; (2) generate new training samples using this detector'sprediction as pseudo labels of unlabeled images; (3) retrain the detector onthe labeled samples and partial pseudo labeled samples. In this way, thedetector can learn from both labeled and unlabeled data to become robust. Inthis paper, we propose an interaction mechanism between a teacher and twostudents to generate more reliable pseudo labels for unlabeled data, which arebeneficial to semi-supervised facial landmark detection. Specifically, the twostudents are instantiated as dual detectors. The teacher learns to judge thequality of the pseudo labels generated by the students and filter outunqualified samples before the retraining stage. In this way, the studentdetectors get feedback from their teacher and are retrained by premium datagenerated by itself. Since the two students are trained by different samples, acombination of their predictions will be more robust as the final predictioncompared to either prediction. Extensive experiments on 300-W and AFLWbenchmarks show that the interactions between teacher and students contributeto better utilization of the unlabeled data and achieves state-of-the-artperformance.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/06",
    "Article_PDF": "https://arxiv.org/pdf/1908.02116"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01711",
    "DOI": "arXiv:1908.01711v1",
    "Article_Title": "fgivenx: A Python package for functional posterior plotting",
    "Article_Abstract": "fgivenx is a Python package for functional posterior plotting, currently usedin astronomy, but will be of use to scientists performing any Bayesian analysiswhich has predictive posteriors that are functions. The source code for fgivenxis available on GitHub at https://github.com/williamjameshandley/fgivenx",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.01711"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01373",
    "DOI": "arXiv:1908.01373v2",
    "Article_Title": "Unsupervised Microvascular Image Segmentation Using an Active Contours Mimicking Neural Network",
    "Article_Abstract": "The task of blood vessel segmentation in microscopy images is crucial formany diagnostic and research applications. However, vessels can look vastlydifferent, depending on the transient imaging conditions, and collecting datafor supervised training is laborious. We present a novel deep learning methodfor unsupervised segmentation of blood vessels. The method is inspired by thefield of active contours and we introduce a new loss term, which is based onthe morphological Active Contours Without Edges (ACWE) optimization method. Therole of the morphological operators is played by novel pooling layers that areincorporated to the network's architecture. We demonstrate the challenges thatare faced by previous supervised learning solutions, when the imagingconditions shift. Our unsupervised method is able to outperform such previousmethods in both the labeled dataset, and when applied to similar but differentdatasets. Our code, as well as efficient PyTorch reimplementations of thebaseline methods VesselNN and DeepVess is available on GitHub -https://github.com/shirgur/UMIS.",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/04",
    "Article_PDF": "https://arxiv.org/pdf/1908.01373"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01242",
    "DOI": "arXiv:1908.01242v1",
    "Article_Title": "Kannada-MNIST: A new handwritten digits dataset for the Kannada language",
    "Article_Abstract": "In this paper, we disseminate a new handwritten digits-dataset, termedKannada-MNIST, for the Kannada script, that can potentially serve as a directdrop-in replacement for the original MNIST dataset. In addition to thisdataset, we disseminate an additional real world handwritten dataset (with$10k$ images), which we term as the Dig-MNIST dataset that can serve as anout-of-domain test dataset. We also duly open source all the code as well asthe raw scanned images along with the scanner settings so that researchers whowant to try out different signal processing pipelines can perform end-to-endcomparisons. We provide high level morphological comparisons with the MNISTdataset and provide baselines accuracies for the dataset disseminated. Theinitial baselines obtained using an oft-used CNN architecture ($96.8\\%$ for themain test-set and $76.1\\%$ for the Dig-MNIST test-set) indicate that thesedatasets do provide a sterner challenge with regards to generalizability thanMNIST or the KMNIST datasets. We also hope this dissemination will spur thecreation of similar datasets for all the languages that use different symbolsfor the numeral digits.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/03",
    "Article_PDF": "https://arxiv.org/pdf/1908.01242"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01031",
    "DOI": "arXiv:1908.01031v1",
    "Article_Title": "RuleKit: A Comprehensive Suite for Rule-Based Learning",
    "Article_Abstract": "Rule-based models are often used for data analysis as they combineinterpretability with predictive power. We present RuleKit, a versatile toolfor rule learning. Based on a sequential covering induction algorithm, it issuitable for classification, regression, and survival problems. The presence ofa user-guided induction facilitates verifying hypotheses concerning datadependencies which are expected or of interest. The powerful and flexibleexperimental environment allows straightforward investigation of differentinduction schemes. The analysis can be performed in batch mode, throughRapidMiner plug-in, or R package. A documented Java API is also provided forconvenience. The software is publicly available at GitHub under GNU AGPL-3.0license.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.01031"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.00867",
    "DOI": "arXiv:1908.00867v1",
    "Article_Title": "An Evaluation of Action Recognition Models on EPIC-Kitchens",
    "Article_Abstract": "We benchmark contemporary action recognition models (TSN, TRN, and TSM) onthe recently introduced EPIC-Kitchens dataset and release pretrained models onGitHub (https://github.com/epic-kitchens/action-models) for others to buildupon. In contrast to popular action recognition datasets like Kinetics,Something-Something, UCF101, and HMDB51, EPIC-Kitchens is shot from anegocentric perspective and captures daily actions in-situ. In this report, weaim to understand how well these models can tackle the challenges present inthis dataset, such as its long tail class distribution, unseen environment testset, and multiple tasks (verb, noun and, action classification). We discuss themodels' shortcomings and avenues for future research.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.00867"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.00717",
    "DOI": "arXiv:1908.00717v1",
    "Article_Title": "Lagrange2D: A Mathematica package for Lagrangian analysis of two-dimensional fluid flows",
    "Article_Abstract": "We introduce Lagrange2D, a Mathematica package for analysis andcharacterization of complex fluid flows using Lagrangian transport metrics.Lagrange2D includes built-in functions for integrating ensembles oftrajectories subject to time-varying two-dimensional flows, as well asutilities for calculating various quantities of interest, such as finite-timeLyapunov exponents, stretching vector fields, the fractal dimension, andflushing times. The package also includes tools for visualizing transport andpathlines, as well as for generating videos. This package aims to ease rapidcharacterization of arbitrary flows, by allowing identification of Lagrangiancoherent structures and other quantities of interest. The open-source code forthe package is available on GitHub at:\\url{https://github.com/williamgilpin/lagrange2d}",
    "Article_Subject": "Fluid Dynamics (physics.flu-dyn); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.00717"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.00614",
    "DOI": "arXiv:1908.00614v2",
    "Article_Title": "Learning to Identify Security-Related Issues Using Convolutional Neural Networks",
    "Article_Abstract": "Software security is becoming a high priority for both large companies andstart-ups alike due to the increasing potential for harm that vulnerabilitiesand breaches carry with them. However, attaining robust security assurancewhile delivering features requires a precarious balancing act in the context ofagile development practices. One path forward to help aid development teams insecuring their software products is through the design and development ofsecurity-focused automation. Ergo, we present a novel approach, calledSecureReqNet, for automatically identifying whether issues in software issuetracking systems describe security-related content. Our approach consists of atwo-phase neural net architecture that operates purely on the natural languagedescriptions of issues. The first phase of our approach learns high dimensionalword embeddings from hundreds of thousands of vulnerability descriptions listedin the CVE database and issue descriptions extracted from open source projects.The second phase then utilizes the semantic ontology represented by theseembeddings to train a convolutional neural network capable of predictingwhether a given issue is security-related. We evaluated SecureReqNet byapplying it to identify security-related issues from a dataset of thousands ofissues mined from popular projects on GitLab and GitHub. In addition, we alsoapplied our approach to identify security-related requirements from acommercial software project developed by a major telecommunication company. Ourpreliminary results are encouraging, with SecureReqNet achieving an accuracy of96% on open source issues and 71.6% on industrial requirements.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/01",
    "Article_PDF": "https://arxiv.org/pdf/1908.00614"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.13012",
    "DOI": "arXiv:1907.13012v1",
    "Article_Title": "An Empirical Study of GraphQL Schemas",
    "Article_Abstract": "GraphQL is a query language for APIs and a runtime to execute queries. UsingGraphQL queries, clients define precisely what data they wish to retrieve ormutate on a server, leading to fewer round trips and reduced response sizes.Although interest in GraphQL is on the rise, with increasing adoption at majororganizations, little is known about what GraphQL interfaces look like inpractice. This lack of knowledge makes it hard for providers to understand whatpractices promote idiomatic, easy-to-use APIs, and what pitfalls to avoid. Toaddress this gap, we study the design of GraphQL interfaces in practice byanalyzing their schemas - the descriptions of their exposed data types and thepossible operations on the underlying data. We base our study on two novelcorpuses of GraphQL schemas, one of 16 commercial GraphQL schemas and the otherof 8,399 GraphQL schemas mined from GitHub projects. We make both corpusesavailable to other researchers. Using these corpuses, we characterize the sizeof schemas and their use of GraphQL features and assess the use of bothprescribed and organic naming conventions. We also report that a majority ofAPIs are susceptible to denial of service through complex queries, posing realsecurity risks previously discussed only in theory. We also assess ways inwhich GraphQL APIs attempt to address these concerns.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/07/30",
    "Article_PDF": "https://arxiv.org/pdf/1907.13012"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.11017",
    "DOI": "arXiv:1907.11017v2",
    "Article_Title": "Particle Methods for Stochastic Differential Equation Mixed Effects Models",
    "Article_Abstract": "Parameter inference for stochastic differential equation mixed effects models(SDEMEMs) is a challenging problem. Analytical solutions for these models arerarely available, which means that the likelihood is also intractable. In thiscase, exact inference is possible using the pseudo-marginal method, where theintractable likelihood is replaced by its nonnegative unbiased estimate. Auseful application of this idea is particle MCMC, which uses a particle filterestimate of the likelihood. While the exact posterior is targeted by thesemethods, a naive implementation for SDEMEMs can be highly inefficient. Wedevelop three extensions to the naive approach which exploits specific aspectsof SDEMEMs and other advances such as correlated pseudo-marginal methods. Wecompare these methods on real and simulated data from a tumour xenography studyon mice.",
    "Article_Subject": "Computation (stat.CO); Methodology (stat.ME)",
    "Article_Date": "2019/07/25",
    "Article_PDF": "https://arxiv.org/pdf/1907.11017"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.10121",
    "DOI": "arXiv:1907.10121v1",
    "Article_Title": "SciPy 1.0--Fundamental Algorithms for Scientific Computing in Python",
    "Article_Abstract": "SciPy is an open source scientific computing library for the Pythonprogramming language. SciPy 1.0 was released in late 2017, about 16 years afterthe original version 0.1 release. SciPy has become a de facto standard forleveraging scientific algorithms in the Python programming language, with morethan 600 unique code contributors, thousands of dependent packages, over100,000 dependent repositories, and millions of downloads per year. Thisincludes usage of SciPy in almost half of all machine learning projects onGitHub, and usage by high profile projects including LIGO gravitational waveanalysis and creation of the first-ever image of a black hole (M87). Thelibrary includes functionality spanning clustering, Fourier transforms,integration, interpolation, file I/O, linear algebra, image processing,orthogonal distance regression, minimization algorithms, signal processing,sparse matrix handling, computational geometry, and statistics. In this work,we provide an overview of the capabilities and development practices of theSciPy library and highlight some recent technical developments.",
    "Article_Subject": "Mathematical Software (cs.MS); Data Structures and Algorithms (cs.DS); Software Engineering (cs.SE); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/07/23",
    "Article_PDF": "https://arxiv.org/pdf/1907.10121"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.09600",
    "DOI": "arXiv:1907.09600v2",
    "Article_Title": "Evaluation of Embeddings of Laboratory Test Codes for Patients at a Cancer Center",
    "Article_Abstract": "Laboratory test results are an important and generally high dimensionalcomponent of a patient's Electronic Health Record (EHR). We train embeddingrepresentations (via Word2Vec and GloVe) for LOINC codes of laboratory testsfrom the EHRs of about 80,000 patients at a cancer center. To includeinformation about lab test outcomes, we also train embeddings on theconcatenation of a LOINC code with a symbol indicating normality or abnormalityof the result. We observe several clinically meaningful similarities amongLOINC embeddings trained over our data. For the embeddings of the concatenationof LOINCs with abnormality codes, we evaluate the performance for mortalityprediction tasks and the ability to preserve ordinality properties: i.e. a labtest with normal outcome should be more similar to an abnormal one than to thea very abnormal one.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/22",
    "Article_PDF": "https://arxiv.org/pdf/1907.09600"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.08395",
    "DOI": "arXiv:1907.08395v2",
    "Article_Title": "Refractive Interstellar Scintillation of Extra-galactic Radio Sources I: Expectations",
    "Article_Abstract": "Surveys for transient and variable phenomena can be confounded by thepresence of extrinsic variability such as refractive interstellar scintillation(RISS). We have developed an all-sky model for RISS which can predictvariability on a variety of timescales, survey locations, and observingfrequencies. The model makes use of Halpha intensity maps to probe the emissionmeasure along the line of sight, convert this to a scattering measure, andfinally a scintillation strength. The model uses previously developed and longunderstood physics along with (indirect) measurements of the electron contentand distribution within the Milky Way. We develop a set of expectations thatare useful in the planning of future surveys for transient and radiovariability, and demonstrate that the 1-GHz sky is a poor predictor of thevariable nature of the $100$-MHz sky. Interestingly, the correlation betweenthe incidence of variability and Galactic latitude which has been seen at 1GHz,is reversed at 100MHz. We compare the predictions of our model to alow-frequency radio survey that was conducted with the Murchison WidefieldArray, and find good qualitative agreement. We discuss the implications,current limitations, and future development of the model. The model has beenimplemented in a Python code and is available on GitHub/Zenodo.",
    "Article_Subject": "Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/07/19",
    "Article_PDF": "https://arxiv.org/pdf/1907.08395"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.07951",
    "DOI": "arXiv:1907.07951v1",
    "Article_Title": "Automatic vocal tract landmark localization from midsagittal MRI data",
    "Article_Abstract": "The various speech sounds of a language are obtained by varying the shape andposition of the articulators surrounding the vocal tract. Analyzing theirvariability is crucial for understanding speech production, diagnosing speechand swallowing disorders and building intuitive applications forrehabilitation. Magnetic Resonance Imaging (MRI) is currently the most harmlesspowerful imaging modality used for this purpose. Identifying key anatomicallandmarks on it is a pre-requisite for further analyses. This is a challengingtask considering the high inter- and intra-speaker variability and the mutualinteraction between the articulators. This study intends to solve this issueautomatically for the first time. For this purpose, midsagittal anatomical MRIfor 9 speakers sustaining 62 articulations and annotated with the location of21 key anatomical landmarks are considered. Four state-of-the-art methods,including deep learning methods, are adapted from the literature for faciallandmark localization and human pose estimation and evaluated. Furthermore, anapproach based on the description of each landmark location as a heat-map imagestored in a channel of a single multi-channel image embedding all landmarks isproposed. The generation of such a multi-channel image from an input MRI imageis tested through two deep learning networks, one taken from the literature andone designed on purpose in this study, the flat-net. Results show that theflat-net approach outperforms the other methods, leading to an overall RootMean Square Error of 3.4~pixels/0.34~cm obtained in a leave-one-out procedureover the speakers. All of the codes are publicly available on GitHub.",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "Article_Date": "2019/07/18",
    "Article_PDF": "https://arxiv.org/pdf/1907.07951"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.06274",
    "DOI": "arXiv:1907.06274v1",
    "Article_Title": "Predicting Merge Conflicts in Collaborative Software Development",
    "Article_Abstract": "Background. During collaborative software development, developers often usebranches to add features or fix bugs. When merging changes from two branches,conflicts may occur if the changes are inconsistent. Developers need to resolvethese conflicts before completing the merge, which is an error-prone andtime-consuming process. Early detection of merge conflicts, which warnsdevelopers about resolving conflicts before they become large and complicated,is among the ways of dealing with this problem. Existing techniques do this bycontinuously pulling and merging all combinations of branches in the backgroundto notify developers as soon as a conflict occurs, which is a computationallyexpensive process. One potential way for reducing this cost is to use amachine-learning based conflict predictor that filters out the merge scenariosthat are not likely to have conflicts, ie safe merge scenarios. Aims. In thispaper, we assess if conflict prediction is feasible. Method. We design aclassifier for predicting merge conflicts, based on 9 light-weight Git featuresets. To evaluate our predictor, we perform a large-scale study on 267, 657merge scenarios from 744 GitHub repositories in seven programming languages.Results. Our results show that we achieve high f1-scores, varying from 0.95 to0.97 for different programming languages, when predicting safe merge scenarios.The f1-score is between 0.57 and 0.68 for the conflicting merge scenarios.Conclusions. Predicting merge conflicts is feasible in practice, especially inthe context of predicting safe merge scenarios as a pre-filtering step forspeculative merging.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/07/14",
    "Article_PDF": "https://arxiv.org/pdf/1907.06274"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.06146",
    "DOI": "arXiv:1907.06146v1",
    "Article_Title": "Satellite System Graph: Towards the Efficiency Up-Boundary of Graph-Based Approximate Nearest Neighbor Search",
    "Article_Abstract": "Approximate Nearest Neighbor Search (ANNS) in high dimensional space isessential in database and information retrieval. Recently, there has been asurge of interests in exploring efficient graph-based indices for the ANNSproblem. Among them, the NSG has resurrected the theory of Monotonic SearchNetworks (MSNET) and achieved the state-of-the-art performance. However, theperformance of the NSG deviates from a potentially optimal position due to thehigh sparsity of the graph. Specifically, though the average degree of thegraph is small, their search algorithm travels a longer way to reach the query.Integrating both factors, the total search complexity (i.e., the number ofdistance calculations) is not minimized as their wish. In addition, NSG suffersfrom a high indexing time complexity, which limits the efficiency and thescalability of their method. In this paper, we aim to further mine thepotential of the MSNETs. Inspired by the message transfer mechanism of thecommunication satellite system, we find a new family of MSNETs, namely theSatellite System Graphs (SSG). In particular, while inheriting the superiorANNS properties from the MSNET, we try to ensure the angles between the edgesto be no smaller than a given value. Consequently, each node in the graphbuilds effective connections to its neighborhood omnidirectionally, whichensures an efficient search-routing on the graph like the message transferamong the satellites. We also propose an approximation of the SSG, NavigatingSSG, to increase the efficiency of indexing. Both theoretical and extensiveexperimental analysis are provided to demonstrate the strengths of the proposedapproach over the existing state-of-the-art algorithms. Our code has beenreleased on GitHub.",
    "Article_Subject": "Information Retrieval (cs.IR); Databases (cs.DB)",
    "Article_Date": "2019/07/13",
    "Article_PDF": "https://arxiv.org/pdf/1907.06146"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.05062",
    "DOI": "arXiv:1907.05062v1",
    "Article_Title": "FIRE: Unsupervised bi-directional inter-modality registration using deep networks",
    "Article_Abstract": "Inter-modality image registration is an critical preprocessing step for manyapplications within the routine clinical pathway. This paper presents anunsupervised deep inter-modality registration network that can learn theoptimal affine and non-rigid transformations simultaneously.Inverse-consistency is an important property commonly ignored in recent deeplearning based inter-modality registration algorithms. We address this issuethrough the proposed multi-task architecture and the new comprehensivetransformation network. Specifically, the proposed model learns amodality-independent latent representation to perform cycle-consistentcross-modality synthesis, and use an inverse-consistent loss to learn a pair oftransformations to align the synthesized image with the target. We name thisproposed framework as FIRE due to the shape of its structure. Our method showscomparable and better performances with the popular baseline method inexperiments on multi-sequence brain MR data and intra-modality 4D cardiacCine-MR data.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/07/11",
    "Article_PDF": "https://arxiv.org/pdf/1907.05062"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04908",
    "DOI": "arXiv:1907.04908v1",
    "Article_Title": "Executability of Python Snippets in Stack Overflow",
    "Article_Abstract": "Online resources today contain an abundant amount of code snippets fordocumentation, collaboration, learning, and problem-solving purposes. Theirexecutability in a \"plug and play\" manner enables us to confirm their qualityand use them directly in projects. But, in practice that is often not the casedue to several requirements violations or incompleteness. However, it is adifficult task to investigate the executability on a large scale due todifferent possible errors during the execution. We have developed a scalableframework to investigate this for SOTorrent Python snippets. We found that withminor adjustments, 27.92% of snippets are executable. The executability has notchanged significantly over time. The code snippets referenced in GitHub aremore likely to be directly executable. But executability does not affect thechances of the answer to be selected as the accepted answer significantly.These properties help us understand and improve the interaction of users withonline resources that include code snippets.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/07/10",
    "Article_PDF": "https://arxiv.org/pdf/1907.04908"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04527",
    "DOI": "arXiv:1907.04527v1",
    "Article_Title": "Dynamics of Team Library Adoptions: An Exploration of GitHub Commit Logs",
    "Article_Abstract": "When a group of people strives to understand new information, struggle ensuesas various ideas compete for attention. Steep learning curves are surmounted asteams learn together. To understand how these team dynamics play out insoftware development, we explore Git logs, which provide a complete changehistory of software repositories. In these repositories, we observe codeadditions, which represent successfully implemented ideas, and code deletions,which represent ideas that have failed or been superseded. By examining thepatterns between these commit types, we can begin to understand how teams adoptnew information. We specifically study what happens after a software library isadopted by a project, i.e., when a library is used for the first time in theproject. We find that a variety of factors, including team size, librarypopularity, and prevalence on Stack Overflow are associated with how quicklyteams learn and successfully adopt new software libraries.",
    "Article_Subject": "Social and Information Networks (cs.SI); Software Engineering (cs.SE)",
    "Article_Date": "2019/07/10",
    "Article_PDF": "https://arxiv.org/pdf/1907.04527"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04433",
    "DOI": "arXiv:1907.04433v1",
    "Article_Title": "GluonCV and GluonNLP: Deep Learning in Computer Vision and Natural Language Processing",
    "Article_Abstract": "We present GluonCV and GluonNLP, the deep learning toolkits for computervision and natural language processing based on Apache MXNet (incubating).These toolkits provide state-of-the-art pre-trained models, training scripts,and training logs, to facilitate rapid prototyping and promote reproducibleresearch. We also provide modular APIs with flexible building blocks to enableefficient customization. Leveraging the MXNet ecosystem, the deep learningmodels in GluonCV and GluonNLP can be deployed onto a variety of platforms withdifferent programming languages. Benefiting from open source under the Apache2.0 license, GluonCV and GluonNLP have attracted 100 contributors worldwide onGitHub. Models of GluonCV and GluonNLP have been downloaded for more than 1.6million times in fewer than 10 months.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/09",
    "Article_PDF": "https://arxiv.org/pdf/1907.04433"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04002",
    "DOI": "arXiv:1907.04002v1",
    "Article_Title": "Characterizing Bitcoin donations to open source software on GitHub",
    "Article_Abstract": "Web-based hosting services for version control, such as GitHub, have made iteasier for people to develop, share, and donate money to software repositories.In this paper, we study the use of Bitcoin to make donations to open sourcerepositories on GitHub. In particular, we analyze the amount and volume ofdonations over time, in addition to its relationship to the age and popularityof a repository.  We scanned over three million repositories looking for donation addresses. Wethen extracted and analyzed their transactions from Bitcoin's publicblockchain. Overall, we found a limited adoption of Bitcoin as a payment methodfor receiving donations, with nearly 44 thousand deposits adding up to only 8.3million dollars in the last 10 years. We also found weak positive correlationbetween the amount of donations in dollars and the popularity of a repository,with highest correlation (r=0.013) associated with number of forks.",
    "Article_Subject": "Computers and Society (cs.CY); Cryptography and Security (cs.CR)",
    "Article_Date": "2019/07/09",
    "Article_PDF": "https://arxiv.org/pdf/1907.04002"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03892",
    "DOI": "arXiv:1907.03892v5",
    "Article_Title": "Fast Visual Object Tracking with Rotated Bounding Boxes",
    "Article_Abstract": "In this paper, we demonstrate a novel algorithm that uses ellipse fitting toestimate the bounding box rotation angle and size with the segmentation(mask)on the target for online and real-time visual object tracking. Our method,SiamMask_E, improves the bounding box fitting procedure of the state-of-the-artobject tracking algorithm SiamMask and still retains a fast-tracking frame rate(80 fps) on a system equipped with GPU (GeForce GTX 1080 Ti or higher). Wetested our approach on the visual object tracking datasets (VOT2016, VOT2018,and VOT2019) that were labeled with rotated bounding boxes. By comparing withthe original SiamMask, we achieved an improved Accuracy of 0.652 and 0.309 EAOon VOT2019, which is 0.056 and 0.026 higher than the original SiamMask. Theimplementation is available on GitHub:https://github.com/baoxinchen/siammask_e.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/07/08",
    "Article_PDF": "https://arxiv.org/pdf/1907.03892"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03660",
    "DOI": "arXiv:1907.03660v2",
    "Article_Title": "Can Dark Matter be Geometry? A Case Study with Mimetic Dark Matter",
    "Article_Abstract": "We investigate the possibility of dark matter being a pure geometricaleffect, rather than a particle or a compact object, by exploring a specificmodified gravity model: mimetic dark matter. We present an alternativeformulation of the theory, closer to the standard cosmological perturbationtheory framework. We make manifest the presence of arbitrary parameters andextra functions, both at background level and at first order in perturbationtheory. We present the full set of independent equations of motion for thismodel, and we discuss the amount of tuning needed to match predictions of thetheory to actual data. By using the matter power spectrum and cosmic microwavebackground angular power spectra as benchmark observables, we explicitly showthat since there is no natural mechanism to generate adiabatic initialconditions in this specific model, extra fine-tuning is required. We modify thepublicly available Boltzmann code \\texttt{CLASS} to make accurate predictionsfor the observables in mimetic dark matter. Our modified version of\\texttt{CLASS} is available on GitHub. We have used mimetic dark matter as anillustration of how much one is allowed to change the initial conditions beforecontradicting observations when modifying the laws of gravity as described byGeneral Relativity but we point out that modifying gravity without providing anatural mechanism to generate adiabatic initial conditions will always lead tohighly fine-tuned models.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); General Relativity and Quantum Cosmology (gr-qc); High Energy Physics - Theory (hep-th)",
    "Article_Date": "2019/07/08",
    "Article_PDF": "https://arxiv.org/pdf/1907.03660"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03407",
    "DOI": "arXiv:1907.03407v1",
    "Article_Title": "On The Lag of Library Vulnerability Updates: An Investigation into the Repackage and Delivery of Security Fixes Within The npm JavaScript Ecosystem",
    "Article_Abstract": "Vulnerabilities in third-party libraries is a growing concern for thesoftware developer, as it poses risks not only to the software client itselfbut to the entire software ecosystem. To mitigate these risks, developers arestrongly recommended to update their dependencies. Recent studies show thataffected developers are not likely to respond to the vulnerability threat.However, another reason for the lag of vulnerability updates is due to slowrepackaging (i.e., package the vulnerability fix into a new version) anddelivery (i.e., affected client adopt the new version) of the fix. Tounderstand these lags of updates, we use both qualitative and quantitativeapproaches to conduct an empirical study on how 188 fixes were repackaged anddelivered across over eight hundred thousand releases of npm software clientshosted on GitHub. We report two lags: (1) lags in repackaging occur asvulnerability fixes are more likely to be bundled with other non-relatedupdates (i.e., about 83.33\\% of commits are not related to the fix) and (2)lags in the delivery are caused by clients that are more likely to adopt theminor fix than adopt the patch fix. Furthermore, other factors such asdownstream dependencies and severity do have an impact. We also find thatfreshness of packages does not impact the amount of lags. The identification ofthese two lags opens up different avenues on how to facilitate faster fixdelivery throughout a library ecosystem.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/07/08",
    "Article_PDF": "https://arxiv.org/pdf/1907.03407"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03187",
    "DOI": "arXiv:1907.03187v1",
    "Article_Title": "Applying a Pre-trained Language Model to Spanish Twitter Humor Prediction",
    "Article_Abstract": "Our entry into the HAHA 2019 Challenge placed $3^{rd}$ in the classificationtask and $2^{nd}$ in the regression task. We describe our system andinnovations, as well as comparing our results to a Naive Bayes baseline. Alarge Twitter based corpus allowed us to train a language model from scratchfocused on Spanish and transfer that knowledge to our competition model. Toovercome the inherent errors in some labels we reduce our class confidence withlabel smoothing in the loss function. All the code for our project is includedin a GitHub repository for easy reference and to enable replication by others.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/07/06",
    "Article_PDF": "https://arxiv.org/pdf/1907.03187"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.02862",
    "DOI": "arXiv:1907.02862v1",
    "Article_Title": "Essential Motor Cortex Signal Processing: an ERP and functional connectivity MATLAB toolbox -- User Guide",
    "Article_Abstract": "The purpose of this document is to help individuals use the \"Essential MotorCortex Signal Processing MATLAB Toolbox\". The toolbox implements variousmethods for three major aspects of investigating human motor cortex fromNeuroscience view point: (1) ERP estimation and quantification, (2) CorticalFunctional Connectivity analysis and (3) EMG quantification. The toolbox --which is distributed under the terms of the GNU GENERAL PUBLIC LICENSE as a setof MATLAB R routines -- can be downloaded directly at the address:http://oset.ir/category.php?dir=Tools or from the public repository on GitHub,at address below: https://github.com/EsiSeraj/ERP Connectivity EMG Analysis  The purpose of this toolbox is threefold: 1. Extract theevent-related-potential (ERP) from preprocessed cerebral signals (i.e. EEG,MEG, etc.), identify and then quantify the event-relatedsynchronization/desynchronization (ERS/ERD) events. Both time-course dynamicsand time-frequency (TF) analyzes are included. 2. Measure, quantify anddemonstrate the cortical functional connectivity (CFC) across scalp electrodes.These set of functions can also be applied to various types of cerebral signals(i.e. electric and magnetic). 3. Quantify electromyogram (EMG) recorded fromactive muscles during performing motor tasks.",
    "Article_Subject": "Signal Processing (eess.SP); Computational Engineering, Finance, and Science (cs.CE); Image and Video Processing (eess.IV); Neurons and Cognition (q-bio.NC); Quantitative Methods (q-bio.QM)",
    "Article_Date": "2019/06/15",
    "Article_PDF": "https://arxiv.org/pdf/1907.02862"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.02202",
    "DOI": "arXiv:1907.02202v1",
    "Article_Title": "SEntiMoji: An Emoji-Powered Learning Approach for Sentiment Analysis in Software Engineering",
    "Article_Abstract": "Sentiment analysis has various application scenarios in software engineering(SE), such as detecting developers' emotions in commit messages and identifyingtheir opinions on Q&A forums. However, commonly used out-of-the-box sentimentanalysis tools cannot obtain reliable results on SE tasks and themisunderstanding of technical jargon is demonstrated to be the main reason.Then, researchers have to utilize labeled SE-related texts to customizesentiment analysis for SE tasks via a variety of algorithms. However, thescarce labeled data can cover only very limited expressions and thus cannotguarantee the analysis quality. To address such a problem, we turn to theeasily available emoji usage data for help. More specifically, we employemotional emojis as noisy labels of sentiments and propose a representationlearning approach that uses both Tweets and GitHub posts containing emojis tolearn sentiment-aware representations for SE-related texts. These emoji-labeledposts can not only supply the technical jargon, but also incorporate moregeneral sentiment patterns shared across domains. They as well as labeled dataare used to learn the final sentiment classifier. Compared to the existingsentiment analysis methods used in SE, the proposed approach can achievesignificant improvement on representative benchmark datasets. By furthercontrast experiments, we find that the Tweets make a key contribution to thepower of our approach. This finding informs future research not to unilaterallypursue the domain-specific resource, but try to transform knowledge from theopen domain through ubiquitous signals such as emojis.",
    "Article_Subject": "Software Engineering (cs.SE); Computation and Language (cs.CL)",
    "Article_Date": "2019/07/04",
    "Article_PDF": "https://arxiv.org/pdf/1907.02202"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00903",
    "DOI": "arXiv:1907.00903v1",
    "Article_Title": "Resolving the Multiple Withdrawal Attack on ERC20 Tokens",
    "Article_Abstract": "Custom tokens are an integral component of decentralized applications (dapps)deployed on Ethereum and other blockchain platforms. For Ethereum, the ERC20standard is a widely used token interface and is interoperable with manyexisting dapps, user interface platforms, and popular web applications (e.g.,exchange services). An ERC20 security issue, known as the \"multiple withdrawalattack\", was raised on GitHub and has been open since November 2016. The issueconcerns ERC20's defined method approve() which was envisioned as a way fortoken holders to give permission for other users and dapps to withdraw a cappednumber of tokens. The security issue arises when a token holder wants to adjustthe amount of approved tokens from N to M (this could be an increase ordecrease). If malicious, a user or dapp who is approved for N tokens canfront-run the adjustment transaction to first withdraw N tokens, then allow theapproval to be confirmed, and withdraw an additional M tokens. In this paper,we evaluate 10 proposed mitigations for this issues and find that no solutionis fully satisfactory. We then propose 2 new solutions that mitigate theattack, one of which fully fulfills constraints of the standard, and the secondone shows a general limitation in addressing this issue from ERC20's approvemethod.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00903"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00863",
    "DOI": "arXiv:1907.00863v1",
    "Article_Title": "Understanding GCC Builtins to Develop Better Tools",
    "Article_Abstract": "C programs can use compiler builtins to provide functionality that the Clanguage lacks. On Linux, GCC provides several thousands of builtins that arealso supported by other mature compilers, such as Clang and ICC. Maintainers ofother tools lack guidance on whether and which builtins should be implementedto support popular projects. To assist tool developers who want to support GCCbuiltins, we analyzed builtin use in 4,913 C projects from GitHub. We foundthat 37% of these projects relied on at least one builtin. Supporting anincreasing proportion of projects requires support of an exponentiallyincreasing number of builtins; however, implementing only 10 builtins alreadycovers over 30% of the projects. Since we found that many builtins in ourcorpus remained unused, the effort needed to support 90% of the projects ismoderate, requiring about 110 builtins to be implemented. For each project, weanalyzed the evolution of builtin use over time and found that the majority ofprojects mostly added builtins. This suggests that builtins are not a legacyfeature and must be supported in future tools. Systematic testing of builtinsupport in existing tools revealed that many lacked support for builtins eitherpartially or completely; we also discovered incorrect implementations invarious tools, including the formally verified CompCert compiler.",
    "Article_Subject": "Programming Languages (cs.PL); Software Engineering (cs.SE)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00863"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00652",
    "DOI": "arXiv:1907.00652v1",
    "Article_Title": "Avoiding Implementation Pitfalls of \"Matrix Capsules with EM Routing\" by Hinton et al",
    "Article_Abstract": "The recent progress on capsule networks by Hinton et al. has generatedconsiderable excitement in the machine learning community. The idea behind acapsule is inspired by a cortical minicolumn in the brain, whereby a verticallyorganised group of around 100 neurons receive common inputs, have commonoutputs, are interconnected, and may well constitute a fundamental computationunit of the cerebral cortex. However, Hinton's paper on \"Matrix Capsule with EMRouting'\" was unfortunately not accompanied by a release of source code, whichleft interested researchers attempting to implement the architecture andreproduce the benchmarks on their own. This has certainly slowed the progressof research building on this work. While writing our own implementation, wenoticed several common mistakes in other open source implementations that wecame across. In this paper we share some of these learnings, specificallyfocusing on three implementation pitfalls and how to avoid them: (1) parentcapsules with only one child; (2) normalising the amount of data assigned toparent capsules; (3) parent capsules at different positions compete for childcapsules. While our implementation is a considerable improvement over currentlyavailable implementations, it still falls slightly short of the performancereported by Hinton et al. (2018). The source code for this implementation isavailable on GitHub at the following URL:https://github.com/IBM/matrix-capsules-with-em-routing.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00652"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00558",
    "DOI": "arXiv:1907.00558v1",
    "Article_Title": "Improved Forecasting of Cryptocurrency Price using Social Signals",
    "Article_Abstract": "Social media signals have been successfully used to develop large-scalepredictive and anticipatory analytics. For example, forecasting stock marketprices and influenza outbreaks. Recently, social data has been explored toforecast price fluctuations of cryptocurrencies, which are a novel disruptivetechnology with significant political and economic implications. In this paperwe leverage and contrast the predictive power of social signals, specificallyuser behavior and communication patterns, from multiple social platforms GitHuband Reddit to forecast prices for three cyptocurrencies with high developer andcommunity interest - Bitcoin, Ethereum, and Monero. We evaluate the performanceof neural network models that rely on long short-term memory units (LSTMs)trained on historical price data and social data against price only LSTMs andbaseline autoregressive integrated moving average (ARIMA) models, commonly usedto predict stock prices. Our results not only demonstrate that social signalsreduce error when forecasting daily coin price, but also show that the languageused in comments within the official communities on Reddit (r/Bitcoin,r/Ethereum, and r/Monero) are the best predictors overall. We observe thatmodels are more accurate in forecasting price one day ahead for Bitcoin (4%root mean squared percent error) compared to Ethereum (7%) and Monero (8%).",
    "Article_Subject": "Statistical Finance (q-fin.ST); Machine Learning (cs.LG); Social and Information Networks (cs.SI); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00558"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.11976",
    "DOI": "arXiv:1906.11976v1",
    "Article_Title": "Multivariate Big Data Analysis for Intrusion Detection: 5 steps from the haystack to the needle",
    "Article_Abstract": "The research literature on cybersecurity incident detection & response isvery rich in automatic detection methodologies, in particular those based onthe anomaly detection paradigm. However, very little attention has been devotedto the diagnosis ability of the methods, aimed to provide useful information onthe causes of a given detected anomaly. This information is of utmostimportance for the security team to reduce the time from detection to response.In this paper, we present Multivariate Big Data Analysis (MBDA), a completeintrusion detection approach based on 5 steps to effectively handle massiveamounts of disparate data sources. The approach has been designed to deal withthe main characteristics of Big Data, that is, the high volume, velocity andvariety. The core of the approach is the Multivariate Statistical NetworkMonitoring (MSNM) technique proposed in a recent paper. Unlike in state of theart machine learning methodologies applied to the intrusion detection problem,when an anomaly is identified in MBDA the output of the system includes thedetail of the logs of raw information associated to this anomaly, so that thesecurity team can use this information to elucidate its root causes. MBDA isbased in two open software packages available in Github: the MEDA Toolbox andthe FCParser. We illustrate our approach with two case studies. The first onedemonstrates the application of MBDA to semistructured sources of information,using the data from the VAST 2012 mini challenge 2. This complete case study issupplied in a virtual machine available for download. In the second case studywe show the Big Data capabilities of the approach in data collected from a realnetwork with labeled attacks.",
    "Article_Subject": "Networking and Internet Architecture (cs.NI); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Other Statistics (stat.OT)",
    "Article_Date": "2019/06/27",
    "Article_PDF": "https://arxiv.org/pdf/1906.11976"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.11565",
    "DOI": "arXiv:1906.11565v2",
    "Article_Title": "EmotionX-KU: BERT-Max based Contextual Emotion Classifier",
    "Article_Abstract": "We propose a contextual emotion classifier based on a transferable languagemodel and dynamic max pooling, which predicts the emotion of each utterance ina dialogue. A representative emotion analysis task, EmotionX, requires toconsider contextual information from colloquial dialogues and to deal with aclass imbalance problem. To alleviate these problems, our model leverages theself-attention based transferable language model and the weighted cross entropyloss. Furthermore, we apply post-training and fine-tuning mechanisms to enhancethe domain adaptability of our model and utilize several machine learningtechniques to improve its performance. We conduct experiments on twoemotion-labeled datasets named Friends and EmotionPush. As a result, our modeloutperforms the previous state-of-the-art model and also shows competitiveperformance in the EmotionX 2019 challenge. The code will be available in theGithub page.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/06/27",
    "Article_PDF": "https://arxiv.org/pdf/1906.11565"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.11017",
    "DOI": "arXiv:1906.11017v1",
    "Article_Title": "A project-based course on software development for (engineering) research",
    "Article_Abstract": "This paper describes the motivation and design of a 10-week graduate coursethat teaches practices for developing research software; although offered by anengineering program, the content applies broadly to any field of scientificresearch where software may be developed. Topics taught in the course includelocal and remote version control, licensing and copyright, structuring Pythonmodules, testing and test coverage, continuous integration, packaging anddistribution, open science, software citation, and reproducibility basics,among others. Lectures are supplemented by in-class activities and discussions,and all course material is shared openly via GitHub. Coursework is heavilybased on a single, term-long project where students individually develop asoftware package targeted at their own research topic; all contributions mustbe submitted as pull requests and reviewed/merged by other students. The coursewas initially offered in Spring 2018 with 17 students enrolled, and will betaught again in Spring 2019.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/06/13",
    "Article_PDF": "https://arxiv.org/pdf/1906.11017"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.10506",
    "DOI": "arXiv:1906.10506v1",
    "Article_Title": "GaussPy+: A fully automated Gaussian decomposition package for emission line spectra",
    "Article_Abstract": "Our understanding of the dynamics of the interstellar medium is informed bythe study of the detailed velocity structure of emission line observations. Oneapproach to study the velocity structure is to decompose the spectra intoindividual velocity components; this leads to a description of the dataset thatis significantly reduced in complexity. However, this decomposition requiresfull automation lest it becomes prohibitive for large datasets, such asGalactic plane surveys. We developed GaussPy+, a fully automated Gaussiandecomposition package that can be applied to emission line datasets, especiallylarge surveys of HI and isotopologues of CO. We built our package upon theexisting GaussPy algorithm and significantly improved its performance for noisydata. New functionalities of GaussPy+ include: i) automated preparatory steps,such as an accurate noise estimation, which can also be used as standaloneapplications; ii) an improved fitting routine; iii) an automated spatialrefitting routine that can add spatial coherence to the decomposition resultsby refitting spectra based on neighbouring fit solutions. We thoroughly testedthe performance of GaussPy+ on synthetic spectra and a test field from theGalactic Ring Survey. We found that GaussPy+ can deal with cases of complexemission and even low to moderate signal-to-noise values.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Astrophysics of Galaxies (astro-ph.GA)",
    "Article_Date": "2019/06/25",
    "Article_PDF": "https://arxiv.org/pdf/1906.10506"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.10362",
    "DOI": "arXiv:1906.10362v1",
    "Article_Title": "EVulHunter: Detecting Fake Transfer Vulnerabilities for EOSIO's Smart Contracts at Webassembly-level",
    "Article_Abstract": "As one of the representative Delegated Proof-of-Stake (DPoS) blockchainplatforms, EOSIO's ecosystem grows rapidly in recent years. A number ofvulnerabilities and corresponding attacks of EOSIO's smart contracts have beendiscovered and observed in the wild, which caused a large amount of financialdamages. However, the majority of EOSIO's smart contracts are not open-sourced.As a result, the WebAssembly code may become the only available object to beanalyzed in most cases. Unfortunately, current tools are web-applicationoriented and cannot be applied to EOSIO WebAssembly code directly, which makesit more difficult to detect vulnerabilities from those smart contracts. In thispaper, we propose \\toolname, a static analysis tool that can be used to detectvulnerabilities from EOSIO WASM code automatically. We focus on one particulartype of vulnerabilities named \\textit{fake-transfer}, and the exploitation ofsuch vulnerabilities has led to millions of dollars in damages. To the best ofour knowledge, it is the first attempt to build an automatic tool to detectvulnerabilities of EOSIO's smart contracts. The experimental resultsdemonstrate that our tool is able to detect fake transfer vulnerabilitiesquickly and precisely. EVulHunter is available on GitHub\\footnote{Tool andbenchmarks: https://github.com/EVulHunter/EVulHunter} and YouTube\\footnote{Demovideo: https://youtu.be/5SJ0ZJKVZvw}.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/06/25",
    "Article_PDF": "https://arxiv.org/pdf/1906.10362"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.09808",
    "DOI": "arXiv:1906.09808v1",
    "Article_Title": "Recurrent Adversarial Service Times",
    "Article_Abstract": "Service system dynamics occur at the interplay between customer behaviour anda service provider's response. This kind of dynamics can effectively be modeledwithin the framework of queuing theory where customers' arrivals are describedby point process models. However, these approaches are limited by parametricassumptions as to, for example, inter-event time distributions. In this paper,we address these limitations and propose a novel, deep neural network solutionto the queuing problem. Our solution combines a recurrent neural network thatmodels the arrival process with a recurrent generative adversarial networkwhich models the service time distribution. We evaluate our methodology onvarious empirical datasets ranging from internet services (Blockchain, GitHub,Stackoverflow) to mobility service systems (New York taxi cab).",
    "Article_Subject": "Machine Learning (stat.ML); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/24",
    "Article_PDF": "https://arxiv.org/pdf/1906.09808"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08351",
    "DOI": "arXiv:1906.08351v1",
    "Article_Title": "Towards Lakosian Multilingual Software Design Principles",
    "Article_Abstract": "Large software systems often comprise programs written in differentprogramming languages. In the case when cross-language interoperability isaccomplished with a Foreign Function Interface (FFI), for example pybind11,Boost.Python, Emscripten, PyV8, or JNI, among many others, common softwareengineering tools, such as call-graph analysis, are obstructed by the opacityof the FFI. This complicates debugging and fosters potential inefficiency andsecurity problems. One contributing issue is that there is little rigoroussoftware design advice for multilingual software. In this paper, we present ourprogress towards a more rigorous design approach to multilingual software. Theapproach is based on the existing approach to the design of large-scale C++systems developed by Lakos. The Lakosian approach is one of the few designmethodologies to address physical design rather than just logical design. Usingthe MLSA toolkit developed in prior work for analysis of multilingual software,we focus in on one FFI -- the pybind11 FFI. An extension to the Lakosian C++design rules is proposed to address multilingual software that uses pybind11.Using a sample of 50 public GitHub repositories that use pybind11, we measurehow many repositories would currently satisfy these rules. We conclude with aproposed generalization of the pybind11-based rules for any multilingualsoftware using an FFI interface.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08351"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08101",
    "DOI": "arXiv:1906.08101v1",
    "Article_Title": "Pre-Training with Whole Word Masking for Chinese BERT",
    "Article_Abstract": "Bidirectional Encoder Representations from Transformers (BERT) has shownmarvelous improvements across various NLP tasks. Recently, an upgraded versionof BERT has been released with Whole Word Masking (WWM), which mitigate thedrawbacks of masking partial WordPiece tokens in pre-training BERT. In thistechnical report, we adapt whole word masking in Chinese text, that masking thewhole word instead of masking Chinese characters, which could bring anotherchallenge in Masked Language Model (MLM) pre-training task. The model wastrained on the latest Chinese Wikipedia dump. We aim to provide easyextensibility and better performance for Chinese BERT without changing anyneural architecture or even hyper-parameters. The model is verified on variousNLP tasks, across sentence-level to document-level, including sentimentclassification (ChnSentiCorp, Sina Weibo), named entity recognition (PeopleDaily, MSRA-NER), natural language inference (XNLI), sentence pair matching(LCQMC, BQ Corpus), and machine reading comprehension (CMRC 2018, DRCD, CAILRC). Experimental results on these datasets show that the whole word maskingcould bring another significant gain. Moreover, we also examine theeffectiveness of Chinese pre-trained models: BERT, ERNIE, BERT-wwm. We releasethe pre-trained model (both TensorFlow and PyTorch) on GitHub:https://github.com/ymcui/Chinese-BERT-wwm",
    "Article_Subject": "Computation and Language (cs.CL); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08101"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08085",
    "DOI": "arXiv:1906.08085v1",
    "Article_Title": "PLANE: An Extensible Open Source Framework for modeling the Internet of Drones",
    "Article_Abstract": "Python Library for simulating unManNed vehiclEs(PLANE) is an open sourcesoftware module, written in Python, that focuses on Unmanned Aerial Vehicles(UAVs), on their movements and on the mechanics of flight, thus devotingparticular attention to the equations that describe drones' movement. In thecontext of the Internet of Drones (IoD), the module can be widely used for thestudy of the mutual control of position/coordination in scenarios in whichdrones may find obstacles, as it happens in densely populated urban scenarios.Emphasis is put on ease of use, performance evaluation, documentation, andApplication Programming Interface (API) consistency. The software tool hasminimal dependencies and is distributed under MIT License. Source code,binaries, and documentation can be downloaded from GitHub.",
    "Article_Subject": "Robotics (cs.RO); Software Engineering (cs.SE)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08085"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08058",
    "DOI": "arXiv:1906.08058v1",
    "Article_Title": "On the abandonment and survival of open source projects: An empirical investigation",
    "Article_Abstract": "Background: Evolution of open source projects frequently depends on a smallnumber of core developers. The loss of such core developers might bedetrimental for projects and even threaten their entire continuation. However,it is possible that new core developers assume the project maintenance andallow the project to survive. Aims: The objective of this paper is to provideempirical evidence on: 1) the frequency of project abandonment and survival, 2)the differences between abandoned and surviving projects, and 3) the motivationand difficulties faced when assuming an abandoned project. Method: We adopt amixed-methods approach to investigate project abandonment and survival. Wecarefully select 1,932 popular GitHub projects and recover the abandoned andsurviving projects, and conduct a survey with developers that have beeninstrumental in the survival of the projects. Results: We found that 315projects (16%) were abandoned and 128 of these projects (41%) survived becauseof new core developers who assumed the project development. The surveyindicates that (i) in most cases the new maintainers were aware of the projectabandonment risks when they started to contribute; (ii) their own usage of thesystems is the main motivation to contribute to such projects; (iii) human andsocial factors played a key role when making these contributions; and (iv) lackof time and the difficulty to obtain push access to the repositories are themain barriers faced by them. Conclusions: Project abandonment is a reality evenin large open source projects and our work enables a better understanding ofsuch risks, as well as highlights ways in avoiding them.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08058"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.07771",
    "DOI": "arXiv:1906.07771v1",
    "Article_Title": "Crop Lodging Prediction from UAV-Acquired Images of Wheat and Canola using a DCNN Augmented with Handcrafted Texture Features",
    "Article_Abstract": "Lodging, the permanent bending over of food crops, leads to poor plant growthand development. Consequently, lodging results in reduced crop quality, lowerscrop yield, and makes harvesting difficult. Plant breeders routinely evaluateseveral thousand breeding lines, and therefore, automatic lodging detection andprediction is of great value aid in selection. In this paper, we propose a deepconvolutional neural network (DCNN) architecture for lodging classificationusing five spectral channel orthomosaic images from canola and wheat breedingtrials. Also, using transfer learning, we trained 10 lodging detection modelsusing well-established deep convolutional neural network architectures. Ourproposed model outperforms the state-of-the-art lodging detection methods inthe literature that use only handcrafted features. In comparison to 10 DCNNlodging detection models, our proposed model achieves comparable results whilehaving a substantially lower number of parameters. This makes the proposedmodel suitable for applications such as real-time classification usinginexpensive hardware for high-throughput phenotyping pipelines. The GitHubrepository at https://github.com/FarhadMaleki/LodgedNet contains code andmodels.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/06/18",
    "Article_PDF": "https://arxiv.org/pdf/1906.07771"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.07637",
    "DOI": "arXiv:1906.07637v2",
    "Article_Title": "Periphery Plots for Contextualizing Heterogeneous Time-Based Charts",
    "Article_Abstract": "Patterns in temporal data can often be found across different scales, such asdays, weeks, and months, making effective visualization of time-based datachallenging. Here we propose a new approach for providing focus and context intime-based charts to enable interpretation of patterns across time scales. Ourapproach employs a focus zone with a time and a second axis, that can eitherrepresent quantities or categories, as well as a set of adjacent peripheryplots that can aggregate data along the time, value, or both dimensions. Wepresent a framework for periphery plots and describe two use cases thatdemonstrate the utility of our approach.",
    "Article_Subject": "Human-Computer Interaction (cs.HC)",
    "Article_Date": "2019/06/18",
    "Article_PDF": "https://arxiv.org/pdf/1906.07637"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.07505",
    "DOI": "arXiv:1906.07505v1",
    "Article_Title": "A Model-Based General Alternative to the Standardised Precipitation Index",
    "Article_Abstract": "In this paper, we introduce two new model-based versions of the widely-usedstandardized precipitation index (SPI) for detecting and quantifying themagnitude of extreme hydro-climatic events. Our analytical approach is based ongeneralized additive models for location, scale and shape (GAMLSS), which helpsas to overcome some limitations of the SPI. We compare our model-basedstandardised indices (MBSIs) with the SPI using precipitation data collectedbetween January 2004 - December 2013 (522 weeks) in Caapiranga, a road-lessmunicipality of Amazonas State. As a result, it is shown that the MBSI-1 is anindex with similar properties to the SPI, but with improved methodology. Incomparison to the SPI, our MBSI-1 index allows for the use of differentzero-augmented distributions, it works with more flexible time-scales, can beapplied to shorter records of data and also takes into account temporaldependencies in known seasonal behaviours. Our approach is implemented in an Rpackage, mbsi, available from Github.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/06/18",
    "Article_PDF": "https://arxiv.org/pdf/1906.07505"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.06905",
    "DOI": "arXiv:1906.06905v2",
    "Article_Title": "Manipulating the Difficulty of C-Tests",
    "Article_Abstract": "We propose two novel manipulation strategies for increasing and decreasingthe difficulty of C-tests automatically. This is a crucial step towardsgenerating learner-adaptive exercises for self-directed language learning andpreparing language assessment tests. To reach the desired difficulty level, wemanipulate the size and the distribution of gaps based on absolute and relativegap difficulty predictions. We evaluate our approach in corpus-basedexperiments and in a user study with 60 participants. We find that bothstrategies are able to generate C-tests with the desired difficulty level.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/06/17",
    "Article_PDF": "https://arxiv.org/pdf/1906.06905"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.06583",
    "DOI": "arXiv:1906.06583v2",
    "Article_Title": "Linear regression with stationary errors : the R package slm",
    "Article_Abstract": "This paper introduces the R package slm which stands for Stationary LinearModels. The package contains a set of statistical procedures for linearregression in the general context where the error process is strictlystationary with short memory. We work in the setting of Hannan (1973), whoproved the asymptotic normality of the (normalized) least squares estimators(LSE) under very mild conditions on the error process. We propose differentways to estimate the asymptotic covariance matrix of the LSE, and then tocorrect the type I error rates of the usual tests on the parameters (as well asconfidence intervals). The procedures are evaluated through different sets ofsimulations, and two examples of real datasets are studied.",
    "Article_Subject": "Applications (stat.AP); Computation (stat.CO); Methodology (stat.ME)",
    "Article_Date": "2019/06/15",
    "Article_PDF": "https://arxiv.org/pdf/1906.06583"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.06317",
    "DOI": "arXiv:1906.06317v1",
    "Article_Title": "freud: A Software Suite for High Throughput Analysis of Particle Simulation Data",
    "Article_Abstract": "The freud Python package is a powerful library for analyzing simulation data.Written with modern simulation and data analysis workflows in mind, freudprovides a Python interface to fast, parallelized C++ routines that runefficiently on laptops, workstations, and supercomputing clusters. The packageprovides the core tools for finding particle neighbors in periodic systems, andoffers a uniform API to a wide variety of methods implemented using thesetools. As such, freud users can access standard methods such as the radialdistribution function as well as newer, more specialized methods such as thepotential of mean force and torque and local crystal environment analysis withequal ease. While many comparable tools place a heavy emphasis on reading andoperating on trajectory file formats, freud instead accepts numerical arrays ofdata directly as inputs. By remaining agnostic to its data source, freud issuitable for analyzing any coarse-grained particle simulation, regardless ofthe original data representation or simulation method. When used for on-the-flyanalysis in conjunction with scriptable simulation software such as HOOMD-blue,freud enables smart simulations that adapt to the current state of the system,allowing users to study phenomena such as nucleation and growth.",
    "Article_Subject": "Computational Physics (physics.comp-ph); Materials Science (cond-mat.mtrl-sci); Computational Engineering, Finance, and Science (cs.CE)",
    "Article_Date": "2019/06/14",
    "Article_PDF": "https://arxiv.org/pdf/1906.06317"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.05676",
    "DOI": "arXiv:1906.05676v1",
    "Article_Title": "Sionnx: Automatic Unit Test Generator for ONNX Conformance",
    "Article_Abstract": "Open Neural Network Exchange (ONNX) is an open format to represent AI modelsand is supported by many machine learning frameworks. While ONNX definesunified and portable computation operators across various frameworks, theconformance tests for those operators are insufficient, which makes itdifficult to verify if an operator's behavior in an ONNX backend implementationcomplies with the ONNX standard. In this paper, we present the first automaticunit test generator named Sionnx for verifying the compliance of ONNXimplementation. First, we propose a compact yet complete set of rules todescribe the operator's attributes and the properties of its operands. Second,we design an Operator Specification Language (OSL) to provide a high-leveldescription for the operator's syntax. Finally, through this easy-to-usespecification language, we are able to build a full testing specification whichleverages LLVM TableGen to automatically generate unit tests for ONNX operatorswith much large coverage. Sionnx is lightweight and flexible to supportcross-framework verification. The Sionnx framework is open-sourced in thegithub repository (https://github.com/alibaba/Sionnx).",
    "Article_Subject": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/06/12",
    "Article_PDF": "https://arxiv.org/pdf/1906.05676"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.05603",
    "DOI": "arXiv:1906.05603v1",
    "Article_Title": "A review of available software for adaptive clinical trial design",
    "Article_Abstract": "Background/Aims: The increasing expense of the drug development process hasseen interest in the use of adaptive designs (ADs) grow substantially in recentyears. Accordingly, much research has been conducted to identify potentialbarriers to increasing the use of ADs in practice, and several articles haveargued that the availability of user-friendly software will be an importantstep in making ADs easier to implement. Therefore, in this paper we present areview of the current state of software availability for AD. Methods: We firstreview articles from 31 journals published in 2013-17 that relate tomethodology for adaptive trials, in order to assess how often code and softwarefor implementing novel ADs is made available at the time of publication. Wecontrast our findings against these journals' current policies on codedistribution. Secondly, we conduct additional searches of popular coderepositories, such as CRAN and GitHub, to identify further existinguser-contributed software for ADs. From this, we are able to direct interestedparties towards solutions for their problem of interest by classifyingavailable code by type of adaptation. Results: Only 29% of included articlesmade their code available in some form. In many instances, articles publishedin journals that had mandatory requirements on code provision still did notmake code available. There are several areas in which available software iscurrently limited or saturated. In particular, many packages are available toaddress group sequential design, but comparatively little code is present inthe public domain to determine biomarker-guided ADs. Conclusions: There is muchroom for improvement in the provision of software alongside AD publications.Additionally, whilst progress has been made, well-established software forvarious types of trial adaptation remains sparsely available.",
    "Article_Subject": "Computation (stat.CO)",
    "Article_Date": "2019/06/13",
    "Article_PDF": "https://arxiv.org/pdf/1906.05603"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.04554",
    "DOI": "arXiv:1906.04554v1",
    "Article_Title": "Principled Training of Neural Networks with Direct Feedback Alignment",
    "Article_Abstract": "The backpropagation algorithm has long been the canonical training method forneural networks. Modern paradigms are implicitly optimized for it, and numerousguidelines exist to ensure its proper use. Recently, synthetic gradientsmethods -where the error gradient is only roughly approximated - have garneredinterest. These methods not only better portray how biological brains arelearning, but also open new computational possibilities, such as updatinglayers asynchronously. Even so, they have failed to scale past simple taskslike MNIST or CIFAR-10. This is in part due to a lack of standards, leading toill-suited models and practices forbidding such methods from performing to thebest of their abilities. In this work, we focus on direct feedback alignmentand present a set of best practices justified by observations of the alignmentangles. We characterize a bottleneck effect that prevents alignment in narrowlayers, and hypothesize it may explain why feedback alignment methods have yetto scale to large convolutional networks.",
    "Article_Subject": "Machine Learning (stat.ML); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)",
    "Article_Date": "2019/06/11",
    "Article_PDF": "https://arxiv.org/pdf/1906.04554"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.04281",
    "DOI": "arXiv:1906.04281v1",
    "Article_Title": "Towards Amortized Ranking-Critical Training for Collaborative Filtering",
    "Article_Abstract": "Collaborative filtering is widely used in modern recommender systems. Recentresearch shows that variational autoencoders (VAEs) yield state-of-the-artperformance by integrating flexible representations from deep neural networksinto latent variable models, mitigating limitations of traditional linearfactor models. VAEs are typically trained by maximizing the likelihood (MLE) ofusers interacting with ground-truth items. While simple and often effective,MLE-based training does not directly maximize the recommendation-qualitymetrics one typically cares about, such as top-N ranking. In this paper weinvestigate new methods for training collaborative filtering models based onactor-critic reinforcement learning, to directly optimize thenon-differentiable quality metrics of interest. Specifically, we train a criticnetwork to approximate ranking-based metrics, and then update the actor network(represented here by a VAE) to directly optimize against the learned metrics.In contrast to traditional learning-to-rank methods that require to re-run theoptimization procedure for new lists, our critic-based method amortizes thescoring process with a neural network, and can directly provide the(approximate) ranking scores for new lists. Empirically, we show that theproposed methods outperform several state-of-the-art baselines, includingrecently-proposed deep learning approaches, on three large-scale real-worlddatasets. The code to reproduce the experimental results and figure plots is onGithub: https://github.com/samlobel/RaCT_CF",
    "Article_Subject": "Machine Learning (cs.LG); Information Retrieval (cs.IR); Machine Learning (stat.ML)",
    "Article_Date": "2019/06/10",
    "Article_PDF": "https://arxiv.org/pdf/1906.04281"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03951",
    "DOI": "arXiv:1906.03951v1",
    "Article_Title": "SCAN: A Scalable Neural Networks Framework Towards Compact and Efficient Models",
    "Article_Abstract": "Remarkable achievements have been attained by deep neural networks in variousapplications. However, the increasing depth and width of such models also leadto explosive growth in both storage and computation, which has restricted thedeployment of deep neural networks on resource-limited edge devices. To addressthis problem, we propose the so-called SCAN framework for networks training andinference, which is orthogonal and complementary to existing acceleration andcompression methods. The proposed SCAN firstly divides neural networks intomultiple sections according to their depth and constructs shallow classifiersupon the intermediate features of different sections. Moreover, attentionmodules and knowledge distillation are utilized to enhance the accuracy ofshallow classifiers. Based on this architecture, we further propose a thresholdcontrolled scalable inference mechanism to approach human-like sample-specificinference. Experimental results show that SCAN can be easily equipped onvarious neural networks without any adjustment on hyper-parameters or neuralnetworks architectures, yielding significant performance gain on CIFAR100 andImageNet. Codes will be released on github soon.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/27",
    "Article_PDF": "https://arxiv.org/pdf/1906.03951"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03773",
    "DOI": "arXiv:1906.03773v1",
    "Article_Title": "DataLearner: A Data Mining and Knowledge Discovery Tool for Android Smartphones and Tablets",
    "Article_Abstract": "Smartphones have become the ultimate 'personal' computer, yet despite this,general-purpose data-mining and knowledge discovery tools for mobile devicesare surprisingly rare. DataLearner is a new data-mining application designedspecifically for Android devices that imports the Weka data-mining engine andaugments it with algorithms developed by Charles Sturt University. Moreover,DataLearner can be expanded with additional algorithms. Combined, DataLearnerdelivers 40 classification, clustering and association rule mining algorithmsfor model training and evaluation without need for cloud computing resources ornetwork connectivity. It provides the same classification accuracy as PCs andlaptops, while doing so with acceptable processing speed and consumingnegligible battery life. With its ability to provide easy-to-use data-mining ona phone-size screen, DataLearner is a new portable, self-contained data-miningtool for remote, personalised and learning applications alike. DataLearnerfeatures four elements - this paper, the app available on Google Play, theGPL3-licensed source code on GitHub and a short video on YouTube.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/06/10",
    "Article_PDF": "https://arxiv.org/pdf/1906.03773"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03277",
    "DOI": "arXiv:1906.03277v1",
    "Article_Title": "xBIT: an easy to use scanning tool with machine learning abilities",
    "Article_Abstract": "xBIT is a tool for performing parameter scans in beyond the Standard Modeltheories. It's written in Python and fully open source. The main purpose ofxBIT is to provide an easy to use tool to help phenomenologists with theirdaily task: exploring the parameter space of new models. It was developed underthe impression of the SARAH/SPheno framework, but should be use-able with othertools as well that use the SLHA format to transfer data. It also supports bydefault MicrOmegas for dark matter calculations, HiggsBounds and HiggsSignalsfor checking the Higgs properties, and Vevacious for testing the vacuumstability. Classes for other tools can be added if necessary. In order toimprove the efficiency of the parameter scans, the recently proposed 'MachineLearning Scan' approach is included. For this purpose, xBIT uses pyTorch todeal with artificial neural networks.",
    "Article_Subject": "High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Experiment (hep-ex)",
    "Article_Date": "2019/06/07",
    "Article_PDF": "https://arxiv.org/pdf/1906.03277"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03049",
    "DOI": "arXiv:1906.03049v1",
    "Article_Title": "Computing Exact Guarantees for Differential Privacy",
    "Article_Abstract": "Quantification of the privacy loss associated with a randomised algorithm hasbecome an active area of research and $(\\varepsilon,\u03b4)$-differentialprivacy has arisen as the standard measure of it. We propose a numerical methodfor evaluating the parameters of differential privacy for algorithms withcontinuous one dimensional output. In this way the parameters $\\varepsilon$ and$\u03b4$ can be evaluated, for example, for the subsampled multidimensionalGaussian mechanism which is also the underlying mechanism of differentiallyprivate stochastic gradient descent. The proposed method is based on anumerical approximation of an integral formula which gives the exact$(\\varepsilon,\u03b4)$-values. The approximation is carried out by discretisingthe integral and by evaluating discrete convolutions using a fast Fouriertransform algorithm. We give theoretical error bounds which show theconvergence of the approximation and guarantee its accuracy to an arbitrarydegree. Experimental comparisons with state-of-the-art techniques illustratethe efficacy of the method. Python code for the proposed method can be found inGithub (https://github.com/DPBayes/PLD-Accountant/).",
    "Article_Subject": "Machine Learning (stat.ML); Cryptography and Security (cs.CR); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/07",
    "Article_PDF": "https://arxiv.org/pdf/1906.03049"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03008",
    "DOI": "arXiv:1906.03008v2",
    "Article_Title": "RankQA: Neural Question Answering with Answer Re-Ranking",
    "Article_Abstract": "The conventional paradigm in neural question answering (QA) for narrativecontent is limited to a two-stage process: first, relevant text passages areretrieved and, subsequently, a neural network for machine comprehensionextracts the likeliest answer. However, both stages are largely isolated in thestatus quo and, hence, information from the two phases is never properly fused.In contrast, this work proposes RankQA: RankQA extends the conventionaltwo-stage process in neural QA with a third stage that performs an additionalanswer re-ranking. The re-ranking leverages different features that aredirectly extracted from the QA pipeline, i.e., a combination of retrieval andcomprehension features. While our intentionally simple design allows for anefficient, data-sparse estimation, it nevertheless outperforms more complex QAsystems by a significant margin: in fact, RankQA achieves state-of-the-artperformance on 3 out of 4 benchmark datasets. Furthermore, its performance isespecially superior in settings where the size of the corpus is dynamic. Herethe answer re-ranking provides an effective remedy against the underlyingnoise-information trade-off due to a variable corpus size. As a consequence,RankQA represents a novel, powerful, and thus challenging baseline for futureresearch in content-based QA.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/06/07",
    "Article_PDF": "https://arxiv.org/pdf/1906.03008"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.02126",
    "DOI": "arXiv:1906.02126v1",
    "Article_Title": "Extractive Summarization via Weighted Dissimilarity and Importance Aligned Key Iterative Algorithm",
    "Article_Abstract": "We present importance aligned key iterative algorithm for extractivesummarization that is faster than conventional algorithms keeping its accuracy.The computational complexity of our algorithm is O($SNlogN$) to summarizeoriginal $N$ sentences into final $S$ sentences. Our algorithm maximizes theweighted dissimilarity defined by the product of importance and cosinedissimilarity so that the summary represents the document and at the same timethe sentences of the summary are not similar to each other. The weighteddissimilarity is heuristically maximized by iterative greedy search and binarysearch to the sentences ordered by importance. We finally show a benchmarkscore based on summarization of customer reviews of products, which highlightsthe quality of our algorithm comparable to human and existing algorithms. Weprovide the source code of our algorithm on githubhttps://github.com/qhapaq-49/imakita .",
    "Article_Subject": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/05/15",
    "Article_PDF": "https://arxiv.org/pdf/1906.02126"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.01388",
    "DOI": "arXiv:1906.01388v1",
    "Article_Title": "A Comprehensive Study on Deep Learning Bug Characteristics",
    "Article_Abstract": "Deep learning has gained substantial popularity in recent years. Developersmainly rely on libraries and tools to add deep learning capabilities to theirsoftware. What kinds of bugs are frequently found in such software? What arethe root causes of such bugs? What impacts do such bugs have? Which stages ofdeep learning pipeline are more bug prone? Are there any antipatterns?Understanding such characteristics of bugs in deep learning software has thepotential to foster the development of better deep learning platforms,debugging mechanisms, development practices, and encourage the development ofanalysis and verification frameworks. Therefore, we study 2716 high-qualityposts from Stack Overflow and 500 bug fix commits from Github about fivepopular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch tounderstand the types of bugs, root causes of bugs, impacts of bugs, bug-pronestage of deep learning pipeline as well as whether there are some commonantipatterns found in this buggy software. The key findings of our studyinclude: data bug and logic bug are the most severe bug types in deep learningsoftware appearing more than 48% of the times, major root causes of these bugsare Incorrect Model Parameter (IPS) and Structural Inefficiency (SI) showing upmore than 43% of the times. We have also found that the bugs in the usage ofdeep learning libraries have some common antipatterns that lead to a strongcorrelation of bug types among the libraries.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.01388"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.01211",
    "DOI": "arXiv:1906.01211v3",
    "Article_Title": "Raising the Performance of the Tinker-HP Molecular Modeling Package [Article v1.0]",
    "Article_Abstract": "This living paper reviews the present High Performance Computing (HPC)capabilities of the Tinker-HP molecular modeling package. We focus here on thereference, double precision, massively parallel molecular dynamics enginepresent in Tinker-HP and dedicated to perform large scale simulations. We showhow it can be adapted to recent Intel Central Processing Unit (CPU) petascalearchitectures. First, we discuss the new set of Intel Advanced VectorExtensions 512 (Intel AVX-512) instructions present in recent Intel processors(e.g., the Intel Xeon Scalable and Intel Xeon Phi 2nd generation processors)allowing for larger vectorization enhancements. These instructions constitutethe central source of potential computational gains when using the latestprocessors, justifying important vectorization efforts for developers. We thenbriefly review the organization of the Tinker-HP code and identify thecomputational hotspots which require Intel AVX-512 optimization and we proposea general and optimal strategy to vectorize those particular parts of the code.We intended to present our optimization strategy in a pedagogical way so itcould benefit to other researchers and students interested in gainingperformances in their own software. Finally we present the performanceenhancements obtained compared to the unoptimized code both sequentially and atthe scaling limit in parallel for classical non-polarizable (CHARMM) andpolarizable force fields (AMOEBA). This paper never ceases to be updated as weaccumulate new data on the associated Github repository between new versions ofthis living paper.",
    "Article_Subject": "Mathematical Software (cs.MS); Chemical Physics (physics.chem-ph); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/06/04",
    "Article_PDF": "https://arxiv.org/pdf/1906.01211"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.01032",
    "DOI": "arXiv:1906.01032v1",
    "Article_Title": "A Language-Agnostic Model for Semantic Source Code Labeling",
    "Article_Abstract": "Code search and comprehension have become more difficult in recent years dueto the rapid expansion of available source code. Current tools lack a way tolabel arbitrary code at scale while maintaining up-to-date representations ofnew programming languages, libraries, and functionalities. Comprehensivelabeling of source code enables users to search for documents of interest andobtain a high-level understanding of their contents. We use Stack Overflow codesnippets and their tags to train a language-agnostic, deep convolutional neuralnetwork to automatically predict semantic labels for source code documents. OnStack Overflow code snippets, we demonstrate a mean area under ROC of 0.957over a long-tailed list of 4,508 tags. We also manually validate the modeloutputs on a diverse set of unlabeled source code documents retrieved fromGithub, and we obtain a top-1 accuracy of 86.6%. This strongly indicates thatthe model successfully transfers its knowledge from Stack Overflow snippets toarbitrary source code documents.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Software Engineering (cs.SE); Machine Learning (stat.ML)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.01032"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.00966",
    "DOI": "arXiv:1906.00966v3",
    "Article_Title": "Wotan: Comprehensive time-series de-trending in Python",
    "Article_Abstract": "The detection of transiting exoplanets in time-series photometry requires theremoval or modeling of instrumental and stellar noise. While instrumentalsystematics can be reduced using methods such as pixel level decorrelation,removing stellar trends while preserving transit signals proves challenging.Due to vast archives of light curves from recent transit surveys, there is astrong need for accurate automatic detrending, without human intervention. Alarge variety of detrending algorithms are in active use, but their comparativeperformance for transit discovery is unexplored. We benchmark all commonly useddetrending methods against hundreds of Kepler, K2, and TESS planets, selectedto represent the most difficult cases for systems with small planet-to-starradius ratios. The full parameter range is explored for each method todetermine the best choices for planet discovery. We conclude that the idealmethod is a time-windowed slider with an iterative robust location estimatorbased on Tukey's biweight. This method recovers 99% and 94% of the shallowestKepler and K2 planets, respectively. We include an additional analysis foryoung stars with extreme variability and conclude they are best treated using aspline-based method with a robust Huber estimator. All stellar detrendingmethods explored are available for public use in wotan, an open-source Pythonpackage on GitHub (see https://github.com/hippke/wotan).",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.00966"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.00925",
    "DOI": "arXiv:1906.00925v2",
    "Article_Title": "3D Appearance Super-Resolution with Deep Learning",
    "Article_Abstract": "We tackle the problem of retrieving high-resolution (HR) texture maps ofobjects that are captured from multiple view points. In the multi-view case,model-based super-resolution (SR) methods have been recently proved to recoverhigh quality texture maps. On the other hand, the advent of deep learning-basedmethods has already a significant impact on the problem of video and image SR.Yet, a deep learning-based approach to super-resolve the appearance of 3Dobjects is still missing. The main limitation of exploiting the power of deeplearning techniques in the multi-view case is the lack of data. We introduce a3D appearance SR (3DASR) dataset based on the existing ETH3D [42], SyB3R [31],MiddleBury, and our Collection of 3D scenes from TUM [21], Fountain [51] andRelief [53]. We provide the high- and low-resolution texture maps, the 3Dgeometric model, images and projection matrices. We exploit the power of 2Dlearning-based SR methods and design networks suitable for the 3D multi-viewcase. We incorporate the geometric information by introducing normal maps andfurther improve the learning process. Experimental results demonstrate that ourproposed networks successfully incorporate the 3D geometric information andsuper-resolve the texture maps.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.00925"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.00657",
    "DOI": "arXiv:1906.00657v1",
    "Article_Title": "Kandinsky Patterns",
    "Article_Abstract": "Kandinsky Figures and Kandinsky Patterns are mathematically describable,simple self-contained hence controllable test data sets for the development,validation and training of explainability in artificial intelligence. WhilstKandinsky Patterns have these computationally manageable properties, they areat the same time easily distinguishable from human observers. Consequently,controlled patterns can be described by both humans and computers. We define aKandinsky Pattern as a set of Kandinsky Figures, where for each figure an\"infallible authority\" defines that the figure belongs to the KandinskyPattern. With this simple principle we build training and validation data setsfor automatic interpretability and context learning. In this paper we describethe basic idea and some underlying principles of Kandinsky Patterns and providea Github repository to invite the international machine learning researchcommunity to a challenge to experiment with our Kandinsky Patterns to expandand thus make progress in the field of explainable AI and to contribute to theupcoming field of explainability and causability.",
    "Article_Subject": "Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.00657"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.13658",
    "DOI": "arXiv:1905.13658v1",
    "Article_Title": "Ordinal Regression as Structured Classification",
    "Article_Abstract": "This paper extends the class of ordinal regression models with a structuredinterpretation of the problem by applying a novel treatment of encoded labels.The net effect of this is to transform the underlying problem from an ordinalregression task to a (structured) classification task which we solve withconditional random fields, thereby achieving a coherent and probabilistic modelin which all model parameters are jointly learnt. Importantly, we show thatalthough we have cast ordinal regression to classification, our method stillfall within the class of decomposition methods in the ordinal regressionontology. This is an important link since our experience is that manyapplications of machine learning to healthcare ignores completely the importantnature of the label ordering, and hence these approaches should considerednaive in this ontology. We also show that our model is flexible both in how itadapts to data manifolds and in terms of the operations that are available forpractitioner to execute. Our empirical evaluation demonstrates that theproposed approach overwhelmingly produces superior and often statisticallysignificant results over baseline approaches on forty popular ordinalregression models, and demonstrate that the proposed model significantlyout-performs baselines on synthetic and real datasets. Our implementation,together with scripts to reproduce the results of this work, will be availableon a public GitHub repository.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/31",
    "Article_PDF": "https://arxiv.org/pdf/1905.13658"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.13313",
    "DOI": "arXiv:1905.13313v5",
    "Article_Title": "Technical Report of the Video Event Reconstruction and Analysis (VERA) System -- Shooter Localization, Models, Interface, and Beyond",
    "Article_Abstract": "Every minute, hundreds of hours of video are uploaded to social media sitesand the Internet from around the world. This material creates a visual recordof the experiences of a significant percentage of humanity and can helpilluminate how we live in the present moment. When properly analyzed, thisvideo can also help analysts to reconstruct events of interest, including warcrimes, human rights violations, and terrorist acts. Machine learning andcomputer vision can play a crucial role in this process. In this technicalreport, we describe the Video Event Reconstruction and Analysis (VERA) system.This new tool brings together a variety of capabilities we have developed overthe past few years (including video synchronization and geolocation to orderunstructured videos lacking metadata over time and space, and sound recognitionalgorithms) to enable the reconstruction and analysis of events captured onvideo. Among other uses, VERA enables the localization of a shooter from just afew videos that include the sound of gunshots. To demonstrate the efficacy ofthis suite of tools, we present the results of estimating the shooter'slocation of the Las Vegas Shooting in 2017 and show that VERA accuratelypredicts the shooter's location using only the first few gunshots. We thenpoint out future directions that can help improve the system and further reduceunnecessary human labor in the process. All of the components of VERA runthrough a web interface that enables human-in-the-loop verification to ensureaccurate estimations. All relevant source code, including the web interface andmachine learning models, is freely available on Github. We hope thatresearchers and software developers will be inspired to improve and expand thissystem moving forward to better meet the needs of human rights and publicsafety.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multimedia (cs.MM)",
    "Article_Date": "2019/05/26",
    "Article_PDF": "https://arxiv.org/pdf/1905.13313"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.12768",
    "DOI": "arXiv:1905.12768v2",
    "Article_Title": "Using Propensity Scores to Develop and Evaluate Treatment Rules with Observational Data",
    "Article_Abstract": "In this paper, we outline a principled approach to estimate an individualizedtreatment rule that is appropriate for data from observational studies where,in addition to treatment assignment not being independent of individualcharacteristics, some characteristics may affect treatment assignment in thecurrent study but not be available in future clinical settings where theestimated rule would be applied. The estimation framework is quite flexible andaccommodates any prediction method that uses observation weights, where theobservation weights themselves are a ratio of two flexibly estimated propensityscores. We also discuss how to obtain a trustworthy estimate of the rule'spopulation benefit based on simple propensity-score-based estimators of averagetreatment effect. We implement our approach in the R package DevTreatRules andshare the code needed to reproduce our results on GitHub.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/05/29",
    "Article_PDF": "https://arxiv.org/pdf/1905.12768"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.12111",
    "DOI": "arXiv:1905.12111v1",
    "Article_Title": "Analyzing and Supporting Adaptation of Online Code Examples",
    "Article_Abstract": "Developers often resort to online Q&A forums such as Stack Overflow (SO) forfilling their programming needs. Although code examples on those forums aregood starting points, they are often incomplete and inadequate for developers'local program contexts; adaptation of those examples is necessary to integratethem to production code. As a consequence, the process of adapting online codeexamples is done over and over again, by multiple developers independently. Ourwork extensively studies these adaptations and variations, serving as the basisfor a tool that helps integrate these online code examples in a target contextin an interactive manner.  We perform a large-scale empirical study about the nature and extent ofadaptations and variations of SO snippets. We construct a comprehensive datasetlinking SO posts to GitHub counterparts based on clone detection, time stampanalysis, and explicit URL references. We then qualitatively inspect 400 SOexamples and their GitHub counterparts and develop a taxonomy of 24 adaptationtypes. Using this taxonomy, we build an automated adaptation analysis techniqueon top of GumTree to classify the entire dataset into these types. We build aChrome extension called ExampleStack that automatically lifts anadaptation-aware template from each SO example and its GitHub counterparts toidentify hot spots where most changes happen. A user study with sixteenprogrammers shows that seeing the commonalities and variations in similarGitHub counterparts increases their confidence about the given SO example, andhelps them grasp a more comprehensive view about how to reuse the exampledifferently and avoid common pitfalls.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/28",
    "Article_PDF": "https://arxiv.org/pdf/1905.12111"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.11830",
    "DOI": "arXiv:1905.11830v2",
    "Article_Title": "A Graph Theoretic Additive Approximation of Optimal Transport",
    "Article_Abstract": "Transportation cost is an attractive similarity measure between probabilitydistributions due to its many useful theoretical properties. However, solvingoptimal transport exactly can be prohibitively expensive. Therefore, there hasbeen significant effort towards the design of scalable approximationalgorithms. Previous combinatorial results [Sharathkumar, Agarwal STOC '12,Agarwal, Sharathkumar STOC '14] have focused primarily on the design ofstrongly polynomial multiplicative approximation algorithms. There has alsobeen an effort to design approximate solutions with additive errors [CuturiNIPS '13, Altschuler et. al NIPS '17, Dvurechensky et al., ICML '18, Quanrud,SOSA '19] within a time bound that is linear in the size of the cost matrix andpolynomial in $C/\u03b4$; here $C$ is the largest value in the cost matrix and$\u03b4$ is the additive error. We present an adaptation of the classical graphalgorithm of Gabow and Tarjan and provide a novel analysis of this algorithmthat bounds its execution time by $O(\\frac{n^2 C}\u03b4+\\frac{nC^2}{\u03b4^2})$. Our algorithm is extremely simple and executes, for anarbitrarily small constant $\\varepsilon$, only $\\lfloor\\frac{2C}{(1-\\varepsilon)\u03b4}\\rfloor + 1$ iterations, where each iterationconsists only of a Dijkstra search followed by a depth-first search. We alsoprovide empirical results that suggest our algorithm significantly outperformsexisting approaches in execution time.",
    "Article_Subject": "Machine Learning (cs.LG); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/28",
    "Article_PDF": "https://arxiv.org/pdf/1905.11830"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.11681",
    "DOI": "arXiv:1905.11681v2",
    "Article_Title": "Validating the Validation: Reanalyzing a large-scale comparison of Deep Learning and Machine Learning models for bioactivity prediction",
    "Article_Abstract": "Machine learning methods may have the potential to significantly acceleratedrug discovery. However, the increasing rate of new methodological approachesbeing published in the literature raises the fundamental question of how modelsshould be benchmarked and validated. We reanalyze the data generated by arecently published large-scale comparison of machine learning models forbioactivity prediction and arrive at a somewhat different conclusion. We showthat the performance of support vector machines is competitive with that ofdeep learning methods. Additionally, using a series of numerical experiments,we question the relevance of area under the receiver operating characteristiccurve as a metric in virtual screening, and instead suggest that area under theprecision-recall curve should be used in conjunction with the receiveroperating characteristic. Our numerical experiments also highlight challengesin estimating the uncertainty in model performance via scaffold-split nestedcross validation.",
    "Article_Subject": "Machine Learning (cs.LG); Chemical Physics (physics.chem-ph); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/28",
    "Article_PDF": "https://arxiv.org/pdf/1905.11681"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.11127",
    "DOI": "arXiv:1905.11127v1",
    "Article_Title": "DockerizeMe: Automatic Inference of Environment Dependencies for Python Code Snippets",
    "Article_Abstract": "Platforms like Stack Overflow and GitHub's gist system promote the sharing ofideas and programming techniques via the distribution of code snippets designedto illustrate particular tasks. Python, a popular and fast-growing programminglanguage, sees heavy use on both sites, with nearly one million questions askedon Stack Overflow and 400 thousand public gists on GitHub. Unfortunately,around 75% of the Python example code shared through these sites cannot bedirectly executed. When run in a clean environment, over 50% of public Pythongists fail due to an import error for a missing library.  We present DockerizeMe, a technique for inferring the dependencies needed toexecute a Python code snippet without import error. DockerizeMe starts withoffline knowledge acquisition of the resources and dependencies for popularPython packages from the Python Package Index (PyPI). It then builds Dockerspecifications using a graph-based inference procedure. Our inference procedureresolves import errors in 892 out of nearly 3,000 gists from the Gistabledataset for which Gistable's baseline approach could not find and install alldependencies.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/27",
    "Article_PDF": "https://arxiv.org/pdf/1905.11127"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.10536",
    "DOI": "arXiv:1905.10536v1",
    "Article_Title": "DeepRec: An Open-source Toolkit for Deep Learning based Recommendation",
    "Article_Abstract": "Deep learning based recommender systems have been extensively explored inrecent years. However, the large number of models proposed each year poses abig challenge for both researchers and practitioners in reproducing the resultsfor further comparisons. Although a portion of papers provides source code,they adopted different programming languages or different deep learningpackages, which also raises the bar in grasping the ideas. To alleviate thisproblem, we released the open source project: \\textbf{DeepRec}. In thistoolkit, we have implemented a number of deep learning based recommendationalgorithms using Python and the widely used deep learning package - Tensorflow.Three major recommendation scenarios: rating prediction, top-N recommendation(item ranking) and sequential recommendation, were considered. Meanwhile,DeepRec maintains good modularity and extensibility to easily incorporate newmodels into the framework. It is distributed under the terms of the GNU GeneralPublic License. The source code is available at github:\\url{https://github.com/cheungdaven/DeepRec}",
    "Article_Subject": "Information Retrieval (cs.IR); Machine Learning (cs.LG)",
    "Article_Date": "2019/05/25",
    "Article_PDF": "https://arxiv.org/pdf/1905.10536"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.09907",
    "DOI": "arXiv:1905.09907v1",
    "Article_Title": "Multi-level Texture Encoding and Representation (MuLTER) based on Deep Neural Networks",
    "Article_Abstract": "In this paper, we propose a multi-level texture encoding and representationnetwork (MuLTER) for texture-related applications. Based on a multi-levelpooling architecture, the MuLTER network simultaneously leverages low- andhigh-level features to maintain both texture details and spatial information.Such a pooling architecture involves few extra parameters and keeps featuredimensions fixed despite of the changes of image sizes. In comparison withstate-of-the-art texture descriptors, the MuLTER network yields higherrecognition accuracy on typical texture datasets such as MINC-2500 andGTOS-mobile with a discriminative and compact representation. In addition, weanalyze the impact of combining features from different levels, which supportsour claim that the fusion of multi-level features efficiently enhancesrecognition performance. Our source code will be published on GitHub(https://github.com/olivesgatech).",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/05/23",
    "Article_PDF": "https://arxiv.org/pdf/1905.09907"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.09717",
    "DOI": "arXiv:1905.09717v2",
    "Article_Title": "Network Pruning via Transformable Architecture Search",
    "Article_Abstract": "Network pruning reduces the computation costs of an over-parameterizednetwork without performance damage. Prevailing pruning algorithms pre-definethe width and depth of the pruned networks, and then transfer parameters fromthe unpruned network to pruned networks. To break the structure limitation ofthe pruned networks, we propose to apply neural architecture search to searchdirectly for a network with flexible channel and layer sizes. The number of thechannels/layers is learned by minimizing the loss of the pruned networks. Thefeature map of the pruned network is an aggregation of K feature map fragments(generated by K networks of different sizes), which are sampled based on theprobability distribution.The loss can be back-propagated not only to thenetwork weights, but also to the parameterized distribution to explicitly tunethe size of the channels/layers. Specifically, we apply channel-wiseinterpolation to keep the feature map with different channel sizes aligned inthe aggregation procedure. The maximum probability for the size in eachdistribution serves as the width and depth of the pruned network, whoseparameters are learned by knowledge transfer, e.g., knowledge distillation,from the original networks. Experiments on CIFAR-10, CIFAR-100 and ImageNetdemonstrate the effectiveness of our new perspective of network pruningcompared to traditional network pruning algorithms. Various searching andknowledge transfer approaches are conducted to show the effectiveness of thetwo components.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/05/23",
    "Article_PDF": "https://arxiv.org/pdf/1905.09717"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.09263",
    "DOI": "arXiv:1905.09263v4",
    "Article_Title": "FastSpeech: Fast, Robust and Controllable Text to Speech",
    "Article_Abstract": "Neural network based end-to-end text to speech (TTS) has significantlyimproved the quality of synthesized speech. Prominent methods (e.g., Tacotron2) usually first generate mel-spectrogram from text, and then synthesize speechfrom mel-spectrogram using vocoder such as WaveNet. Compared with traditionalconcatenative and statistical parametric approaches, neural network basedend-to-end models suffer from slow inference speed, and the synthesized speechis usually not robust (i.e., some words are skipped or repeated) and lack ofcontrollability (voice speed or prosody control). In this work, we propose anovel feed-forward network based on Transformer to generate mel-spectrogram inparallel for TTS. Specifically, we extract attention alignments from anencoder-decoder based teacher model for phoneme duration prediction, which isused by a length regulator to expand the source phoneme sequence to match thelength of target mel-spectrogram sequence for parallel mel-spectrogramgeneration. Experiments on the LJSpeech dataset show that our parallel modelmatches autoregressive models in terms of speech quality, nearly eliminates theproblem of word skipping and repeating in particularly hard cases, and canadjust voice speed smoothly. Most importantly, compared with autoregressiveTransformer TTS, our model speeds up the mel-spectrogram generation by 270x andthe end-to-end speech synthesis by 38x. Therefore, we call our modelFastSpeech. We will release the code on Github. Synthesized speech samples canbe found in https://speechresearch.github.io/fastspeech/.",
    "Article_Subject": "Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "Article_Date": "2019/05/22",
    "Article_PDF": "https://arxiv.org/pdf/1905.09263"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08880",
    "DOI": "arXiv:1905.08880v1",
    "Article_Title": "A Scalable Hybrid Research Paper Recommender System for Microsoft Academic",
    "Article_Abstract": "We present the design and methodology for the large scale hybrid paperrecommender system used by Microsoft Academic. The system providesrecommendations for approximately 160 million English research papers andpatents. Our approach handles incomplete citation information while alsoalleviating the cold-start problem that often affects other recommendersystems. We use the Microsoft Academic Graph (MAG), titles, and availableabstracts of research papers to build a recommendation list for all documents,thereby combining co-citation and content based approaches. Tuning systemparameters also allows for blending and prioritization of each approach which,in turn, allows us to balance paper novelty versus authority in recommendationresults. We evaluate the generated recommendations via a user study of 40participants, with over 2400 recommendation pairs graded and discuss thequality of the results using P@10 and nDCG scores. We see that there is astrong correlation between participant scores and the similarity rankingsproduced by our system but that additional focus needs to be put towardsimproving recommender precision, particularly for content basedrecommendations. The results of the user survey and associated analysis scriptsare made available via GitHub and the recommendations produced by our systemare available as part of the MAG on Azure to facilitate further research andlight up novel research paper recommendation applications.",
    "Article_Subject": "Digital Libraries (cs.DL); Information Retrieval (cs.IR); Machine Learning (cs.LG)",
    "Article_Date": "2019/05/21",
    "Article_PDF": "https://arxiv.org/pdf/1905.08880"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08667",
    "DOI": "arXiv:1905.08667v1",
    "Article_Title": "Legacy Archive for Microwave Background Data Analysis (LAMBDA): An Overview",
    "Article_Abstract": "This is an overview of the data products and other resources availablethrough NASA's LAMBDA site https://lambda.gsfc.nasa.gov/. An up-to-date versionof this document, along with code tools actively maintained and developed byLAMBDA staff, can be found on the LAMBDA GitHub page athttps://github.com/nasa-lambda/lambda_overview. New data products and otherupdates are announced on LAMBDA's twitter account athttps://twitter.com/NASA_LAMBDA. If you have questions or suggestions relatingto LAMBDA, or are interested in joining a LAMBDA advisory group, please contactus using the form here: https://lambda.gsfc.nasa.gov/contact/contact.cfm.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Article_Date": "2019/05/21",
    "Article_PDF": "https://arxiv.org/pdf/1905.08667"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08628",
    "DOI": "arXiv:1905.08628v1",
    "Article_Title": "Constraining the Parameters of High-Dimensional Models with Active Learning",
    "Article_Abstract": "Constraining the parameters of physical models with $>5-10$ parameters is awidespread problem in fields like particle physics and astronomy. In this paperwe show that this problem can be alleviated by the use of active learning. Weillustrate this with examples from high energy physics, a field wherecomputationally expensive simulations and large parameter spaces are common. Weshow that the active learning techniques query-by-committee andquery-by-dropout-committee allow for the identification of model points ininteresting regions of high-dimensional parameter spaces (e.g. around decisionboundaries). This makes it possible to constrain model parameters moreefficiently than is currently done with the most common sampling algorithms.Code implementing active learning can be found on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Instrumentation and Methods for Astrophysics (astro-ph.IM); High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Theory (hep-th)",
    "Article_Date": "2019/05/19",
    "Article_PDF": "https://arxiv.org/pdf/1905.08628"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08094",
    "DOI": "arXiv:1905.08094v1",
    "Article_Title": "Be Your Own Teacher: Improve the Performance of Convolutional Neural Networks via Self Distillation",
    "Article_Abstract": "Convolutional neural networks have been widely deployed in variousapplication scenarios. In order to extend the applications' boundaries to someaccuracy-crucial domains, researchers have been investigating approaches toboost accuracy through either deeper or wider network structures, which bringswith them the exponential increment of the computational and storage cost,delaying the responding time. In this paper, we propose a general trainingframework named self distillation, which notably enhances the performance(accuracy) of convolutional neural networks through shrinking the size of thenetwork rather than aggrandizing it. Different from traditional knowledgedistillation - a knowledge transformation methodology among networks, whichforces student neural networks to approximate the softmax layer outputs ofpre-trained teacher neural networks, the proposed self distillation frameworkdistills knowledge within network itself. The networks are firstly divided intoseveral sections. Then the knowledge in the deeper portion of the networks issqueezed into the shallow ones. Experiments further prove the generalization ofthe proposed self distillation framework: enhancement of accuracy at averagelevel is 2.65%, varying from 0.61% in ResNeXt as minimum to 4.07% in VGG19 asmaximum. In addition, it can also provide flexibility of depth-wise scalableinference on resource-limited edge devices.Our codes will be released on githubsoon.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/17",
    "Article_PDF": "https://arxiv.org/pdf/1905.08094"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.07650",
    "DOI": "arXiv:1905.07650v1",
    "Article_Title": "SAWNet: A Spatially Aware Deep Neural Network for 3D Point Cloud Processing",
    "Article_Abstract": "Deep neural networks have established themselves as the state-of-the-artmethodology in almost all computer vision tasks to date. But their applicationto processing data lying on non-Euclidean domains is still a very active areaof research. One such area is the analysis of point cloud data which poses achallenge due to its lack of order. Many recent techniques have been proposed,spearheaded by the PointNet architecture. These techniques use either global orlocal information from the point clouds to extract a latent representation forthe points, which is then used for the task at hand(classification/segmentation). In our work, we introduce a neural network layerthat combines both global and local information to produce better embeddings ofthese points. We enhance our architecture with residual connections, to passinformation between the layers, which also makes the network easier to train.We achieve state-of-the-art results on the ModelNet40 dataset with ourarchitecture, and our results are also highly competitive with thestate-of-the-art on the ShapeNet part segmentation dataset and the indoor scenesegmentation dataset. We plan to open source our pre-trained models on githubto encourage the research community to test our networks on their data, orsimply use them for benchmarking purposes.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/05/18",
    "Article_PDF": "https://arxiv.org/pdf/1905.07650"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.06280",
    "DOI": "arXiv:1905.06280v1",
    "Article_Title": "Trustee: Full Privacy Preserving Vickrey Auction on top of Ethereum",
    "Article_Abstract": "The wide deployment of tokens for digital assets on top of Ethereum impliesthe need for powerful trading platforms. Vickrey auctions have been known todetermine the real market price of items as bidders are motivated to submittheir own monetary valuations without leaking their information to thecompetitors. Recent constructions have utilized various cryptographic protocolssuch as ZKP and MPC, however, these approaches either are partiallyprivacy-preserving or require complex computations with several rounds. In thispaper, we overcome these limits by presenting Trustee as a Vickrey auction onEthereum which fully preserves bids' privacy at relatively much lower fees.Trustee consists of three components: a front-end smart contract deployed onEthereum, an Intel SGX enclave, and a relay to redirect messages between them.Initially, the enclave generates an Ethereum account and ECDH key-pair.Subsequently, the relay publishes the account's address and ECDH public key onthe smart contract. As a prerequisite, bidders are encouraged to verify theauthenticity and security of Trustee by using the SGX remote attestationservice. To participate in the auction, bidders utilize the ECDH public key toencrypt their bids and submit them to the smart contract. Once the biddinginterval is closed, the relay retrieves the encrypted bids and feeds them tothe enclave that autonomously generates a signed transaction indicating theauction winner. Finally, the relay submits the transaction to the smartcontract which verifies the transaction's authenticity and the parameters'consistency before accepting the claimed auction winner. As part of ourcontributions, we have made a prototype for Trustee available on Github for thecommunity to review and inspect it. Additionally, we analyze the securityfeatures of Trustee and report on the transactions' gas cost incurred onTrustee smart contract.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/05/15",
    "Article_PDF": "https://arxiv.org/pdf/1905.06280"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.04482",
    "DOI": "arXiv:1905.04482v1",
    "Article_Title": "GE852: A Dataset of 852 Game Engines",
    "Article_Abstract": "Game engines provide a platform for developers to build games with aninterface tailored to handle the complexity during game development. To reduceeffort and improve quality of game development, there is a strong need tounderstand and analyze the quality of game engines and their various aspectssuch as API usability, code quality, code reuse and so on. To the best ourknowledge, we are not aware of any dataset that caters to game engines in theliterature. To this end, we present GE852, a dataset of 852 game enginerepositories mined from GitHub in two languages, namely Java and C++. Thedataset contains metadata of all the mined repositories including commits, pullrequests, issues and so on. We believe that our dataset can lay foundation forempirical investigation in the area of game engines.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/11",
    "Article_PDF": "https://arxiv.org/pdf/1905.04482"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.04303",
    "DOI": "arXiv:1905.04303v1",
    "Article_Title": "Using Convolutional Neural Networks to identify Gravitational Lenses in Astronomical images",
    "Article_Abstract": "The Euclid telescope, due for launch in 2021, will perform an imaging andslitless spectroscopy survey over half the sky, to map baryon wiggles and weaklensing. During the survey Euclid is expected to resolve 100,000 stronggravitational lens systems. This is ideal to find rare lens configurations,provided they can be identified reliably and on a reasonable timescale. Forthis reason we have developed a Convolutional Neural Network (CNN) that can beused to identify images containing lensing systems. CNNs have already been usedfor image and digit classification as well as being used in astronomy forstar-galaxy classification. Here our CNN is trained and tested on Euclid-likeand KiDS-like simulations from the Euclid Strong Lensing Group, successfullyclassifying 77% of lenses, with an area under the ROC curve of up to 0.96. OurCNN also attempts to classify the lenses in COSMOS HST F814W-band images. Afterconvolution to the Euclid resolution, we find we can recover most systems thatare identifiable by eye. The Python code is available on Github.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Astrophysics of Galaxies (astro-ph.GA)",
    "Article_Date": "2019/05/10",
    "Article_PDF": "https://arxiv.org/pdf/1905.04303"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.04294",
    "DOI": "arXiv:1905.04294v1",
    "Article_Title": "Fruitbat: A Python Package for Estimating Redshifts of Fast Radio Bursts",
    "Article_Abstract": "Fruitbat is an open source Python 2/3 package for estimating redshifts,energies and the galactic dispersion measure contributions of fast radio bursts(FRBs). Fruitbat combines various dispersion measure (DM) and redshiftrelations with the YMW16 galactic dispersion measure model into a single easyto use API.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); High Energy Astrophysical Phenomena (astro-ph.HE)",
    "Article_Date": "2019/05/10",
    "Article_PDF": "https://arxiv.org/pdf/1905.04294"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.03593",
    "DOI": "arXiv:1905.03593v3",
    "Article_Title": "A Topological Analysis of Communication Channels for Knowledge Sharing in Contemporary GitHub Projects",
    "Article_Abstract": "With over 28 million developers, success of the GitHub collaborative platformis highlighted through an abundance of communication channels amongcontemporary software projects. Knowledge is broken into two forms and itssharing (through communication channels) can be described as externalization orcombination by the SECI model. Such platforms have revolutionized the waydevelopers work, introducing new channels to share knowledge in the form ofpull requests, issues and wikis. It is unclear how these channels capture andshare knowledge. In this research, our goal is to analyze these communicationchannels in GitHub. First, using the SECI model, we are able to map howknowledge is shared through the communication channels. Then in a large-scaletopology analysis of seven library package projects (i.e., involving over 70thousand projects), we extracted insights of the different communicationchannels within GitHub. Using two research questions, we explored the evolutionof the channels and adoption of channels by both popular and unpopular librarypackage projects. Results show that (i) contemporary GitHub Projects tend toadopt multiple communication channels, (ii) communication channels change overtime and (iii) communication channels are used to both capture new knowledge(i.e., externalization) and updating existing knowledge (i.e., combination).",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/09",
    "Article_PDF": "https://arxiv.org/pdf/1905.03593"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.02050",
    "DOI": "arXiv:1905.02050v1",
    "Article_Title": "Analyzing Code Comments to Boost Program Comprehension",
    "Article_Abstract": "We are trying to find source code comments that help programmers understand anontrivial part of source code. One of such examples would be explaining toassign a zero as a way to \"clear\" a buffer. Such comments are invaluable toprogrammers and identifying them correctly would be of great help. Toward thisgoal, we developed a method to discover explanatory code comments in a sourcecode. We first propose eleven distinct categories of code comments. We thendeveloped a decision-tree based classifier that can identify explanatorycomments with 60% precision and 80% recall. We analyzed 2,000 GitHub projectsthat are written in two languages: Java and Python. This task is novel in thatit focuses on a microscopic comment (\"local comment\") within a method orfunction, in contrast to the prior efforts that focused on API- or method-levelcomments. We also investigated how different category of comments is used indifferent projects. Our key finding is that there are two dominant types ofcomments: preconditional and postconditional. Our findings also suggest thatmany English code comments have a certain grammatical structure that areconsistent across different projects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/06",
    "Article_PDF": "https://arxiv.org/pdf/1905.02050"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.02005",
    "DOI": "arXiv:1905.02005v2",
    "Article_Title": "Deep Ordinal Reinforcement Learning",
    "Article_Abstract": "Reinforcement learning usually makes use of numerical rewards, which havenice properties but also come with drawbacks and difficulties. Using rewards onan ordinal scale (ordinal rewards) is an alternative to numerical rewards thathas received more attention in recent years. In this paper, a general approachto adapting reinforcement learning problems to the use of ordinal rewards ispresented and motivated. We show how to convert common reinforcement learningalgorithms to an ordinal variation by the example of Q-learning and introduceOrdinal Deep Q-Networks, which adapt deep reinforcement learning to ordinalrewards. Additionally, we run evaluations on problems provided by the OpenAIGym framework, showing that our ordinal variants exhibit a performance that iscomparable to the numerical variations for a number of problems. We also givefirst evidence that our ordinal variant is able to produce better results forproblems with less engineered and simpler-to-design reward signals.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/06",
    "Article_PDF": "https://arxiv.org/pdf/1905.02005"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.01833",
    "DOI": "arXiv:1905.01833v3",
    "Article_Title": "Characterizing and Detecting CUDA Program Bugs",
    "Article_Abstract": "While CUDA has become a major parallel computing platform and programmingmodel for general-purpose GPU computing, CUDA-induced bug patterns have not yetbeen well explored. In this paper, we conduct the first empirical study toreveal important categories of CUDA program bug patterns based on 319 bugsidentified within 5 popular CUDA projects in GitHub. Our findings demonstratethat CUDA-specific characteristics may cause program bugs such assynchronization bugs that are rather difficult to detect. To efficiently detectsuch synchronization bugs, we establish the first lightweight general CUDA bugdetection framework, namely Simulee, to simulate CUDA program execution byinterpreting the corresponding llvm bytecode and collecting the memory-accessinformation to automatically detect CUDA synchronization bugs. To evaluate theeffectiveness and efficiency of Simulee, we conduct a set of experiments andthe experimental results suggest that Simulee can detect 20 out of the 27studied synchronization bugs and successfully detects 26 previously unknownsynchronization bugs, 10 of which have been confirmed by the developers.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/06",
    "Article_PDF": "https://arxiv.org/pdf/1905.01833"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.00976",
    "DOI": "arXiv:1905.00976v2",
    "Article_Title": "Collaborative Evolutionary Reinforcement Learning",
    "Article_Abstract": "Deep reinforcement learning algorithms have been successfully applied to arange of challenging control tasks. However, these methods typically strugglewith achieving effective exploration and are extremely sensitive to the choiceof hyperparameters. One reason is that most approaches use a noisy version oftheir operating policy to explore - thereby limiting the range of exploration.In this paper, we introduce Collaborative Evolutionary Reinforcement Learning(CERL), a scalable framework that comprises a portfolio of policies thatsimultaneously explore and exploit diverse regions of the solution space. Acollection of learners - typically proven algorithms like TD3 - optimize overvarying time-horizons leading to this diverse portfolio. All learnerscontribute to and use a shared replay buffer to achieve greater sampleefficiency. Computational resources are dynamically distributed to favor thebest learners as a form of online algorithm selection. Neuroevolution bindsthis entire process to generate a single emergent learner that exceeds thecapabilities of any individual learner. Experiments in a range of continuouscontrol benchmarks demonstrate that the emergent learner significantlyoutperforms its composite learners while remaining overall moresample-efficient - notably solving the Mujoco Humanoid benchmark where all ofits composite learners (TD3) fail entirely in isolation.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/02",
    "Article_PDF": "https://arxiv.org/pdf/1905.00976"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.00221",
    "DOI": "arXiv:1905.00221v1",
    "Article_Title": "Concerns about the reliability of publicly available SNe Ia data",
    "Article_Abstract": "I highlight several concerns regarding the consistency of Type Ia supernovadata in the publicly available Pantheon and JLA compilations. The measuredheliocentric redshifts (zhel) of $\\sim$150 SNe Ia as reported in the Pantheoncatalogue are significantly discrepant from those in JLA - with 58 havingdifferences amounting to between 5 and 137 times the quoted measurementuncertainty. The discrepancy seems to have been introduced in the process ofrectifying a previously reported issue. The Pantheon catalogue until veryrecently had the redshifts of all SNe Ia up to z $\\sim$ 0.3 modified under theguise of 'peculiar velocity corrections' - although there is no information onpeculiar velocities at such high redshifts. While this has reportedly beenrectified on Github by removing peculiar velocity corrections for z > 0.08, theimpact of this on the published cosmological analysis of the Pantheon catalogueis not stated. In JLA, the effect of these 'corrections' is to significantlybias the inferred value of $\u03a9_\u039b$ towards higher values, while theequivalent effect on Pantheon cannot be ascertained due to the unavailabilityof the individual components of the covariance matrix in the public domain. Iprovide Jupyter notebooks and URLs in order to allow the reader to ascertainthe veracity of these assertions.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Article_Date": "2019/05/01",
    "Article_PDF": "https://arxiv.org/pdf/1905.00221"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.12903",
    "DOI": "arXiv:1904.12903v1",
    "Article_Title": "Modified Gravity Away from a $\\Lambda$CDM Background",
    "Article_Abstract": "Within the effective field theory approach to cosmic acceleration, thebackground expansion can be specified separately from the gravitationalmodifications. We explore the impact of modified gravity in a backgrounddifferent from a cosmological constant plus cold dark matter ($\u039b$CDM) onthe stability and cosmological observables, including covariance betweengravity and expansion parameters. In No Slip Gravity the more generalbackground allows more gravitational freedom, including both positive andnegative Planck mass running. We examine the effects on cosmic structuregrowth, as well as showing that a viable positive integrated Sachs-Wolfe effectcrosscorrelation easily arises from this modified gravity theory. Using currentdata we constrain parameters with a Monte Carlo analysis, finding a maximumrunning $|\u03b1_M|\\lesssim 0.03$. We provide the modified {\\tt hi\\_class} codepublicly on GitHub, now enabling computation and inclusion of the redshiftspace distortion observable $f\u03c3_8$ as well as the No Slip Gravitymodifications.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); General Relativity and Quantum Cosmology (gr-qc)",
    "Article_Date": "2019/04/29",
    "Article_PDF": "https://arxiv.org/pdf/1904.12903"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.11603",
    "DOI": "arXiv:1904.11603v1",
    "Article_Title": "Bayesian Factor Analysis for Inference on Interactions",
    "Article_Abstract": "This article is motivated by the problem of inference on interactions amongchemical exposures impacting human health outcomes. Chemicals often co-occur inthe environment or in synthetic mixtures and as a result exposure levels can behighly correlated. We propose a latent factor joint model, which includesshared factors in both the predictor and response components while assumingconditional independence. By including a quadratic regression in the latentvariables in the response component, we induce flexible dimension reduction incharacterizing main effects and interactions. We propose a Bayesian approach toinference under this Factor analysis for INteractions (FIN) framework. Throughappropriate modifications of the factor modeling structure, FIN can accommodatehigher order interactions and multivariate outcomes. We provide theory onposterior consistency and the impact of misspecifying the number of factors. Weevaluate the performance using a simulation study and data from the NationalHealth and Nutrition Examination Survey (NHANES). Code is available on GitHub.",
    "Article_Subject": "Methodology (stat.ME); Applications (stat.AP)",
    "Article_Date": "2019/04/25",
    "Article_PDF": "https://arxiv.org/pdf/1904.11603"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.11164",
    "DOI": "arXiv:1904.11164v1",
    "Article_Title": "PHANTOM: Curating GitHub for engineered software projects using time-series clustering",
    "Article_Abstract": "Context: Within the field of Mining Software Repositories, there are numerousmethods employed to filter datasets in order to avoid analysing low-qualityprojects. Unfortunately, the existing filtering methods have not kept up withthe growth of existing data sources, such as GitHub, and researchers often relyon quick and dirty techniques to curate datasets.  Objective: The objective of this study is to develop a method capable offiltering large quantities of software projects in a time-efficient way.  Method: This study follows the Design Science Research (DSR) methodology. Theproposed method, PHANTOM, extracts five measures from Git logs. Each measure istransformed into a time-series, which is represented as a feature vector forclustering using the k-means algorithm.  Results: Using the ground truth from a previous study, PHANTOM was shown tobe able to rediscover the ground truth with up to 0.87 Precision or 0.94Recall, and be able to identify \"well-engineered\" projects with up to 0.87Precision and 0.94 Recall on the validation dataset. PHANTOM downloaded andprocessed the metadata of 1,786,601 GitHub repositories in 21.5 days, which isover 33\\% faster than a similar study, which used a computer cluster of 200nodes.  Conclusions: It is possible to use an unsupervised approach to identifywell-engineering projects. PHANTOM was shown to be competitive compared to theexisting supervised approaches while reducing the hardware requirements by twoorders of magnitude.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/25",
    "Article_PDF": "https://arxiv.org/pdf/1904.11164"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10581",
    "DOI": "arXiv:1904.10581v2",
    "Article_Title": "Quantifying Correlated Truncation Errors in Effective Field Theory",
    "Article_Abstract": "Effective field theories (EFTs) organize the description of complex systemsinto an infinite sequence of decreasing importance. Predictions are made with afinite number of terms, which induces a truncation error that is often leftunquantified. We formalize the notion of EFT convergence and propose a Bayesiantruncation error model for predictions that are correlated across theindependent variables, e.g., energy or scattering angle. Central to ourapproach are Gaussian processes that encode both the naturalness andcorrelation structure of EFT coefficients. Our use of Gaussian processespermits efficient and accurate assessment of credible intervals, allows EFTfits to easily include correlated theory errors, and provides analyticposteriors for physical EFT-related quantities such as the expansion parameter.We demonstrate that model-checking diagnostics---applied to the case ofmultiple curves---are powerful tools for EFT validation. As an example, weassess a set of nucleon-nucleon scattering observables in chiral EFT. In aneffort to be self contained, appendices include thorough derivations of ourstatistical results. Our methods are packaged in Python code, called gsum, thatis available for download on GitHub.",
    "Article_Subject": "Nuclear Theory (nucl-th); High Energy Physics - Phenomenology (hep-ph); Nuclear Experiment (nucl-ex); Data Analysis, Statistics and Probability (physics.data-an)",
    "Article_Date": "2019/04/24",
    "Article_PDF": "https://arxiv.org/pdf/1904.10581"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10464",
    "DOI": "arXiv:1904.10464v1",
    "Article_Title": "$\\mathtt{bimEX}$: A Mathematica package for exact computations in 3$+$1 bimetric relativity",
    "Article_Abstract": "We present $\\mathtt{bimEX}$, a Mathematica package for exact computations in3$+$1 bimetric relativity. It is based on the $\\mathtt{xAct}$ bundle, which canhandle computations involving both abstract tensors and their components. Inthis communication, we refer to the latter case as concrete computations. Thepackage consists of two main parts. The first part involves the abstracttensors, and focuses on how to deal with multiple metrics in $\\mathtt{xAct}$.The second part takes an ansatz for the primary variables in a chart as theinput, and returns the covariant BSSN bimetric equations in components in thatchart. Several functions are implemented to make this process as fast anduser-friendly as possible. The package has been used and tested extensively inspherical symmetry and was the workhorse in obtaining the bimetric covariantBSSN equations and reproducing the bimetric 3$+$1 equations in the sphericalpolar chart.",
    "Article_Subject": "Symbolic Computation (cs.SC); Cosmology and Nongalactic Astrophysics (astro-ph.CO); Mathematical Software (cs.MS); General Relativity and Quantum Cosmology (gr-qc)",
    "Article_Date": "2019/04/23",
    "Article_PDF": "https://arxiv.org/pdf/1904.10464"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10255",
    "DOI": "arXiv:1904.10255v1",
    "Article_Title": "End-to-end Sleep Staging with Raw Single Channel EEG using Deep Residual ConvNets",
    "Article_Abstract": "Humans approximately spend a third of their life sleeping, which makesmonitoring sleep an integral part of well-being. In this paper, a 34-layer deepresidual ConvNet architecture for end-to-end sleep staging is proposed. Thenetwork takes raw single channel electroencephalogram (Fpz-Cz) signal as inputand yields hypnogram annotations for each 30s segments as output. Experimentsare carried out for two different scoring standards (5 and 6 stageclassification) on the expanded PhysioNet Sleep-EDF dataset, which containsmulti-source data from hospital and household polysomnography setups. Theperformance of the proposed network is compared with that of thestate-of-the-art algorithms in patient independent validation tasks. Theexperimental results demonstrate the superiority of the proposed networkcompared to the best existing method, providing a relative improvement inepoch-wise average accuracy of 6.8% and 6.3% on the household data andmulti-source data, respectively. Codes are made publicly available on Github.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/23",
    "Article_PDF": "https://arxiv.org/pdf/1904.10255"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10247",
    "DOI": "arXiv:1904.10247v3",
    "Article_Title": "Free-form Video Inpainting with 3D Gated Convolution and Temporal PatchGAN",
    "Article_Abstract": "Free-form video inpainting is a very challenging task that could be widelyused for video editing such as text removal. Existing patch-based methods couldnot handle non-repetitive structures such as faces, while directly applyingimage-based inpainting models to videos will result in temporal inconsistency(see http://bit.ly/2Fu1n6b ). In this paper, we introduce a deep learn-ingbased free-form video inpainting model, with proposed 3D gated convolutions totackle the uncertainty of free-form masks and a novel Temporal PatchGAN loss toenhance temporal consistency. In addition, we collect videos and design afree-form mask generation algorithm to build the free-form video inpainting(FVI) dataset for training and evaluation of video inpainting models. Wedemonstrate the benefits of these components and experiments on both theFaceForensics and our FVI dataset suggest that our method is superior toexisting ones. Related source code, full-resolution result videos and the FVIdataset could be found on Githubhttps://github.com/amjltc295/Free-Form-Video-Inpainting .",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/04/23",
    "Article_PDF": "https://arxiv.org/pdf/1904.10247"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.09954",
    "DOI": "arXiv:1904.09954v1",
    "Article_Title": "Why Software Projects need Heroes (Lessons Learned from 1100+ Projects)",
    "Article_Abstract": "A \"hero\" project is one where 80% or more of the contributions are made bythe 20% of the developers. In the literature, such projects are deprecatedsince they might cause bottlenecks in development and communication. However,there is little empirical evidence on this matter. Further, recent studies showthat such hero projects are very prevalent. Accordingly, this paper exploresthe effect of having heroes in project, from a code quality perspective. Weidentify the heroes developer communities in 1100+ open source GitHub projects.Based on the analysis, we find that (a) hero projects are majorly all projects;and (b) the commits from \"hero developers\" (who contribute most to the code)result in far fewer bugs than other developers. That is, contrary to theliterature, heroes are standard and very useful part of modern open sourceprojects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/22",
    "Article_PDF": "https://arxiv.org/pdf/1904.09954"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.09416",
    "DOI": "arXiv:1904.09416v2",
    "Article_Title": "An Analysis of 35+ Million Jobs of Travis CI",
    "Article_Abstract": "Travis CI handles automatically thousands of builds every day to, amongstother things, provide valuable feedback to thousands of open-source developers.In this paper, we investigate Travis CI to firstly understand who is using it,and when they start to use it. Secondly, we investigate how the developers useTravis CI and finally, how frequently the developers change the Travis CIconfigurations. We observed during our analysis that the main users of TravisCI are corporate users such as Microsoft. And the programming languages used inTravis CI by those users do not follow the same popularity trend than onGitHub, for example, Python is the most popular language on Travis CI, but itis only the third one on GitHub. We also observe that Travis CI is set up onaverage seven days after the creation of the repository and the jobs are stillmainly used (60%) to run tests. And finally, we observe that 7.34% of thecommits modify the Travis CI configuration. We share the biggest benchmark ofTravis CI jobs (to our knowledge): it contains 35,793,144 jobs from 272,917different GitHub projects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/20",
    "Article_PDF": "https://arxiv.org/pdf/1904.09416"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.09355",
    "DOI": "arXiv:1904.09355v2",
    "Article_Title": "Exoplanet Reflected Light Spectroscopy with PICASO",
    "Article_Abstract": "Here we present the first open-source radiative transfer model for computingthe reflected light of exoplanets at any phase geometry, called PICASO:Planetary Intensity Code for Atmospheric Scattering Observations. This code,written in Python, has heritage from a decades old, well-known Fortran modelused for several studies of planetary objects within the Solar System andbeyond. We have adopted it to include several methodologies for computing bothdirect and diffuse scattering phase functions, and have added several updatesincluding the ability to compute Raman scattering spectral features. Here webenchmark PICASO against two independent codes and discuss the degree to whichthe model is sensitive to a user's specification for various phase functions.Then, we conduct a full information content study of the model across a wideparameter space in temperature, cloud profile, SNR and resolving power.",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP)",
    "Article_Date": "2019/04/19",
    "Article_PDF": "https://arxiv.org/pdf/1904.09355"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.08315",
    "DOI": "arXiv:1904.08315v1",
    "Article_Title": "Multi-Level Mesa",
    "Article_Abstract": "Multi-level Mesa is an extension to support the Python based Agents BasedModel (ABM) library Mesa. Multi-level Mesa provides ABM infrastructure to allowfor the inclusion of complex networks, which have modules (groups) andhierarchies (layers) of agents. This approach allows for users to define andsimulate multi-layered adaptions of complex networks. This study reviews othermulti-level libraries currently in the field, describes the main functions andclasses of the Multi-level Mesa, and describes its implementation and impact innumerous varieties using the seminal ABM - Sugarscape. Multi-level Mesa andSugarscape examples are available on GitHub athttps://github.com/tpike3/multilevel_mesa andhttps://github.com/tpike3/SugarScape.",
    "Article_Subject": "Multiagent Systems (cs.MA)",
    "Article_Date": "2019/03/22",
    "Article_PDF": "https://arxiv.org/pdf/1904.08315"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07577",
    "DOI": "arXiv:1904.07577v1",
    "Article_Title": "ASD-DiagNet: A hybrid learning approach for detection of Autism Spectrum Disorder using fMRI data",
    "Article_Abstract": "Mental disorders such as Autism Spectrum Disorders (ASD) are heterogeneousdisorders that are notoriously difficult to diagnose, especially in children.The current psychiatric diagnostic process is based purely on the behaviouralobservation of symptomology (DSM-5/ICD-10) and may be prone to over-prescribingof drugs due to misdiagnosis. In order to move the field towards morequantitative fashion, we need advanced and scalable machine learninginfrastructure that will allow us to identify reliable biomarkers of mentalhealth disorders. In this paper, we propose a framework called ASD-DiagNet forclassifying subjects with ASD from healthy subjects by using only fMRI data. Wedesigned and implemented a joint learning procedure using an autoencoder and asingle layer perceptron which results in improved quality of extracted featuresand optimized parameters for the model. Further, we designed and implemented adata augmentation strategy, based on linear interpolation on available featurevectors, that allows us to produce synthetic datasets needed for training ofmachine learning models. The proposed approach is evaluated on a public datasetprovided by Autism Brain Imaging Data Exchange including 1035 subjects comingfrom 17 different brain imaging centers. Our machine learning model outperformsother state of the art methods from 13 imaging centers with increase inclassification accuracy up to 20% with maximum accuracy of 80%. The machinelearning technique presented in this paper, in addition to yielding betterquality, gives enormous advantages in terms of execution time (40 minutes vs. 6hours on other methods). The implemented code is available as GPL license onGitHub portal of our lab (https://github.com/pcdslab/ASD-DiagNet).",
    "Article_Subject": "Machine Learning (cs.LG); Image and Video Processing (eess.IV); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/16",
    "Article_PDF": "https://arxiv.org/pdf/1904.07577"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07387",
    "DOI": "arXiv:1904.07387v2",
    "Article_Title": "Predicting Fluid Intelligence of Children using T1-weighted MR Images and a StackNet",
    "Article_Abstract": "In this work, we utilize T1-weighted MR images and StackNet to predict fluidintelligence in adolescents. Our framework includes feature extraction, featurenormalization, feature denoising, feature selection, training a StackNet, andpredicting fluid intelligence. The extracted feature is the distribution ofdifferent brain tissues in different brain parcellation regions. The proposedStackNet consists of three layers and 11 models. Each layer uses thepredictions from all previous layers including the input layer. The proposedStackNet is tested on a public benchmark Adolescent Brain Cognitive DevelopmentNeurocognitive Prediction Challenge 2019 and achieves a mean squared error of82.42 on the combined training and validation set with 10-foldcross-validation. In addition, the proposed StackNet also achieves a meansquared error of 94.25 on the testing data. The source code is available onGitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/16",
    "Article_PDF": "https://arxiv.org/pdf/1904.07387"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07197",
    "DOI": "arXiv:1904.07197v1",
    "Article_Title": "Identification of Parameters for Large-scale Models in Systems Biology",
    "Article_Abstract": "Inverse problem for the identification of the parameters for large-scalesystems of nonlinear ordinary differential equations (ODEs) arising in systemsbiology is analyzed. In a recent paper in \\textit{Mathematical Biosciences,305(2018), 133-145}, the authors implemented the numerical method suggested byone of the authors in \\textit{J. Optim. Theory Appl., 85, 3(1995), 509-526} foridentification of parameters in moderate scale models of systems biology. Thismethod combines Pontryagin optimization or Bellman's quasilinearization withsensitivity analysis and Tikhonov regularization. We suggest modification ofthe method by embedding a method of staggered corrector for sensitivityanalysis and by enhancing multi-objective optimization which enablesapplication of the method to large-scale models with practicallynon-identifiable parameters based on multiple data sets, possibly with partialand noisy measurements. We apply the modified method to a benchmark model of athree-step pathway modeled by 8 nonlinear ODEs with 36 unknown parameters andtwo control input parameters. The numerical results demonstrate geometricconvergence with a minimum of five data sets and with minimum measurements perdata set. Software package \\textit{qlopt} is developed and posted in GitHub.MATLAB package AMIGO2 is used to demonstrate advantage of \\textit{qlopt} overmost popular methods/software such as \\textit{lsqnonlin}, \\textit{fmincon} and\\textit{nl2sol}.",
    "Article_Subject": "Quantitative Methods (q-bio.QM); Numerical Analysis (math.NA)",
    "Article_Date": "2019/04/15",
    "Article_PDF": "https://arxiv.org/pdf/1904.07197"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07088",
    "DOI": "arXiv:1904.07088v1",
    "Article_Title": "P4-MACsec: Dynamic Topology Monitoring and Data Layer Protection with MACsec in P4-SDN",
    "Article_Abstract": "We propose P4-MACsec to protect network links between P4 switches throughautomated deployment of MACsec, a widespread IEEE standard for securing Layer 2infrastructures. It is supported by switches and routers from majormanufacturers and has only little performance limitations compared to VPNtechnologies such as IPsec. P4-MACsec introduces a data plane implementation ofMACsec including AES-GCM encryption and decryption directly on P4 switches.P4-MACsec features a two-tier control plane structure where local controllersrunning on the P4 switches interact with a central controller. We propose anovel secure link discovery mechanism that leverages protected LLDP frames andthe two-tier control plane structure for secure and efficient management of aglobal link map. Automated deployment of MACsec creates secure channel,generates keying material, and configures the P4 switches for each detectedlink between two P4 switches. It detects link changes and performs rekeying toprovide a secure, configuration-free operation of MACsec. In this paper, wereview the technological background of P4-MACsec and explain its architecture.To demonstrate the feasibility of P4-MACsec, we implement it on the BMv2 P4software switch and validate the prototype through experiments. We evaluate itsperformance through experiments that focus on TCP throughput and round-triptime. We publish the prototype and experiment setups on Github.",
    "Article_Subject": "Networking and Internet Architecture (cs.NI)",
    "Article_Date": "2019/04/15",
    "Article_PDF": "https://arxiv.org/pdf/1904.07088"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.05257",
    "DOI": "arXiv:1904.05257v1",
    "Article_Title": "Instance Segmentation of Biological Images Using Harmonic Embeddings",
    "Article_Abstract": "We present a new instance segmentation approach tailored to biologicalimages, where instances may correspond to individual cells, organisms or plantparts. Unlike instance segmentation for user photographs or road scenes, inbiological data object instances may be particularly densely packed, theappearance variation may be particularly low, the processing power may berestricted, while, on the other hand, the variability of sizes of individualinstances may be limited. These peculiarities are successfully addressed andexploited by the proposed approach.  Our approach describes each object instance using an expectation of a limitednumber of sine waves with frequencies and phases adjusted to particular objectsizes and densities. At train time, a fully-convolutional network is learned topredict the object embeddings at each pixel using a simple pixelwise regressionloss, while at test time the instances are recovered using clustering in theembeddings space. In the experiments, we show that our approach outperformsprevious embedding-based instance segmentation approaches on a number ofbiological datasets, achieving state-of-the-art on a popular CVPPP benchmark.Notably, this excellent performance is combined with computational efficiencythat is needed for deployment to domain specialists.  The source code is publicly available at Github:https://github.com/kulikovv/harmonic",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/04/10",
    "Article_PDF": "https://arxiv.org/pdf/1904.05257"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.03801",
    "DOI": "arXiv:1904.03801v1",
    "Article_Title": "pdbmine: A Node.js API for the RCSB Protein Data Bank (PDB)",
    "Article_Abstract": "Summary: The advent of Web-based tools that assist in the analysis andvisualization of macromolecules require application programming interfaces(APIs) designed for modern web frameworks. To this end, we have developed aNode.js module pdbmine that allows any user to generate faster data-requestqueries to the RCSB Protein Data Bank (PDB). This JavaScript API acts as alayer over the XML-based RCSB PDB RESTful API. The relatively simple nature ofthe function calls within this module allows the user to easily implement andintegrate pdbmine into larger Node.js web applications.  Availability: This module can be installed via the Node Package Manager (NPM)at https://www.npmjs.com/package/pdbmine/, and is hosted on GitHub under theopen-source MIT license at https://github.com/nnj1/pdbmine/. Relevantdocumentation is detailed at https://nnj1.github.io/pdbmine/",
    "Article_Subject": "Genomics (q-bio.GN)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.03801"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.02724",
    "DOI": "arXiv:1904.02724v1",
    "Article_Title": "Bounties in Open Source Development on GitHub: A Case Study of Bountysource Bounties",
    "Article_Abstract": "Due to the voluntary nature of open source software, it can be hard to find adeveloper to work on a particular task. For example, some issue reports may betoo cumbersome and unexciting for someone to volunteer to do them, yet theseissue reports may be of high priority to the success of a project. To providean incentive for implementing such issue reports, one can propose a monetaryreward, i.e., a bounty, to the developer who completes that particular task. Inthis paper, we study bounties in open source projects on GitHub to betterunderstand how bounties can be leveraged to evolve such projects in terms ofaddressing issue reports. We investigated 5,445 bounties for GitHub projects.These bounties were proposed through the Bountysource platform with a totalbounty value of $406,425. We find that 1) in general, the timing of proposingbounties and the bounty-usage frequency are the most important factors thatimpact the likelihood of an issue being addressed. More specifically, issuereports are more likely to be addressed if they are for projects in whichbounties are used more frequently and if they are proposed earlier. 2) Thebounty value that an issue report has is the most important factor that impactsthe issue-addressing likelihood in the projects in which no bounties were usedbefore. Backers in such projects proposed higher bounty values to get issuesaddressed. 3) There is a risk of wasting money for backers who invest money onlong-standing issue reports.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/04",
    "Article_PDF": "https://arxiv.org/pdf/1904.02724"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.02414",
    "DOI": "arXiv:1904.02414v1",
    "Article_Title": "\"Won't We Fix this Issue?\" Qualitative Characterization and Automated Identification of Wontfix Issues on GitHub",
    "Article_Abstract": "Addressing users requests in the form of bug reports and Github issuesrepresents a crucial task of any successful software project. However,user-submitted issue reports tend to widely differ in their quality, anddevelopers spend a considerable amount of time handling these reports.Moreover, an inefficient prioritization of requested changes could have anegative impact on the developers' workloads. By collecting a dataset of around6,000 issues from the history of 323 GitHub projects, we observe thatdevelopers spend a long time (i.e., about five months, on average) beforelabeling an issue as a wontfix. For this reason, in this paper, we empiricallyinvestigate the nature of wontfix issues, by manually analyzing a sample of 800issues of this kind, extracted from heterogeneous projects. We explore thecommon reasons behind a \"wontfix decision\", the main characteristics of wontfixissues and the potential factors that could be connected with the time to closethem. Furthermore, we experiment approaches for just-in-time prediction ofwontfix issues using machine learning techniques to analyze the titles anddescriptions of reported issues. Our investigation shed some light on thewontfix issues' characteristics, as well as the potential factors that mayaffect the time required to make a \"wontfix decision\". Our results alsodemonstrate that it is possible to predict whether an issue will be closed as awontfix with average values of precision, recall, and F-measure close to 99%,confirming the practical usefulness of the proposed approach for improving theissue management practices on GitHub.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/04",
    "Article_PDF": "https://arxiv.org/pdf/1904.02414"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.01754",
    "DOI": "arXiv:1904.01754v1",
    "Article_Title": "Styler: Learning Formatting Conventions to Repair Checkstyle Errors",
    "Article_Abstract": "Formatting coding conventions play an important role on code readability. Inthis paper, we present Styler, an automatic repair tool dedicated to fixformatting-related errors raised by Checkstyle, a highly configurable formatchecker for Java. To fix formatting errors in a given project, Styler learnsfixes based on the Checkstyle ruleset defined in the project and predictsrepairs for the current errors using machine learning. In an empiricalevaluation, we found that Styler repaired 24% of 497 real Checkstyle errorsmined from five GitHub projects. Moreover, in a comparison of Styler with thestate-of-the-art machine learning code formatters Naturalize and CodeBuff, wefound that Styler is the tool that fixes more real Checkstyle errors and alsogenerates smaller repairs. Finally, we conclude that Styler is promising to beused in IDEs and in a Continuous Integration environment to repair Checkstyleerrors.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.01754"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.01740",
    "DOI": "arXiv:1904.01740v2",
    "Article_Title": "FaceQnet: Quality Assessment for Face Recognition based on Deep Learning",
    "Article_Abstract": "In this paper we develop a Quality Assessment approach for face recognitionbased on deep learning. The method consists of a Convolutional Neural Network,FaceQnet, that is used to predict the suitability of a specific input image forface recognition purposes. The training of FaceQnet is done using the VGGFace2database. We employ the BioLab-ICAO framework for labeling the VGGFace2 imageswith quality information related to their ICAO compliance level. Thegroundtruth quality labels are obtained using FaceNet to generate comparisonscores. We employ the groundtruth data to fine-tune a ResNet-based CNN, makingit capable of returning a numerical quality measure for each input image.Finally, we verify if the FaceQnet scores are suitable to predict the expectedperformance when employing a specific image for face recognition with a COTSface recognition system. Several conclusions can be drawn from this work, mostnotably: 1) we managed to employ an existing ICAO compliance framework and apretrained CNN to automatically label data with quality information, 2) wetrained FaceQnet for quality estimation by fine-tuning a pre-trained facerecognition network (ResNet-50), and 3) we have shown that the predictions fromFaceQnet are highly correlated with the face recognition accuracy of astate-of-the-art commercial system not used during development. FaceQnet ispublicly available in GitHub.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.01740"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.01738",
    "DOI": "arXiv:1904.01738v3",
    "Article_Title": "Adinkra Height Yielding Matrix Numbers: Eigenvalue Equivalence Classes for Minimal Four-Color Adinkras",
    "Article_Abstract": "An adinkra is a graph-theoretic representation of spacetime supersymmetry.Minimal four-color valise adinkras have been extensively studied due to theirrelations to minimal 4D, $\\cal N$ = 1 supermultiplets. Valise adinkras,although an important subclass, do not encode all the information present whena 4D supermultiplet is reduced to 1D. Eigenvalue equivalence classes for valiseadinkra matrices exist, known as $\u03c7_{\\rm o}$ equivalence classes, wherevalise adinkras within the same $\u03c7_{\\rm o}$ equivalence class are isomorphicin the sense that adinkras within a $\u03c7_{\\rm o}$-equivalence class can betransformed into each other via field redefinitions of the nodes. We extendthis to non-valise adinkras, via Python code, providing a complete eigenvalueclassification of \"node-lifting\" for all 36,864 valise adinkras associated withthe Coxeter group $BC{}_4$. We term the eigenvalues associated with thesenode-lifted adinkras Height Yielding Matrix Numbers (HYMNs) and introduce HYMNequivalence classes. These findings have been summarized in a $Mathematica$notebook that can found at the HEPTHools Data Repository(https://hepthools.github.io/Data/) on GitHub.",
    "Article_Subject": "High Energy Physics - Theory (hep-th); Representation Theory (math.RT)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.01738"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.00935",
    "DOI": "arXiv:1904.00935v1",
    "Article_Title": "STYLE-ANALYZER: fixing code style inconsistencies with interpretable unsupervised algorithms",
    "Article_Abstract": "Source code reviews are manual, time-consuming, and expensive. Humaninvolvement should be focused on analyzing the most relevant aspects of theprogram, such as logic and maintainability, rather than amending style, syntax,or formatting defects. Some tools with linting capabilities can format codeautomatically and report various stylistic violations for supported programminglanguages. They are based on rules written by domain experts, hence, theirconfiguration is often tedious, and it is impractical for the given set ofrules to cover all possible corner cases. Some machine learning-based solutionsexist, but they remain uninterpretable black boxes. This paper introducesSTYLE-ANALYZER, a new open source tool to automatically fix code formattingviolations using the decision tree forest model which adapts to each codebaseand is fully unsupervised. STYLE-ANALYZER is built on top of our novel assistedcode review framework, Lookout. It accurately mines the formatting style ofeach analyzed Git repository and expresses the found format patterns withcompact human-readable rules. STYLE-ANALYZER can then suggest styleinconsistency fixes in the form of code review comments. We evaluate the outputquality and practical relevance of STYLE-ANALYZER by demonstrating that it canreproduce the original style with high precision, measured on 19 popularJavaScript projects, and by showing that it yields promising results in fixingreal style mistakes. STYLE-ANALYZER includes a web application to visualize howthe rules are triggered. We release STYLE-ANALYZER as a reusable and extendableopen source software package on GitHub for the benefit of the community.",
    "Article_Subject": "Machine Learning (cs.LG); Software Engineering (cs.SE); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/01",
    "Article_PDF": "https://arxiv.org/pdf/1904.00935"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.00243",
    "DOI": "arXiv:1904.00243v3",
    "Article_Title": "Symmetry-Based Disentangled Representation Learning requires Interaction with Environments",
    "Article_Abstract": "Finding a generally accepted formal definition of a disentangledrepresentation in the context of an agent behaving in an environment is animportant challenge towards the construction of data-efficient autonomousagents. Higgins et al. recently proposed Symmetry-Based DisentangledRepresentation Learning, a definition based on a characterization of symmetriesin the environment using group theory. We build on their work and makeobservations, theoretical and empirical, that lead us to argue thatSymmetry-Based Disentangled Representation Learning cannot only be based onstatic observations: agents should interact with the environment to discoverits symmetries. Our experiments can be reproduced in Colab and the code isavailable on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/30",
    "Article_PDF": "https://arxiv.org/pdf/1904.00243"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.12180",
    "DOI": "arXiv:1903.12180v1",
    "Article_Title": "ACRONYM: Acronym CReatiON for You and Me",
    "Article_Abstract": "Each year, countless hours of productive research time is spent brainstormingcreative acronyms for surveys, simulations, codes, and conferences. We presentACRONYM, a command-line program developed specifically to assist astronomers inidentifying the best acronyms for ongoing projects. The code returns allapproximately-English-language words that appear within an input string oftext, regardless of whether the letters occur at the beginning of the componentwords (in true astronomer fashion).",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/03/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.12180"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.12112",
    "DOI": "arXiv:1903.12112v2",
    "Article_Title": "Merging Combinatorial Design and Optimization: the Oberwolfach Problem",
    "Article_Abstract": "The Oberwolfach Problem $OP(F)$, posed by Gerhard Ringel in 1967, is aparadigmatic Combinatorial Design problem asking whether the complete graph$K_v$ decomposes into edge-disjoint copies of a $2$-regular graph $F$ of order$v$. In Combinatorial Design Theory, so-called difference methods represent awell-known solution technique and construct solutions in infinitely many casesexploiting symmetric and balanced structures. This approach reduces the problemto finding a well-structured $2$-factor which allows us to build solutions thatwe call $1$- or $2$-rotational according to their symmetries. We tackle $OP$ bymodeling difference methods with Optimization tools, specifically ConstraintProgramming ($CP$) and Integer Programming ($IP$), and correspondingly solveinstances with up to $v=120$ within $60s$. In particular, we model the$2$-rotational method by solving in cascade two subproblems, namely the binaryand group labeling, respectively. A polynomial-time algorithm solves the binarylabeling, while $CP$ tackles the group labeling. Furthermore, we providenecessary conditions for the existence of some $1$-rotational solutions whichstem from computational results. This paper shows thereby that both theoreticaland empirical results may arise from the interaction between CombinatorialDesign Theory and Operation Research.",
    "Article_Subject": "Combinatorics (math.CO)",
    "Article_Date": "2019/03/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.12112"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.11914",
    "DOI": "arXiv:1903.11914v3",
    "Article_Title": "Improving convergence of volume penalized fluid-solid interactions",
    "Article_Abstract": "Boundary conditions on arbitrary geometries are a common issue in simulatingpartial differential equations. The conventional approach is to discretize on agrid conforming to the geometry. However grid construction is challenging, andthis difficulty is compounded for evolving domains. Several methods insteadaugment the equations themselves to implicitly enforce the boundary conditions.This paper examines the Volume Penalty Method, which approximates Dirichletboundary conditions in the Navier Stokes equations with rapid linear damping(non-dimensional time scale $\u03b7$) inside the object. This technique is provento converge to the true solution, and also leads to simple volume-integralforce and torque calculations. Unfortunately, previous analysis showedconvergence of only $\\mathcal{O}(\u03b7^{1/2})$. We analyze the source of thiserror using matched asymptotic expansions and show that it stems from adisplacement length, proportional to a Reynolds number Re dependent boundarylayer of size $\\mathcal{O}(\u03b7^{1/2}\\text{Re}^{-1/2})$. The relative size ofthe displacement length and damping time scale lead to the emergence ofmultiple asymptotic regimes. The key finding is that there is a simplecorrection that can be efficiently calculated to eliminate the displacementlength and promote the accuracy to $\\mathcal{O}(\u03b7)$. This improvement alsoextends to the force and torque calculations. We demonstrate these findings in1D planar Poiseuille flow, 2D steady flow past a viscous stagnation point, and2D unsteady flow past a rotating cylinder, and finally show that Richardsonextrapolation can be used with our correction to further improve convergence to$\\mathcal{O}(\u03b7^{2})$.",
    "Article_Subject": "Numerical Analysis (math.NA)",
    "Article_Date": "2019/03/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.11914"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.10729",
    "DOI": "arXiv:1903.10729v3",
    "Article_Title": "WGANSing: A Multi-Voice Singing Voice Synthesizer Based on the Wasserstein-GAN",
    "Article_Abstract": "We present a deep neural network based singing voice synthesizer, inspired bythe Deep Convolutions Generative Adversarial Networks (DCGAN) architecture andoptimized using the Wasserstein-GAN algorithm. We use vocoder parameters foracoustic modelling, to separate the influence of pitch and timbre. Thisfacilitates the modelling of the large variability of pitch in the singingvoice. Our network takes a block of consecutive frame-wise linguistic andfundamental frequency features, along with global singer identity as input andoutputs vocoder features, corresponding to the block of features. Thisblock-wise approach, along with the training methodology allows us to modeltemporal dependencies within the features of the input block. For inference,sequential blocks are concatenated using an overlap-add procedure. We show thatthe performance of our model is competitive with regards to thestate-of-the-art and the original sample using objective metrics and asubjective listening test. We also present examples of the synthesis on asupplementary website and the source code via GitHub.",
    "Article_Subject": "Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "Article_Date": "2019/03/26",
    "Article_PDF": "https://arxiv.org/pdf/1903.10729"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.10326",
    "DOI": "arXiv:1903.10326v1",
    "Article_Title": "topFiberM: Scalable and Efficient Boolean Matrix Factorization",
    "Article_Abstract": "Matrix Factorization has many applications such as clustering. When thematrix is Boolean it is favorable to have Boolean factors too. This will savethe efforts of quantizing the reconstructed data back, which usually is doneusing arbitrary thresholds. Here we introduce topFiberM a Boolean matrixfactorization algorithm. topFiberM chooses in a greedy way the fibers (rows orcolumns) to represent the entire matrix. Fibers are extended to rectanglesaccording to a threshold on precision. The search for these \"top fibers\" cancontinue beyond the required rank and according to an optional parameter thatdefines the limit for this search. A factor with a better gain replaces thefactor with minimum gain in \"top fibers\". We compared topFiberM to thestate-of-the-art methods, it achieved better quality for the set of datasetsusually used in literature. We also applied our algorithm to linked-data toshow its scalability. topFiberM was in average 128 times faster than the wellknown Asso method when applied to a set of matrices representing a realmultigraph although Asso is implemented in C and topFiberM is implemented in Rwhich is generally slower than C. topFiberM is publicly available from Github(https://github.com/dice-group/BMF).",
    "Article_Subject": "Data Structures and Algorithms (cs.DS)",
    "Article_Date": "2019/03/06",
    "Article_PDF": "https://arxiv.org/pdf/1903.10326"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08718",
    "DOI": "arXiv:1903.08718v1",
    "Article_Title": "CRAFT: A multifunction online platform for speech prosody visualisation",
    "Article_Abstract": "There are many research tools which are also used for teaching the acousticphonetics of speech rhythm and speech melody. But they were notpurpose-designed for teaching-learning situations, and some have a steeplearning curve. CRAFT (Creation and Recovery of Amplitude and Frequency Tracks)is custom-designed as a novel flexible online tool for visualisation andcritical comparison of functions and transforms, with implementations of theReaper, RAPT, PyRapt, YAAPT, YIN and PySWIPE F0 estimators, three Praatconfigurations, and two purpose-built estimators, PyAMDF, S0FT. Visualisationsof amplitude and frequency envelope spectra, spectral edge detection of rhythmzones, and a parametrised spectrogram are included. A selection of audio clipsfrom tone and intonation languages is provided for demonstration purposes. Themain advantages of online tools are consistency (users have the same versionand the same data selection), interoperability over different platforms, andease of maintenance. The code is available on GitHub.",
    "Article_Subject": "Sound (cs.SD); Computation and Language (cs.CL)",
    "Article_Date": "2019/03/18",
    "Article_PDF": "https://arxiv.org/pdf/1903.08718"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08621",
    "DOI": "arXiv:1903.08621v1",
    "Article_Title": "Column2Vec: Structural Understanding via Distributed Representations of Database Schemas",
    "Article_Abstract": "We present Column2Vec, a distributed representation of database columns basedon column metadata. Our distributed representation has several applications.Using known names for groups of columns (i.e., a table name), we train a modelto generate an appropriate name for columns in an unnamed table. We demonstratethe viability of our approach using schema information collected from opensource applications on GitHub.",
    "Article_Subject": "Databases (cs.DB); Machine Learning (cs.LG)",
    "Article_Date": "2019/03/20",
    "Article_PDF": "https://arxiv.org/pdf/1903.08621"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08215",
    "DOI": "arXiv:1903.08215v2",
    "Article_Title": "The Galaxy Cluster 'Pypeline' for X-ray Temperature Maps: ClusterPyXT",
    "Article_Abstract": "ClusterPyXT is a new software pipeline to generate spectral temperature,X-ray surface brightness, pressure, and density maps from X-ray observations ofgalaxy clusters. These data products help elucidate the physics of processesoccurring within clusters of galaxies, including turbulence, shock fronts,nonthermal phenomena, and the overall dynamics of cluster mergers. ClusterPyXTautomates the creation of these data products with minimal user interaction,and allows for rapid analyses of archival data with user defined parameters andthe ability to straightforwardly incorporate additional observations. In thispaper, we describe in detail the use of this code and release it as an opensource Python project on GitHub.",
    "Article_Subject": "High Energy Astrophysical Phenomena (astro-ph.HE); Cosmology and Nongalactic Astrophysics (astro-ph.CO); Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/03/19",
    "Article_PDF": "https://arxiv.org/pdf/1903.08215"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08186",
    "DOI": "arXiv:1903.08186v1",
    "Article_Title": "Spectroscopic Transit Search: a self-calibrating method for detecting planets around bright stars",
    "Article_Abstract": "We search for transiting exoplanets around the star $\u03b2$ Pictoris usinghigh resolution spectroscopy and Doppler imaging that removes the need forstandard star observations. These data were obtained on the VLT with UVESduring the course of an observing campaign throughout 2017 that monitored theHill sphere transit of the exoplanet $\u03b2$ Pictoris b. We utilize lineprofile tomography as a method for the discovery of transiting exoplanets. Bymeasuring the exoplanet distortion of the stellar line profile, we remove theneed for reference star measurements. We demonstrate the method with whitenoise simulations, and then look at the case of $\u03b2$ Pictoris, which is a$\u03b4$ Scuti pulsator. We describe a method to remove the stellar pulsationsand perform a search for any transiting exoplanets in the resultant data set.We inject fake planet transits with varying orbital periods and planet radiiinto the spectra and determine the recovery fraction. In the photon noiselimited case we can recover planets down to a Neptune radius with an $\\sim$80%success rate, using an 8 m telescope with a $R\\sim 100,000$ spectrograph and 20minutes of observations per night. The pulsations of $\u03b2$ Pictoris limit oursensitivity to Jupiter-sized planets, but a pulsation removal algorithmimproves this limit to Saturn-sized planets. We present two planet candidates,but argue that their signals are most likely caused by other phenomena. We havedemonstrated a method for searching for transiting exoplanets that (i) does notrequire ancillary calibration observations, (ii) can work on any star whoserotational broadening can be resolved with a high spectral dispersionspectrograph and (iii) provides the lowest limits so far on the radii oftransiting Jupiter-sized exoplanets around $\u03b2$ Pictoris with orbitalperiods from 15 days to 200 days with >50% coverage.",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/03/19",
    "Article_PDF": "https://arxiv.org/pdf/1903.08186"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08113",
    "DOI": "arXiv:1903.08113v1",
    "Article_Title": "Identifying Experts in Software Libraries and Frameworks among GitHub Users",
    "Article_Abstract": "Software development increasingly depends on libraries and frameworks toincrease productivity and reduce time-to-market. Despite this fact, we stilllack techniques to assess developers expertise in widely popular libraries andframeworks. In this paper, we evaluate the performance of unsupervised (basedon clustering) and supervised machine learning classifiers (Random Forest andSVM) to identify experts in three popular JavaScript libraries: facebook/react,mongodb/node-mongodb, and socketio/socket.io. First, we collect 13 featuresabout developers activity on GitHub projects, including commits on source codefiles that depend on these libraries. We also build a ground truth includingthe expertise of 575 developers on the studied libraries, as self-reported bythem in a survey. Based on our findings, we document the challenges of usingmachine learning classifiers to predict expertise in software libraries, usingfeatures extracted from GitHub. Then, we propose a method to identify libraryexperts based on clustering feature data from GitHub; by triangulating theresults of this method with information available on Linkedin profiles, we showthat it is able to recommend dozens of GitHub users with evidences of beingexperts in the studied JavaScript libraries. We also provide a public datasetwith the expertise of 575 developers on the studied libraries.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/03/19",
    "Article_PDF": "https://arxiv.org/pdf/1903.08113"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.07611",
    "DOI": "arXiv:1903.07611v1",
    "Article_Title": "Total Power Map to Visibilities (TP2VIS): Joint Deconvolution of ALMA 12m, 7m, and Total Power Array Data",
    "Article_Abstract": "We present a new package for joint deconvolution of ALMA 12m, 7m, and TotalPower (TP) data, dubbed ``Total Power Map to Visibilities (TP2VIS)\". Itconverts a TP (single-dish) map into visibilities on the CASA platform, whichcan be input into deconvolvers (e.g., CLEAN) along with 12m and 7mvisibilities. A manual is presented in the Github repository(https://github.com/tp2vis/distribute). Combining data from the different ALMAarrays is a driver for a number of science topics, namely those that probe sizescales of extended and compact structures simultaneously. We test TP2VIS usingmodel images, one with a single Gaussian and another that mimics the internalstructures of giant molecular clouds. The result shows that the better uvcoverage with TP2VIS visibilities helps the deconvolution process andreproduces the model image within errors of only 5% over two orders ofmagnitude in flux.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Earth and Planetary Astrophysics (astro-ph.EP); Astrophysics of Galaxies (astro-ph.GA); Solar and Stellar Astrophysics (astro-ph.SR)",
    "Article_Date": "2019/03/18",
    "Article_PDF": "https://arxiv.org/pdf/1903.07611"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.06768",
    "DOI": "arXiv:1903.06768v2",
    "Article_Title": "Joint Mean-Covariance Estimation via the Horseshoe with an Application in Genomic Data Analysis",
    "Article_Abstract": "Seemingly unrelated regression is a natural framework for regressing multiplecorrelated responses on multiple predictors. The model is very flexible, withmultiple linear regression and covariance selection models being special cases.However, its practical deployment in genomic data analysis under a Bayesianframework is limited due to both statistical and computational challenges. Thestatistical challenge is that one needs to infer both the mean vector and theinverse covariance matrix, a problem inherently more complex than separatelyestimating each. The computational challenge is due to the dimensionality ofthe parameter space that routinely exceeds the sample size. We propose the useof horseshoe priors on both the mean vector and the inverse covariance matrix.This prior has demonstrated excellent performance when estimating a mean vectoror inverse covariance matrix separately. The current work shows theseadvantages are also present when addressing both simultaneously. A fullBayesian treatment is proposed, with a sampling algorithm that is linear in thenumber of predictors. MATLAB code implementing the algorithm is freelyavailable from github at https://github.com/liyf1988/HS_GHS. Extensiveperformance comparisons are provided with both frequentist and Bayesianalternatives, and both estimation and prediction performances are verified on agenomic data set.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/03/15",
    "Article_PDF": "https://arxiv.org/pdf/1903.06768"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.06348",
    "DOI": "arXiv:1903.06348v1",
    "Article_Title": "Automatically Generating Documentation for Lambda Expressions in Java",
    "Article_Abstract": "When lambda expressions were introduced to the Java programming language aspart of the release of Java 8 in 2014, they were the language's first step intofunctional programming. Since lambda expressions are still relatively new, notall developers use or understand them. In this paper, we first present theresults of an empirical study to determine how frequently developers of GitHubrepositories make use of lambda expressions and how they are documented. Wefind that 11% of Java GitHub repositories use lambda expressions, and that only6% of the lambda expressions are accompanied by source code comments. We thenpresent a tool called LambdaDoc which can automatically detect lambdaexpressions in a Java repository and generate natural language documentationfor them. Our evaluation of LambdaDoc with 23 professional developers showsthat they perceive the generated documentation to be complete, concise, andexpressive, while the majority of the documentation produced by ourparticipants without tool support was inadequate. Our contribution builds animportant step towards automatically generating documentation for functionalprogramming constructs in an object-oriented language.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/03/15",
    "Article_PDF": "https://arxiv.org/pdf/1903.06348"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.05277",
    "DOI": "arXiv:1903.05277v1",
    "Article_Title": "Activity-Based Analysis of Open Source Software Contributors: Roles and Dynamics",
    "Article_Abstract": "Contributors to open source software (OSS) communities assume diverse rolesto take different responsibilities. One major limitation of the current OSStools and platforms is that they provide a uniform user interface regardless ofthe activities performed by the various types of contributors. This paperserves as a non-trivial first step towards resolving this challenge bydemonstrating a methodology and establishing knowledge to understand how thecontributors' roles and their dynamics, reflected in the activitiescontributors perform, are exhibited in OSS communities. Based on an analysis ofuser action data from 29 GitHub projects, we extracted six activities thatdistinguished four Active roles and five Supporting roles of OSS contributors,as well as patterns in role changes. Through the lens of the Activity Theory,these findings provided rich design guidelines for OSS tools to support diversecontributor roles.",
    "Article_Subject": "Software Engineering (cs.SE); Human-Computer Interaction (cs.HC)",
    "Article_Date": "2019/03/13",
    "Article_PDF": "https://arxiv.org/pdf/1903.05277"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.05084",
    "DOI": "arXiv:1903.05084v3",
    "Article_Title": "Decay Replay Mining to Predict Next Process Events",
    "Article_Abstract": "In complex processes, various events can happen in different sequences. Theprediction of the next event given an a-priori process state is of importancein such processes. Recent methods have proposed deep learning techniques suchas recurrent neural networks, developed on raw event logs, to predict the nextevent from a process state. However, such deep learning models by themselveslack a clear representation of the process states. At the same time, recentmethods have neglected the time feature of event instances. In this paper, wetake advantage of Petri nets as a powerful tool in modeling complex processbehaviors considering time as an elemental variable. We propose an approachwhich starts from a Petri net process model constructed by a process miningalgorithm. We enhance the Petri net model with time decay functions to createcontinuous process state samples. Finally, we use these samples in combinationwith discrete token movement counters and Petri net markings to train a deeplearning model that predicts the next event. We demonstrate significantperformance improvements and outperform the state-of-the-art methods on ninereal-world benchmark event logs.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/12",
    "Article_PDF": "https://arxiv.org/pdf/1903.05084"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.04042",
    "DOI": "arXiv:1903.04042v1",
    "Article_Title": "Algorithms for an Efficient Tensor Biclustering",
    "Article_Abstract": "Consider a data set collected by (individuals-features) pairs in differenttimes. It can be represented as a tensor of three dimensions (Individuals,features and times). The tensor biclustering problem computes a subset ofindividuals and a subset of features whose signal trajectories over time lie ina low-dimensional subspace, modeling similarity among the signal trajectorieswhile allowing different scalings across different individuals or differentfeatures. This approach are based on spectral decomposition in order to buildthe desired biclusters. We evaluate the quality of the results from eachalgorithms with both synthetic and real data set.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/10",
    "Article_PDF": "https://arxiv.org/pdf/1903.04042"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.03804",
    "DOI": "arXiv:1903.03804v1",
    "Article_Title": "Program Classification Using Gated Graph Attention Neural Network for Online Programming Service",
    "Article_Abstract": "The online programing services, such as Github,TopCoder, and EduCoder, havepromoted a lot of social interactions among the service users. However, theexisting social interactions is rather limited and inefficient due to the rapidincreasing of source-code repositories, which is difficult to explore manually.The emergence of source-code mining provides a promising way to analyze thosesource codes, so that those source codes can be relatively easy to understandand share among those service users. Among all the source-code miningattempts,program classification lays a foundation for various tasks related tosource-code understanding, because it is impossible for a machine to understanda computer program if it cannot classify the program correctly. Althoughnumerous machine learning models, such as the Natural Language Processing (NLP)based models and the Abstract Syntax Tree (AST) based models, have beenproposed to classify computer programs based on their corresponding sourcecodes, the existing works cannot fully characterize the source codes from theperspective of both the syntax and semantic information. To address thisproblem, we proposed a Graph Neural Network (GNN) based model, which integratesdata flow and function call information to the AST,and applies an improved GNNmodel to the integrated graph, so as to achieve the state-of-art programclassification accuracy. The experiment results have shown that the proposedwork can classify programs with accuracy over 97%.",
    "Article_Subject": "Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/03/09",
    "Article_PDF": "https://arxiv.org/pdf/1903.03804"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.03375",
    "DOI": "arXiv:1903.03375v1",
    "Article_Title": "Online division of labour: emergent structures in Open Source Software",
    "Article_Abstract": "The development Open Source Software fundamentally depends on theparticipation and commitment of volunteer developers to progress. Several workshave presented strategies to increase the on-boarding and engagement of newcontributors, but little is known on how these diverse groups of developersself-organise to work together. To understand this, one must consider that, onone hand, platforms like GitHub provide a virtually unlimited developmentframework: any number of actors can potentially join to contribute in adecentralised, distributed, remote, and asynchronous manner. On the other,however, it seems reasonable that some sort of hierarchy and division of labourmust be in place to meet human biological and cognitive limits, and also toachieve some level of efficiency. These latter features (hierarchy and divisionof labour) should translate into recognisable structural arrangements whenprojects are represented as developer-file bipartite networks. In this paper weanalyse a set of popular open source projects from GitHub, placing the accenton three key properties: nestedness, modularity and in-block nestedness -whichtypify the emergence of heterogeneities among contributors, the emergence ofsubgroups of developers working on specific subgroups of files, and a mixtureof the two previous, respectively. These analyses show that indeed projectsevolve into internally organised blocks. Furthermore, the distribution of sizesof such blocks is bounded, connecting our results to the celebrated Dunbarnumber both in off- and on-line environments. Our analyses create a linkbetween bio-cognitive constraints, group formation and online workingenvironments, opening up a rich scenario for future research on (online) workteam assembly.",
    "Article_Subject": "Physics and Society (physics.soc-ph); Computers and Society (cs.CY); Software Engineering (cs.SE)",
    "Article_Date": "2019/03/08",
    "Article_PDF": "https://arxiv.org/pdf/1903.03375"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.02904",
    "DOI": "arXiv:1903.02904v1",
    "Article_Title": "Halin graphs are 3-vertex-colorable except even wheels",
    "Article_Abstract": "A Halin graph is a graph obtained by embedding a tree having no nodes ofdegree two in the plane, and then adding a cycle to join the leaves of the treein such a way that the resulting graph is planar. According to the four colortheorem, Halin graphs are 4-vertex-colorable. On the other hand, they are not2-vertex-colorable because they have triangles. We show that all Halin graphsare 3-vertex-colorable except even wheels. We also show how to find the perfectelimination ordering of a chordal completion for a given Halin graph. Thealgorithms are implemented in Python using the graphtheory package. Generatorsof random Halin graphs (general or cubic) are included. The source code isavailable from the public GitHub repository.",
    "Article_Subject": "Data Structures and Algorithms (cs.DS)",
    "Article_Date": "2019/03/07",
    "Article_PDF": "https://arxiv.org/pdf/1903.02904"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.02779",
    "DOI": "arXiv:1903.02779v4",
    "Article_Title": "Deep neural networks for classifying complex features in diffraction images",
    "Article_Abstract": "Intense short-wavelength pulses from free-electron lasers andhigh-harmonic-generation sources enable diffractive imaging of individualnano-sized objects with a single x-ray laser shot. The enormous data sets withup to several million diffraction patterns represent a severe problem for dataanalysis, due to the high dimensionality of imaging data. Feature recognitionand selection is a crucial step to reduce the dimensionality. Usually,custom-made algorithms are developed at a considerable effort to approximatethe particular features connected to an individual specimen, but facingdifferent experimental conditions, these approaches do not generalize well. Onthe other hand, deep neural networks are the principal instrument for today'srevolution in automated image recognition, a development that has not beenadapted to its full potential for data analysis in science. We recentlypublished in Langbehn et al. (Phys. Rev. Lett. 121, 255301 (2018)) the firstapplication of a deep neural network as a feature extractor for wide-anglediffraction images of helium nanodroplets. Here we present the setup, ourmodifications and the training process of the deep neural network fordiffraction image classification and its systematic benchmarking. We find thatdeep neural networks significantly outperform previous attempts for sorting andclassifying complex diffraction patterns and are a significant improvement forthe much-needed assistance during post-processing of large amounts ofexperimental coherent diffraction imaging data.",
    "Article_Subject": "Data Analysis, Statistics and Probability (physics.data-an); Atomic and Molecular Clusters (physics.atm-clus)",
    "Article_Date": "2019/03/07",
    "Article_PDF": "https://arxiv.org/pdf/1903.02779"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.02557",
    "DOI": "arXiv:1903.02557v3",
    "Article_Title": "DASH: Deep Learning for the Automated Spectral Classification of Supernovae and their Hosts",
    "Article_Abstract": "We present DASH (Deep Automated Supernova and Host classifier), a novelsoftware package that automates the classification of the type, age, redshift,and host galaxy of supernova spectra. DASH makes use of a new approach thatdoes not rely on iterative template matching techniques like all previoussoftware, but instead classifies based on the learned features of eachsupernova's type and age. It has achieved this by employing a deepconvolutional neural network to train a matching algorithm. This approach hasenabled DASH to be orders of magnitude faster than previous tools, being ableto accurately classify hundreds or thousands of objects within seconds. We havetested its performance on four years of data from the Australian Dark EnergySurvey (OzDES). The deep learning models were developed using TensorFlow, andwere trained using over 4000 supernova spectra taken from the CfA SupernovaProgram and the Berkeley SN Ia Program as used in SNID (SupernovaIdentification software, Blondin & Tonry 2007). Unlike template matchingmethods, the trained models are independent of the number of spectra in thetraining data, which allows for DASH's unprecedented speed. We have developedboth a graphical interface for easy visual classification and analysis ofsupernovae, and a Python library for the autonomous and quick classification ofseveral supernova spectra. The speed, accuracy, user-friendliness, andversatility of DASH presents an advancement to existing spectral classificationtools. We have made the code publicly available on GitHub and PyPI (pip installastrodash) to allow for further contributions and development. The packagedocumentation is available at https://astrodash.readthedocs.io.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Article_Date": "2019/03/06",
    "Article_PDF": "https://arxiv.org/pdf/1903.02557"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01742",
    "DOI": "arXiv:1903.01742v2",
    "Article_Title": "SZZ Unleashed: An Open Implementation of the SZZ Algorithm -- Featuring Example Usage in a Study of Just-in-Time Bug Prediction for the Jenkins Project",
    "Article_Abstract": "Numerous empirical software engineering studies rely on detailed informationabout bugs. While issue trackers often contain information about when bugs werefixed, details about when they were introduced to the system are often absent.As a remedy, researchers often rely on the SZZ algorithm as a heuristicapproach to identify bug-introducing software changes. Unfortunately, asreported in a recent systematic literature review, few researchers have madetheir SZZ implementations publicly available. Consequently, there is a riskthat research effort is wasted as new projects based on SZZ output need toinitially reimplement the approach. Furthermore, there is a risk that newlydeveloped (closed source) SZZ implementations have not been properly tested,thus conducting research based on their output might introduce threats tovalidity. We present SZZ Unleashed, an open implementation of the SZZ algorithmfor git repositories. This paper describes our implementation along with ausage example for the Jenkins project, and conclude with an illustrative studyon just-in-time bug prediction. We hope to continue evolving SZZ Unleashed onGitHub, and warmly invite the community to contribute.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/03/05",
    "Article_PDF": "https://arxiv.org/pdf/1903.01742"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01698",
    "DOI": "arXiv:1903.01698v3",
    "Article_Title": "Improving Cross-Domain Chinese Word Segmentation with Word Embeddings",
    "Article_Abstract": "Cross-domain Chinese Word Segmentation (CWS) remains a challenge despiterecent progress in neural-based CWS. The limited amount of annotated data inthe target domain has been the key obstacle to a satisfactory performance. Inthis paper, we propose a semi-supervised word-based approach to improvingcross-domain CWS given a baseline segmenter. Particularly, our model onlydeploys word embeddings trained on raw text in the target domain, discardingcomplex hand-crafted features and domain-specific dictionaries. Innovativesubsampling and negative sampling methods are proposed to derive wordembeddings optimized for CWS. We conduct experiments on five datasets inspecial domains, covering domains in novels, medicine, and patent. Results showthat our model can obviously improve cross-domain CWS, especially in thesegmentation of domain-specific noun entities. The word F-measure increases byover 3.0% on four datasets, outperforming state-of-the-art semi-supervised andunsupervised cross-domain CWS approaches with a large margin. We make our codeand data available on Github.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/03/05",
    "Article_PDF": "https://arxiv.org/pdf/1903.01698"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01555",
    "DOI": "arXiv:1903.01555v1",
    "Article_Title": "An Explorative Study of GitHub Repositories of AI Papers",
    "Article_Abstract": "With the rapid development of AI technologies, thousands of AI papers arebeing published each year. Many of these papers have released sample code tofacilitate follow-up researchers. This paper presents an explorative study ofover 1700 code repositories of AI papers hosted on GitHub. We find that theserepositories are often poorly written, lack of documents, lack of maintenance,and hard to configure the underlying runtime environment. Thus, many coderepositories become inactive and abandoned. Such a situation makes follow-upresearchers hard to reproduce the results or do further research. In addition,these hard-to-reuse code makes a gap between academia and industry. Based onthe findings, we give some recommendations on how to improve the quality ofcode repositories of AI papers.",
    "Article_Subject": "Digital Libraries (cs.DL)",
    "Article_Date": "2019/02/16",
    "Article_PDF": "https://arxiv.org/pdf/1903.01555"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01284",
    "DOI": "arXiv:1903.01284v1",
    "Article_Title": "Relation Extraction Datasets in the Digital Humanities Domain and their Evaluation with Word Embeddings",
    "Article_Abstract": "In this research, we manually create high-quality datasets in the digitalhumanities domain for the evaluation of language models, specifically wordembedding models. The first step comprises the creation of unigram and n-gramdatasets for two fantasy novel book series for two task types each, analogy anddoesn't-match. This is followed by the training of models on the two bookseries with various popular word embedding model types such as word2vec, GloVe,fastText, or LexVec. Finally, we evaluate the suitability of word embeddingmodels for such specific relation extraction tasks in a situation of comparablysmall corpus sizes. In the evaluations, we also investigate and analyzeparticular aspects such as the impact of corpus term frequencies and taskdifficulty on accuracy. The datasets, and the underlying system and wordembedding models are available on github and can be easily extended with newdatasets and tasks, be used to reproduce the presented results, or betransferred to other domains.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/03/04",
    "Article_PDF": "https://arxiv.org/pdf/1903.01284"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.00904",
    "DOI": "arXiv:1903.00904v1",
    "Article_Title": "Self-adversarial Variational Autoencoder with Gaussian Anomaly Prior Distribution for Anomaly Detection",
    "Article_Abstract": "Recently, deep generative models have become increasingly popular inunsupervised anomaly detection. However, deep generative models aim atrecovering the data distribution rather than detecting anomalies. Besides, deepgenerative models have the risk of overfitting training samples, which hasdisastrous effects on anomaly detection performance. To solve the above twoproblems, we propose a Self-adversarial Variational Autoencoder with a Gaussiananomaly prior assumption. We assume that both the anomalous and the normalprior distribution are Gaussian and have overlaps in the latent space.Therefore, a Gaussian transformer net T is trained to synthesize anomalous butnear-normal latent variables. Keeping the original training objective ofVariational Autoencoder, besides, the generator G tries to distinguish betweenthe normal latent variables and the anomalous ones synthesized by T, and theencoder E is trained to discriminate whether the output of G is real. These newobjectives we added not only give both G and E the ability to discriminate butalso introduce additional regularization to prevent overfitting. Compared withthe SOTA baselines, the proposed model achieves significant improvements inextensive experiments. Datasets and our model are available at a Githubrepository.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/03",
    "Article_PDF": "https://arxiv.org/pdf/1903.00904"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.00037",
    "DOI": "arXiv:1903.00037v1",
    "Article_Title": "Distance-Based Independence Screening for Canonical Analysis",
    "Article_Abstract": "This paper introduces a new method named Distance-based IndependenceScreening for Canonical Analysis (DISCA) to reduce dimensions of two randomvectors with arbitrary dimensions. The objective of our method is to identifythe low dimensional linear projections of two random vectors, such that anydimension reduction based on linear projection with lower dimensions willsurely affect some dependent structure -- the removed components are notindependent. The essence of DISCA is to use the distance correlation toeliminate the \"redundant\" dimensions until infeasible. Unlike the existingcanonical analysis methods, DISCA does not require the dimensions of thereduced subspaces of the two random vectors to be equal, nor does it requirecertain distributional assumption on the random vectors. We show that undermild conditions, our approach does undercover the lowest possible lineardependency structures between two random vectors, and our conditions are weakerthan some sufficient linear subspace-based methods. Numerically, DISCA is tosolve a non-convex optimization problem. We formulate it as adifference-of-convex (DC) optimization problem, and then further adopt thealternating direction method of multipliers (ADMM) on the convex step of the DCalgorithms to parallelize/accelerate the computation. Some sufficient linearsubspace-based methods use potentially numerically-intensive bootstrap methodto determine the dimensions of the reduced subspaces in advance; our methodavoids this complexity. In simulations, we present cases that DISCA can solveeffectively, while other methods cannot. In both the simulation studies andreal data cases, when the other state-of-the-art dimension reduction methodsare applicable, we observe that DISCA performs either comparably or better thanmost of them. Codes and an R package can be found in GitHubhttps://github.com/ChuanpingYu/DISCA.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/02/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.00037"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.11108",
    "DOI": "arXiv:1902.11108v2",
    "Article_Title": "Artist Style Transfer Via Quadratic Potential",
    "Article_Abstract": "In this paper we address the problem of artist style transfer where thepainting style of a given artist is applied on a real world photograph. Wetrain our neural networks in adversarial setting via recently introducedquadratic potential divergence for stable learning process. To further improvethe quality of generated artist stylized images we also integrate some of therecently introduced deep learning techniques in our method. To our bestknowledge this is the first attempt towards artist style transfer via quadraticpotential divergence. We provide some stylized image samples in thesupplementary material. The source code for experimentation was written inPyTorch and is available online in my GitHub repository.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/02/14",
    "Article_PDF": "https://arxiv.org/pdf/1902.11108"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.10149",
    "DOI": "arXiv:1902.10149v2",
    "Article_Title": "Primordial power spectrum and cosmology from black-box galaxy surveys",
    "Article_Abstract": "We propose a new, likelihood-free approach to inferring the primordial matterpower spectrum and cosmological parameters from arbitrarily complex forwardmodels of galaxy surveys where all relevant statistics can be determined fromnumerical simulations, i.e. black-boxes. Our approach, which we call simulatorexpansion for likelihood-free inference (SELFI), builds upon approximateBayesian computation using a novel effective likelihood, and upon thelinearisation of black-box models around an expansion point. Consequently, weobtain simple \"filter equations\" for an effective posterior of the primordialpower spectrum, and a straightforward scheme for cosmological parameterinference. We demonstrate that the workload is computationally tractable, fixeda priori, and perfectly parallel. As a proof of concept, we apply our frameworkto a realistic synthetic galaxy survey, with a data model accounting forphysical structure formation and incomplete and noisy galaxy observations. Indoing so, we show that the use of non-linear numerical models allows the galaxypower spectrum to be safely fitted up to at least $k_\\mathrm{max} = 0.5$$h$/Mpc, outperforming state-of-the-art backward-modelling techniques by afactor of $\\sim 5$ in the number of modes used. The result is an unbiasedinference of the primordial matter power spectrum across the entire range ofscales considered, including a high-fidelity reconstruction of baryon acousticoscillations. It translates into an unbiased and robust inference ofcosmological parameters. Our results pave the path towards easy applications oflikelihood-free simulation-based inference in cosmology. We have made our codepySELFI and our data products publicly available athttp://pyselfi.florent-leclercq.eu.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/02/26",
    "Article_PDF": "https://arxiv.org/pdf/1902.10149"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.09386",
    "DOI": "arXiv:1902.09386v1",
    "Article_Title": "SMARTp: A SMART design for non-surgical treatments of chronic periodontitis with spatially-referenced and non-randomly missing skewed outcomes",
    "Article_Abstract": "This paper proposes dynamic treatment regimes for choosing individualizedeffective treatment strategies of chronic periodontal disease. R codes forimplementing the proposed sample size formula are available in GitHub.",
    "Article_Subject": "Applications (stat.AP)",
    "Article_Date": "2019/02/25",
    "Article_PDF": "https://arxiv.org/pdf/1902.09386"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.08702",
    "DOI": "arXiv:1902.08702v1",
    "Article_Title": "pyro: a framework for hydrodynamics explorations and prototyping",
    "Article_Abstract": "pyro is a Python-based simulation framework designed for ease ofimplementation and exploration of hydrodynamics methods. It is built in aobject-oriented fashion, allowing for the reuse of the core components and fastprototyping of new methods.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/02/22",
    "Article_PDF": "https://arxiv.org/pdf/1902.08702"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.08182",
    "DOI": "arXiv:1902.08182v1",
    "Article_Title": "Finding the Needle in a Haystack: Detrending Photometric Timeseries Data of Strictly Periodic Astrophysical Objects",
    "Article_Abstract": "Light curves of astrophysical objects frequently contain strictly periodicsignals. In those cases we can use that property to aid the detrendingalgorithm to fully disentangle an unknown periodic signal and an unknownbaseline signal with no power at that period. The periodic signal is modeled asa discrete probability distribution function (pdf), while the baseline signalis modeled as a residual timeseries. Those two components are disentangled byminimizing the length of the residual timeseries w.r.t. the per-bin pdf fluxes.We demonstrate the use of the algorithm on a synthetic case, on the eclipsingbinary KIC 3953981 and on the eccentric ellipsoidal variable KIC 3547874. Wefurther discuss the parameters and the limitations of the algorithm andspeculate on the two most common use cases: detrending the periodic signal ofinterest and measuring the dependence of instrumental response on controlledinstrumental variables. A more sophisticated version of the algorithm isreleased as open source on github and available via pip.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Solar and Stellar Astrophysics (astro-ph.SR)",
    "Article_Date": "2019/02/21",
    "Article_PDF": "https://arxiv.org/pdf/1902.08182"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.07740",
    "DOI": "arXiv:1902.07740v1",
    "Article_Title": "Nitrogen Oxide Concentrations in Natural Waters on Early Earth",
    "Article_Abstract": "A key challenge in origins-of-life studies is estimating the abundances ofspecies relevant to the chemical pathways proposed to have contributed to theemergence of life on early Earth. Dissolved nitrogen oxide anions(NO$_{X}^{-}$), in particular nitrate (NO$_{3}^{-}$) and nitrite(NO$_{2}^{-}$), have been invoked in diverse origins-of-life chemistry, fromthe oligomerization of RNA to the emergence of protometabolism. Recent work hascalculated the supply of NO$_{X}^{-}$ from the prebiotic atmosphere to theocean, and reported steady-state [NO$_{X}^{-}$] to be high across all plausibleparameter space. These findings rest on the assumption that NO$_{X}^{-}$ isstable in natural waters unless processed at a hydrothermal vent. Here, we showthat NO$_{X}^{-}$ is unstable in the reducing environment of early Earth. Sinksdue to UV photolysis and reactions with reduced iron (Fe$^{2+}$) suppress[NO$_{X}^{-}$] by several orders of magnitude relative to past predictions. ForpH$=6.5-8$ and $T=0-50^\\circ$C, we find that it is most probable thatNO$_{X}^{-}$]$<1~\u03bc$M in the prebiotic ocean. On the other hand, prebioticponds with favorable drainage characteristics may have sustained[NO$_{X}^{-}$]$\\geq 1~\u03bc$M. As on modern Earth, most NO$_{X}^{-}$ on prebioticEarth should have been present as NO$_{3}^{-}$, due to its much greaterstability. These findings inform the kind of prebiotic chemistries that wouldhave been possible on early Earth. We discuss the implications for proposedprebiotic chemistries, and highlight the need for further studies ofNO$_{X}^{-}$ kinetics to reduce the considerable uncertainties in predicting[NO$_{X}^{-}$] on early Earth.",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP)",
    "Article_Date": "2019/02/20",
    "Article_PDF": "https://arxiv.org/pdf/1902.07740"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.07704",
    "DOI": "arXiv:1902.07704v1",
    "Article_Title": "How Do the Open Source Communities Address Usability and UX Issues? An Exploratory Study",
    "Article_Abstract": "Usability and user experience (UX) issues are often not well emphasized andaddressed in open source software (OSS) development. There is an imperativeneed for supporting OSS communities to collaboratively identify, understand,and fix UX design issues in a distributed environment. In this paper, weprovide an initial step towards this effort and report on an exploratory studythat investigated how the OSS communities currently reported, discussed,negotiated, and eventually addressed usability and UX issues. We conductedin-depth qualitative analysis of selected issue tracking threads from three OSSprojects hosted on GitHub. Our findings indicated that discussions aboutusability and UX issues in OSS communities were largely influenced by thepersonal opinions and experiences of the participants. Moreover, thecharacteristics of the community may have greatly affected the focus of suchdiscussion.",
    "Article_Subject": "Human-Computer Interaction (cs.HC); Software Engineering (cs.SE)",
    "Article_Date": "2019/02/20",
    "Article_PDF": "https://arxiv.org/pdf/1902.07704"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.03867",
    "DOI": "arXiv:1910.03867v1",
    "Article_Title": "Loss Surface Sightseeing by Multi-Point Optimization",
    "Article_Abstract": "We present multi-point optimization: an optimization technique that allows totrain several models simultaneously without the need to keep the parameters ofeach one individually. The proposed method is used for a thorough empiricalanalysis of the loss landscape of neural networks. By extensive experiments onFashionMNIST and CIFAR10 datasets we demonstrate two things: 1) loss surface issurprisingly diverse and intricate in terms of landscape patterns it contains,and 2) adding batch normalization makes it more smooth. Source code toreproduce all the reported results is available on GitHub:https://github.com/universome/loss-patterns.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/10/09",
    "Article_PDF": "https://arxiv.org/pdf/1910.03867"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.02513",
    "DOI": "arXiv:1910.02513v1",
    "Article_Title": "Automated Isolation for White-box Test Generation",
    "Article_Abstract": "Context. White-box test generation is a technique used for automaticallyselecting test inputs using only the source or binary code. However, suchtechniques encounter challenges when applying them to complex programs. One ofthe main challenges is handling the dependencies of the unit under test.  Objective. Without proper actions, generated tests cannot cover all parts ofthe source code, or calling the dependencies may cause unexpected side effects(e.g., file system or network access). These issues should be tackled whilemaintaining the advantages of white-box test generation.  Method. In this paper, we present an automated source code transformationapproach tackling the dependency issue for white-box test generation. Thistechnique isolates the test execution by creating a parameterized sandboxwrapped around the transformed unit. We implemented the approach in aready-to-use tool using Microsoft Pex as a test generator, and evaluated it on10 open-source projects from GitHub having more than 38.000 lines of code intotal.  Results. The results from the evaluation indicate that if the lack ofisolation hinders white-box test generation, then our approach is able to help:it increases the code coverage reached by the automatically generated test,while it reduces unwanted side effects. Also, our results act as a uniquebaseline for the test generation performance of Microsoft Pex on open-sourceprojects.  Conclusion. Based on the results, our source code transformations might servewell for alleviating the isolation problem in white-box test generation as itincreases the coverage reached in such situations, while maintaining thepractical applicability of the tests generated on the isolated code.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/10/06",
    "Article_PDF": "https://arxiv.org/pdf/1910.02513"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01750",
    "DOI": "arXiv:1910.01750v2",
    "Article_Title": "PEXO: a global modeling framework for nanosecond timing, microsecond astrometry, and {\\mu}m/s radial velocities",
    "Article_Abstract": "The ability to make independent detections of the signatures of exoplanetswith complementary telescopes and instruments brings a new potential for robustidentification of exoplanets and precision characterization. We introduce PEXO,a package for Precise EXOplanetology to facilitate the efficient modeling oftiming, astrometry, and radial velocity data, which will benefit not onlyexoplanet science but also various astrophysical studies in general. PEXO isgeneral enough to account for binary motion and stellar reflex motions inducedby planetary companions and is precise enough to treat various relativisticeffects both in the solar system and in the target system. We also model thepost-Newtonian barycentric motion for future tests of general relativity inextrasolar systems. We benchmark PEXO with the pulsar timing package TEMPO2 andfind that PEXO produces numerically similar results with timing precision ofabout 1 ns, space-based astrometry to a precision of 1\u03bcas, and radialvelocity of 1 \u03bcm/s and improves on TEMPO2 for decade-long timing data ofnearby targets, due to its consideration of third-order terms of Roemer delay.PEXO is able to avoid the bias introduced by decoupling the target system andthe solar system and to account for the atmospheric effects which set apractical limit for ground-based radial velocities close to 1 cm/s. Consideringthe various caveats in barycentric correction and ancillary data required torealize cm/s modeling, we recommend the preservation of original observationaldata. The PEXO modeling package is available at GitHub(https://github.com/phillippro/pexo).",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM); Solar and Stellar Astrophysics (astro-ph.SR)",
    "Article_Date": "2019/10/03",
    "Article_PDF": "https://arxiv.org/pdf/1910.01750"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01321",
    "DOI": "arXiv:1910.01321v1",
    "Article_Title": "An Empirical Study of C++ Vulnerabilities in Crowd-Sourced Code Examples",
    "Article_Abstract": "Software developers share programming solutions in Q&A sites like StackOverflow. The reuse of crowd-sourced code snippets can facilitate rapidprototyping. However, recent research shows that the shared code snippets maybe of low quality and can even contain vulnerabilities. This paper aims tounderstand the nature and the prevalence of security vulnerabilities incrowd-sourced code examples. To achieve this goal, we investigate securityvulnerabilities in the C++ code snippets shared on Stack Overflow over a periodof 10 years. In collaborative sessions involving multiple human coders, wemanually assessed each code snippet for security vulnerabilities following CWE(Common Weakness Enumeration) guidelines. From the 72,483 reviewed codesnippets used in at least one project hosted on GitHub, we found a total of 69vulnerable code snippets categorized into 29 types. Many of the investigatedcode snippets are still not corrected on Stack Overflow. The 69 vulnerable codesnippets found in Stack Overflow were reused in a total of 2859 GitHubprojects. To help improve the quality of code snippets shared on StackOverflow, we developed a browser extension that allow Stack Overflow users tocheck for vulnerabilities in code snippets when they upload them on theplatform.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/10/03",
    "Article_PDF": "https://arxiv.org/pdf/1910.01321"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01212",
    "DOI": "arXiv:1910.01212v1",
    "Article_Title": "Social Influence and Radicalization: A Social Data Analytics Study",
    "Article_Abstract": "The confluence of technological and societal advances is changing the natureof global terrorism. For example, engagement with Web, social media, and smartdevices has the potential to affect the mental behavior of the individuals andinfluence extremist and criminal behaviors such as Radicalization. In thiscontext, social data analytics (i.e., the discovery, interpretation, andcommunication of meaningful patterns in social data) and influence maximization(i.e., the problem of finding a small subset of nodes in a social network whichcan maximize the propagation of influence) has the potential to become a vitalasset to explore the factors involved in influencing people to participate inextremist activities.  To address this challenge, we study and analyze the recent work done ininfluence maximization and social data analytics from effectiveness, efficiencyand scalability viewpoints. We introduce a social data analytics pipeline,namely iRadical, to enable analysts engage with social data to explore thepotential for online radicalization. In iRadical, we present algorithms toanalyse the social data as well as the user activity patterns to learn howinfluence flows in social networks. We implement iRadical as an extensiblearchitecture that is publicly available on GitHub and present the evaluationresults.",
    "Article_Subject": "Computers and Society (cs.CY); Machine Learning (cs.LG)",
    "Article_Date": "2019/09/04",
    "Article_PDF": "https://arxiv.org/pdf/1910.01212"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01078",
    "DOI": "arXiv:1910.01078v1",
    "Article_Title": "ROS Rescue : Fault Tolerance System for Robot Operating System",
    "Article_Abstract": "In this chapter we discuss the problem of master failure in ROS1.0 and itsimpact on robotic deployments in the real world. We address this issue in thistutorial chapter where we outline, design and demonstrate a fault tolerantmechanism associated with ROS master failure. Unlike previous solutions whichuse primary backup replication and external checkpointing libraries which areprocess heavy, our mechanism adds a lightweight functionality to the ROS masterto enable it to recover from failure.  We present a modified version of ROS master which is equipped with a loggingmechanism to record the meta information and network state of ROS nodes as wellas a recovery mechanism to go back to the previous state without having toabort or restart all the nodes. We also implement an additional master monitornode responsible for failure detection on the master by polling it for itsavailability. Our code is implemented in python and preliminary tests wereconducted successfully on a variety of land, aerial and underwater robots and atele-operating computer running ROS Kinetic on Ubuntu 16.04. The code ispublicly available under a creative commons license on github athttps://github.com/PushyamiKaveti/fault-tolerant-ros-master",
    "Article_Subject": "Robotics (cs.RO)",
    "Article_Date": "2019/10/02",
    "Article_PDF": "https://arxiv.org/pdf/1910.01078"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00725",
    "DOI": "arXiv:1910.00725v1",
    "Article_Title": "Cosmic Microwave Background Anisotropy numerical solution (CMBAns) I: An introduction to $C_l$ calculation",
    "Article_Abstract": "Cosmological Boltzmann codes are often used by researchers for calculatingthe CMB angular power spectra from different theoretical models, forcosmological parameter estimation, etc. Therefore, the accuracy of a Boltzmanncode is of utmost importance. Different Markov Chain Monte Carlo basedparameter estimation algorithms typically require 10^3 - 10^4 iterations ofBoltzmann code. This makes the time complexity of such codes another criticalfactor. In the last two decades, several Boltzmann packages, such as CMBFAST,CAMB, CMBEasy, CLASS etc., have been developed. In this paper, we present a newcosmological Boltzmann code, CMBAns, that can be used for accurate calculationof the CMB power spectrum. At present, CMBAns is developed for a flatbackground matrix. It is mostly written in the C language. However, we borrowedthe concept of class from C++. This gives researchers the flexibility todevelop their own independent package based on CMBAns, without an in-depthunderstanding of the source code. We also develop multiple stand-alonefacilities which can be directly compiled and run on a given parameter set. Inthis paper, we discuss all the mathematical formulation, approximation schemes,integration methods etc., that are used in CMBAns. The package will be madeavailable through github for public use in the near future.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); Instrumentation and Methods for Astrophysics (astro-ph.IM); General Relativity and Quantum Cosmology (gr-qc)",
    "Article_Date": "2019/10/02",
    "Article_PDF": "https://arxiv.org/pdf/1910.00725"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00536",
    "DOI": "arXiv:1910.00536v1",
    "Article_Title": "Scalable String Reconciliation by Recursive Content-Dependent Shingling",
    "Article_Abstract": "We consider the problem of reconciling similar, but remote, strings withminimum communication complexity. This \"string reconciliation\" problem is afundamental building block for a variety of networking applications, includingthose that maintain large-scale distributed networks and perform remote filesynchronization. We present the novel Recursive Content-Dependent Shingling(RCDS) protocol that is computationally practical for large strings and scaleslinearly with the edit distance between the remote strings. We providecomparisons to the performance of Rsync, one of the most popular filesynchronization tools in active use. Our experiments show that, with minimalengineering, RCDS outperforms the heavily optimized Rsync in reconcilingrelease revisions for about 51% of the 5000 top starred git repositories onGitHub. The improvement is particularly evident for repositories that seefrequent, but small, updates.",
    "Article_Subject": "Information Theory (cs.IT)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00536"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00286",
    "DOI": "arXiv:1910.00286v1",
    "Article_Title": "Ransomware Analysis using Feature Engineering and Deep Neural Networks",
    "Article_Abstract": "Detection and Analysis of a potential malware specifically, used for ransomis a challenging task. Recently, intruders are utilizing advance cryptographictechniques to get hold of digital assets and then demand ransom. It is believedthat generally, the files comprise of some attributes, states, and patternsthat can be recognized by a machine learning technique. This work thus focuseson detection of Ransomware by performing feature engineering, which helps inanalyzing vital attributes and behaviors of the malware. The main contributionof this work is the identification of important and distinct characteristics ofRansomware that can help in detecting them. Finally, based on the selectedfeatures, both conventional machine learning techniques and Transfer Learningbased Deep Convolutional Neural Networks have been used to detect Ransomware.In order to perform feature engineering and analysis, two separate datasets(static and dynamic) were generated. The static dataset has 3646 samples (1700Ransomware and 1946 Goodware). On the other hand, the dynamic dataset comprisedof 3444 samples (1455 Ransomware and 1989 Goodware). Through variousexperiments, it is observed that the Registry changes, API calls, and DLLs arethe most important features for Ransomware detection. Additionally, importantsequences are found with the help of N Gram technique. It is also observed thatin case of Registry Delete operation, if a malicious file tries to deleteregistries, it follows a specific and repeated sequence. However for the benignfile, it doesnt follow any specific sequence or repetition. Similarly, aninteresting observation made through this study is that there is no commonRegistry deleted sequence between malicious and benign file. And thus thisdiscernible fact can be readily exploited for Ransomware detection. Therelevant Python code and dataset are available at github.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00286"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00199",
    "DOI": "arXiv:1910.00199v1",
    "Article_Title": "Underwhelming Generalization Improvements From Controlling Feature Attribution",
    "Article_Abstract": "Overfitting is a common issue in machine learning, which can arise when themodel learns to predict class membership using convenient butspuriously-correlated image features instead of the true image features thatdenote a class. These are typically visualized using saliency maps. In someobject classification tasks such as for medical images, one may have someimages with masks, indicating a region of interest, i.e., which part of theimage contains the most relevant information for the classification. Wedescribe a simple method for taking advantage of such auxiliary labels, bytraining networks to ignore the distracting features which may be extractedoutside of the region of interest, on the training images for which such masksare available. This mask information is only used during training and has animpact on generalization accuracy in a dataset-dependent way. We observe anunderwhelming relationship between controlling saliency maps and improvinggeneralization performance.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00199"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00188",
    "DOI": "arXiv:1910.00188v1",
    "Article_Title": "Beyond Textual Issues: Understanding the Usage and Impact of GitHub Reactions",
    "Article_Abstract": "Recently, GitHub introduced a new social feature, named reactions, which are\"pictorial characters\" similar to emoji symbols widely used nowadays intext-based communications. Particularly, GitHub users can use a pre-defined setof such symbols to react to issues and pull requests. However, little is knownabout the real usage and impact of GitHub reactions. In this paper, we analyzethe reactions provided by developers to more than 2.5 million issues and 9.7million issue comments, in order to answer an extensive list of nine researchquestions about the usage and adoption of reactions. We show that reactions arebeing increasingly used by open source developers. Moreover, we also found thatissues with reactions usually take more time to be handled and have longerdiscussions.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00188"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00024",
    "DOI": "arXiv:1910.00024v1",
    "Article_Title": "Neural Canonical Transformation with Symplectic Flows",
    "Article_Abstract": "Canonical transformation plays a fundamental role in simplifying and solvingclassical Hamiltonian systems. We construct flexible and powerful canonicaltransformations as generative models using symplectic neural networks. Themodel transforms physical variables towards a latent representation with anindependent harmonic oscillator Hamiltonian. Correspondingly, the phase spacedensity of the physical system flows towards a factorized Gaussian distributionin the latent space. Since the canonical transformation preserves theHamiltonian evolution, the model captures nonlinear collective modes in thelearned latent representation. We present an efficient implementation ofsymplectic neural coordinate transformations and two ways to train the model.The variational free energy calculation is based on the analytical form ofphysical Hamiltonian. While the phase space density estimation only requiressamples in the coordinate space for separable Hamiltonians. We demonstrateappealing features of neural canonical transformation using toy problemsincluding two-dimensional ring potential and harmonic chain. Finally, we applythe approach to real-world problems such as identifying slow collective modesin alanine dipeptide and conceptual compression of the MNIST dataset.",
    "Article_Subject": "Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG); Computational Physics (physics.comp-ph); Machine Learning (stat.ML)",
    "Article_Date": "2019/09/30",
    "Article_PDF": "https://arxiv.org/pdf/1910.00024"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.13589",
    "DOI": "arXiv:1909.13589v1",
    "Article_Title": "Domain Adaptation for Semantic Segmentation with Maximum Squares Loss",
    "Article_Abstract": "Deep neural networks for semantic segmentation always require a large numberof samples with pixel-level labels, which becomes the major difficulty in theirreal-world applications. To reduce the labeling cost, unsupervised domainadaptation (UDA) approaches are proposed to transfer knowledge from labeledsynthesized datasets to unlabeled real-world datasets. Recently, somesemi-supervised learning methods have been applied to UDA and achievedstate-of-the-art performance. One of the most popular approaches insemi-supervised learning is the entropy minimization method. However, whenapplying the entropy minimization to UDA for semantic segmentation, thegradient of the entropy is biased towards samples that are easy to transfer. Tobalance the gradient of well-classified target samples, we propose the maximumsquares loss. Our maximum squares loss prevents the training process beingdominated by easy-to-transfer samples in the target domain. Besides, weintroduce the image-wise weighting ratio to alleviate the class imbalance inthe unlabeled target domain. Both synthetic-to-real and cross-city adaptationexperiments demonstrate the effectiveness of our proposed approach. The code isreleased at https://github. com/ZJULearning/MaxSquareLoss.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/30",
    "Article_PDF": "https://arxiv.org/pdf/1909.13589"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.13092",
    "DOI": "arXiv:1909.13092v1",
    "Article_Title": "GLA-Net: An Attention Network with Guided Loss for Mismatch Removal",
    "Article_Abstract": "Mismatch removal is a critical prerequisite in many feature-based tasks.Recent attempts cast the mismatch removal task as a binary classificationproblem and solve it through deep learning based methods. In these methods, theimbalance between positive and negative classes is important, which affectsnetwork performance, i.e., Fn-score. To establish the link between Fn-score andloss, we propose to guide the loss with the Fn-score directly. We theoreticallydemonstrate the direct link between our Guided Loss and Fn-score duringtraining. Moreover, we discover that outliers often impair global context inmismatch removal networks. To address this issue, we introduce the attentionmechanism to mismatch removal task and propose a novel Inlier Attention Block(IA Block). To evaluate the effectiveness of our loss and IA Block, we designan end-to-end network for mismatch removal, called GLA-Net \\footnote{Our codewill be available in Github later.}. Experiments have shown that our networkachieves the state-of-the-art performance on benchmark datasets.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/28",
    "Article_PDF": "https://arxiv.org/pdf/1909.13092"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.11977",
    "DOI": "arXiv:1909.11977v1",
    "Article_Title": "Stochastic Weight Matrix-based Regularization Methods for Deep Neural Networks",
    "Article_Abstract": "The aim of this paper is to introduce two widely applicable regularizationmethods based on the direct modification of weight matrices. The first method,Weight Reinitialization, utilizes a simplified Bayesian assumption withpartially resetting a sparse subset of the parameters. The second one, WeightShuffling, introduces an entropy- and weight distribution-invariant non-whitenoise to the parameters. The latter can also be interpreted as an ensembleapproach. The proposed methods are evaluated on benchmark datasets, such asMNIST, CIFAR-10 or the JSB Chorales database, and also on time series modelingtasks. We report gains both regarding performance and entropy of the analyzednetworks. We also made our code available as a GitHub repository(https://github.com/rpatrik96/lod-wmm-2019).",
    "Article_Subject": "Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)",
    "Article_Date": "2019/09/26",
    "Article_PDF": "https://arxiv.org/pdf/1909.11977"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.11811",
    "DOI": "arXiv:1909.11811v1",
    "Article_Title": "A fast, complete, point cloud based loop closure for LiDAR odometry and mapping",
    "Article_Abstract": "This paper presents a loop closure method to correct the long-term drift inLiDAR odometry and mapping (LOAM). Our proposed method computes the 2Dhistogram of keyframes, a local map patch, and uses the normalizedcross-correlation of the 2D histograms as the similarity metric between thecurrent keyframe and those in the map. We show that this method is fast,invariant to rotation, and produces reliable and accurate loop detection. Theproposed method is implemented with careful engineering and integrated into theLOAM algorithm, forming a complete and practical system ready to use. Tobenefit the community by serving a benchmark for loop closure, the entiresystem is made open source on Github",
    "Article_Subject": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/25",
    "Article_PDF": "https://arxiv.org/pdf/1909.11811"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.11544",
    "DOI": "arXiv:1909.11544v1",
    "Article_Title": "PyDEns: a Python Framework for Solving Differential Equations with Neural Networks",
    "Article_Abstract": "Recently, a lot of papers proposed to use neural networks to approximatelysolve partial differential equations (PDEs). Yet, there has been a lack offlexible framework for convenient experimentation. In an attempt to fill thegap, we introduce a PyDEns-module open-sourced on GitHub. Coupled withcapabilities of BatchFlow, open-source framework for convenient andreproducible deep learning, PyDEns-module allows to 1) solve partialdifferential equations from a large family, including heat equation and waveequation 2) easily search for the best neural-network architecture among thezoo, that includes ResNet and DenseNet 3) fully control the process ofmodel-training by testing different point-sampling schemes. With that in mind,our main contribution goes as follows: implementation of a ready-to-use andopen-source numerical solver of PDEs of a novel format, based on neuralnetworks.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/09/25",
    "Article_PDF": "https://arxiv.org/pdf/1909.11544"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.10051",
    "DOI": "arXiv:1909.10051v1",
    "Article_Title": "PyIT2FLS: A New Python Toolkit for Interval Type 2 Fuzzy Logic Systems",
    "Article_Abstract": "Fuzzy logic is an accepted and well-developed approach for constructingverbal models. Fuzzy based methods are getting more popular, while theengineers deal with more daily life tasks. This paper presents a new Pythontoolkit for Interval Type 2 Fuzzy Logic Systems (IT2FLS). Developing softwaretools is an important issue for facilitating the practical use of theoreticalresults. There are limited tools for implementing IT2FLSs in Python. Thedeveloped PyIT2FLS is providing a set of tools for fast and easy modeling offuzzy systems. This paper includes a brief description of how developed toolkitcan be used. Also, three examples are given showing the usage of the developedtoolkit for simulating IT2FLSs. First, a simple rule-based system is developedand it's codes are presented in the paper. The second example is the predictionof the Mackey-Glass chaotic time series using IT2FLS. In this example, theParticle Swarm Optimization (PSO) algorithm is used for determining systemparameters while minimizing the mean square error. In the last example, anIT2FPID is used in a linear time-delay system. The code for the examples areavailable on toolkit's GitHub page: https://github.com/Haghrah/PyIT2FLS. Thesimulations and their results confirm the ability of the developed toolkit tobe used in a wide range of the applications.",
    "Article_Subject": "Systems and Control (eess.SY); Mathematical Software (cs.MS)",
    "Article_Date": "2019/09/22",
    "Article_PDF": "https://arxiv.org/pdf/1909.10051"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.09029",
    "DOI": "arXiv:1909.09029v2",
    "Article_Title": "DIRE: A Neural Approach to Decompiled Identifier Naming",
    "Article_Abstract": "The decompiler is one of the most common tools for examining binaries withoutcorresponding source code. It transforms binaries into high-level code,reversing the compilation process. Decompilers can reconstruct much of theinformation that is lost during the compilation process (e.g., structure andtype information). Unfortunately, they do not reconstruct semanticallymeaningful variable names, which are known to increase code understandability.We propose the Decompiled Identifier Renaming Engine (DIRE), a novelprobabilistic technique for variable name recovery that uses both lexical andstructural information recovered by the decompiler. We also present a techniquefor generating corpora suitable for training and evaluating models ofdecompiled code renaming, which we use to create a corpus of 164,632 uniquex86-64 binaries generated from C projects mined from GitHub. Our results showthat on this corpus DIRE can predict variable names identical to the names inthe original source code up to 74.3% of the time.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/09/19",
    "Article_PDF": "https://arxiv.org/pdf/1909.09029"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.08766",
    "DOI": "arXiv:1909.08766v1",
    "Article_Title": "A High-Fidelity Open Embodied Avatar with Lip Syncing and Expression Capabilities",
    "Article_Abstract": "Embodied avatars as virtual agents have many applications and providebenefits over disembodied agents, allowing non-verbal social and interactionalcues to be leveraged, in a similar manner to how humans interact with eachother. We present an open embodied avatar built upon the Unreal Engine that canbe controlled via a simple python programming interface. The avatar has lipsyncing (phoneme control), head gesture and facial expression (using eitherfacial action units or cardinal emotion categories) capabilities. We releasecode and models to illustrate how the avatar can be controlled like a puppet orused to create a simple conversational agent using public applicationprogramming interfaces (APIs). GITHUB link:https://github.com/danmcduff/AvatarSim",
    "Article_Subject": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)",
    "Article_Date": "2019/09/19",
    "Article_PDF": "https://arxiv.org/pdf/1909.08766"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.06700",
    "DOI": "arXiv:1909.06700v1",
    "Article_Title": "Loam_livox: A fast, robust, high-precision LiDAR odometry and mapping package for LiDARs of small FoV",
    "Article_Abstract": "LiDAR odometry and mapping (LOAM) has been playing an important role inautonomous vehicles, due to its ability to simultaneously localize the robot'spose and build high-precision, high-resolution maps of the surroundingenvironment. This enables autonomous navigation and safe path planning ofautonomous vehicles. In this paper, we present a robust, real-time LOAMalgorithm for LiDARs with small FoV and irregular samplings. By taking efforton both front-end and back-end, we address several fundamental challengesarising from such LiDARs, and achieve better performance in both precision andefficiency compared to existing baselines. To share our findings and to makecontributions to the community, we open source our codes on Github",
    "Article_Subject": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/09/15",
    "Article_PDF": "https://arxiv.org/pdf/1909.06700"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.05983",
    "DOI": "arXiv:1909.05983v1",
    "Article_Title": "Content-Aware Unsupervised Deep Homography Estimation",
    "Article_Abstract": "Robust homography estimation between two images is a fundamental task whichhas been widely applied to various vision applications. Traditional featurebased methods often detect image features and fit a homography according tomatched features with RANSAC outlier removal. However, the quality ofhomography heavily relies on the quality of image features, which are prone toerrors with respect to low light and low texture images. On the other hand,previous deep homography approaches either synthesize images for supervisedlearning or adopt aerial images for unsupervised learning, both ignoring theimportance of depth disparities in homography estimation. Moreover, they treatthe image content equally, including regions of dynamic objects and near-rangeforegrounds, which further decreases the quality of estimation. In this work,to overcome such problems, we propose an unsupervised deep homography methodwith a new architecture design. We learn a mask during the estimation to rejectoutlier regions. In addition, we calculate loss with respect to our learneddeep features instead of directly comparing the image contents as didpreviously. Moreover, a comprehensive dataset is presented, covering bothregular and challenging cases, such as poor textures and non-planarinterferences. The effectiveness of our method is validated through comparisonswith both feature-based and previous deep-based methods. Code will be soonavailable at Github.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/12",
    "Article_PDF": "https://arxiv.org/pdf/1909.05983"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.05090",
    "DOI": "arXiv:1909.05090v1",
    "Article_Title": "DNANet: De-Normalized Attention Based Multi-Resolution Network for Human Pose Estimation",
    "Article_Abstract": "Recently, multi-resolution networks (such as Hourglass, CPN, HRNet, etc.)have achieved significant performance on the task of human pose estimation bycombining features from various resolutions. In this paper, we propose a noveltype of attention module, namely De-Normalized Attention (DNA) to deal with thefeature attenuations of conventional attention modules. Our method extends theoriginal HRNet with spatial, channel-wise and resolution-wise DNAs, which aimsat evaluating the importance of features from different locations, channels andresolutions to enhance the network capability for feature representation. Wealso propose to add fine-to-coarse connections across high-to-low resolutionsin-side each layer of HRNet to increase the maximum depth of network topology.In addition, we propose to modify the keypoint regressor at the end of HRNetfor accurate keypoint heatmap prediction. The effectiveness of our proposednetwork is demonstrated on COCO keypoint detection dataset, achievingstate-of-the-art performance at 76.9 AP score on COCO val2017 dataset withoutusing extra keypoint training data. Our paper will be accompanied with publiclyavailable codes at GitHub.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/09/11",
    "Article_PDF": "https://arxiv.org/pdf/1909.05090"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.04556",
    "DOI": "arXiv:1909.04556v1",
    "Article_Title": "Human Languages in Source Code: Auto-Translation for Localized Instruction",
    "Article_Abstract": "Computer science education has promised open access around the world, butaccess is largely determined by what human language you speak. As youngerstudents learn computer science it is less appropriate to assume that theyshould learn English beforehand. To that end we present CodeInternational, thefirst tool to translate code between human languages. To develop a theory ofnon-English code, and inform our translation decisions, we conduct a study ofpublic code repositories on GitHub. The study is to the best of our knowledgethe first on human-language in code and covers 2.9 million Java repositories.To demonstrate CodeInternational's educational utility, we build an interactiveversion of the popular English-language Karel reader and translate it into 100spoken languages. Our translations have already been used in classrooms aroundthe world, and represent a first step in an important open CS-educationproblem.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/09/10",
    "Article_PDF": "https://arxiv.org/pdf/1909.04556"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.04301",
    "DOI": "arXiv:1909.04301v1",
    "Article_Title": "Frequency domain variant of Velvet noise and its application to acoustic measurements",
    "Article_Abstract": "We propose a new family of test signals for acoustic measurements such asimpulse response, nonlinearity, and the effects of background noise. Theproposed family complements difficulties in existing families, the Swept-Sine(SS), pseudo-random noise such as the maximum length sequence (MLS). Theproposed family uses the frequency domain variant of the Velvet noise (FVN) asits building block. An FVN is an impulse response of an all-pass filter andyields the unit impulse when convolved with the time-reversed version ofitself. In this respect, FVN is a member of the time-stretched pulse (TSP) inthe broadest sense. The high degree of freedom in designing an FVN opens a vastrange of applications in acoustic measurement. We introduce the followingapplications and their specific procedures, among other possibilities. They areas follows. a) Spectrum shaping adaptive to background noise. b) Simultaneousmeasurement of impulse responses of multiple acoustic paths. d) Simultaneousmeasurement of linear and nonlinear components of an acoustic path. e)Automatic procedure for time axis alignment of the source and the receiver whenthey are using independent clocks in acoustic impulse response measurement. Weimplemented a reference measurement tool equipped with all these procedures.The MATLAB source code and related materials are open-sourced and placed in aGitHub repository.",
    "Article_Subject": "Audio and Speech Processing (eess.AS); Sound (cs.SD); Signal Processing (eess.SP)",
    "Article_Date": "2019/09/10",
    "Article_PDF": "https://arxiv.org/pdf/1909.04301"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.03650",
    "DOI": "arXiv:1909.03650v1",
    "Article_Title": "Real-time and interactive tools for vocal training based on an analytic signal with a cosine series envelope",
    "Article_Abstract": "We introduce real-time and interactive tools for assisting vocal training. Inthis presentation, we demonstrate mainly a tool based on real-time visualizerof fundamental frequency candidates to provide information-rich feedback tolearners. The visualizer uses an efficient algorithm using analytic signals forderiving phase-based attributes. We start using these tools in vocal trainingfor assisting learners to acquire the awareness of appropriate vocalization.The first author made the MATLAB implementation of the tools open-source. Thecode and associated video materials are accessible in the first author's GitHubrepository.",
    "Article_Subject": "Sound (cs.SD); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)",
    "Article_Date": "2019/09/09",
    "Article_PDF": "https://arxiv.org/pdf/1909.03650"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.03181",
    "DOI": "arXiv:1909.03181v2",
    "Article_Title": "Receding Horizon Control for Drinking Water Networks: The Case for Geometric Programming",
    "Article_Abstract": "Optimal, network-driven control of Water Distribution Network (WDN) is verydifficult: valve and pump models form non-trivial, combinatorial logic,hydraulic models are nonconvex, water demand patterns are uncertain, and WDNsare naturally large-scale. Prior research on control of WDNs addressed majorresearch challenges, yet mostly adopted simplified hydraulic models, WDNtopologies, and rudimentary valve/pump modeling.  The objective of this paper is to develop tractable computational algorithmsto manage WDN operation, while considering arbitrary topology, flow direction,an abundance of valve types, control objectives, hydraulic models, andoperational constraints. Specifically, we propose new Geometric Programming(GP)-based Model Predictive Control (MPC) algorithms, designed to solve thewater flow equations and obtain WDN controls---pump/valve schedules alongsideheads and flows. The proposed approach amounts to solving a series of convexoptimization problems that graciously scale to large networks. Under demanduncertainty, the proposed approach is tested using a 126-node network with manyvalves and pumps. The developed GP-based MPC algorithms, as well as thenumerical test results are all included on Github.",
    "Article_Subject": "Systems and Control (eess.SY); Optimization and Control (math.OC)",
    "Article_Date": "2019/09/07",
    "Article_PDF": "https://arxiv.org/pdf/1909.03181"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.03147",
    "DOI": "arXiv:1909.03147v1",
    "Article_Title": "Self Learning from Large Scale Code Corpus to Infer Structure of Method Invocations",
    "Article_Abstract": "Automatically generating code from a textual description of method invocationconfronts challenges. There were two current research directions for thisproblem. One direction focuses on considering a textual description of methodinvocations as a separate Natural Language query and do not consider thesurrounding context of the code. Another direction takes advantage of apractical large scale code corpus for providing a Machine Translation model togenerate code. However, this direction got very low accuracy. In this work, wetried to improve these drawbacks by proposing MethodInfoToCode, an approachthat embeds context information and optimizes the ability of learning oforiginal Phrase-based Statistical Machine Translation (PBMT) in NLP to inferimplementation of method invocation given method name and other contextinformation. We conduct an expression prediction models learned from 2.86million method invocations from the practical data of high qualities corpus onGithub that used 6 popular libraries: JDK, Android, GWT, Joda-Time, Hibernate,and Xstream. By the evaluation, we show that if the developers only write themethod name of a method invocation in a body of a method, MethodInfoToCode canpredict the generated expression correctly at 73% in F1 score.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/09/06",
    "Article_PDF": "https://arxiv.org/pdf/1909.03147"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.02548",
    "DOI": "arXiv:1909.02548v1",
    "Article_Title": "Explanation based Handwriting Verification",
    "Article_Abstract": "Deep learning system have drawback that their output is not accompanied withex-planation. In a domain such as forensic handwriting verification it isessential to provideexplanation to jurors. The goal of handwriting verificationis to find a measure of confi-dence whether the given handwritten samples arewritten by the same or different writer.We propose a method to generateexplanations for the confidence provided by convolu-tional neural network (CNN)which maps the input image to 15 annotations (features)provided by experts. Oursystem comprises of: (1) Feature learning network (FLN),a differentiablesystem, (2) Inference module for providing explanations. Furthermore,inferencemodule provides two types of explanations: (a) Based on cosinesimilaritybetween categorical probabilities of each feature, (b) Based onLog-Likelihood Ratio(LLR) using directed probabilistic graphical model. Weperform experiments using acombination of feature learning network (FLN) andeach inference module. We evaluateour system using XAI-AND dataset, containing13700 handwritten samples and 15 cor-responding expert examined features foreach sample. The dataset is released for publicuse and the methods can beextended to provide explanations on other verification taskslike faceverification and bio-medical comparison. This dataset can serve as the basisand benchmark for future research in explanation based handwritingverification. The code is available on github.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
    "Article_Date": "2019/08/14",
    "Article_PDF": "https://arxiv.org/pdf/1909.02548"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.02218",
    "DOI": "arXiv:1909.02218v1",
    "Article_Title": "A Better Way to Attend: Attention with Trees for Video Question Answering",
    "Article_Abstract": "We propose a new attention model for video question answering. The main ideaof the attention models is to locate on the most informative parts of thevisual data. The attention mechanisms are quite popular these days. However,most existing visual attention mechanisms regard the question as a whole. Theyignore the word-level semantics where each word can have different attentionsand some words need no attention. Neither do they consider the semanticstructure of the sentences. Although the Extended Soft Attention (E-SA) modelfor video question answering leverages the word-level attention, it performspoorly on long question sentences. In this paper, we propose the heterogeneoustree-structured memory network (HTreeMN) for video question answering. Ourproposed approach is based upon the syntax parse trees of the questionsentences. The HTreeMN treats the words differently where the \\textit{visual}words are processed with an attention module and the \\textit{verbal} ones not.It also utilizes the semantic structure of the sentences by combining theneighbors based on the recursive structure of the parse trees. Theunderstandings of the words and the videos are propagated and merged fromleaves to the root. Furthermore, we build a hierarchical attention mechanism todistill the attended features. We evaluate our approach on two datasets. Theexperimental results show the superiority of our HTreeMN model over the otherattention models especially on complex questions. Our code is available ongithub.  Our code is available at https://github.com/ZJULearning/TreeAttention",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Machine Learning (cs.LG)",
    "Article_Date": "2019/09/05",
    "Article_PDF": "https://arxiv.org/pdf/1909.02218"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.02203",
    "DOI": "arXiv:1909.02203v2",
    "Article_Title": "Elastic_HH: Tailored Elastic for Finding Heavy Hitters",
    "Article_Abstract": "Finding heavy hitters has been of vital importance in network measurement.Among all the recent works in finding heavy hitters, the Elastic sketchachieves the highest accuracy and fastest speed. However, we find that there isstill room for improvement of the Elastic sketch in finding heavy hitters. Inthis paper, we propose a tailored Elastic to enhance the sketch only forfinding heavy hitters at the cost of losing the generality of Elastic. Totailor Elastic, we abandon the light part, and improve the eviction strategy.Our experimental results show that compared with the standard Elastic, ourtailored Elastic reduces the error rate to 5.7~8.1 times and increases thespeed to 2.5 times. All the related source codes and datasets are available atGithub.",
    "Article_Subject": "Networking and Internet Architecture (cs.NI)",
    "Article_Date": "2019/09/05",
    "Article_PDF": "https://arxiv.org/pdf/1909.02203"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.01441",
    "DOI": "arXiv:1909.01441v1",
    "Article_Title": "CrossWeigh: Training Named Entity Tagger from Imperfect Annotations",
    "Article_Abstract": "Everyone makes mistakes. So do human annotators when curating labels fornamed entity recognition (NER). Such label mistakes might hurt model trainingand interfere model comparison. In this study, we dive deep into one of thewidely-adopted NER benchmark datasets, CoNLL03 NER. We are able to identifylabel mistakes in about 5.38% test sentences, which is a significant ratioconsidering that the state-of-the-art test F1 score is already around 93%.Therefore, we manually correct these label mistakes and form a cleaner testset. Our re-evaluation of popular models on this corrected test set leads tomore accurate assessments, compared to those on the original test set. Moreimportantly, we propose a simple yet effective framework, CrossWeigh, to handlelabel mistakes during NER model training. Specifically, it partitions thetraining data into several folds and train independent NER models to identifypotential mistakes in each fold. Then it adjusts the weights of training dataaccordingly to train the final NER model. Extensive experiments demonstratesignificant improvements of plugging various NER models into our proposedframework on three datasets. All implementations and corrected test set areavailable at our Github repo: https://github.com/ZihanWangKi/CrossWeigh.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/09/03",
    "Article_PDF": "https://arxiv.org/pdf/1909.01441"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.01377",
    "DOI": "arXiv:1909.01377v1",
    "Article_Title": "Deep Equilibrium Models",
    "Article_Abstract": "We present a new approach to modeling sequential data: the deep equilibriummodel (DEQ). Motivated by an observation that the hidden layers of manyexisting deep sequence models converge towards some fixed point, we propose theDEQ approach that directly finds these equilibrium points via root-finding.Such a method is equivalent to running an infinite depth (weight-tied)feedforward network, but has the notable advantage that we can analyticallybackpropagate through the equilibrium point using implicit differentiation.Using this approach, training and prediction in these networks require onlyconstant memory, regardless of the effective \"depth\" of the network. Wedemonstrate how DEQs can be applied to two state-of-the-art deep sequencemodels: self-attention transformers and trellis networks. On large-scalelanguage modeling tasks, such as the WikiText-103 benchmark, we show that DEQs1) often improve performance over these state-of-the-art models (for similarparameter counts); 2) have similar computational requirements as existingmodels; and 3) vastly reduce memory consumption (often the bottleneck fortraining large sequence models), demonstrating an up-to 88% memory reduction inour experiments. The code is available at https://github. com/locuslab/deq .",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/09/03",
    "Article_PDF": "https://arxiv.org/pdf/1909.01377"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.11527",
    "DOI": "arXiv:1908.11527v2",
    "Article_Title": "Implicit Deep Latent Variable Models for Text Generation",
    "Article_Abstract": "Deep latent variable models (LVM) such as variational auto-encoder (VAE) haverecently played an important role in text generation. One key factor is theexploitation of smooth latent structures to guide the generation. However, therepresentation power of VAEs is limited due to two reasons: (1) the Gaussianassumption is often made on the variational posteriors; and meanwhile (2) anotorious \"posterior collapse\" issue occurs. In this paper, we advocatesample-based representations of variational distributions for natural language,leading to implicit latent features, which can provide flexible representationpower compared with Gaussian-based posteriors. We further develop an LVM todirectly match the aggregated posterior to the prior. It can be viewed as anatural extension of VAEs with a regularization of maximizing mutualinformation, mitigating the \"posterior collapse\" issue. We demonstrate theeffectiveness and versatility of our models in various text generationscenarios, including language modeling, unaligned style transfer, and dialogresponse generation. The source code to reproduce our experimental results isavailable on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/30",
    "Article_PDF": "https://arxiv.org/pdf/1908.11527"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.10267",
    "DOI": "arXiv:1908.10267v2",
    "Article_Title": "DRD-Net: Detail-recovery Image Deraining via Context Aggregation Networks",
    "Article_Abstract": "Image deraining is a fundamental, yet not well-solved problem in computervision and graphics. The traditional image deraining approaches commonly behaveineffectively in medium and heavy rain removal, while the learning-based oneslead to image degradations such as the loss of image details, halo artifactsand/or color distortion. Unlike existing image deraining approaches that lackthe detail-recovery mechanism, we propose an end-to-end detail-recovery imagederaining network (termed a DRD-Net) for single images. We for the first timeintroduce two sub-networks with a comprehensive loss function which synergizeto derain and recover the lost details caused by deraining. We have three keycontributions. First, we present a rain residual network to remove rain streaksfrom the rainy images, which combines the squeeze-and-excitation (SE) operationwith residual blocks to make full advantage of spatial contextual information.Second, we design a new connection style block, named structure detail contextaggregation block (SDCAB), which aggregates context feature information and hasa large reception field. Third, benefiting from the SDCAB, we construct adetail repair network to encourage the lost details to return for eliminatingimage degradations. We have validated our approach on four recognized datasets(three synthetic and one real-world). Both quantitative and qualitativecomparisons show that our approach outperforms the state-of-the-art derainingmethods in terms of the deraining robustness and detail accuracy. The sourcecode has been available for public evaluation and use on GitHub.",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/27",
    "Article_PDF": "https://arxiv.org/pdf/1908.10267"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.09195",
    "DOI": "arXiv:1908.09195v1",
    "Article_Title": "Scalable Modeling of Spatiotemporal Data using the Variational Autoencoder: an Application in Glaucoma",
    "Article_Abstract": "As big spatial data becomes increasingly prevalent, classical spatiotemporal(ST) methods often do not scale well. While methods have been developed toaccount for high-dimensional spatial objects, the setting where there areexceedingly large samples of spatial observations has had less attention. Thevariational autoencoder (VAE), an unsupervised generative model based on deeplearning and approximate Bayesian inference, fills this void using a latentvariable specification that is inferred jointly across the large number ofsamples. In this manuscript, we compare the performance of the VAE with a moreclassical ST method when analyzing longitudinal visual fields from a largecohort of patients in a prospective glaucoma study. Through simulation and acase study, we demonstrate that the VAE is a scalable method for analyzing STdata, when the goal is to obtain accurate predictions. R code to implement theVAE can be found on GitHub: https://github.com/berchuck/vaeST.",
    "Article_Subject": "Applications (stat.AP); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/24",
    "Article_PDF": "https://arxiv.org/pdf/1908.09195"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08856",
    "DOI": "arXiv:1908.08856v1",
    "Article_Title": "Assessing Knee OA Severity with CNN attention-based end-to-end architectures",
    "Article_Abstract": "This work proposes a novel end-to-end convolutional neural network (CNN)architecture to automatically quantify the severity of knee osteoarthritis (OA)using X-Ray images, which incorporates trainable attention modules acting asunsupervised fine-grained detectors of the region of interest (ROI). Theproposed attention modules can be applied at different levels and scales acrossany CNN pipeline helping the network to learn relevant attention patterns overthe most informative parts of the image at different resolutions. We test theproposed attention mechanism on existing state-of-the-art CNN architectures asour base models, achieving promising results on the benchmark knee OA datasetsfrom the osteoarthritis initiative (OAI) and multicenter osteoarthritis study(MOST). All code from our experiments will be publicly available on the githubrepository: https://github.com/marc-gorriz/KneeOA-CNNAttention",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
    "Article_Date": "2019/08/23",
    "Article_PDF": "https://arxiv.org/pdf/1908.08856"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08584",
    "DOI": "arXiv:1908.08584v1",
    "Article_Title": "Feedbackward Decoding for Semantic Segmentation",
    "Article_Abstract": "We propose a novel approach for semantic segmentation that uses an encoder inthe reverse direction to decode. Many semantic segmentation networks adopt afeedforward encoder-decoder architecture. Typically, an input is firstdownsampled by the encoder to extract high-level semantic features andcontinues to be fed forward through the decoder module to recover low-levelspatial clues. Our method works in an alternative direction that letsinformation flow backward from the last layer of the encoder towards the first.The encoder performs encoding in the forward pass and the same network performsdecoding in the backward pass. Therefore, the encoder itself is also thedecoder. Compared to conventional encoder-decoder architectures, ours doesn'trequire additional layers for decoding and further reuses the encoder weightsthereby reducing the total number of parameters required for processing. Weshow by using only the 13 convolutional layers from VGG-16 plus one tinyclassification layer, our model significantly outperforms other frequentlycited models that are also adapted from VGG-16. On the Cityscapes semanticsegmentation benchmark, our model uses 50.0% less parameters than SegNet andachieves an 18.1% higher \"IoU class\" score; it uses 28.3% less parameters thanDeepLab LargeFOV and the achieved \"IoU class\" score is 3.9% higher; it uses89.1% fewer parameters than FCN-8s and the achieved \"IoU class\" score is 3.1%higher. Our code will be publicly available on Github later.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Image and Video Processing (eess.IV); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/22",
    "Article_PDF": "https://arxiv.org/pdf/1908.08584"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08196",
    "DOI": "arXiv:1908.08196v1",
    "Article_Title": "Unveiling Elite Developers' Activities in Open Source Projects",
    "Article_Abstract": "Open-source developers, particularly the elite developers, maintain a diverseportfolio of contributing activities. They do not only commit source code butalso spend a significant amount of effort on other communicative,organizational, and supportive activities. However, almost all prior researchfocuses on a limited number of specific activities and fails to analyze elitedevelopers' activities in a comprehensive way. To bridge this gap, we conductan empirical study with fine-grained event data from 20 large open-sourceprojects hosted on GitHub. Thus, we investigate elite developers' contributingactivities and their impacts on project outcomes. Our analyses reveal three keyfindings: (1) they participate in a variety of activities while technicalcontributions (e.g., coding) accounting for a small proportion only; (2) theytend to put more effort into supportive and communicative activities and lesseffort into coding as the project grows; (3) their participation innon-technical activities is negatively associated with the project's outcomesin term of productivity and software quality. These results provide a panoramicview of elite developers' activities and can inform an individual's decisionmaking about effort allocation, thus leading to finer project outcomes. Theresults also provide implications for supporting these elite developers.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/22",
    "Article_PDF": "https://arxiv.org/pdf/1908.08196"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08123",
    "DOI": "arXiv:1908.08123v3",
    "Article_Title": "Computing System Congestion Management Using Exponential Smoothing Forecasting",
    "Article_Abstract": "An overloaded computer must finish what it starts and not start what willfail or hang. A congestion management algorithm the author developed, andSiemens Corporation patented for telecom products, effectively manages trafficoverload with its unique formulation of Exponential Smoothing forecasting.Siemens filed for exclusive rights to this technique in 2003 and obtained USpatent US7301903B2 in 2007 with this author, an employee at the time of thefiling, the sole inventor. A computer program, written in C language, whichexercises the methodology is listed at the end of this document and availableon GitHub.",
    "Article_Subject": "Performance (cs.PF)",
    "Article_Date": "2019/08/21",
    "Article_PDF": "https://arxiv.org/pdf/1908.08123"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.07984",
    "DOI": "arXiv:1908.07984v1",
    "Article_Title": "Minimal residual multistep methods for large stiff non-autonomous linear problems",
    "Article_Abstract": "The purpose of this work is to introduce a new idea of how to avoid thefactorization of large matrices during the solution of stiff systems of ODEs.Starting from the general form of an explicit linear multistep method wesuggest to adaptively choose its coefficients on each integration step in orderto minimize the norm of the residual of an implicit BDF formula. Thereby wereduce the number of unknowns on each step from $n$ to $O(1)$, where $n$ is thedimension of the ODE system. We call this type of methods Minimal ResidualMultistep (MRMS) methods. In the case of linear non-autonomous problem, besidesthe evaluations of the right-hand side of ODE, the resulting numerical schemeadditionally requires one solution of a linear least-squares problem with athin matrix per step. We show that the order of the method and itszero-stability properties coincide with those of the used underlying BDFformula. For the simplest analog of the implicit Euler method the properties oflinear stability are investigated. Though the classical absolute stabilityanalysis is not fully relevant to the MRMS methods, it is shown that thisone-step method is applicable in stiff case. In the numerical experimentsection we consider the fixed-step integration of a two-dimensionalnon-autonomous heat equation using the MRMS methods and their classical BDFcounterparts. The starting values are taken from a preset slowly-varying exactsolution. The comparison showed that both methods give similar numericalsolutions, but in the case of large systems the MRMS methods are faster, andtheir advantage considerably increases with the growth of dimension. Pythoncode with the experimantal code can be downloaded from the GitHub repositoryhttps://github.com/bfaleichik/mrms.",
    "Article_Subject": "Numerical Analysis (math.NA)",
    "Article_Date": "2019/08/21",
    "Article_PDF": "https://arxiv.org/pdf/1908.07984"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.07883",
    "DOI": "arXiv:1908.07883v3",
    "Article_Title": "Scala Implicits are Everywhere: A large-scale study of the use of Implicits in the wild",
    "Article_Abstract": "The Scala programming language offers two distinctive language featuresimplicit parameters and implicit conversions, often referred together asimplicits. Announced without fanfare in 2004, implicits have quickly grown tobecome a widely and pervasively used feature of the language. They provide away to reduce the boilerplate code in Scala programs. They are also used toimplement certain language features without having to modify the compiler. Wereport on a large-scale study of the use of implicits in the wild. For this, weanalyzed 7,280 Scala projects hosted on GitHub, spanning over 8.1M call sitesinvolving implicits and 370.7K implicit declarations across 18.7M lines ofScala code.",
    "Article_Subject": "Programming Languages (cs.PL); Software Engineering (cs.SE)",
    "Article_Date": "2019/08/21",
    "Article_PDF": "https://arxiv.org/pdf/1908.07883"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.06473",
    "DOI": "arXiv:1908.06473v1",
    "Article_Title": "From Open Set to Closed Set: Counting Objects by Spatial Divide-and-Conquer",
    "Article_Abstract": "Visual counting, a task that predicts the number of objects from animage/video, is an open-set problem by nature, i.e., the number of populationcan vary in $[0,+\\infty)$ in theory. However, the collected images and labeledcount values are limited in reality, which means only a small closed set isobserved. Existing methods typically model this task in a regression manner,while they are likely to suffer from an unseen scene with counts out of thescope of the closed set. In fact, counting is decomposable. A dense region canalways be divided until sub-region counts are within the previously observedclosed set. Inspired by this idea, we propose a simple but effective approach,Spatial Divide-and- Conquer Network (S-DCNet). S-DCNet only learns from aclosed set but can generalize well to open-set scenarios via S-DC. S-DCNet isalso efficient. To avoid repeatedly computing sub-region convolutionalfeatures, S-DC is executed on the feature map instead of on the input image.S-DCNet achieves the state-of-the-art performance on three crowd countingdatasets (ShanghaiTech, UCF_CC_50 and UCF-QNRF), a vehicle counting dataset(TRANCOS) and a plant counting dataset (MTC). Compared to the previous bestmethods, S-DCNet brings a 20.2% relative improvement on the ShanghaiTech PartB, 20.9% on the UCF-QNRF, 22.5% on the TRANCOS and 15.1% on the MTC. Code hasbeen made available at: https://github. com/xhp-hust-2018-2011/S-DCNet.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/15",
    "Article_PDF": "https://arxiv.org/pdf/1908.06473"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.06412",
    "DOI": "arXiv:1908.06412v1",
    "Article_Title": "Characterizing the transition to Kotlin of Android apps: a study on F-Droid, Play Store and GitHub",
    "Article_Abstract": "Kotlin is a novel language that represents an alternative to Java, and hasbeen recently adopted as a first-class programming language for Androidapplications. Kotlin is achieving a significant diffusion among developers, andseveral studies have highlighted various advantages of the language whencompared to Java.  The objective of this paper is to analyze a set of open-source Android apps,to evaluate their transition to the Kotlin programming language throughouttheir lifespan and understand whether the adoption of Kotlin has impacts on thesuccess of Android apps.  We mined all the projects from the F-Droid repository of Android open-sourceapplications, and we found the corresponding projects on the official GooglePlay Store and on the GitHub platform. We defined a set of eight metrics toquantify the relevance of Kotlin code in the latest update and through allreleases of an application. Then, we statistically analyzed the correlationbetween the presence of Kotlin code in a project and popularity metrics minedfrom the platforms where the apps were released.  Of a set of 1232 projects that were updated after October 2017, near 20%adopted Kotlin and about 12% had more Kotlin code than Java; most of theprojects that adopted Kotlin quickly transitioned from Java to the newlanguage. The projects featuring Kotlin had on average higher popularitymetrics; a statistically significant correlation has been found between thepresence of Kotlin and the number of stars on the GitHub repository.  The Kotlin language seems able to guarantee a seamless migration from Javafor Android developers. With an inspection on a large set of open-sourceAndroid apps, we observed that the adoption of the Kotlin language is rapid(when compared to the average lifespan of an Android project) and seems to comeat no cost in terms of popularity among the users and other developers.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/18",
    "Article_PDF": "https://arxiv.org/pdf/1908.06412"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.06309",
    "DOI": "arXiv:1908.06309v1",
    "Article_Title": "ED2: Two-stage Active Learning for Error Detection -- Technical Report",
    "Article_Abstract": "Traditional error detection approaches require user-defined parameters andrules. Thus, the user has to know both the error detection system and the data.However, we can also formulate error detection as a semi-supervisedclassification problem that only requires domain expertise. The challenges forsuch an approach are twofold: (1) to represent the data in a way that enables aclassification model to identify various kinds of data errors, and (2) to pickthe most promising data values for learning. In this paper, we address thesechallenges with ED2, our new example-driven error detection method. First, wepresent a new two-dimensional multi-classifier sampling strategy for activelearning. Second, we propose novel multi-column features. The combinedapplication of these techniques provides fast convergence of the classificationtask with high detection accuracy. On several real-world datasets, ED2requires, on average, less than 1% labels to outperform existing errordetection approaches. This report extends the peer-reviewed paper \"ED2: A Casefor Active Learning in Error Detection\". All source code related to thisproject is available on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Databases (cs.DB); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/17",
    "Article_PDF": "https://arxiv.org/pdf/1908.06309"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05541",
    "DOI": "arXiv:1908.05541v1",
    "Article_Title": "Hamming Sentence Embeddings for Information Retrieval",
    "Article_Abstract": "In retrieval applications, binary hashes are known to offer significantimprovements in terms of both memory and speed. We investigate the compressionof sentence embeddings using a neural encoder-decoder architecture, which istrained by minimizing reconstruction error. Instead of employing the originalreal-valued embeddings, we use latent representations in Hamming space producedby the encoder for similarity calculations.  In quantitative experiments on several benchmarks for semantic similaritytasks, we show that our compressed hamming embeddings yield a comparableperformance to uncompressed embeddings (Sent2Vec, InferSent, Glove-BoW), atcompression ratios of up to 256:1. We further demonstrate that our modelstrongly decorrelates input features, and that the compressor generalizes wellwhen pre-trained on Wikipedia sentences. We publish the source code on Githuband all experimental results.",
    "Article_Subject": "Information Retrieval (cs.IR); Computation and Language (cs.CL); Machine Learning (cs.LG)",
    "Article_Date": "2019/08/15",
    "Article_PDF": "https://arxiv.org/pdf/1908.05541"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05437",
    "DOI": "arXiv:1908.05437v1",
    "Article_Title": "Massive Multi-Agent Data-Driven Simulations of the GitHub Ecosystem",
    "Article_Abstract": "Simulating and predicting planetary-scale techno-social systems poses heavycomputational and modeling challenges. The DARPA SocialSim program set thechallenge to model the evolution of GitHub, a large collaborativesoftware-development ecosystem, using massive multi-agent simulations. Wedescribe our best performing models and our agent-based simulation framework,which we are currently extending to allow simulating other planetary-scaletechno-social systems. The challenge problem measured participant's ability,given 30 months of meta-data on user activity on GitHub, to predict the nextmonths' activity as measured by a broad range of metrics applied to groundtruth, using agent-based simulation. The challenge required scaling to asimulation of roughly 3 million agents producing a combined 30 million actions,acting on 6 million repositories with commodity hardware. It was also importantto use the data optimally to predict the agent's next moves. We describe theagent framework and the data analysis employed by one of the winning teams inthe challenge. Six different agent models were tested based on a variety ofmachine learning and statistical methods. While no single method proved themost accurate on every metric, the broadly most successful sampled from astationary probability distribution of actions and repositories for each agent.Two reasons for the success of these agents were their use of a distinctcharacterization of each agent, and that GitHub users change their behaviorrelatively slowly.",
    "Article_Subject": "Multiagent Systems (cs.MA); Social and Information Networks (cs.SI)",
    "Article_Date": "2019/08/15",
    "Article_PDF": "https://arxiv.org/pdf/1908.05437"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05354",
    "DOI": "arXiv:1908.05354v2",
    "Article_Title": "Large-Scale-Exploit of GitHub Repository Metadata and Preventive Measures",
    "Article_Abstract": "When working with Git, a popular version-control system, email addresses arepart of the metadata for each individual commit. When those commits are pushedto remote hosting services like GitHub, those email addresses become visiblenot only to fellow developers, but also to malicious actors aiming to exploitthem.  As a part of our research we created a tool that leverages the publiclyavailable GitHub API to collect user data. Analysis of this data not only givesaccess to millions of email addresses in very little time, but is also powerfuland dense enough to create targeted phishing attacks posing a great threat toall GitHub users and their private, potentially sensitive data. Even worse,existing countermeasures fail to effectively protect against such exploits.  As a consequence and main conclusion of this paper, we suggest multiplepreventive measures that should be implemented as soon as possible. We alsoconsider it the duty of both companies like GitHub and well informed softwareengineers to inform fellow developers about the risk of exposing private emailaddresses in Git commits published publicly.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/08/14",
    "Article_PDF": "https://arxiv.org/pdf/1908.05354"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05097",
    "DOI": "arXiv:1908.05097v1",
    "Article_Title": "Causal discovery in heavy-tailed models",
    "Article_Abstract": "Causal questions are omnipresent in many scientific problems. While muchprogress has been made in the analysis of causal relationships between randomvariables, these methods are not well suited if the causal mechanisms manifestthemselves only in extremes. This work aims to connect the two fields of causalinference and extreme value theory. We define the causal tail coefficient thatcaptures asymmetries in the extremal dependence of two random variables. In thepopulation case, the causal tail coefficient is shown to reveal the causalstructure if the distribution follows a linear structural causal model. Thisholds even in the presence of latent common causes that have the same tailindex as the observed variables. Based on a consistent estimator of the causaltail coefficient, we propose a computationally highly efficient algorithm thatinfers causal structure from finitely many data. We prove that our methodconsistently estimates the causal order and compare it to otherwell-established and non-extremal approaches in causal discovery on syntheticdata. The code is available as an open-access R package on Github.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/08/14",
    "Article_PDF": "https://arxiv.org/pdf/1908.05097"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.04710",
    "DOI": "arXiv:1908.04710v1",
    "Article_Title": "metric-learn: Metric Learning Algorithms in Python",
    "Article_Abstract": "metric-learn is an open source Python package implementing supervised andweakly-supervised distance metric learning algorithms. As part ofscikit-learn-contrib, it provides a unified interface compatible withscikit-learn which allows to easily perform cross-validation, model selection,and pipelining with other machine learning estimators. metric-learn isthoroughly tested and available on PyPi under the MIT licence.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/13",
    "Article_PDF": "https://arxiv.org/pdf/1908.04710"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.04219",
    "DOI": "arXiv:1908.04219v1",
    "Article_Title": "How do Developers Promote Open Source Projects?",
    "Article_Abstract": "Open source projects have an increasing importance on modern softwaredevelopment. For this reason, these projects, as usual with commercial softwareprojects, should make use of promotion channels to communicate and establishcontact with users and contributors. In this article, we study the channelsused to promote a set of 100 popular GitHub projects. First, we reveal thatTwitter, user meetings, and blogs are the most common promotion channels usedby the studied projects. Second, we report a major difference between thestudied projects and a random sample of projects, regarding the use of theinvestigated promotion channels. Third, we show the importance of a popularnews aggregation site (Hacker News) on the promotion of open source. Weconclude by presenting a set of practical recommendation to open source projectmanagers and leaders, regarding the promotion of their projects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/12",
    "Article_PDF": "https://arxiv.org/pdf/1908.04219"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.03952",
    "DOI": "arXiv:1908.03952v2",
    "Article_Title": "Constraining new physics from Higgs measurements with Lilith: update to LHC Run 2 results",
    "Article_Abstract": "Lilith is a public Python library for constraining new physics from Higgssignal strength measurements. We here present version 2.0 of Lilith togetherwith an updated XML database which includes the current ATLAS and CMS Run 2Higgs results for 36/fb. Both the code and the database were extended from theordinary Gaussian approximation employed in Lilith-1.1 to using variableGaussian and Poisson likelihoods. Moreover, Lilith can now make use ofcorrelation matrices of arbitrary dimension. We provide detailed validations ofthe implemented experimental results as well as a status of global fits forreduced Higgs couplings, Two-Higgs-doublet models of Type I and Type II, andinvisible Higgs decays. Lilith-2.0 is available on GitHub and ready to be usedto constrain a wide class of new physics scenarios.",
    "Article_Subject": "High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Experiment (hep-ex)",
    "Article_Date": "2019/08/11",
    "Article_PDF": "https://arxiv.org/pdf/1908.03952"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.02320",
    "DOI": "arXiv:1908.02320v1",
    "Article_Title": "Do as I Do, Not as I Say: Do Contribution Guidelines Match the GitHub Contribution Process?",
    "Article_Abstract": "Developer contribution guidelines are used in social coding sites like GitHubto explain and shape the process a project expects contributors to follow. Theyset standards for all participants and \"save time and hassle caused byimproperly created pull requests or issues that have to be rejected andresubmitted\" (GitHub). Yet, we lack a systematic understanding of the contentof a typical contribution guideline, as well as the extent to which theseguidelines are followed in practice. Additionally, understanding how guidelinesmay impact projects that use Continuous Integration as part of the contributionprocess is of particular interest. To address this knowledge gap, we conducteda mixed-methods study of 53 GitHub projects with explicit contributionguidelines and coded the guidelines to extract key themes. We then created aprocess model using GitHub activity data (e.g., commit, new issue, new pullrequest) to compare the actual activity with the prescribed contributionguidelines. We show that approximately 68% of these projects divergesignificantly from the expected process.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/06",
    "Article_PDF": "https://arxiv.org/pdf/1908.02320"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.02116",
    "DOI": "arXiv:1908.02116v3",
    "Article_Title": "Teacher Supervises Students How to Learn From Partially Labeled Images for Facial Landmark Detection",
    "Article_Abstract": "Facial landmark detection aims to localize the anatomically defined points ofhuman faces. In this paper, we study facial landmark detection from partiallylabeled facial images. A typical approach is to (1) train a detector on thelabeled images; (2) generate new training samples using this detector'sprediction as pseudo labels of unlabeled images; (3) retrain the detector onthe labeled samples and partial pseudo labeled samples. In this way, thedetector can learn from both labeled and unlabeled data to become robust. Inthis paper, we propose an interaction mechanism between a teacher and twostudents to generate more reliable pseudo labels for unlabeled data, which arebeneficial to semi-supervised facial landmark detection. Specifically, the twostudents are instantiated as dual detectors. The teacher learns to judge thequality of the pseudo labels generated by the students and filter outunqualified samples before the retraining stage. In this way, the studentdetectors get feedback from their teacher and are retrained by premium datagenerated by itself. Since the two students are trained by different samples, acombination of their predictions will be more robust as the final predictioncompared to either prediction. Extensive experiments on 300-W and AFLWbenchmarks show that the interactions between teacher and students contributeto better utilization of the unlabeled data and achieves state-of-the-artperformance.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/06",
    "Article_PDF": "https://arxiv.org/pdf/1908.02116"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01711",
    "DOI": "arXiv:1908.01711v1",
    "Article_Title": "fgivenx: A Python package for functional posterior plotting",
    "Article_Abstract": "fgivenx is a Python package for functional posterior plotting, currently usedin astronomy, but will be of use to scientists performing any Bayesian analysiswhich has predictive posteriors that are functions. The source code for fgivenxis available on GitHub at https://github.com/williamjameshandley/fgivenx",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.01711"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01373",
    "DOI": "arXiv:1908.01373v2",
    "Article_Title": "Unsupervised Microvascular Image Segmentation Using an Active Contours Mimicking Neural Network",
    "Article_Abstract": "The task of blood vessel segmentation in microscopy images is crucial formany diagnostic and research applications. However, vessels can look vastlydifferent, depending on the transient imaging conditions, and collecting datafor supervised training is laborious. We present a novel deep learning methodfor unsupervised segmentation of blood vessels. The method is inspired by thefield of active contours and we introduce a new loss term, which is based onthe morphological Active Contours Without Edges (ACWE) optimization method. Therole of the morphological operators is played by novel pooling layers that areincorporated to the network's architecture. We demonstrate the challenges thatare faced by previous supervised learning solutions, when the imagingconditions shift. Our unsupervised method is able to outperform such previousmethods in both the labeled dataset, and when applied to similar but differentdatasets. Our code, as well as efficient PyTorch reimplementations of thebaseline methods VesselNN and DeepVess is available on GitHub -https://github.com/shirgur/UMIS.",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/04",
    "Article_PDF": "https://arxiv.org/pdf/1908.01373"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01242",
    "DOI": "arXiv:1908.01242v1",
    "Article_Title": "Kannada-MNIST: A new handwritten digits dataset for the Kannada language",
    "Article_Abstract": "In this paper, we disseminate a new handwritten digits-dataset, termedKannada-MNIST, for the Kannada script, that can potentially serve as a directdrop-in replacement for the original MNIST dataset. In addition to thisdataset, we disseminate an additional real world handwritten dataset (with$10k$ images), which we term as the Dig-MNIST dataset that can serve as anout-of-domain test dataset. We also duly open source all the code as well asthe raw scanned images along with the scanner settings so that researchers whowant to try out different signal processing pipelines can perform end-to-endcomparisons. We provide high level morphological comparisons with the MNISTdataset and provide baselines accuracies for the dataset disseminated. Theinitial baselines obtained using an oft-used CNN architecture ($96.8\\%$ for themain test-set and $76.1\\%$ for the Dig-MNIST test-set) indicate that thesedatasets do provide a sterner challenge with regards to generalizability thanMNIST or the KMNIST datasets. We also hope this dissemination will spur thecreation of similar datasets for all the languages that use different symbolsfor the numeral digits.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/03",
    "Article_PDF": "https://arxiv.org/pdf/1908.01242"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01031",
    "DOI": "arXiv:1908.01031v1",
    "Article_Title": "RuleKit: A Comprehensive Suite for Rule-Based Learning",
    "Article_Abstract": "Rule-based models are often used for data analysis as they combineinterpretability with predictive power. We present RuleKit, a versatile toolfor rule learning. Based on a sequential covering induction algorithm, it issuitable for classification, regression, and survival problems. The presence ofa user-guided induction facilitates verifying hypotheses concerning datadependencies which are expected or of interest. The powerful and flexibleexperimental environment allows straightforward investigation of differentinduction schemes. The analysis can be performed in batch mode, throughRapidMiner plug-in, or R package. A documented Java API is also provided forconvenience. The software is publicly available at GitHub under GNU AGPL-3.0license.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.01031"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.00867",
    "DOI": "arXiv:1908.00867v1",
    "Article_Title": "An Evaluation of Action Recognition Models on EPIC-Kitchens",
    "Article_Abstract": "We benchmark contemporary action recognition models (TSN, TRN, and TSM) onthe recently introduced EPIC-Kitchens dataset and release pretrained models onGitHub (https://github.com/epic-kitchens/action-models) for others to buildupon. In contrast to popular action recognition datasets like Kinetics,Something-Something, UCF101, and HMDB51, EPIC-Kitchens is shot from anegocentric perspective and captures daily actions in-situ. In this report, weaim to understand how well these models can tackle the challenges present inthis dataset, such as its long tail class distribution, unseen environment testset, and multiple tasks (verb, noun and, action classification). We discuss themodels' shortcomings and avenues for future research.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.00867"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.00717",
    "DOI": "arXiv:1908.00717v1",
    "Article_Title": "Lagrange2D: A Mathematica package for Lagrangian analysis of two-dimensional fluid flows",
    "Article_Abstract": "We introduce Lagrange2D, a Mathematica package for analysis andcharacterization of complex fluid flows using Lagrangian transport metrics.Lagrange2D includes built-in functions for integrating ensembles oftrajectories subject to time-varying two-dimensional flows, as well asutilities for calculating various quantities of interest, such as finite-timeLyapunov exponents, stretching vector fields, the fractal dimension, andflushing times. The package also includes tools for visualizing transport andpathlines, as well as for generating videos. This package aims to ease rapidcharacterization of arbitrary flows, by allowing identification of Lagrangiancoherent structures and other quantities of interest. The open-source code forthe package is available on GitHub at:\\url{https://github.com/williamgilpin/lagrange2d}",
    "Article_Subject": "Fluid Dynamics (physics.flu-dyn); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.00717"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.00614",
    "DOI": "arXiv:1908.00614v2",
    "Article_Title": "Learning to Identify Security-Related Issues Using Convolutional Neural Networks",
    "Article_Abstract": "Software security is becoming a high priority for both large companies andstart-ups alike due to the increasing potential for harm that vulnerabilitiesand breaches carry with them. However, attaining robust security assurancewhile delivering features requires a precarious balancing act in the context ofagile development practices. One path forward to help aid development teams insecuring their software products is through the design and development ofsecurity-focused automation. Ergo, we present a novel approach, calledSecureReqNet, for automatically identifying whether issues in software issuetracking systems describe security-related content. Our approach consists of atwo-phase neural net architecture that operates purely on the natural languagedescriptions of issues. The first phase of our approach learns high dimensionalword embeddings from hundreds of thousands of vulnerability descriptions listedin the CVE database and issue descriptions extracted from open source projects.The second phase then utilizes the semantic ontology represented by theseembeddings to train a convolutional neural network capable of predictingwhether a given issue is security-related. We evaluated SecureReqNet byapplying it to identify security-related issues from a dataset of thousands ofissues mined from popular projects on GitLab and GitHub. In addition, we alsoapplied our approach to identify security-related requirements from acommercial software project developed by a major telecommunication company. Ourpreliminary results are encouraging, with SecureReqNet achieving an accuracy of96% on open source issues and 71.6% on industrial requirements.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/01",
    "Article_PDF": "https://arxiv.org/pdf/1908.00614"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.13012",
    "DOI": "arXiv:1907.13012v1",
    "Article_Title": "An Empirical Study of GraphQL Schemas",
    "Article_Abstract": "GraphQL is a query language for APIs and a runtime to execute queries. UsingGraphQL queries, clients define precisely what data they wish to retrieve ormutate on a server, leading to fewer round trips and reduced response sizes.Although interest in GraphQL is on the rise, with increasing adoption at majororganizations, little is known about what GraphQL interfaces look like inpractice. This lack of knowledge makes it hard for providers to understand whatpractices promote idiomatic, easy-to-use APIs, and what pitfalls to avoid. Toaddress this gap, we study the design of GraphQL interfaces in practice byanalyzing their schemas - the descriptions of their exposed data types and thepossible operations on the underlying data. We base our study on two novelcorpuses of GraphQL schemas, one of 16 commercial GraphQL schemas and the otherof 8,399 GraphQL schemas mined from GitHub projects. We make both corpusesavailable to other researchers. Using these corpuses, we characterize the sizeof schemas and their use of GraphQL features and assess the use of bothprescribed and organic naming conventions. We also report that a majority ofAPIs are susceptible to denial of service through complex queries, posing realsecurity risks previously discussed only in theory. We also assess ways inwhich GraphQL APIs attempt to address these concerns.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/07/30",
    "Article_PDF": "https://arxiv.org/pdf/1907.13012"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.11017",
    "DOI": "arXiv:1907.11017v2",
    "Article_Title": "Particle Methods for Stochastic Differential Equation Mixed Effects Models",
    "Article_Abstract": "Parameter inference for stochastic differential equation mixed effects models(SDEMEMs) is a challenging problem. Analytical solutions for these models arerarely available, which means that the likelihood is also intractable. In thiscase, exact inference is possible using the pseudo-marginal method, where theintractable likelihood is replaced by its nonnegative unbiased estimate. Auseful application of this idea is particle MCMC, which uses a particle filterestimate of the likelihood. While the exact posterior is targeted by thesemethods, a naive implementation for SDEMEMs can be highly inefficient. Wedevelop three extensions to the naive approach which exploits specific aspectsof SDEMEMs and other advances such as correlated pseudo-marginal methods. Wecompare these methods on real and simulated data from a tumour xenography studyon mice.",
    "Article_Subject": "Computation (stat.CO); Methodology (stat.ME)",
    "Article_Date": "2019/07/25",
    "Article_PDF": "https://arxiv.org/pdf/1907.11017"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.10121",
    "DOI": "arXiv:1907.10121v1",
    "Article_Title": "SciPy 1.0--Fundamental Algorithms for Scientific Computing in Python",
    "Article_Abstract": "SciPy is an open source scientific computing library for the Pythonprogramming language. SciPy 1.0 was released in late 2017, about 16 years afterthe original version 0.1 release. SciPy has become a de facto standard forleveraging scientific algorithms in the Python programming language, with morethan 600 unique code contributors, thousands of dependent packages, over100,000 dependent repositories, and millions of downloads per year. Thisincludes usage of SciPy in almost half of all machine learning projects onGitHub, and usage by high profile projects including LIGO gravitational waveanalysis and creation of the first-ever image of a black hole (M87). Thelibrary includes functionality spanning clustering, Fourier transforms,integration, interpolation, file I/O, linear algebra, image processing,orthogonal distance regression, minimization algorithms, signal processing,sparse matrix handling, computational geometry, and statistics. In this work,we provide an overview of the capabilities and development practices of theSciPy library and highlight some recent technical developments.",
    "Article_Subject": "Mathematical Software (cs.MS); Data Structures and Algorithms (cs.DS); Software Engineering (cs.SE); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/07/23",
    "Article_PDF": "https://arxiv.org/pdf/1907.10121"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.09600",
    "DOI": "arXiv:1907.09600v2",
    "Article_Title": "Evaluation of Embeddings of Laboratory Test Codes for Patients at a Cancer Center",
    "Article_Abstract": "Laboratory test results are an important and generally high dimensionalcomponent of a patient's Electronic Health Record (EHR). We train embeddingrepresentations (via Word2Vec and GloVe) for LOINC codes of laboratory testsfrom the EHRs of about 80,000 patients at a cancer center. To includeinformation about lab test outcomes, we also train embeddings on theconcatenation of a LOINC code with a symbol indicating normality or abnormalityof the result. We observe several clinically meaningful similarities amongLOINC embeddings trained over our data. For the embeddings of the concatenationof LOINCs with abnormality codes, we evaluate the performance for mortalityprediction tasks and the ability to preserve ordinality properties: i.e. a labtest with normal outcome should be more similar to an abnormal one than to thea very abnormal one.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/22",
    "Article_PDF": "https://arxiv.org/pdf/1907.09600"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.08395",
    "DOI": "arXiv:1907.08395v2",
    "Article_Title": "Refractive Interstellar Scintillation of Extra-galactic Radio Sources I: Expectations",
    "Article_Abstract": "Surveys for transient and variable phenomena can be confounded by thepresence of extrinsic variability such as refractive interstellar scintillation(RISS). We have developed an all-sky model for RISS which can predictvariability on a variety of timescales, survey locations, and observingfrequencies. The model makes use of Halpha intensity maps to probe the emissionmeasure along the line of sight, convert this to a scattering measure, andfinally a scintillation strength. The model uses previously developed and longunderstood physics along with (indirect) measurements of the electron contentand distribution within the Milky Way. We develop a set of expectations thatare useful in the planning of future surveys for transient and radiovariability, and demonstrate that the 1-GHz sky is a poor predictor of thevariable nature of the $100$-MHz sky. Interestingly, the correlation betweenthe incidence of variability and Galactic latitude which has been seen at 1GHz,is reversed at 100MHz. We compare the predictions of our model to alow-frequency radio survey that was conducted with the Murchison WidefieldArray, and find good qualitative agreement. We discuss the implications,current limitations, and future development of the model. The model has beenimplemented in a Python code and is available on GitHub/Zenodo.",
    "Article_Subject": "Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/07/19",
    "Article_PDF": "https://arxiv.org/pdf/1907.08395"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.07951",
    "DOI": "arXiv:1907.07951v1",
    "Article_Title": "Automatic vocal tract landmark localization from midsagittal MRI data",
    "Article_Abstract": "The various speech sounds of a language are obtained by varying the shape andposition of the articulators surrounding the vocal tract. Analyzing theirvariability is crucial for understanding speech production, diagnosing speechand swallowing disorders and building intuitive applications forrehabilitation. Magnetic Resonance Imaging (MRI) is currently the most harmlesspowerful imaging modality used for this purpose. Identifying key anatomicallandmarks on it is a pre-requisite for further analyses. This is a challengingtask considering the high inter- and intra-speaker variability and the mutualinteraction between the articulators. This study intends to solve this issueautomatically for the first time. For this purpose, midsagittal anatomical MRIfor 9 speakers sustaining 62 articulations and annotated with the location of21 key anatomical landmarks are considered. Four state-of-the-art methods,including deep learning methods, are adapted from the literature for faciallandmark localization and human pose estimation and evaluated. Furthermore, anapproach based on the description of each landmark location as a heat-map imagestored in a channel of a single multi-channel image embedding all landmarks isproposed. The generation of such a multi-channel image from an input MRI imageis tested through two deep learning networks, one taken from the literature andone designed on purpose in this study, the flat-net. Results show that theflat-net approach outperforms the other methods, leading to an overall RootMean Square Error of 3.4~pixels/0.34~cm obtained in a leave-one-out procedureover the speakers. All of the codes are publicly available on GitHub.",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "Article_Date": "2019/07/18",
    "Article_PDF": "https://arxiv.org/pdf/1907.07951"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.06274",
    "DOI": "arXiv:1907.06274v1",
    "Article_Title": "Predicting Merge Conflicts in Collaborative Software Development",
    "Article_Abstract": "Background. During collaborative software development, developers often usebranches to add features or fix bugs. When merging changes from two branches,conflicts may occur if the changes are inconsistent. Developers need to resolvethese conflicts before completing the merge, which is an error-prone andtime-consuming process. Early detection of merge conflicts, which warnsdevelopers about resolving conflicts before they become large and complicated,is among the ways of dealing with this problem. Existing techniques do this bycontinuously pulling and merging all combinations of branches in the backgroundto notify developers as soon as a conflict occurs, which is a computationallyexpensive process. One potential way for reducing this cost is to use amachine-learning based conflict predictor that filters out the merge scenariosthat are not likely to have conflicts, ie safe merge scenarios. Aims. In thispaper, we assess if conflict prediction is feasible. Method. We design aclassifier for predicting merge conflicts, based on 9 light-weight Git featuresets. To evaluate our predictor, we perform a large-scale study on 267, 657merge scenarios from 744 GitHub repositories in seven programming languages.Results. Our results show that we achieve high f1-scores, varying from 0.95 to0.97 for different programming languages, when predicting safe merge scenarios.The f1-score is between 0.57 and 0.68 for the conflicting merge scenarios.Conclusions. Predicting merge conflicts is feasible in practice, especially inthe context of predicting safe merge scenarios as a pre-filtering step forspeculative merging.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/07/14",
    "Article_PDF": "https://arxiv.org/pdf/1907.06274"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.06146",
    "DOI": "arXiv:1907.06146v1",
    "Article_Title": "Satellite System Graph: Towards the Efficiency Up-Boundary of Graph-Based Approximate Nearest Neighbor Search",
    "Article_Abstract": "Approximate Nearest Neighbor Search (ANNS) in high dimensional space isessential in database and information retrieval. Recently, there has been asurge of interests in exploring efficient graph-based indices for the ANNSproblem. Among them, the NSG has resurrected the theory of Monotonic SearchNetworks (MSNET) and achieved the state-of-the-art performance. However, theperformance of the NSG deviates from a potentially optimal position due to thehigh sparsity of the graph. Specifically, though the average degree of thegraph is small, their search algorithm travels a longer way to reach the query.Integrating both factors, the total search complexity (i.e., the number ofdistance calculations) is not minimized as their wish. In addition, NSG suffersfrom a high indexing time complexity, which limits the efficiency and thescalability of their method. In this paper, we aim to further mine thepotential of the MSNETs. Inspired by the message transfer mechanism of thecommunication satellite system, we find a new family of MSNETs, namely theSatellite System Graphs (SSG). In particular, while inheriting the superiorANNS properties from the MSNET, we try to ensure the angles between the edgesto be no smaller than a given value. Consequently, each node in the graphbuilds effective connections to its neighborhood omnidirectionally, whichensures an efficient search-routing on the graph like the message transferamong the satellites. We also propose an approximation of the SSG, NavigatingSSG, to increase the efficiency of indexing. Both theoretical and extensiveexperimental analysis are provided to demonstrate the strengths of the proposedapproach over the existing state-of-the-art algorithms. Our code has beenreleased on GitHub.",
    "Article_Subject": "Information Retrieval (cs.IR); Databases (cs.DB)",
    "Article_Date": "2019/07/13",
    "Article_PDF": "https://arxiv.org/pdf/1907.06146"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.05062",
    "DOI": "arXiv:1907.05062v1",
    "Article_Title": "FIRE: Unsupervised bi-directional inter-modality registration using deep networks",
    "Article_Abstract": "Inter-modality image registration is an critical preprocessing step for manyapplications within the routine clinical pathway. This paper presents anunsupervised deep inter-modality registration network that can learn theoptimal affine and non-rigid transformations simultaneously.Inverse-consistency is an important property commonly ignored in recent deeplearning based inter-modality registration algorithms. We address this issuethrough the proposed multi-task architecture and the new comprehensivetransformation network. Specifically, the proposed model learns amodality-independent latent representation to perform cycle-consistentcross-modality synthesis, and use an inverse-consistent loss to learn a pair oftransformations to align the synthesized image with the target. We name thisproposed framework as FIRE due to the shape of its structure. Our method showscomparable and better performances with the popular baseline method inexperiments on multi-sequence brain MR data and intra-modality 4D cardiacCine-MR data.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/07/11",
    "Article_PDF": "https://arxiv.org/pdf/1907.05062"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04908",
    "DOI": "arXiv:1907.04908v1",
    "Article_Title": "Executability of Python Snippets in Stack Overflow",
    "Article_Abstract": "Online resources today contain an abundant amount of code snippets fordocumentation, collaboration, learning, and problem-solving purposes. Theirexecutability in a \"plug and play\" manner enables us to confirm their qualityand use them directly in projects. But, in practice that is often not the casedue to several requirements violations or incompleteness. However, it is adifficult task to investigate the executability on a large scale due todifferent possible errors during the execution. We have developed a scalableframework to investigate this for SOTorrent Python snippets. We found that withminor adjustments, 27.92% of snippets are executable. The executability has notchanged significantly over time. The code snippets referenced in GitHub aremore likely to be directly executable. But executability does not affect thechances of the answer to be selected as the accepted answer significantly.These properties help us understand and improve the interaction of users withonline resources that include code snippets.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/07/10",
    "Article_PDF": "https://arxiv.org/pdf/1907.04908"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04527",
    "DOI": "arXiv:1907.04527v1",
    "Article_Title": "Dynamics of Team Library Adoptions: An Exploration of GitHub Commit Logs",
    "Article_Abstract": "When a group of people strives to understand new information, struggle ensuesas various ideas compete for attention. Steep learning curves are surmounted asteams learn together. To understand how these team dynamics play out insoftware development, we explore Git logs, which provide a complete changehistory of software repositories. In these repositories, we observe codeadditions, which represent successfully implemented ideas, and code deletions,which represent ideas that have failed or been superseded. By examining thepatterns between these commit types, we can begin to understand how teams adoptnew information. We specifically study what happens after a software library isadopted by a project, i.e., when a library is used for the first time in theproject. We find that a variety of factors, including team size, librarypopularity, and prevalence on Stack Overflow are associated with how quicklyteams learn and successfully adopt new software libraries.",
    "Article_Subject": "Social and Information Networks (cs.SI); Software Engineering (cs.SE)",
    "Article_Date": "2019/07/10",
    "Article_PDF": "https://arxiv.org/pdf/1907.04527"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04433",
    "DOI": "arXiv:1907.04433v1",
    "Article_Title": "GluonCV and GluonNLP: Deep Learning in Computer Vision and Natural Language Processing",
    "Article_Abstract": "We present GluonCV and GluonNLP, the deep learning toolkits for computervision and natural language processing based on Apache MXNet (incubating).These toolkits provide state-of-the-art pre-trained models, training scripts,and training logs, to facilitate rapid prototyping and promote reproducibleresearch. We also provide modular APIs with flexible building blocks to enableefficient customization. Leveraging the MXNet ecosystem, the deep learningmodels in GluonCV and GluonNLP can be deployed onto a variety of platforms withdifferent programming languages. Benefiting from open source under the Apache2.0 license, GluonCV and GluonNLP have attracted 100 contributors worldwide onGitHub. Models of GluonCV and GluonNLP have been downloaded for more than 1.6million times in fewer than 10 months.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/09",
    "Article_PDF": "https://arxiv.org/pdf/1907.04433"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04002",
    "DOI": "arXiv:1907.04002v1",
    "Article_Title": "Characterizing Bitcoin donations to open source software on GitHub",
    "Article_Abstract": "Web-based hosting services for version control, such as GitHub, have made iteasier for people to develop, share, and donate money to software repositories.In this paper, we study the use of Bitcoin to make donations to open sourcerepositories on GitHub. In particular, we analyze the amount and volume ofdonations over time, in addition to its relationship to the age and popularityof a repository.  We scanned over three million repositories looking for donation addresses. Wethen extracted and analyzed their transactions from Bitcoin's publicblockchain. Overall, we found a limited adoption of Bitcoin as a payment methodfor receiving donations, with nearly 44 thousand deposits adding up to only 8.3million dollars in the last 10 years. We also found weak positive correlationbetween the amount of donations in dollars and the popularity of a repository,with highest correlation (r=0.013) associated with number of forks.",
    "Article_Subject": "Computers and Society (cs.CY); Cryptography and Security (cs.CR)",
    "Article_Date": "2019/07/09",
    "Article_PDF": "https://arxiv.org/pdf/1907.04002"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03892",
    "DOI": "arXiv:1907.03892v5",
    "Article_Title": "Fast Visual Object Tracking with Rotated Bounding Boxes",
    "Article_Abstract": "In this paper, we demonstrate a novel algorithm that uses ellipse fitting toestimate the bounding box rotation angle and size with the segmentation(mask)on the target for online and real-time visual object tracking. Our method,SiamMask_E, improves the bounding box fitting procedure of the state-of-the-artobject tracking algorithm SiamMask and still retains a fast-tracking frame rate(80 fps) on a system equipped with GPU (GeForce GTX 1080 Ti or higher). Wetested our approach on the visual object tracking datasets (VOT2016, VOT2018,and VOT2019) that were labeled with rotated bounding boxes. By comparing withthe original SiamMask, we achieved an improved Accuracy of 0.652 and 0.309 EAOon VOT2019, which is 0.056 and 0.026 higher than the original SiamMask. Theimplementation is available on GitHub:https://github.com/baoxinchen/siammask_e.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/07/08",
    "Article_PDF": "https://arxiv.org/pdf/1907.03892"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03660",
    "DOI": "arXiv:1907.03660v2",
    "Article_Title": "Can Dark Matter be Geometry? A Case Study with Mimetic Dark Matter",
    "Article_Abstract": "We investigate the possibility of dark matter being a pure geometricaleffect, rather than a particle or a compact object, by exploring a specificmodified gravity model: mimetic dark matter. We present an alternativeformulation of the theory, closer to the standard cosmological perturbationtheory framework. We make manifest the presence of arbitrary parameters andextra functions, both at background level and at first order in perturbationtheory. We present the full set of independent equations of motion for thismodel, and we discuss the amount of tuning needed to match predictions of thetheory to actual data. By using the matter power spectrum and cosmic microwavebackground angular power spectra as benchmark observables, we explicitly showthat since there is no natural mechanism to generate adiabatic initialconditions in this specific model, extra fine-tuning is required. We modify thepublicly available Boltzmann code \\texttt{CLASS} to make accurate predictionsfor the observables in mimetic dark matter. Our modified version of\\texttt{CLASS} is available on GitHub. We have used mimetic dark matter as anillustration of how much one is allowed to change the initial conditions beforecontradicting observations when modifying the laws of gravity as described byGeneral Relativity but we point out that modifying gravity without providing anatural mechanism to generate adiabatic initial conditions will always lead tohighly fine-tuned models.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); General Relativity and Quantum Cosmology (gr-qc); High Energy Physics - Theory (hep-th)",
    "Article_Date": "2019/07/08",
    "Article_PDF": "https://arxiv.org/pdf/1907.03660"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03407",
    "DOI": "arXiv:1907.03407v1",
    "Article_Title": "On The Lag of Library Vulnerability Updates: An Investigation into the Repackage and Delivery of Security Fixes Within The npm JavaScript Ecosystem",
    "Article_Abstract": "Vulnerabilities in third-party libraries is a growing concern for thesoftware developer, as it poses risks not only to the software client itselfbut to the entire software ecosystem. To mitigate these risks, developers arestrongly recommended to update their dependencies. Recent studies show thataffected developers are not likely to respond to the vulnerability threat.However, another reason for the lag of vulnerability updates is due to slowrepackaging (i.e., package the vulnerability fix into a new version) anddelivery (i.e., affected client adopt the new version) of the fix. Tounderstand these lags of updates, we use both qualitative and quantitativeapproaches to conduct an empirical study on how 188 fixes were repackaged anddelivered across over eight hundred thousand releases of npm software clientshosted on GitHub. We report two lags: (1) lags in repackaging occur asvulnerability fixes are more likely to be bundled with other non-relatedupdates (i.e., about 83.33\\% of commits are not related to the fix) and (2)lags in the delivery are caused by clients that are more likely to adopt theminor fix than adopt the patch fix. Furthermore, other factors such asdownstream dependencies and severity do have an impact. We also find thatfreshness of packages does not impact the amount of lags. The identification ofthese two lags opens up different avenues on how to facilitate faster fixdelivery throughout a library ecosystem.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/07/08",
    "Article_PDF": "https://arxiv.org/pdf/1907.03407"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03187",
    "DOI": "arXiv:1907.03187v1",
    "Article_Title": "Applying a Pre-trained Language Model to Spanish Twitter Humor Prediction",
    "Article_Abstract": "Our entry into the HAHA 2019 Challenge placed $3^{rd}$ in the classificationtask and $2^{nd}$ in the regression task. We describe our system andinnovations, as well as comparing our results to a Naive Bayes baseline. Alarge Twitter based corpus allowed us to train a language model from scratchfocused on Spanish and transfer that knowledge to our competition model. Toovercome the inherent errors in some labels we reduce our class confidence withlabel smoothing in the loss function. All the code for our project is includedin a GitHub repository for easy reference and to enable replication by others.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/07/06",
    "Article_PDF": "https://arxiv.org/pdf/1907.03187"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.02862",
    "DOI": "arXiv:1907.02862v1",
    "Article_Title": "Essential Motor Cortex Signal Processing: an ERP and functional connectivity MATLAB toolbox -- User Guide",
    "Article_Abstract": "The purpose of this document is to help individuals use the \"Essential MotorCortex Signal Processing MATLAB Toolbox\". The toolbox implements variousmethods for three major aspects of investigating human motor cortex fromNeuroscience view point: (1) ERP estimation and quantification, (2) CorticalFunctional Connectivity analysis and (3) EMG quantification. The toolbox --which is distributed under the terms of the GNU GENERAL PUBLIC LICENSE as a setof MATLAB R routines -- can be downloaded directly at the address:http://oset.ir/category.php?dir=Tools or from the public repository on GitHub,at address below: https://github.com/EsiSeraj/ERP Connectivity EMG Analysis  The purpose of this toolbox is threefold: 1. Extract theevent-related-potential (ERP) from preprocessed cerebral signals (i.e. EEG,MEG, etc.), identify and then quantify the event-relatedsynchronization/desynchronization (ERS/ERD) events. Both time-course dynamicsand time-frequency (TF) analyzes are included. 2. Measure, quantify anddemonstrate the cortical functional connectivity (CFC) across scalp electrodes.These set of functions can also be applied to various types of cerebral signals(i.e. electric and magnetic). 3. Quantify electromyogram (EMG) recorded fromactive muscles during performing motor tasks.",
    "Article_Subject": "Signal Processing (eess.SP); Computational Engineering, Finance, and Science (cs.CE); Image and Video Processing (eess.IV); Neurons and Cognition (q-bio.NC); Quantitative Methods (q-bio.QM)",
    "Article_Date": "2019/06/15",
    "Article_PDF": "https://arxiv.org/pdf/1907.02862"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.02202",
    "DOI": "arXiv:1907.02202v1",
    "Article_Title": "SEntiMoji: An Emoji-Powered Learning Approach for Sentiment Analysis in Software Engineering",
    "Article_Abstract": "Sentiment analysis has various application scenarios in software engineering(SE), such as detecting developers' emotions in commit messages and identifyingtheir opinions on Q&A forums. However, commonly used out-of-the-box sentimentanalysis tools cannot obtain reliable results on SE tasks and themisunderstanding of technical jargon is demonstrated to be the main reason.Then, researchers have to utilize labeled SE-related texts to customizesentiment analysis for SE tasks via a variety of algorithms. However, thescarce labeled data can cover only very limited expressions and thus cannotguarantee the analysis quality. To address such a problem, we turn to theeasily available emoji usage data for help. More specifically, we employemotional emojis as noisy labels of sentiments and propose a representationlearning approach that uses both Tweets and GitHub posts containing emojis tolearn sentiment-aware representations for SE-related texts. These emoji-labeledposts can not only supply the technical jargon, but also incorporate moregeneral sentiment patterns shared across domains. They as well as labeled dataare used to learn the final sentiment classifier. Compared to the existingsentiment analysis methods used in SE, the proposed approach can achievesignificant improvement on representative benchmark datasets. By furthercontrast experiments, we find that the Tweets make a key contribution to thepower of our approach. This finding informs future research not to unilaterallypursue the domain-specific resource, but try to transform knowledge from theopen domain through ubiquitous signals such as emojis.",
    "Article_Subject": "Software Engineering (cs.SE); Computation and Language (cs.CL)",
    "Article_Date": "2019/07/04",
    "Article_PDF": "https://arxiv.org/pdf/1907.02202"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00903",
    "DOI": "arXiv:1907.00903v1",
    "Article_Title": "Resolving the Multiple Withdrawal Attack on ERC20 Tokens",
    "Article_Abstract": "Custom tokens are an integral component of decentralized applications (dapps)deployed on Ethereum and other blockchain platforms. For Ethereum, the ERC20standard is a widely used token interface and is interoperable with manyexisting dapps, user interface platforms, and popular web applications (e.g.,exchange services). An ERC20 security issue, known as the \"multiple withdrawalattack\", was raised on GitHub and has been open since November 2016. The issueconcerns ERC20's defined method approve() which was envisioned as a way fortoken holders to give permission for other users and dapps to withdraw a cappednumber of tokens. The security issue arises when a token holder wants to adjustthe amount of approved tokens from N to M (this could be an increase ordecrease). If malicious, a user or dapp who is approved for N tokens canfront-run the adjustment transaction to first withdraw N tokens, then allow theapproval to be confirmed, and withdraw an additional M tokens. In this paper,we evaluate 10 proposed mitigations for this issues and find that no solutionis fully satisfactory. We then propose 2 new solutions that mitigate theattack, one of which fully fulfills constraints of the standard, and the secondone shows a general limitation in addressing this issue from ERC20's approvemethod.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00903"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00863",
    "DOI": "arXiv:1907.00863v1",
    "Article_Title": "Understanding GCC Builtins to Develop Better Tools",
    "Article_Abstract": "C programs can use compiler builtins to provide functionality that the Clanguage lacks. On Linux, GCC provides several thousands of builtins that arealso supported by other mature compilers, such as Clang and ICC. Maintainers ofother tools lack guidance on whether and which builtins should be implementedto support popular projects. To assist tool developers who want to support GCCbuiltins, we analyzed builtin use in 4,913 C projects from GitHub. We foundthat 37% of these projects relied on at least one builtin. Supporting anincreasing proportion of projects requires support of an exponentiallyincreasing number of builtins; however, implementing only 10 builtins alreadycovers over 30% of the projects. Since we found that many builtins in ourcorpus remained unused, the effort needed to support 90% of the projects ismoderate, requiring about 110 builtins to be implemented. For each project, weanalyzed the evolution of builtin use over time and found that the majority ofprojects mostly added builtins. This suggests that builtins are not a legacyfeature and must be supported in future tools. Systematic testing of builtinsupport in existing tools revealed that many lacked support for builtins eitherpartially or completely; we also discovered incorrect implementations invarious tools, including the formally verified CompCert compiler.",
    "Article_Subject": "Programming Languages (cs.PL); Software Engineering (cs.SE)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00863"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00652",
    "DOI": "arXiv:1907.00652v1",
    "Article_Title": "Avoiding Implementation Pitfalls of \"Matrix Capsules with EM Routing\" by Hinton et al",
    "Article_Abstract": "The recent progress on capsule networks by Hinton et al. has generatedconsiderable excitement in the machine learning community. The idea behind acapsule is inspired by a cortical minicolumn in the brain, whereby a verticallyorganised group of around 100 neurons receive common inputs, have commonoutputs, are interconnected, and may well constitute a fundamental computationunit of the cerebral cortex. However, Hinton's paper on \"Matrix Capsule with EMRouting'\" was unfortunately not accompanied by a release of source code, whichleft interested researchers attempting to implement the architecture andreproduce the benchmarks on their own. This has certainly slowed the progressof research building on this work. While writing our own implementation, wenoticed several common mistakes in other open source implementations that wecame across. In this paper we share some of these learnings, specificallyfocusing on three implementation pitfalls and how to avoid them: (1) parentcapsules with only one child; (2) normalising the amount of data assigned toparent capsules; (3) parent capsules at different positions compete for childcapsules. While our implementation is a considerable improvement over currentlyavailable implementations, it still falls slightly short of the performancereported by Hinton et al. (2018). The source code for this implementation isavailable on GitHub at the following URL:https://github.com/IBM/matrix-capsules-with-em-routing.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00652"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00558",
    "DOI": "arXiv:1907.00558v1",
    "Article_Title": "Improved Forecasting of Cryptocurrency Price using Social Signals",
    "Article_Abstract": "Social media signals have been successfully used to develop large-scalepredictive and anticipatory analytics. For example, forecasting stock marketprices and influenza outbreaks. Recently, social data has been explored toforecast price fluctuations of cryptocurrencies, which are a novel disruptivetechnology with significant political and economic implications. In this paperwe leverage and contrast the predictive power of social signals, specificallyuser behavior and communication patterns, from multiple social platforms GitHuband Reddit to forecast prices for three cyptocurrencies with high developer andcommunity interest - Bitcoin, Ethereum, and Monero. We evaluate the performanceof neural network models that rely on long short-term memory units (LSTMs)trained on historical price data and social data against price only LSTMs andbaseline autoregressive integrated moving average (ARIMA) models, commonly usedto predict stock prices. Our results not only demonstrate that social signalsreduce error when forecasting daily coin price, but also show that the languageused in comments within the official communities on Reddit (r/Bitcoin,r/Ethereum, and r/Monero) are the best predictors overall. We observe thatmodels are more accurate in forecasting price one day ahead for Bitcoin (4%root mean squared percent error) compared to Ethereum (7%) and Monero (8%).",
    "Article_Subject": "Statistical Finance (q-fin.ST); Machine Learning (cs.LG); Social and Information Networks (cs.SI); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00558"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.11976",
    "DOI": "arXiv:1906.11976v1",
    "Article_Title": "Multivariate Big Data Analysis for Intrusion Detection: 5 steps from the haystack to the needle",
    "Article_Abstract": "The research literature on cybersecurity incident detection & response isvery rich in automatic detection methodologies, in particular those based onthe anomaly detection paradigm. However, very little attention has been devotedto the diagnosis ability of the methods, aimed to provide useful information onthe causes of a given detected anomaly. This information is of utmostimportance for the security team to reduce the time from detection to response.In this paper, we present Multivariate Big Data Analysis (MBDA), a completeintrusion detection approach based on 5 steps to effectively handle massiveamounts of disparate data sources. The approach has been designed to deal withthe main characteristics of Big Data, that is, the high volume, velocity andvariety. The core of the approach is the Multivariate Statistical NetworkMonitoring (MSNM) technique proposed in a recent paper. Unlike in state of theart machine learning methodologies applied to the intrusion detection problem,when an anomaly is identified in MBDA the output of the system includes thedetail of the logs of raw information associated to this anomaly, so that thesecurity team can use this information to elucidate its root causes. MBDA isbased in two open software packages available in Github: the MEDA Toolbox andthe FCParser. We illustrate our approach with two case studies. The first onedemonstrates the application of MBDA to semistructured sources of information,using the data from the VAST 2012 mini challenge 2. This complete case study issupplied in a virtual machine available for download. In the second case studywe show the Big Data capabilities of the approach in data collected from a realnetwork with labeled attacks.",
    "Article_Subject": "Networking and Internet Architecture (cs.NI); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Other Statistics (stat.OT)",
    "Article_Date": "2019/06/27",
    "Article_PDF": "https://arxiv.org/pdf/1906.11976"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.11565",
    "DOI": "arXiv:1906.11565v2",
    "Article_Title": "EmotionX-KU: BERT-Max based Contextual Emotion Classifier",
    "Article_Abstract": "We propose a contextual emotion classifier based on a transferable languagemodel and dynamic max pooling, which predicts the emotion of each utterance ina dialogue. A representative emotion analysis task, EmotionX, requires toconsider contextual information from colloquial dialogues and to deal with aclass imbalance problem. To alleviate these problems, our model leverages theself-attention based transferable language model and the weighted cross entropyloss. Furthermore, we apply post-training and fine-tuning mechanisms to enhancethe domain adaptability of our model and utilize several machine learningtechniques to improve its performance. We conduct experiments on twoemotion-labeled datasets named Friends and EmotionPush. As a result, our modeloutperforms the previous state-of-the-art model and also shows competitiveperformance in the EmotionX 2019 challenge. The code will be available in theGithub page.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/06/27",
    "Article_PDF": "https://arxiv.org/pdf/1906.11565"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.11017",
    "DOI": "arXiv:1906.11017v1",
    "Article_Title": "A project-based course on software development for (engineering) research",
    "Article_Abstract": "This paper describes the motivation and design of a 10-week graduate coursethat teaches practices for developing research software; although offered by anengineering program, the content applies broadly to any field of scientificresearch where software may be developed. Topics taught in the course includelocal and remote version control, licensing and copyright, structuring Pythonmodules, testing and test coverage, continuous integration, packaging anddistribution, open science, software citation, and reproducibility basics,among others. Lectures are supplemented by in-class activities and discussions,and all course material is shared openly via GitHub. Coursework is heavilybased on a single, term-long project where students individually develop asoftware package targeted at their own research topic; all contributions mustbe submitted as pull requests and reviewed/merged by other students. The coursewas initially offered in Spring 2018 with 17 students enrolled, and will betaught again in Spring 2019.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/06/13",
    "Article_PDF": "https://arxiv.org/pdf/1906.11017"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.10506",
    "DOI": "arXiv:1906.10506v1",
    "Article_Title": "GaussPy+: A fully automated Gaussian decomposition package for emission line spectra",
    "Article_Abstract": "Our understanding of the dynamics of the interstellar medium is informed bythe study of the detailed velocity structure of emission line observations. Oneapproach to study the velocity structure is to decompose the spectra intoindividual velocity components; this leads to a description of the dataset thatis significantly reduced in complexity. However, this decomposition requiresfull automation lest it becomes prohibitive for large datasets, such asGalactic plane surveys. We developed GaussPy+, a fully automated Gaussiandecomposition package that can be applied to emission line datasets, especiallylarge surveys of HI and isotopologues of CO. We built our package upon theexisting GaussPy algorithm and significantly improved its performance for noisydata. New functionalities of GaussPy+ include: i) automated preparatory steps,such as an accurate noise estimation, which can also be used as standaloneapplications; ii) an improved fitting routine; iii) an automated spatialrefitting routine that can add spatial coherence to the decomposition resultsby refitting spectra based on neighbouring fit solutions. We thoroughly testedthe performance of GaussPy+ on synthetic spectra and a test field from theGalactic Ring Survey. We found that GaussPy+ can deal with cases of complexemission and even low to moderate signal-to-noise values.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Astrophysics of Galaxies (astro-ph.GA)",
    "Article_Date": "2019/06/25",
    "Article_PDF": "https://arxiv.org/pdf/1906.10506"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.10362",
    "DOI": "arXiv:1906.10362v1",
    "Article_Title": "EVulHunter: Detecting Fake Transfer Vulnerabilities for EOSIO's Smart Contracts at Webassembly-level",
    "Article_Abstract": "As one of the representative Delegated Proof-of-Stake (DPoS) blockchainplatforms, EOSIO's ecosystem grows rapidly in recent years. A number ofvulnerabilities and corresponding attacks of EOSIO's smart contracts have beendiscovered and observed in the wild, which caused a large amount of financialdamages. However, the majority of EOSIO's smart contracts are not open-sourced.As a result, the WebAssembly code may become the only available object to beanalyzed in most cases. Unfortunately, current tools are web-applicationoriented and cannot be applied to EOSIO WebAssembly code directly, which makesit more difficult to detect vulnerabilities from those smart contracts. In thispaper, we propose \\toolname, a static analysis tool that can be used to detectvulnerabilities from EOSIO WASM code automatically. We focus on one particulartype of vulnerabilities named \\textit{fake-transfer}, and the exploitation ofsuch vulnerabilities has led to millions of dollars in damages. To the best ofour knowledge, it is the first attempt to build an automatic tool to detectvulnerabilities of EOSIO's smart contracts. The experimental resultsdemonstrate that our tool is able to detect fake transfer vulnerabilitiesquickly and precisely. EVulHunter is available on GitHub\\footnote{Tool andbenchmarks: https://github.com/EVulHunter/EVulHunter} and YouTube\\footnote{Demovideo: https://youtu.be/5SJ0ZJKVZvw}.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/06/25",
    "Article_PDF": "https://arxiv.org/pdf/1906.10362"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.09808",
    "DOI": "arXiv:1906.09808v1",
    "Article_Title": "Recurrent Adversarial Service Times",
    "Article_Abstract": "Service system dynamics occur at the interplay between customer behaviour anda service provider's response. This kind of dynamics can effectively be modeledwithin the framework of queuing theory where customers' arrivals are describedby point process models. However, these approaches are limited by parametricassumptions as to, for example, inter-event time distributions. In this paper,we address these limitations and propose a novel, deep neural network solutionto the queuing problem. Our solution combines a recurrent neural network thatmodels the arrival process with a recurrent generative adversarial networkwhich models the service time distribution. We evaluate our methodology onvarious empirical datasets ranging from internet services (Blockchain, GitHub,Stackoverflow) to mobility service systems (New York taxi cab).",
    "Article_Subject": "Machine Learning (stat.ML); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/24",
    "Article_PDF": "https://arxiv.org/pdf/1906.09808"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08351",
    "DOI": "arXiv:1906.08351v1",
    "Article_Title": "Towards Lakosian Multilingual Software Design Principles",
    "Article_Abstract": "Large software systems often comprise programs written in differentprogramming languages. In the case when cross-language interoperability isaccomplished with a Foreign Function Interface (FFI), for example pybind11,Boost.Python, Emscripten, PyV8, or JNI, among many others, common softwareengineering tools, such as call-graph analysis, are obstructed by the opacityof the FFI. This complicates debugging and fosters potential inefficiency andsecurity problems. One contributing issue is that there is little rigoroussoftware design advice for multilingual software. In this paper, we present ourprogress towards a more rigorous design approach to multilingual software. Theapproach is based on the existing approach to the design of large-scale C++systems developed by Lakos. The Lakosian approach is one of the few designmethodologies to address physical design rather than just logical design. Usingthe MLSA toolkit developed in prior work for analysis of multilingual software,we focus in on one FFI -- the pybind11 FFI. An extension to the Lakosian C++design rules is proposed to address multilingual software that uses pybind11.Using a sample of 50 public GitHub repositories that use pybind11, we measurehow many repositories would currently satisfy these rules. We conclude with aproposed generalization of the pybind11-based rules for any multilingualsoftware using an FFI interface.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08351"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08101",
    "DOI": "arXiv:1906.08101v1",
    "Article_Title": "Pre-Training with Whole Word Masking for Chinese BERT",
    "Article_Abstract": "Bidirectional Encoder Representations from Transformers (BERT) has shownmarvelous improvements across various NLP tasks. Recently, an upgraded versionof BERT has been released with Whole Word Masking (WWM), which mitigate thedrawbacks of masking partial WordPiece tokens in pre-training BERT. In thistechnical report, we adapt whole word masking in Chinese text, that masking thewhole word instead of masking Chinese characters, which could bring anotherchallenge in Masked Language Model (MLM) pre-training task. The model wastrained on the latest Chinese Wikipedia dump. We aim to provide easyextensibility and better performance for Chinese BERT without changing anyneural architecture or even hyper-parameters. The model is verified on variousNLP tasks, across sentence-level to document-level, including sentimentclassification (ChnSentiCorp, Sina Weibo), named entity recognition (PeopleDaily, MSRA-NER), natural language inference (XNLI), sentence pair matching(LCQMC, BQ Corpus), and machine reading comprehension (CMRC 2018, DRCD, CAILRC). Experimental results on these datasets show that the whole word maskingcould bring another significant gain. Moreover, we also examine theeffectiveness of Chinese pre-trained models: BERT, ERNIE, BERT-wwm. We releasethe pre-trained model (both TensorFlow and PyTorch) on GitHub:https://github.com/ymcui/Chinese-BERT-wwm",
    "Article_Subject": "Computation and Language (cs.CL); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08101"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08085",
    "DOI": "arXiv:1906.08085v1",
    "Article_Title": "PLANE: An Extensible Open Source Framework for modeling the Internet of Drones",
    "Article_Abstract": "Python Library for simulating unManNed vehiclEs(PLANE) is an open sourcesoftware module, written in Python, that focuses on Unmanned Aerial Vehicles(UAVs), on their movements and on the mechanics of flight, thus devotingparticular attention to the equations that describe drones' movement. In thecontext of the Internet of Drones (IoD), the module can be widely used for thestudy of the mutual control of position/coordination in scenarios in whichdrones may find obstacles, as it happens in densely populated urban scenarios.Emphasis is put on ease of use, performance evaluation, documentation, andApplication Programming Interface (API) consistency. The software tool hasminimal dependencies and is distributed under MIT License. Source code,binaries, and documentation can be downloaded from GitHub.",
    "Article_Subject": "Robotics (cs.RO); Software Engineering (cs.SE)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08085"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08058",
    "DOI": "arXiv:1906.08058v1",
    "Article_Title": "On the abandonment and survival of open source projects: An empirical investigation",
    "Article_Abstract": "Background: Evolution of open source projects frequently depends on a smallnumber of core developers. The loss of such core developers might bedetrimental for projects and even threaten their entire continuation. However,it is possible that new core developers assume the project maintenance andallow the project to survive. Aims: The objective of this paper is to provideempirical evidence on: 1) the frequency of project abandonment and survival, 2)the differences between abandoned and surviving projects, and 3) the motivationand difficulties faced when assuming an abandoned project. Method: We adopt amixed-methods approach to investigate project abandonment and survival. Wecarefully select 1,932 popular GitHub projects and recover the abandoned andsurviving projects, and conduct a survey with developers that have beeninstrumental in the survival of the projects. Results: We found that 315projects (16%) were abandoned and 128 of these projects (41%) survived becauseof new core developers who assumed the project development. The surveyindicates that (i) in most cases the new maintainers were aware of the projectabandonment risks when they started to contribute; (ii) their own usage of thesystems is the main motivation to contribute to such projects; (iii) human andsocial factors played a key role when making these contributions; and (iv) lackof time and the difficulty to obtain push access to the repositories are themain barriers faced by them. Conclusions: Project abandonment is a reality evenin large open source projects and our work enables a better understanding ofsuch risks, as well as highlights ways in avoiding them.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08058"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.07771",
    "DOI": "arXiv:1906.07771v1",
    "Article_Title": "Crop Lodging Prediction from UAV-Acquired Images of Wheat and Canola using a DCNN Augmented with Handcrafted Texture Features",
    "Article_Abstract": "Lodging, the permanent bending over of food crops, leads to poor plant growthand development. Consequently, lodging results in reduced crop quality, lowerscrop yield, and makes harvesting difficult. Plant breeders routinely evaluateseveral thousand breeding lines, and therefore, automatic lodging detection andprediction is of great value aid in selection. In this paper, we propose a deepconvolutional neural network (DCNN) architecture for lodging classificationusing five spectral channel orthomosaic images from canola and wheat breedingtrials. Also, using transfer learning, we trained 10 lodging detection modelsusing well-established deep convolutional neural network architectures. Ourproposed model outperforms the state-of-the-art lodging detection methods inthe literature that use only handcrafted features. In comparison to 10 DCNNlodging detection models, our proposed model achieves comparable results whilehaving a substantially lower number of parameters. This makes the proposedmodel suitable for applications such as real-time classification usinginexpensive hardware for high-throughput phenotyping pipelines. The GitHubrepository at https://github.com/FarhadMaleki/LodgedNet contains code andmodels.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/06/18",
    "Article_PDF": "https://arxiv.org/pdf/1906.07771"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.07637",
    "DOI": "arXiv:1906.07637v2",
    "Article_Title": "Periphery Plots for Contextualizing Heterogeneous Time-Based Charts",
    "Article_Abstract": "Patterns in temporal data can often be found across different scales, such asdays, weeks, and months, making effective visualization of time-based datachallenging. Here we propose a new approach for providing focus and context intime-based charts to enable interpretation of patterns across time scales. Ourapproach employs a focus zone with a time and a second axis, that can eitherrepresent quantities or categories, as well as a set of adjacent peripheryplots that can aggregate data along the time, value, or both dimensions. Wepresent a framework for periphery plots and describe two use cases thatdemonstrate the utility of our approach.",
    "Article_Subject": "Human-Computer Interaction (cs.HC)",
    "Article_Date": "2019/06/18",
    "Article_PDF": "https://arxiv.org/pdf/1906.07637"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.07505",
    "DOI": "arXiv:1906.07505v1",
    "Article_Title": "A Model-Based General Alternative to the Standardised Precipitation Index",
    "Article_Abstract": "In this paper, we introduce two new model-based versions of the widely-usedstandardized precipitation index (SPI) for detecting and quantifying themagnitude of extreme hydro-climatic events. Our analytical approach is based ongeneralized additive models for location, scale and shape (GAMLSS), which helpsas to overcome some limitations of the SPI. We compare our model-basedstandardised indices (MBSIs) with the SPI using precipitation data collectedbetween January 2004 - December 2013 (522 weeks) in Caapiranga, a road-lessmunicipality of Amazonas State. As a result, it is shown that the MBSI-1 is anindex with similar properties to the SPI, but with improved methodology. Incomparison to the SPI, our MBSI-1 index allows for the use of differentzero-augmented distributions, it works with more flexible time-scales, can beapplied to shorter records of data and also takes into account temporaldependencies in known seasonal behaviours. Our approach is implemented in an Rpackage, mbsi, available from Github.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/06/18",
    "Article_PDF": "https://arxiv.org/pdf/1906.07505"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.06905",
    "DOI": "arXiv:1906.06905v2",
    "Article_Title": "Manipulating the Difficulty of C-Tests",
    "Article_Abstract": "We propose two novel manipulation strategies for increasing and decreasingthe difficulty of C-tests automatically. This is a crucial step towardsgenerating learner-adaptive exercises for self-directed language learning andpreparing language assessment tests. To reach the desired difficulty level, wemanipulate the size and the distribution of gaps based on absolute and relativegap difficulty predictions. We evaluate our approach in corpus-basedexperiments and in a user study with 60 participants. We find that bothstrategies are able to generate C-tests with the desired difficulty level.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/06/17",
    "Article_PDF": "https://arxiv.org/pdf/1906.06905"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.06583",
    "DOI": "arXiv:1906.06583v2",
    "Article_Title": "Linear regression with stationary errors : the R package slm",
    "Article_Abstract": "This paper introduces the R package slm which stands for Stationary LinearModels. The package contains a set of statistical procedures for linearregression in the general context where the error process is strictlystationary with short memory. We work in the setting of Hannan (1973), whoproved the asymptotic normality of the (normalized) least squares estimators(LSE) under very mild conditions on the error process. We propose differentways to estimate the asymptotic covariance matrix of the LSE, and then tocorrect the type I error rates of the usual tests on the parameters (as well asconfidence intervals). The procedures are evaluated through different sets ofsimulations, and two examples of real datasets are studied.",
    "Article_Subject": "Applications (stat.AP); Computation (stat.CO); Methodology (stat.ME)",
    "Article_Date": "2019/06/15",
    "Article_PDF": "https://arxiv.org/pdf/1906.06583"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.06317",
    "DOI": "arXiv:1906.06317v1",
    "Article_Title": "freud: A Software Suite for High Throughput Analysis of Particle Simulation Data",
    "Article_Abstract": "The freud Python package is a powerful library for analyzing simulation data.Written with modern simulation and data analysis workflows in mind, freudprovides a Python interface to fast, parallelized C++ routines that runefficiently on laptops, workstations, and supercomputing clusters. The packageprovides the core tools for finding particle neighbors in periodic systems, andoffers a uniform API to a wide variety of methods implemented using thesetools. As such, freud users can access standard methods such as the radialdistribution function as well as newer, more specialized methods such as thepotential of mean force and torque and local crystal environment analysis withequal ease. While many comparable tools place a heavy emphasis on reading andoperating on trajectory file formats, freud instead accepts numerical arrays ofdata directly as inputs. By remaining agnostic to its data source, freud issuitable for analyzing any coarse-grained particle simulation, regardless ofthe original data representation or simulation method. When used for on-the-flyanalysis in conjunction with scriptable simulation software such as HOOMD-blue,freud enables smart simulations that adapt to the current state of the system,allowing users to study phenomena such as nucleation and growth.",
    "Article_Subject": "Computational Physics (physics.comp-ph); Materials Science (cond-mat.mtrl-sci); Computational Engineering, Finance, and Science (cs.CE)",
    "Article_Date": "2019/06/14",
    "Article_PDF": "https://arxiv.org/pdf/1906.06317"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.05676",
    "DOI": "arXiv:1906.05676v1",
    "Article_Title": "Sionnx: Automatic Unit Test Generator for ONNX Conformance",
    "Article_Abstract": "Open Neural Network Exchange (ONNX) is an open format to represent AI modelsand is supported by many machine learning frameworks. While ONNX definesunified and portable computation operators across various frameworks, theconformance tests for those operators are insufficient, which makes itdifficult to verify if an operator's behavior in an ONNX backend implementationcomplies with the ONNX standard. In this paper, we present the first automaticunit test generator named Sionnx for verifying the compliance of ONNXimplementation. First, we propose a compact yet complete set of rules todescribe the operator's attributes and the properties of its operands. Second,we design an Operator Specification Language (OSL) to provide a high-leveldescription for the operator's syntax. Finally, through this easy-to-usespecification language, we are able to build a full testing specification whichleverages LLVM TableGen to automatically generate unit tests for ONNX operatorswith much large coverage. Sionnx is lightweight and flexible to supportcross-framework verification. The Sionnx framework is open-sourced in thegithub repository (https://github.com/alibaba/Sionnx).",
    "Article_Subject": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/06/12",
    "Article_PDF": "https://arxiv.org/pdf/1906.05676"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.05603",
    "DOI": "arXiv:1906.05603v1",
    "Article_Title": "A review of available software for adaptive clinical trial design",
    "Article_Abstract": "Background/Aims: The increasing expense of the drug development process hasseen interest in the use of adaptive designs (ADs) grow substantially in recentyears. Accordingly, much research has been conducted to identify potentialbarriers to increasing the use of ADs in practice, and several articles haveargued that the availability of user-friendly software will be an importantstep in making ADs easier to implement. Therefore, in this paper we present areview of the current state of software availability for AD. Methods: We firstreview articles from 31 journals published in 2013-17 that relate tomethodology for adaptive trials, in order to assess how often code and softwarefor implementing novel ADs is made available at the time of publication. Wecontrast our findings against these journals' current policies on codedistribution. Secondly, we conduct additional searches of popular coderepositories, such as CRAN and GitHub, to identify further existinguser-contributed software for ADs. From this, we are able to direct interestedparties towards solutions for their problem of interest by classifyingavailable code by type of adaptation. Results: Only 29% of included articlesmade their code available in some form. In many instances, articles publishedin journals that had mandatory requirements on code provision still did notmake code available. There are several areas in which available software iscurrently limited or saturated. In particular, many packages are available toaddress group sequential design, but comparatively little code is present inthe public domain to determine biomarker-guided ADs. Conclusions: There is muchroom for improvement in the provision of software alongside AD publications.Additionally, whilst progress has been made, well-established software forvarious types of trial adaptation remains sparsely available.",
    "Article_Subject": "Computation (stat.CO)",
    "Article_Date": "2019/06/13",
    "Article_PDF": "https://arxiv.org/pdf/1906.05603"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.04554",
    "DOI": "arXiv:1906.04554v1",
    "Article_Title": "Principled Training of Neural Networks with Direct Feedback Alignment",
    "Article_Abstract": "The backpropagation algorithm has long been the canonical training method forneural networks. Modern paradigms are implicitly optimized for it, and numerousguidelines exist to ensure its proper use. Recently, synthetic gradientsmethods -where the error gradient is only roughly approximated - have garneredinterest. These methods not only better portray how biological brains arelearning, but also open new computational possibilities, such as updatinglayers asynchronously. Even so, they have failed to scale past simple taskslike MNIST or CIFAR-10. This is in part due to a lack of standards, leading toill-suited models and practices forbidding such methods from performing to thebest of their abilities. In this work, we focus on direct feedback alignmentand present a set of best practices justified by observations of the alignmentangles. We characterize a bottleneck effect that prevents alignment in narrowlayers, and hypothesize it may explain why feedback alignment methods have yetto scale to large convolutional networks.",
    "Article_Subject": "Machine Learning (stat.ML); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)",
    "Article_Date": "2019/06/11",
    "Article_PDF": "https://arxiv.org/pdf/1906.04554"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.04281",
    "DOI": "arXiv:1906.04281v1",
    "Article_Title": "Towards Amortized Ranking-Critical Training for Collaborative Filtering",
    "Article_Abstract": "Collaborative filtering is widely used in modern recommender systems. Recentresearch shows that variational autoencoders (VAEs) yield state-of-the-artperformance by integrating flexible representations from deep neural networksinto latent variable models, mitigating limitations of traditional linearfactor models. VAEs are typically trained by maximizing the likelihood (MLE) ofusers interacting with ground-truth items. While simple and often effective,MLE-based training does not directly maximize the recommendation-qualitymetrics one typically cares about, such as top-N ranking. In this paper weinvestigate new methods for training collaborative filtering models based onactor-critic reinforcement learning, to directly optimize thenon-differentiable quality metrics of interest. Specifically, we train a criticnetwork to approximate ranking-based metrics, and then update the actor network(represented here by a VAE) to directly optimize against the learned metrics.In contrast to traditional learning-to-rank methods that require to re-run theoptimization procedure for new lists, our critic-based method amortizes thescoring process with a neural network, and can directly provide the(approximate) ranking scores for new lists. Empirically, we show that theproposed methods outperform several state-of-the-art baselines, includingrecently-proposed deep learning approaches, on three large-scale real-worlddatasets. The code to reproduce the experimental results and figure plots is onGithub: https://github.com/samlobel/RaCT_CF",
    "Article_Subject": "Machine Learning (cs.LG); Information Retrieval (cs.IR); Machine Learning (stat.ML)",
    "Article_Date": "2019/06/10",
    "Article_PDF": "https://arxiv.org/pdf/1906.04281"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03951",
    "DOI": "arXiv:1906.03951v1",
    "Article_Title": "SCAN: A Scalable Neural Networks Framework Towards Compact and Efficient Models",
    "Article_Abstract": "Remarkable achievements have been attained by deep neural networks in variousapplications. However, the increasing depth and width of such models also leadto explosive growth in both storage and computation, which has restricted thedeployment of deep neural networks on resource-limited edge devices. To addressthis problem, we propose the so-called SCAN framework for networks training andinference, which is orthogonal and complementary to existing acceleration andcompression methods. The proposed SCAN firstly divides neural networks intomultiple sections according to their depth and constructs shallow classifiersupon the intermediate features of different sections. Moreover, attentionmodules and knowledge distillation are utilized to enhance the accuracy ofshallow classifiers. Based on this architecture, we further propose a thresholdcontrolled scalable inference mechanism to approach human-like sample-specificinference. Experimental results show that SCAN can be easily equipped onvarious neural networks without any adjustment on hyper-parameters or neuralnetworks architectures, yielding significant performance gain on CIFAR100 andImageNet. Codes will be released on github soon.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/27",
    "Article_PDF": "https://arxiv.org/pdf/1906.03951"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03773",
    "DOI": "arXiv:1906.03773v1",
    "Article_Title": "DataLearner: A Data Mining and Knowledge Discovery Tool for Android Smartphones and Tablets",
    "Article_Abstract": "Smartphones have become the ultimate 'personal' computer, yet despite this,general-purpose data-mining and knowledge discovery tools for mobile devicesare surprisingly rare. DataLearner is a new data-mining application designedspecifically for Android devices that imports the Weka data-mining engine andaugments it with algorithms developed by Charles Sturt University. Moreover,DataLearner can be expanded with additional algorithms. Combined, DataLearnerdelivers 40 classification, clustering and association rule mining algorithmsfor model training and evaluation without need for cloud computing resources ornetwork connectivity. It provides the same classification accuracy as PCs andlaptops, while doing so with acceptable processing speed and consumingnegligible battery life. With its ability to provide easy-to-use data-mining ona phone-size screen, DataLearner is a new portable, self-contained data-miningtool for remote, personalised and learning applications alike. DataLearnerfeatures four elements - this paper, the app available on Google Play, theGPL3-licensed source code on GitHub and a short video on YouTube.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/06/10",
    "Article_PDF": "https://arxiv.org/pdf/1906.03773"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03277",
    "DOI": "arXiv:1906.03277v1",
    "Article_Title": "xBIT: an easy to use scanning tool with machine learning abilities",
    "Article_Abstract": "xBIT is a tool for performing parameter scans in beyond the Standard Modeltheories. It's written in Python and fully open source. The main purpose ofxBIT is to provide an easy to use tool to help phenomenologists with theirdaily task: exploring the parameter space of new models. It was developed underthe impression of the SARAH/SPheno framework, but should be use-able with othertools as well that use the SLHA format to transfer data. It also supports bydefault MicrOmegas for dark matter calculations, HiggsBounds and HiggsSignalsfor checking the Higgs properties, and Vevacious for testing the vacuumstability. Classes for other tools can be added if necessary. In order toimprove the efficiency of the parameter scans, the recently proposed 'MachineLearning Scan' approach is included. For this purpose, xBIT uses pyTorch todeal with artificial neural networks.",
    "Article_Subject": "High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Experiment (hep-ex)",
    "Article_Date": "2019/06/07",
    "Article_PDF": "https://arxiv.org/pdf/1906.03277"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03049",
    "DOI": "arXiv:1906.03049v1",
    "Article_Title": "Computing Exact Guarantees for Differential Privacy",
    "Article_Abstract": "Quantification of the privacy loss associated with a randomised algorithm hasbecome an active area of research and $(\\varepsilon,\u03b4)$-differentialprivacy has arisen as the standard measure of it. We propose a numerical methodfor evaluating the parameters of differential privacy for algorithms withcontinuous one dimensional output. In this way the parameters $\\varepsilon$ and$\u03b4$ can be evaluated, for example, for the subsampled multidimensionalGaussian mechanism which is also the underlying mechanism of differentiallyprivate stochastic gradient descent. The proposed method is based on anumerical approximation of an integral formula which gives the exact$(\\varepsilon,\u03b4)$-values. The approximation is carried out by discretisingthe integral and by evaluating discrete convolutions using a fast Fouriertransform algorithm. We give theoretical error bounds which show theconvergence of the approximation and guarantee its accuracy to an arbitrarydegree. Experimental comparisons with state-of-the-art techniques illustratethe efficacy of the method. Python code for the proposed method can be found inGithub (https://github.com/DPBayes/PLD-Accountant/).",
    "Article_Subject": "Machine Learning (stat.ML); Cryptography and Security (cs.CR); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/07",
    "Article_PDF": "https://arxiv.org/pdf/1906.03049"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03008",
    "DOI": "arXiv:1906.03008v2",
    "Article_Title": "RankQA: Neural Question Answering with Answer Re-Ranking",
    "Article_Abstract": "The conventional paradigm in neural question answering (QA) for narrativecontent is limited to a two-stage process: first, relevant text passages areretrieved and, subsequently, a neural network for machine comprehensionextracts the likeliest answer. However, both stages are largely isolated in thestatus quo and, hence, information from the two phases is never properly fused.In contrast, this work proposes RankQA: RankQA extends the conventionaltwo-stage process in neural QA with a third stage that performs an additionalanswer re-ranking. The re-ranking leverages different features that aredirectly extracted from the QA pipeline, i.e., a combination of retrieval andcomprehension features. While our intentionally simple design allows for anefficient, data-sparse estimation, it nevertheless outperforms more complex QAsystems by a significant margin: in fact, RankQA achieves state-of-the-artperformance on 3 out of 4 benchmark datasets. Furthermore, its performance isespecially superior in settings where the size of the corpus is dynamic. Herethe answer re-ranking provides an effective remedy against the underlyingnoise-information trade-off due to a variable corpus size. As a consequence,RankQA represents a novel, powerful, and thus challenging baseline for futureresearch in content-based QA.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/06/07",
    "Article_PDF": "https://arxiv.org/pdf/1906.03008"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.02126",
    "DOI": "arXiv:1906.02126v1",
    "Article_Title": "Extractive Summarization via Weighted Dissimilarity and Importance Aligned Key Iterative Algorithm",
    "Article_Abstract": "We present importance aligned key iterative algorithm for extractivesummarization that is faster than conventional algorithms keeping its accuracy.The computational complexity of our algorithm is O($SNlogN$) to summarizeoriginal $N$ sentences into final $S$ sentences. Our algorithm maximizes theweighted dissimilarity defined by the product of importance and cosinedissimilarity so that the summary represents the document and at the same timethe sentences of the summary are not similar to each other. The weighteddissimilarity is heuristically maximized by iterative greedy search and binarysearch to the sentences ordered by importance. We finally show a benchmarkscore based on summarization of customer reviews of products, which highlightsthe quality of our algorithm comparable to human and existing algorithms. Weprovide the source code of our algorithm on githubhttps://github.com/qhapaq-49/imakita .",
    "Article_Subject": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/05/15",
    "Article_PDF": "https://arxiv.org/pdf/1906.02126"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.01388",
    "DOI": "arXiv:1906.01388v1",
    "Article_Title": "A Comprehensive Study on Deep Learning Bug Characteristics",
    "Article_Abstract": "Deep learning has gained substantial popularity in recent years. Developersmainly rely on libraries and tools to add deep learning capabilities to theirsoftware. What kinds of bugs are frequently found in such software? What arethe root causes of such bugs? What impacts do such bugs have? Which stages ofdeep learning pipeline are more bug prone? Are there any antipatterns?Understanding such characteristics of bugs in deep learning software has thepotential to foster the development of better deep learning platforms,debugging mechanisms, development practices, and encourage the development ofanalysis and verification frameworks. Therefore, we study 2716 high-qualityposts from Stack Overflow and 500 bug fix commits from Github about fivepopular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch tounderstand the types of bugs, root causes of bugs, impacts of bugs, bug-pronestage of deep learning pipeline as well as whether there are some commonantipatterns found in this buggy software. The key findings of our studyinclude: data bug and logic bug are the most severe bug types in deep learningsoftware appearing more than 48% of the times, major root causes of these bugsare Incorrect Model Parameter (IPS) and Structural Inefficiency (SI) showing upmore than 43% of the times. We have also found that the bugs in the usage ofdeep learning libraries have some common antipatterns that lead to a strongcorrelation of bug types among the libraries.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.01388"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.01211",
    "DOI": "arXiv:1906.01211v3",
    "Article_Title": "Raising the Performance of the Tinker-HP Molecular Modeling Package [Article v1.0]",
    "Article_Abstract": "This living paper reviews the present High Performance Computing (HPC)capabilities of the Tinker-HP molecular modeling package. We focus here on thereference, double precision, massively parallel molecular dynamics enginepresent in Tinker-HP and dedicated to perform large scale simulations. We showhow it can be adapted to recent Intel Central Processing Unit (CPU) petascalearchitectures. First, we discuss the new set of Intel Advanced VectorExtensions 512 (Intel AVX-512) instructions present in recent Intel processors(e.g., the Intel Xeon Scalable and Intel Xeon Phi 2nd generation processors)allowing for larger vectorization enhancements. These instructions constitutethe central source of potential computational gains when using the latestprocessors, justifying important vectorization efforts for developers. We thenbriefly review the organization of the Tinker-HP code and identify thecomputational hotspots which require Intel AVX-512 optimization and we proposea general and optimal strategy to vectorize those particular parts of the code.We intended to present our optimization strategy in a pedagogical way so itcould benefit to other researchers and students interested in gainingperformances in their own software. Finally we present the performanceenhancements obtained compared to the unoptimized code both sequentially and atthe scaling limit in parallel for classical non-polarizable (CHARMM) andpolarizable force fields (AMOEBA). This paper never ceases to be updated as weaccumulate new data on the associated Github repository between new versions ofthis living paper.",
    "Article_Subject": "Mathematical Software (cs.MS); Chemical Physics (physics.chem-ph); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/06/04",
    "Article_PDF": "https://arxiv.org/pdf/1906.01211"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.01032",
    "DOI": "arXiv:1906.01032v1",
    "Article_Title": "A Language-Agnostic Model for Semantic Source Code Labeling",
    "Article_Abstract": "Code search and comprehension have become more difficult in recent years dueto the rapid expansion of available source code. Current tools lack a way tolabel arbitrary code at scale while maintaining up-to-date representations ofnew programming languages, libraries, and functionalities. Comprehensivelabeling of source code enables users to search for documents of interest andobtain a high-level understanding of their contents. We use Stack Overflow codesnippets and their tags to train a language-agnostic, deep convolutional neuralnetwork to automatically predict semantic labels for source code documents. OnStack Overflow code snippets, we demonstrate a mean area under ROC of 0.957over a long-tailed list of 4,508 tags. We also manually validate the modeloutputs on a diverse set of unlabeled source code documents retrieved fromGithub, and we obtain a top-1 accuracy of 86.6%. This strongly indicates thatthe model successfully transfers its knowledge from Stack Overflow snippets toarbitrary source code documents.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Software Engineering (cs.SE); Machine Learning (stat.ML)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.01032"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.00966",
    "DOI": "arXiv:1906.00966v3",
    "Article_Title": "Wotan: Comprehensive time-series de-trending in Python",
    "Article_Abstract": "The detection of transiting exoplanets in time-series photometry requires theremoval or modeling of instrumental and stellar noise. While instrumentalsystematics can be reduced using methods such as pixel level decorrelation,removing stellar trends while preserving transit signals proves challenging.Due to vast archives of light curves from recent transit surveys, there is astrong need for accurate automatic detrending, without human intervention. Alarge variety of detrending algorithms are in active use, but their comparativeperformance for transit discovery is unexplored. We benchmark all commonly useddetrending methods against hundreds of Kepler, K2, and TESS planets, selectedto represent the most difficult cases for systems with small planet-to-starradius ratios. The full parameter range is explored for each method todetermine the best choices for planet discovery. We conclude that the idealmethod is a time-windowed slider with an iterative robust location estimatorbased on Tukey's biweight. This method recovers 99% and 94% of the shallowestKepler and K2 planets, respectively. We include an additional analysis foryoung stars with extreme variability and conclude they are best treated using aspline-based method with a robust Huber estimator. All stellar detrendingmethods explored are available for public use in wotan, an open-source Pythonpackage on GitHub (see https://github.com/hippke/wotan).",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.00966"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.00925",
    "DOI": "arXiv:1906.00925v2",
    "Article_Title": "3D Appearance Super-Resolution with Deep Learning",
    "Article_Abstract": "We tackle the problem of retrieving high-resolution (HR) texture maps ofobjects that are captured from multiple view points. In the multi-view case,model-based super-resolution (SR) methods have been recently proved to recoverhigh quality texture maps. On the other hand, the advent of deep learning-basedmethods has already a significant impact on the problem of video and image SR.Yet, a deep learning-based approach to super-resolve the appearance of 3Dobjects is still missing. The main limitation of exploiting the power of deeplearning techniques in the multi-view case is the lack of data. We introduce a3D appearance SR (3DASR) dataset based on the existing ETH3D [42], SyB3R [31],MiddleBury, and our Collection of 3D scenes from TUM [21], Fountain [51] andRelief [53]. We provide the high- and low-resolution texture maps, the 3Dgeometric model, images and projection matrices. We exploit the power of 2Dlearning-based SR methods and design networks suitable for the 3D multi-viewcase. We incorporate the geometric information by introducing normal maps andfurther improve the learning process. Experimental results demonstrate that ourproposed networks successfully incorporate the 3D geometric information andsuper-resolve the texture maps.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.00925"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.00657",
    "DOI": "arXiv:1906.00657v1",
    "Article_Title": "Kandinsky Patterns",
    "Article_Abstract": "Kandinsky Figures and Kandinsky Patterns are mathematically describable,simple self-contained hence controllable test data sets for the development,validation and training of explainability in artificial intelligence. WhilstKandinsky Patterns have these computationally manageable properties, they areat the same time easily distinguishable from human observers. Consequently,controlled patterns can be described by both humans and computers. We define aKandinsky Pattern as a set of Kandinsky Figures, where for each figure an\"infallible authority\" defines that the figure belongs to the KandinskyPattern. With this simple principle we build training and validation data setsfor automatic interpretability and context learning. In this paper we describethe basic idea and some underlying principles of Kandinsky Patterns and providea Github repository to invite the international machine learning researchcommunity to a challenge to experiment with our Kandinsky Patterns to expandand thus make progress in the field of explainable AI and to contribute to theupcoming field of explainability and causability.",
    "Article_Subject": "Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.00657"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.13658",
    "DOI": "arXiv:1905.13658v1",
    "Article_Title": "Ordinal Regression as Structured Classification",
    "Article_Abstract": "This paper extends the class of ordinal regression models with a structuredinterpretation of the problem by applying a novel treatment of encoded labels.The net effect of this is to transform the underlying problem from an ordinalregression task to a (structured) classification task which we solve withconditional random fields, thereby achieving a coherent and probabilistic modelin which all model parameters are jointly learnt. Importantly, we show thatalthough we have cast ordinal regression to classification, our method stillfall within the class of decomposition methods in the ordinal regressionontology. This is an important link since our experience is that manyapplications of machine learning to healthcare ignores completely the importantnature of the label ordering, and hence these approaches should considerednaive in this ontology. We also show that our model is flexible both in how itadapts to data manifolds and in terms of the operations that are available forpractitioner to execute. Our empirical evaluation demonstrates that theproposed approach overwhelmingly produces superior and often statisticallysignificant results over baseline approaches on forty popular ordinalregression models, and demonstrate that the proposed model significantlyout-performs baselines on synthetic and real datasets. Our implementation,together with scripts to reproduce the results of this work, will be availableon a public GitHub repository.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/31",
    "Article_PDF": "https://arxiv.org/pdf/1905.13658"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.13313",
    "DOI": "arXiv:1905.13313v5",
    "Article_Title": "Technical Report of the Video Event Reconstruction and Analysis (VERA) System -- Shooter Localization, Models, Interface, and Beyond",
    "Article_Abstract": "Every minute, hundreds of hours of video are uploaded to social media sitesand the Internet from around the world. This material creates a visual recordof the experiences of a significant percentage of humanity and can helpilluminate how we live in the present moment. When properly analyzed, thisvideo can also help analysts to reconstruct events of interest, including warcrimes, human rights violations, and terrorist acts. Machine learning andcomputer vision can play a crucial role in this process. In this technicalreport, we describe the Video Event Reconstruction and Analysis (VERA) system.This new tool brings together a variety of capabilities we have developed overthe past few years (including video synchronization and geolocation to orderunstructured videos lacking metadata over time and space, and sound recognitionalgorithms) to enable the reconstruction and analysis of events captured onvideo. Among other uses, VERA enables the localization of a shooter from just afew videos that include the sound of gunshots. To demonstrate the efficacy ofthis suite of tools, we present the results of estimating the shooter'slocation of the Las Vegas Shooting in 2017 and show that VERA accuratelypredicts the shooter's location using only the first few gunshots. We thenpoint out future directions that can help improve the system and further reduceunnecessary human labor in the process. All of the components of VERA runthrough a web interface that enables human-in-the-loop verification to ensureaccurate estimations. All relevant source code, including the web interface andmachine learning models, is freely available on Github. We hope thatresearchers and software developers will be inspired to improve and expand thissystem moving forward to better meet the needs of human rights and publicsafety.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multimedia (cs.MM)",
    "Article_Date": "2019/05/26",
    "Article_PDF": "https://arxiv.org/pdf/1905.13313"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.12768",
    "DOI": "arXiv:1905.12768v2",
    "Article_Title": "Using Propensity Scores to Develop and Evaluate Treatment Rules with Observational Data",
    "Article_Abstract": "In this paper, we outline a principled approach to estimate an individualizedtreatment rule that is appropriate for data from observational studies where,in addition to treatment assignment not being independent of individualcharacteristics, some characteristics may affect treatment assignment in thecurrent study but not be available in future clinical settings where theestimated rule would be applied. The estimation framework is quite flexible andaccommodates any prediction method that uses observation weights, where theobservation weights themselves are a ratio of two flexibly estimated propensityscores. We also discuss how to obtain a trustworthy estimate of the rule'spopulation benefit based on simple propensity-score-based estimators of averagetreatment effect. We implement our approach in the R package DevTreatRules andshare the code needed to reproduce our results on GitHub.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/05/29",
    "Article_PDF": "https://arxiv.org/pdf/1905.12768"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.12111",
    "DOI": "arXiv:1905.12111v1",
    "Article_Title": "Analyzing and Supporting Adaptation of Online Code Examples",
    "Article_Abstract": "Developers often resort to online Q&A forums such as Stack Overflow (SO) forfilling their programming needs. Although code examples on those forums aregood starting points, they are often incomplete and inadequate for developers'local program contexts; adaptation of those examples is necessary to integratethem to production code. As a consequence, the process of adapting online codeexamples is done over and over again, by multiple developers independently. Ourwork extensively studies these adaptations and variations, serving as the basisfor a tool that helps integrate these online code examples in a target contextin an interactive manner.  We perform a large-scale empirical study about the nature and extent ofadaptations and variations of SO snippets. We construct a comprehensive datasetlinking SO posts to GitHub counterparts based on clone detection, time stampanalysis, and explicit URL references. We then qualitatively inspect 400 SOexamples and their GitHub counterparts and develop a taxonomy of 24 adaptationtypes. Using this taxonomy, we build an automated adaptation analysis techniqueon top of GumTree to classify the entire dataset into these types. We build aChrome extension called ExampleStack that automatically lifts anadaptation-aware template from each SO example and its GitHub counterparts toidentify hot spots where most changes happen. A user study with sixteenprogrammers shows that seeing the commonalities and variations in similarGitHub counterparts increases their confidence about the given SO example, andhelps them grasp a more comprehensive view about how to reuse the exampledifferently and avoid common pitfalls.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/28",
    "Article_PDF": "https://arxiv.org/pdf/1905.12111"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.11830",
    "DOI": "arXiv:1905.11830v2",
    "Article_Title": "A Graph Theoretic Additive Approximation of Optimal Transport",
    "Article_Abstract": "Transportation cost is an attractive similarity measure between probabilitydistributions due to its many useful theoretical properties. However, solvingoptimal transport exactly can be prohibitively expensive. Therefore, there hasbeen significant effort towards the design of scalable approximationalgorithms. Previous combinatorial results [Sharathkumar, Agarwal STOC '12,Agarwal, Sharathkumar STOC '14] have focused primarily on the design ofstrongly polynomial multiplicative approximation algorithms. There has alsobeen an effort to design approximate solutions with additive errors [CuturiNIPS '13, Altschuler et. al NIPS '17, Dvurechensky et al., ICML '18, Quanrud,SOSA '19] within a time bound that is linear in the size of the cost matrix andpolynomial in $C/\u03b4$; here $C$ is the largest value in the cost matrix and$\u03b4$ is the additive error. We present an adaptation of the classical graphalgorithm of Gabow and Tarjan and provide a novel analysis of this algorithmthat bounds its execution time by $O(\\frac{n^2 C}\u03b4+\\frac{nC^2}{\u03b4^2})$. Our algorithm is extremely simple and executes, for anarbitrarily small constant $\\varepsilon$, only $\\lfloor\\frac{2C}{(1-\\varepsilon)\u03b4}\\rfloor + 1$ iterations, where each iterationconsists only of a Dijkstra search followed by a depth-first search. We alsoprovide empirical results that suggest our algorithm significantly outperformsexisting approaches in execution time.",
    "Article_Subject": "Machine Learning (cs.LG); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/28",
    "Article_PDF": "https://arxiv.org/pdf/1905.11830"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.11681",
    "DOI": "arXiv:1905.11681v2",
    "Article_Title": "Validating the Validation: Reanalyzing a large-scale comparison of Deep Learning and Machine Learning models for bioactivity prediction",
    "Article_Abstract": "Machine learning methods may have the potential to significantly acceleratedrug discovery. However, the increasing rate of new methodological approachesbeing published in the literature raises the fundamental question of how modelsshould be benchmarked and validated. We reanalyze the data generated by arecently published large-scale comparison of machine learning models forbioactivity prediction and arrive at a somewhat different conclusion. We showthat the performance of support vector machines is competitive with that ofdeep learning methods. Additionally, using a series of numerical experiments,we question the relevance of area under the receiver operating characteristiccurve as a metric in virtual screening, and instead suggest that area under theprecision-recall curve should be used in conjunction with the receiveroperating characteristic. Our numerical experiments also highlight challengesin estimating the uncertainty in model performance via scaffold-split nestedcross validation.",
    "Article_Subject": "Machine Learning (cs.LG); Chemical Physics (physics.chem-ph); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/28",
    "Article_PDF": "https://arxiv.org/pdf/1905.11681"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.11127",
    "DOI": "arXiv:1905.11127v1",
    "Article_Title": "DockerizeMe: Automatic Inference of Environment Dependencies for Python Code Snippets",
    "Article_Abstract": "Platforms like Stack Overflow and GitHub's gist system promote the sharing ofideas and programming techniques via the distribution of code snippets designedto illustrate particular tasks. Python, a popular and fast-growing programminglanguage, sees heavy use on both sites, with nearly one million questions askedon Stack Overflow and 400 thousand public gists on GitHub. Unfortunately,around 75% of the Python example code shared through these sites cannot bedirectly executed. When run in a clean environment, over 50% of public Pythongists fail due to an import error for a missing library.  We present DockerizeMe, a technique for inferring the dependencies needed toexecute a Python code snippet without import error. DockerizeMe starts withoffline knowledge acquisition of the resources and dependencies for popularPython packages from the Python Package Index (PyPI). It then builds Dockerspecifications using a graph-based inference procedure. Our inference procedureresolves import errors in 892 out of nearly 3,000 gists from the Gistabledataset for which Gistable's baseline approach could not find and install alldependencies.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/27",
    "Article_PDF": "https://arxiv.org/pdf/1905.11127"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.10536",
    "DOI": "arXiv:1905.10536v1",
    "Article_Title": "DeepRec: An Open-source Toolkit for Deep Learning based Recommendation",
    "Article_Abstract": "Deep learning based recommender systems have been extensively explored inrecent years. However, the large number of models proposed each year poses abig challenge for both researchers and practitioners in reproducing the resultsfor further comparisons. Although a portion of papers provides source code,they adopted different programming languages or different deep learningpackages, which also raises the bar in grasping the ideas. To alleviate thisproblem, we released the open source project: \\textbf{DeepRec}. In thistoolkit, we have implemented a number of deep learning based recommendationalgorithms using Python and the widely used deep learning package - Tensorflow.Three major recommendation scenarios: rating prediction, top-N recommendation(item ranking) and sequential recommendation, were considered. Meanwhile,DeepRec maintains good modularity and extensibility to easily incorporate newmodels into the framework. It is distributed under the terms of the GNU GeneralPublic License. The source code is available at github:\\url{https://github.com/cheungdaven/DeepRec}",
    "Article_Subject": "Information Retrieval (cs.IR); Machine Learning (cs.LG)",
    "Article_Date": "2019/05/25",
    "Article_PDF": "https://arxiv.org/pdf/1905.10536"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.09907",
    "DOI": "arXiv:1905.09907v1",
    "Article_Title": "Multi-level Texture Encoding and Representation (MuLTER) based on Deep Neural Networks",
    "Article_Abstract": "In this paper, we propose a multi-level texture encoding and representationnetwork (MuLTER) for texture-related applications. Based on a multi-levelpooling architecture, the MuLTER network simultaneously leverages low- andhigh-level features to maintain both texture details and spatial information.Such a pooling architecture involves few extra parameters and keeps featuredimensions fixed despite of the changes of image sizes. In comparison withstate-of-the-art texture descriptors, the MuLTER network yields higherrecognition accuracy on typical texture datasets such as MINC-2500 andGTOS-mobile with a discriminative and compact representation. In addition, weanalyze the impact of combining features from different levels, which supportsour claim that the fusion of multi-level features efficiently enhancesrecognition performance. Our source code will be published on GitHub(https://github.com/olivesgatech).",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/05/23",
    "Article_PDF": "https://arxiv.org/pdf/1905.09907"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.09717",
    "DOI": "arXiv:1905.09717v2",
    "Article_Title": "Network Pruning via Transformable Architecture Search",
    "Article_Abstract": "Network pruning reduces the computation costs of an over-parameterizednetwork without performance damage. Prevailing pruning algorithms pre-definethe width and depth of the pruned networks, and then transfer parameters fromthe unpruned network to pruned networks. To break the structure limitation ofthe pruned networks, we propose to apply neural architecture search to searchdirectly for a network with flexible channel and layer sizes. The number of thechannels/layers is learned by minimizing the loss of the pruned networks. Thefeature map of the pruned network is an aggregation of K feature map fragments(generated by K networks of different sizes), which are sampled based on theprobability distribution.The loss can be back-propagated not only to thenetwork weights, but also to the parameterized distribution to explicitly tunethe size of the channels/layers. Specifically, we apply channel-wiseinterpolation to keep the feature map with different channel sizes aligned inthe aggregation procedure. The maximum probability for the size in eachdistribution serves as the width and depth of the pruned network, whoseparameters are learned by knowledge transfer, e.g., knowledge distillation,from the original networks. Experiments on CIFAR-10, CIFAR-100 and ImageNetdemonstrate the effectiveness of our new perspective of network pruningcompared to traditional network pruning algorithms. Various searching andknowledge transfer approaches are conducted to show the effectiveness of thetwo components.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/05/23",
    "Article_PDF": "https://arxiv.org/pdf/1905.09717"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.09263",
    "DOI": "arXiv:1905.09263v4",
    "Article_Title": "FastSpeech: Fast, Robust and Controllable Text to Speech",
    "Article_Abstract": "Neural network based end-to-end text to speech (TTS) has significantlyimproved the quality of synthesized speech. Prominent methods (e.g., Tacotron2) usually first generate mel-spectrogram from text, and then synthesize speechfrom mel-spectrogram using vocoder such as WaveNet. Compared with traditionalconcatenative and statistical parametric approaches, neural network basedend-to-end models suffer from slow inference speed, and the synthesized speechis usually not robust (i.e., some words are skipped or repeated) and lack ofcontrollability (voice speed or prosody control). In this work, we propose anovel feed-forward network based on Transformer to generate mel-spectrogram inparallel for TTS. Specifically, we extract attention alignments from anencoder-decoder based teacher model for phoneme duration prediction, which isused by a length regulator to expand the source phoneme sequence to match thelength of target mel-spectrogram sequence for parallel mel-spectrogramgeneration. Experiments on the LJSpeech dataset show that our parallel modelmatches autoregressive models in terms of speech quality, nearly eliminates theproblem of word skipping and repeating in particularly hard cases, and canadjust voice speed smoothly. Most importantly, compared with autoregressiveTransformer TTS, our model speeds up the mel-spectrogram generation by 270x andthe end-to-end speech synthesis by 38x. Therefore, we call our modelFastSpeech. We will release the code on Github. Synthesized speech samples canbe found in https://speechresearch.github.io/fastspeech/.",
    "Article_Subject": "Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "Article_Date": "2019/05/22",
    "Article_PDF": "https://arxiv.org/pdf/1905.09263"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08880",
    "DOI": "arXiv:1905.08880v1",
    "Article_Title": "A Scalable Hybrid Research Paper Recommender System for Microsoft Academic",
    "Article_Abstract": "We present the design and methodology for the large scale hybrid paperrecommender system used by Microsoft Academic. The system providesrecommendations for approximately 160 million English research papers andpatents. Our approach handles incomplete citation information while alsoalleviating the cold-start problem that often affects other recommendersystems. We use the Microsoft Academic Graph (MAG), titles, and availableabstracts of research papers to build a recommendation list for all documents,thereby combining co-citation and content based approaches. Tuning systemparameters also allows for blending and prioritization of each approach which,in turn, allows us to balance paper novelty versus authority in recommendationresults. We evaluate the generated recommendations via a user study of 40participants, with over 2400 recommendation pairs graded and discuss thequality of the results using P@10 and nDCG scores. We see that there is astrong correlation between participant scores and the similarity rankingsproduced by our system but that additional focus needs to be put towardsimproving recommender precision, particularly for content basedrecommendations. The results of the user survey and associated analysis scriptsare made available via GitHub and the recommendations produced by our systemare available as part of the MAG on Azure to facilitate further research andlight up novel research paper recommendation applications.",
    "Article_Subject": "Digital Libraries (cs.DL); Information Retrieval (cs.IR); Machine Learning (cs.LG)",
    "Article_Date": "2019/05/21",
    "Article_PDF": "https://arxiv.org/pdf/1905.08880"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08667",
    "DOI": "arXiv:1905.08667v1",
    "Article_Title": "Legacy Archive for Microwave Background Data Analysis (LAMBDA): An Overview",
    "Article_Abstract": "This is an overview of the data products and other resources availablethrough NASA's LAMBDA site https://lambda.gsfc.nasa.gov/. An up-to-date versionof this document, along with code tools actively maintained and developed byLAMBDA staff, can be found on the LAMBDA GitHub page athttps://github.com/nasa-lambda/lambda_overview. New data products and otherupdates are announced on LAMBDA's twitter account athttps://twitter.com/NASA_LAMBDA. If you have questions or suggestions relatingto LAMBDA, or are interested in joining a LAMBDA advisory group, please contactus using the form here: https://lambda.gsfc.nasa.gov/contact/contact.cfm.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Article_Date": "2019/05/21",
    "Article_PDF": "https://arxiv.org/pdf/1905.08667"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08628",
    "DOI": "arXiv:1905.08628v1",
    "Article_Title": "Constraining the Parameters of High-Dimensional Models with Active Learning",
    "Article_Abstract": "Constraining the parameters of physical models with $>5-10$ parameters is awidespread problem in fields like particle physics and astronomy. In this paperwe show that this problem can be alleviated by the use of active learning. Weillustrate this with examples from high energy physics, a field wherecomputationally expensive simulations and large parameter spaces are common. Weshow that the active learning techniques query-by-committee andquery-by-dropout-committee allow for the identification of model points ininteresting regions of high-dimensional parameter spaces (e.g. around decisionboundaries). This makes it possible to constrain model parameters moreefficiently than is currently done with the most common sampling algorithms.Code implementing active learning can be found on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Instrumentation and Methods for Astrophysics (astro-ph.IM); High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Theory (hep-th)",
    "Article_Date": "2019/05/19",
    "Article_PDF": "https://arxiv.org/pdf/1905.08628"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08094",
    "DOI": "arXiv:1905.08094v1",
    "Article_Title": "Be Your Own Teacher: Improve the Performance of Convolutional Neural Networks via Self Distillation",
    "Article_Abstract": "Convolutional neural networks have been widely deployed in variousapplication scenarios. In order to extend the applications' boundaries to someaccuracy-crucial domains, researchers have been investigating approaches toboost accuracy through either deeper or wider network structures, which bringswith them the exponential increment of the computational and storage cost,delaying the responding time. In this paper, we propose a general trainingframework named self distillation, which notably enhances the performance(accuracy) of convolutional neural networks through shrinking the size of thenetwork rather than aggrandizing it. Different from traditional knowledgedistillation - a knowledge transformation methodology among networks, whichforces student neural networks to approximate the softmax layer outputs ofpre-trained teacher neural networks, the proposed self distillation frameworkdistills knowledge within network itself. The networks are firstly divided intoseveral sections. Then the knowledge in the deeper portion of the networks issqueezed into the shallow ones. Experiments further prove the generalization ofthe proposed self distillation framework: enhancement of accuracy at averagelevel is 2.65%, varying from 0.61% in ResNeXt as minimum to 4.07% in VGG19 asmaximum. In addition, it can also provide flexibility of depth-wise scalableinference on resource-limited edge devices.Our codes will be released on githubsoon.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/17",
    "Article_PDF": "https://arxiv.org/pdf/1905.08094"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.07650",
    "DOI": "arXiv:1905.07650v1",
    "Article_Title": "SAWNet: A Spatially Aware Deep Neural Network for 3D Point Cloud Processing",
    "Article_Abstract": "Deep neural networks have established themselves as the state-of-the-artmethodology in almost all computer vision tasks to date. But their applicationto processing data lying on non-Euclidean domains is still a very active areaof research. One such area is the analysis of point cloud data which poses achallenge due to its lack of order. Many recent techniques have been proposed,spearheaded by the PointNet architecture. These techniques use either global orlocal information from the point clouds to extract a latent representation forthe points, which is then used for the task at hand(classification/segmentation). In our work, we introduce a neural network layerthat combines both global and local information to produce better embeddings ofthese points. We enhance our architecture with residual connections, to passinformation between the layers, which also makes the network easier to train.We achieve state-of-the-art results on the ModelNet40 dataset with ourarchitecture, and our results are also highly competitive with thestate-of-the-art on the ShapeNet part segmentation dataset and the indoor scenesegmentation dataset. We plan to open source our pre-trained models on githubto encourage the research community to test our networks on their data, orsimply use them for benchmarking purposes.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/05/18",
    "Article_PDF": "https://arxiv.org/pdf/1905.07650"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.06280",
    "DOI": "arXiv:1905.06280v1",
    "Article_Title": "Trustee: Full Privacy Preserving Vickrey Auction on top of Ethereum",
    "Article_Abstract": "The wide deployment of tokens for digital assets on top of Ethereum impliesthe need for powerful trading platforms. Vickrey auctions have been known todetermine the real market price of items as bidders are motivated to submittheir own monetary valuations without leaking their information to thecompetitors. Recent constructions have utilized various cryptographic protocolssuch as ZKP and MPC, however, these approaches either are partiallyprivacy-preserving or require complex computations with several rounds. In thispaper, we overcome these limits by presenting Trustee as a Vickrey auction onEthereum which fully preserves bids' privacy at relatively much lower fees.Trustee consists of three components: a front-end smart contract deployed onEthereum, an Intel SGX enclave, and a relay to redirect messages between them.Initially, the enclave generates an Ethereum account and ECDH key-pair.Subsequently, the relay publishes the account's address and ECDH public key onthe smart contract. As a prerequisite, bidders are encouraged to verify theauthenticity and security of Trustee by using the SGX remote attestationservice. To participate in the auction, bidders utilize the ECDH public key toencrypt their bids and submit them to the smart contract. Once the biddinginterval is closed, the relay retrieves the encrypted bids and feeds them tothe enclave that autonomously generates a signed transaction indicating theauction winner. Finally, the relay submits the transaction to the smartcontract which verifies the transaction's authenticity and the parameters'consistency before accepting the claimed auction winner. As part of ourcontributions, we have made a prototype for Trustee available on Github for thecommunity to review and inspect it. Additionally, we analyze the securityfeatures of Trustee and report on the transactions' gas cost incurred onTrustee smart contract.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/05/15",
    "Article_PDF": "https://arxiv.org/pdf/1905.06280"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.04482",
    "DOI": "arXiv:1905.04482v1",
    "Article_Title": "GE852: A Dataset of 852 Game Engines",
    "Article_Abstract": "Game engines provide a platform for developers to build games with aninterface tailored to handle the complexity during game development. To reduceeffort and improve quality of game development, there is a strong need tounderstand and analyze the quality of game engines and their various aspectssuch as API usability, code quality, code reuse and so on. To the best ourknowledge, we are not aware of any dataset that caters to game engines in theliterature. To this end, we present GE852, a dataset of 852 game enginerepositories mined from GitHub in two languages, namely Java and C++. Thedataset contains metadata of all the mined repositories including commits, pullrequests, issues and so on. We believe that our dataset can lay foundation forempirical investigation in the area of game engines.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/11",
    "Article_PDF": "https://arxiv.org/pdf/1905.04482"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.04303",
    "DOI": "arXiv:1905.04303v1",
    "Article_Title": "Using Convolutional Neural Networks to identify Gravitational Lenses in Astronomical images",
    "Article_Abstract": "The Euclid telescope, due for launch in 2021, will perform an imaging andslitless spectroscopy survey over half the sky, to map baryon wiggles and weaklensing. During the survey Euclid is expected to resolve 100,000 stronggravitational lens systems. This is ideal to find rare lens configurations,provided they can be identified reliably and on a reasonable timescale. Forthis reason we have developed a Convolutional Neural Network (CNN) that can beused to identify images containing lensing systems. CNNs have already been usedfor image and digit classification as well as being used in astronomy forstar-galaxy classification. Here our CNN is trained and tested on Euclid-likeand KiDS-like simulations from the Euclid Strong Lensing Group, successfullyclassifying 77% of lenses, with an area under the ROC curve of up to 0.96. OurCNN also attempts to classify the lenses in COSMOS HST F814W-band images. Afterconvolution to the Euclid resolution, we find we can recover most systems thatare identifiable by eye. The Python code is available on Github.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Astrophysics of Galaxies (astro-ph.GA)",
    "Article_Date": "2019/05/10",
    "Article_PDF": "https://arxiv.org/pdf/1905.04303"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.04294",
    "DOI": "arXiv:1905.04294v1",
    "Article_Title": "Fruitbat: A Python Package for Estimating Redshifts of Fast Radio Bursts",
    "Article_Abstract": "Fruitbat is an open source Python 2/3 package for estimating redshifts,energies and the galactic dispersion measure contributions of fast radio bursts(FRBs). Fruitbat combines various dispersion measure (DM) and redshiftrelations with the YMW16 galactic dispersion measure model into a single easyto use API.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); High Energy Astrophysical Phenomena (astro-ph.HE)",
    "Article_Date": "2019/05/10",
    "Article_PDF": "https://arxiv.org/pdf/1905.04294"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.03593",
    "DOI": "arXiv:1905.03593v3",
    "Article_Title": "A Topological Analysis of Communication Channels for Knowledge Sharing in Contemporary GitHub Projects",
    "Article_Abstract": "With over 28 million developers, success of the GitHub collaborative platformis highlighted through an abundance of communication channels amongcontemporary software projects. Knowledge is broken into two forms and itssharing (through communication channels) can be described as externalization orcombination by the SECI model. Such platforms have revolutionized the waydevelopers work, introducing new channels to share knowledge in the form ofpull requests, issues and wikis. It is unclear how these channels capture andshare knowledge. In this research, our goal is to analyze these communicationchannels in GitHub. First, using the SECI model, we are able to map howknowledge is shared through the communication channels. Then in a large-scaletopology analysis of seven library package projects (i.e., involving over 70thousand projects), we extracted insights of the different communicationchannels within GitHub. Using two research questions, we explored the evolutionof the channels and adoption of channels by both popular and unpopular librarypackage projects. Results show that (i) contemporary GitHub Projects tend toadopt multiple communication channels, (ii) communication channels change overtime and (iii) communication channels are used to both capture new knowledge(i.e., externalization) and updating existing knowledge (i.e., combination).",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/09",
    "Article_PDF": "https://arxiv.org/pdf/1905.03593"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.02050",
    "DOI": "arXiv:1905.02050v1",
    "Article_Title": "Analyzing Code Comments to Boost Program Comprehension",
    "Article_Abstract": "We are trying to find source code comments that help programmers understand anontrivial part of source code. One of such examples would be explaining toassign a zero as a way to \"clear\" a buffer. Such comments are invaluable toprogrammers and identifying them correctly would be of great help. Toward thisgoal, we developed a method to discover explanatory code comments in a sourcecode. We first propose eleven distinct categories of code comments. We thendeveloped a decision-tree based classifier that can identify explanatorycomments with 60% precision and 80% recall. We analyzed 2,000 GitHub projectsthat are written in two languages: Java and Python. This task is novel in thatit focuses on a microscopic comment (\"local comment\") within a method orfunction, in contrast to the prior efforts that focused on API- or method-levelcomments. We also investigated how different category of comments is used indifferent projects. Our key finding is that there are two dominant types ofcomments: preconditional and postconditional. Our findings also suggest thatmany English code comments have a certain grammatical structure that areconsistent across different projects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/06",
    "Article_PDF": "https://arxiv.org/pdf/1905.02050"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.02005",
    "DOI": "arXiv:1905.02005v2",
    "Article_Title": "Deep Ordinal Reinforcement Learning",
    "Article_Abstract": "Reinforcement learning usually makes use of numerical rewards, which havenice properties but also come with drawbacks and difficulties. Using rewards onan ordinal scale (ordinal rewards) is an alternative to numerical rewards thathas received more attention in recent years. In this paper, a general approachto adapting reinforcement learning problems to the use of ordinal rewards ispresented and motivated. We show how to convert common reinforcement learningalgorithms to an ordinal variation by the example of Q-learning and introduceOrdinal Deep Q-Networks, which adapt deep reinforcement learning to ordinalrewards. Additionally, we run evaluations on problems provided by the OpenAIGym framework, showing that our ordinal variants exhibit a performance that iscomparable to the numerical variations for a number of problems. We also givefirst evidence that our ordinal variant is able to produce better results forproblems with less engineered and simpler-to-design reward signals.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/06",
    "Article_PDF": "https://arxiv.org/pdf/1905.02005"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.01833",
    "DOI": "arXiv:1905.01833v3",
    "Article_Title": "Characterizing and Detecting CUDA Program Bugs",
    "Article_Abstract": "While CUDA has become a major parallel computing platform and programmingmodel for general-purpose GPU computing, CUDA-induced bug patterns have not yetbeen well explored. In this paper, we conduct the first empirical study toreveal important categories of CUDA program bug patterns based on 319 bugsidentified within 5 popular CUDA projects in GitHub. Our findings demonstratethat CUDA-specific characteristics may cause program bugs such assynchronization bugs that are rather difficult to detect. To efficiently detectsuch synchronization bugs, we establish the first lightweight general CUDA bugdetection framework, namely Simulee, to simulate CUDA program execution byinterpreting the corresponding llvm bytecode and collecting the memory-accessinformation to automatically detect CUDA synchronization bugs. To evaluate theeffectiveness and efficiency of Simulee, we conduct a set of experiments andthe experimental results suggest that Simulee can detect 20 out of the 27studied synchronization bugs and successfully detects 26 previously unknownsynchronization bugs, 10 of which have been confirmed by the developers.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/06",
    "Article_PDF": "https://arxiv.org/pdf/1905.01833"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.00976",
    "DOI": "arXiv:1905.00976v2",
    "Article_Title": "Collaborative Evolutionary Reinforcement Learning",
    "Article_Abstract": "Deep reinforcement learning algorithms have been successfully applied to arange of challenging control tasks. However, these methods typically strugglewith achieving effective exploration and are extremely sensitive to the choiceof hyperparameters. One reason is that most approaches use a noisy version oftheir operating policy to explore - thereby limiting the range of exploration.In this paper, we introduce Collaborative Evolutionary Reinforcement Learning(CERL), a scalable framework that comprises a portfolio of policies thatsimultaneously explore and exploit diverse regions of the solution space. Acollection of learners - typically proven algorithms like TD3 - optimize overvarying time-horizons leading to this diverse portfolio. All learnerscontribute to and use a shared replay buffer to achieve greater sampleefficiency. Computational resources are dynamically distributed to favor thebest learners as a form of online algorithm selection. Neuroevolution bindsthis entire process to generate a single emergent learner that exceeds thecapabilities of any individual learner. Experiments in a range of continuouscontrol benchmarks demonstrate that the emergent learner significantlyoutperforms its composite learners while remaining overall moresample-efficient - notably solving the Mujoco Humanoid benchmark where all ofits composite learners (TD3) fail entirely in isolation.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/02",
    "Article_PDF": "https://arxiv.org/pdf/1905.00976"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.00221",
    "DOI": "arXiv:1905.00221v1",
    "Article_Title": "Concerns about the reliability of publicly available SNe Ia data",
    "Article_Abstract": "I highlight several concerns regarding the consistency of Type Ia supernovadata in the publicly available Pantheon and JLA compilations. The measuredheliocentric redshifts (zhel) of $\\sim$150 SNe Ia as reported in the Pantheoncatalogue are significantly discrepant from those in JLA - with 58 havingdifferences amounting to between 5 and 137 times the quoted measurementuncertainty. The discrepancy seems to have been introduced in the process ofrectifying a previously reported issue. The Pantheon catalogue until veryrecently had the redshifts of all SNe Ia up to z $\\sim$ 0.3 modified under theguise of 'peculiar velocity corrections' - although there is no information onpeculiar velocities at such high redshifts. While this has reportedly beenrectified on Github by removing peculiar velocity corrections for z > 0.08, theimpact of this on the published cosmological analysis of the Pantheon catalogueis not stated. In JLA, the effect of these 'corrections' is to significantlybias the inferred value of $\u03a9_\u039b$ towards higher values, while theequivalent effect on Pantheon cannot be ascertained due to the unavailabilityof the individual components of the covariance matrix in the public domain. Iprovide Jupyter notebooks and URLs in order to allow the reader to ascertainthe veracity of these assertions.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Article_Date": "2019/05/01",
    "Article_PDF": "https://arxiv.org/pdf/1905.00221"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.12903",
    "DOI": "arXiv:1904.12903v1",
    "Article_Title": "Modified Gravity Away from a $\\Lambda$CDM Background",
    "Article_Abstract": "Within the effective field theory approach to cosmic acceleration, thebackground expansion can be specified separately from the gravitationalmodifications. We explore the impact of modified gravity in a backgrounddifferent from a cosmological constant plus cold dark matter ($\u039b$CDM) onthe stability and cosmological observables, including covariance betweengravity and expansion parameters. In No Slip Gravity the more generalbackground allows more gravitational freedom, including both positive andnegative Planck mass running. We examine the effects on cosmic structuregrowth, as well as showing that a viable positive integrated Sachs-Wolfe effectcrosscorrelation easily arises from this modified gravity theory. Using currentdata we constrain parameters with a Monte Carlo analysis, finding a maximumrunning $|\u03b1_M|\\lesssim 0.03$. We provide the modified {\\tt hi\\_class} codepublicly on GitHub, now enabling computation and inclusion of the redshiftspace distortion observable $f\u03c3_8$ as well as the No Slip Gravitymodifications.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); General Relativity and Quantum Cosmology (gr-qc)",
    "Article_Date": "2019/04/29",
    "Article_PDF": "https://arxiv.org/pdf/1904.12903"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.11603",
    "DOI": "arXiv:1904.11603v1",
    "Article_Title": "Bayesian Factor Analysis for Inference on Interactions",
    "Article_Abstract": "This article is motivated by the problem of inference on interactions amongchemical exposures impacting human health outcomes. Chemicals often co-occur inthe environment or in synthetic mixtures and as a result exposure levels can behighly correlated. We propose a latent factor joint model, which includesshared factors in both the predictor and response components while assumingconditional independence. By including a quadratic regression in the latentvariables in the response component, we induce flexible dimension reduction incharacterizing main effects and interactions. We propose a Bayesian approach toinference under this Factor analysis for INteractions (FIN) framework. Throughappropriate modifications of the factor modeling structure, FIN can accommodatehigher order interactions and multivariate outcomes. We provide theory onposterior consistency and the impact of misspecifying the number of factors. Weevaluate the performance using a simulation study and data from the NationalHealth and Nutrition Examination Survey (NHANES). Code is available on GitHub.",
    "Article_Subject": "Methodology (stat.ME); Applications (stat.AP)",
    "Article_Date": "2019/04/25",
    "Article_PDF": "https://arxiv.org/pdf/1904.11603"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.11164",
    "DOI": "arXiv:1904.11164v1",
    "Article_Title": "PHANTOM: Curating GitHub for engineered software projects using time-series clustering",
    "Article_Abstract": "Context: Within the field of Mining Software Repositories, there are numerousmethods employed to filter datasets in order to avoid analysing low-qualityprojects. Unfortunately, the existing filtering methods have not kept up withthe growth of existing data sources, such as GitHub, and researchers often relyon quick and dirty techniques to curate datasets.  Objective: The objective of this study is to develop a method capable offiltering large quantities of software projects in a time-efficient way.  Method: This study follows the Design Science Research (DSR) methodology. Theproposed method, PHANTOM, extracts five measures from Git logs. Each measure istransformed into a time-series, which is represented as a feature vector forclustering using the k-means algorithm.  Results: Using the ground truth from a previous study, PHANTOM was shown tobe able to rediscover the ground truth with up to 0.87 Precision or 0.94Recall, and be able to identify \"well-engineered\" projects with up to 0.87Precision and 0.94 Recall on the validation dataset. PHANTOM downloaded andprocessed the metadata of 1,786,601 GitHub repositories in 21.5 days, which isover 33\\% faster than a similar study, which used a computer cluster of 200nodes.  Conclusions: It is possible to use an unsupervised approach to identifywell-engineering projects. PHANTOM was shown to be competitive compared to theexisting supervised approaches while reducing the hardware requirements by twoorders of magnitude.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/25",
    "Article_PDF": "https://arxiv.org/pdf/1904.11164"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10581",
    "DOI": "arXiv:1904.10581v2",
    "Article_Title": "Quantifying Correlated Truncation Errors in Effective Field Theory",
    "Article_Abstract": "Effective field theories (EFTs) organize the description of complex systemsinto an infinite sequence of decreasing importance. Predictions are made with afinite number of terms, which induces a truncation error that is often leftunquantified. We formalize the notion of EFT convergence and propose a Bayesiantruncation error model for predictions that are correlated across theindependent variables, e.g., energy or scattering angle. Central to ourapproach are Gaussian processes that encode both the naturalness andcorrelation structure of EFT coefficients. Our use of Gaussian processespermits efficient and accurate assessment of credible intervals, allows EFTfits to easily include correlated theory errors, and provides analyticposteriors for physical EFT-related quantities such as the expansion parameter.We demonstrate that model-checking diagnostics---applied to the case ofmultiple curves---are powerful tools for EFT validation. As an example, weassess a set of nucleon-nucleon scattering observables in chiral EFT. In aneffort to be self contained, appendices include thorough derivations of ourstatistical results. Our methods are packaged in Python code, called gsum, thatis available for download on GitHub.",
    "Article_Subject": "Nuclear Theory (nucl-th); High Energy Physics - Phenomenology (hep-ph); Nuclear Experiment (nucl-ex); Data Analysis, Statistics and Probability (physics.data-an)",
    "Article_Date": "2019/04/24",
    "Article_PDF": "https://arxiv.org/pdf/1904.10581"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10464",
    "DOI": "arXiv:1904.10464v1",
    "Article_Title": "$\\mathtt{bimEX}$: A Mathematica package for exact computations in 3$+$1 bimetric relativity",
    "Article_Abstract": "We present $\\mathtt{bimEX}$, a Mathematica package for exact computations in3$+$1 bimetric relativity. It is based on the $\\mathtt{xAct}$ bundle, which canhandle computations involving both abstract tensors and their components. Inthis communication, we refer to the latter case as concrete computations. Thepackage consists of two main parts. The first part involves the abstracttensors, and focuses on how to deal with multiple metrics in $\\mathtt{xAct}$.The second part takes an ansatz for the primary variables in a chart as theinput, and returns the covariant BSSN bimetric equations in components in thatchart. Several functions are implemented to make this process as fast anduser-friendly as possible. The package has been used and tested extensively inspherical symmetry and was the workhorse in obtaining the bimetric covariantBSSN equations and reproducing the bimetric 3$+$1 equations in the sphericalpolar chart.",
    "Article_Subject": "Symbolic Computation (cs.SC); Cosmology and Nongalactic Astrophysics (astro-ph.CO); Mathematical Software (cs.MS); General Relativity and Quantum Cosmology (gr-qc)",
    "Article_Date": "2019/04/23",
    "Article_PDF": "https://arxiv.org/pdf/1904.10464"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10255",
    "DOI": "arXiv:1904.10255v1",
    "Article_Title": "End-to-end Sleep Staging with Raw Single Channel EEG using Deep Residual ConvNets",
    "Article_Abstract": "Humans approximately spend a third of their life sleeping, which makesmonitoring sleep an integral part of well-being. In this paper, a 34-layer deepresidual ConvNet architecture for end-to-end sleep staging is proposed. Thenetwork takes raw single channel electroencephalogram (Fpz-Cz) signal as inputand yields hypnogram annotations for each 30s segments as output. Experimentsare carried out for two different scoring standards (5 and 6 stageclassification) on the expanded PhysioNet Sleep-EDF dataset, which containsmulti-source data from hospital and household polysomnography setups. Theperformance of the proposed network is compared with that of thestate-of-the-art algorithms in patient independent validation tasks. Theexperimental results demonstrate the superiority of the proposed networkcompared to the best existing method, providing a relative improvement inepoch-wise average accuracy of 6.8% and 6.3% on the household data andmulti-source data, respectively. Codes are made publicly available on Github.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/23",
    "Article_PDF": "https://arxiv.org/pdf/1904.10255"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10247",
    "DOI": "arXiv:1904.10247v3",
    "Article_Title": "Free-form Video Inpainting with 3D Gated Convolution and Temporal PatchGAN",
    "Article_Abstract": "Free-form video inpainting is a very challenging task that could be widelyused for video editing such as text removal. Existing patch-based methods couldnot handle non-repetitive structures such as faces, while directly applyingimage-based inpainting models to videos will result in temporal inconsistency(see http://bit.ly/2Fu1n6b ). In this paper, we introduce a deep learn-ingbased free-form video inpainting model, with proposed 3D gated convolutions totackle the uncertainty of free-form masks and a novel Temporal PatchGAN loss toenhance temporal consistency. In addition, we collect videos and design afree-form mask generation algorithm to build the free-form video inpainting(FVI) dataset for training and evaluation of video inpainting models. Wedemonstrate the benefits of these components and experiments on both theFaceForensics and our FVI dataset suggest that our method is superior toexisting ones. Related source code, full-resolution result videos and the FVIdataset could be found on Githubhttps://github.com/amjltc295/Free-Form-Video-Inpainting .",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/04/23",
    "Article_PDF": "https://arxiv.org/pdf/1904.10247"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.09954",
    "DOI": "arXiv:1904.09954v1",
    "Article_Title": "Why Software Projects need Heroes (Lessons Learned from 1100+ Projects)",
    "Article_Abstract": "A \"hero\" project is one where 80% or more of the contributions are made bythe 20% of the developers. In the literature, such projects are deprecatedsince they might cause bottlenecks in development and communication. However,there is little empirical evidence on this matter. Further, recent studies showthat such hero projects are very prevalent. Accordingly, this paper exploresthe effect of having heroes in project, from a code quality perspective. Weidentify the heroes developer communities in 1100+ open source GitHub projects.Based on the analysis, we find that (a) hero projects are majorly all projects;and (b) the commits from \"hero developers\" (who contribute most to the code)result in far fewer bugs than other developers. That is, contrary to theliterature, heroes are standard and very useful part of modern open sourceprojects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/22",
    "Article_PDF": "https://arxiv.org/pdf/1904.09954"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.09416",
    "DOI": "arXiv:1904.09416v2",
    "Article_Title": "An Analysis of 35+ Million Jobs of Travis CI",
    "Article_Abstract": "Travis CI handles automatically thousands of builds every day to, amongstother things, provide valuable feedback to thousands of open-source developers.In this paper, we investigate Travis CI to firstly understand who is using it,and when they start to use it. Secondly, we investigate how the developers useTravis CI and finally, how frequently the developers change the Travis CIconfigurations. We observed during our analysis that the main users of TravisCI are corporate users such as Microsoft. And the programming languages used inTravis CI by those users do not follow the same popularity trend than onGitHub, for example, Python is the most popular language on Travis CI, but itis only the third one on GitHub. We also observe that Travis CI is set up onaverage seven days after the creation of the repository and the jobs are stillmainly used (60%) to run tests. And finally, we observe that 7.34% of thecommits modify the Travis CI configuration. We share the biggest benchmark ofTravis CI jobs (to our knowledge): it contains 35,793,144 jobs from 272,917different GitHub projects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/20",
    "Article_PDF": "https://arxiv.org/pdf/1904.09416"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.09355",
    "DOI": "arXiv:1904.09355v2",
    "Article_Title": "Exoplanet Reflected Light Spectroscopy with PICASO",
    "Article_Abstract": "Here we present the first open-source radiative transfer model for computingthe reflected light of exoplanets at any phase geometry, called PICASO:Planetary Intensity Code for Atmospheric Scattering Observations. This code,written in Python, has heritage from a decades old, well-known Fortran modelused for several studies of planetary objects within the Solar System andbeyond. We have adopted it to include several methodologies for computing bothdirect and diffuse scattering phase functions, and have added several updatesincluding the ability to compute Raman scattering spectral features. Here webenchmark PICASO against two independent codes and discuss the degree to whichthe model is sensitive to a user's specification for various phase functions.Then, we conduct a full information content study of the model across a wideparameter space in temperature, cloud profile, SNR and resolving power.",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP)",
    "Article_Date": "2019/04/19",
    "Article_PDF": "https://arxiv.org/pdf/1904.09355"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.08315",
    "DOI": "arXiv:1904.08315v1",
    "Article_Title": "Multi-Level Mesa",
    "Article_Abstract": "Multi-level Mesa is an extension to support the Python based Agents BasedModel (ABM) library Mesa. Multi-level Mesa provides ABM infrastructure to allowfor the inclusion of complex networks, which have modules (groups) andhierarchies (layers) of agents. This approach allows for users to define andsimulate multi-layered adaptions of complex networks. This study reviews othermulti-level libraries currently in the field, describes the main functions andclasses of the Multi-level Mesa, and describes its implementation and impact innumerous varieties using the seminal ABM - Sugarscape. Multi-level Mesa andSugarscape examples are available on GitHub athttps://github.com/tpike3/multilevel_mesa andhttps://github.com/tpike3/SugarScape.",
    "Article_Subject": "Multiagent Systems (cs.MA)",
    "Article_Date": "2019/03/22",
    "Article_PDF": "https://arxiv.org/pdf/1904.08315"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07577",
    "DOI": "arXiv:1904.07577v1",
    "Article_Title": "ASD-DiagNet: A hybrid learning approach for detection of Autism Spectrum Disorder using fMRI data",
    "Article_Abstract": "Mental disorders such as Autism Spectrum Disorders (ASD) are heterogeneousdisorders that are notoriously difficult to diagnose, especially in children.The current psychiatric diagnostic process is based purely on the behaviouralobservation of symptomology (DSM-5/ICD-10) and may be prone to over-prescribingof drugs due to misdiagnosis. In order to move the field towards morequantitative fashion, we need advanced and scalable machine learninginfrastructure that will allow us to identify reliable biomarkers of mentalhealth disorders. In this paper, we propose a framework called ASD-DiagNet forclassifying subjects with ASD from healthy subjects by using only fMRI data. Wedesigned and implemented a joint learning procedure using an autoencoder and asingle layer perceptron which results in improved quality of extracted featuresand optimized parameters for the model. Further, we designed and implemented adata augmentation strategy, based on linear interpolation on available featurevectors, that allows us to produce synthetic datasets needed for training ofmachine learning models. The proposed approach is evaluated on a public datasetprovided by Autism Brain Imaging Data Exchange including 1035 subjects comingfrom 17 different brain imaging centers. Our machine learning model outperformsother state of the art methods from 13 imaging centers with increase inclassification accuracy up to 20% with maximum accuracy of 80%. The machinelearning technique presented in this paper, in addition to yielding betterquality, gives enormous advantages in terms of execution time (40 minutes vs. 6hours on other methods). The implemented code is available as GPL license onGitHub portal of our lab (https://github.com/pcdslab/ASD-DiagNet).",
    "Article_Subject": "Machine Learning (cs.LG); Image and Video Processing (eess.IV); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/16",
    "Article_PDF": "https://arxiv.org/pdf/1904.07577"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07387",
    "DOI": "arXiv:1904.07387v2",
    "Article_Title": "Predicting Fluid Intelligence of Children using T1-weighted MR Images and a StackNet",
    "Article_Abstract": "In this work, we utilize T1-weighted MR images and StackNet to predict fluidintelligence in adolescents. Our framework includes feature extraction, featurenormalization, feature denoising, feature selection, training a StackNet, andpredicting fluid intelligence. The extracted feature is the distribution ofdifferent brain tissues in different brain parcellation regions. The proposedStackNet consists of three layers and 11 models. Each layer uses thepredictions from all previous layers including the input layer. The proposedStackNet is tested on a public benchmark Adolescent Brain Cognitive DevelopmentNeurocognitive Prediction Challenge 2019 and achieves a mean squared error of82.42 on the combined training and validation set with 10-foldcross-validation. In addition, the proposed StackNet also achieves a meansquared error of 94.25 on the testing data. The source code is available onGitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/16",
    "Article_PDF": "https://arxiv.org/pdf/1904.07387"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07197",
    "DOI": "arXiv:1904.07197v1",
    "Article_Title": "Identification of Parameters for Large-scale Models in Systems Biology",
    "Article_Abstract": "Inverse problem for the identification of the parameters for large-scalesystems of nonlinear ordinary differential equations (ODEs) arising in systemsbiology is analyzed. In a recent paper in \\textit{Mathematical Biosciences,305(2018), 133-145}, the authors implemented the numerical method suggested byone of the authors in \\textit{J. Optim. Theory Appl., 85, 3(1995), 509-526} foridentification of parameters in moderate scale models of systems biology. Thismethod combines Pontryagin optimization or Bellman's quasilinearization withsensitivity analysis and Tikhonov regularization. We suggest modification ofthe method by embedding a method of staggered corrector for sensitivityanalysis and by enhancing multi-objective optimization which enablesapplication of the method to large-scale models with practicallynon-identifiable parameters based on multiple data sets, possibly with partialand noisy measurements. We apply the modified method to a benchmark model of athree-step pathway modeled by 8 nonlinear ODEs with 36 unknown parameters andtwo control input parameters. The numerical results demonstrate geometricconvergence with a minimum of five data sets and with minimum measurements perdata set. Software package \\textit{qlopt} is developed and posted in GitHub.MATLAB package AMIGO2 is used to demonstrate advantage of \\textit{qlopt} overmost popular methods/software such as \\textit{lsqnonlin}, \\textit{fmincon} and\\textit{nl2sol}.",
    "Article_Subject": "Quantitative Methods (q-bio.QM); Numerical Analysis (math.NA)",
    "Article_Date": "2019/04/15",
    "Article_PDF": "https://arxiv.org/pdf/1904.07197"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07088",
    "DOI": "arXiv:1904.07088v1",
    "Article_Title": "P4-MACsec: Dynamic Topology Monitoring and Data Layer Protection with MACsec in P4-SDN",
    "Article_Abstract": "We propose P4-MACsec to protect network links between P4 switches throughautomated deployment of MACsec, a widespread IEEE standard for securing Layer 2infrastructures. It is supported by switches and routers from majormanufacturers and has only little performance limitations compared to VPNtechnologies such as IPsec. P4-MACsec introduces a data plane implementation ofMACsec including AES-GCM encryption and decryption directly on P4 switches.P4-MACsec features a two-tier control plane structure where local controllersrunning on the P4 switches interact with a central controller. We propose anovel secure link discovery mechanism that leverages protected LLDP frames andthe two-tier control plane structure for secure and efficient management of aglobal link map. Automated deployment of MACsec creates secure channel,generates keying material, and configures the P4 switches for each detectedlink between two P4 switches. It detects link changes and performs rekeying toprovide a secure, configuration-free operation of MACsec. In this paper, wereview the technological background of P4-MACsec and explain its architecture.To demonstrate the feasibility of P4-MACsec, we implement it on the BMv2 P4software switch and validate the prototype through experiments. We evaluate itsperformance through experiments that focus on TCP throughput and round-triptime. We publish the prototype and experiment setups on Github.",
    "Article_Subject": "Networking and Internet Architecture (cs.NI)",
    "Article_Date": "2019/04/15",
    "Article_PDF": "https://arxiv.org/pdf/1904.07088"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.05257",
    "DOI": "arXiv:1904.05257v1",
    "Article_Title": "Instance Segmentation of Biological Images Using Harmonic Embeddings",
    "Article_Abstract": "We present a new instance segmentation approach tailored to biologicalimages, where instances may correspond to individual cells, organisms or plantparts. Unlike instance segmentation for user photographs or road scenes, inbiological data object instances may be particularly densely packed, theappearance variation may be particularly low, the processing power may berestricted, while, on the other hand, the variability of sizes of individualinstances may be limited. These peculiarities are successfully addressed andexploited by the proposed approach.  Our approach describes each object instance using an expectation of a limitednumber of sine waves with frequencies and phases adjusted to particular objectsizes and densities. At train time, a fully-convolutional network is learned topredict the object embeddings at each pixel using a simple pixelwise regressionloss, while at test time the instances are recovered using clustering in theembeddings space. In the experiments, we show that our approach outperformsprevious embedding-based instance segmentation approaches on a number ofbiological datasets, achieving state-of-the-art on a popular CVPPP benchmark.Notably, this excellent performance is combined with computational efficiencythat is needed for deployment to domain specialists.  The source code is publicly available at Github:https://github.com/kulikovv/harmonic",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/04/10",
    "Article_PDF": "https://arxiv.org/pdf/1904.05257"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.03801",
    "DOI": "arXiv:1904.03801v1",
    "Article_Title": "pdbmine: A Node.js API for the RCSB Protein Data Bank (PDB)",
    "Article_Abstract": "Summary: The advent of Web-based tools that assist in the analysis andvisualization of macromolecules require application programming interfaces(APIs) designed for modern web frameworks. To this end, we have developed aNode.js module pdbmine that allows any user to generate faster data-requestqueries to the RCSB Protein Data Bank (PDB). This JavaScript API acts as alayer over the XML-based RCSB PDB RESTful API. The relatively simple nature ofthe function calls within this module allows the user to easily implement andintegrate pdbmine into larger Node.js web applications.  Availability: This module can be installed via the Node Package Manager (NPM)at https://www.npmjs.com/package/pdbmine/, and is hosted on GitHub under theopen-source MIT license at https://github.com/nnj1/pdbmine/. Relevantdocumentation is detailed at https://nnj1.github.io/pdbmine/",
    "Article_Subject": "Genomics (q-bio.GN)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.03801"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.02724",
    "DOI": "arXiv:1904.02724v1",
    "Article_Title": "Bounties in Open Source Development on GitHub: A Case Study of Bountysource Bounties",
    "Article_Abstract": "Due to the voluntary nature of open source software, it can be hard to find adeveloper to work on a particular task. For example, some issue reports may betoo cumbersome and unexciting for someone to volunteer to do them, yet theseissue reports may be of high priority to the success of a project. To providean incentive for implementing such issue reports, one can propose a monetaryreward, i.e., a bounty, to the developer who completes that particular task. Inthis paper, we study bounties in open source projects on GitHub to betterunderstand how bounties can be leveraged to evolve such projects in terms ofaddressing issue reports. We investigated 5,445 bounties for GitHub projects.These bounties were proposed through the Bountysource platform with a totalbounty value of $406,425. We find that 1) in general, the timing of proposingbounties and the bounty-usage frequency are the most important factors thatimpact the likelihood of an issue being addressed. More specifically, issuereports are more likely to be addressed if they are for projects in whichbounties are used more frequently and if they are proposed earlier. 2) Thebounty value that an issue report has is the most important factor that impactsthe issue-addressing likelihood in the projects in which no bounties were usedbefore. Backers in such projects proposed higher bounty values to get issuesaddressed. 3) There is a risk of wasting money for backers who invest money onlong-standing issue reports.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/04",
    "Article_PDF": "https://arxiv.org/pdf/1904.02724"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.02414",
    "DOI": "arXiv:1904.02414v1",
    "Article_Title": "\"Won't We Fix this Issue?\" Qualitative Characterization and Automated Identification of Wontfix Issues on GitHub",
    "Article_Abstract": "Addressing users requests in the form of bug reports and Github issuesrepresents a crucial task of any successful software project. However,user-submitted issue reports tend to widely differ in their quality, anddevelopers spend a considerable amount of time handling these reports.Moreover, an inefficient prioritization of requested changes could have anegative impact on the developers' workloads. By collecting a dataset of around6,000 issues from the history of 323 GitHub projects, we observe thatdevelopers spend a long time (i.e., about five months, on average) beforelabeling an issue as a wontfix. For this reason, in this paper, we empiricallyinvestigate the nature of wontfix issues, by manually analyzing a sample of 800issues of this kind, extracted from heterogeneous projects. We explore thecommon reasons behind a \"wontfix decision\", the main characteristics of wontfixissues and the potential factors that could be connected with the time to closethem. Furthermore, we experiment approaches for just-in-time prediction ofwontfix issues using machine learning techniques to analyze the titles anddescriptions of reported issues. Our investigation shed some light on thewontfix issues' characteristics, as well as the potential factors that mayaffect the time required to make a \"wontfix decision\". Our results alsodemonstrate that it is possible to predict whether an issue will be closed as awontfix with average values of precision, recall, and F-measure close to 99%,confirming the practical usefulness of the proposed approach for improving theissue management practices on GitHub.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/04",
    "Article_PDF": "https://arxiv.org/pdf/1904.02414"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.01754",
    "DOI": "arXiv:1904.01754v1",
    "Article_Title": "Styler: Learning Formatting Conventions to Repair Checkstyle Errors",
    "Article_Abstract": "Formatting coding conventions play an important role on code readability. Inthis paper, we present Styler, an automatic repair tool dedicated to fixformatting-related errors raised by Checkstyle, a highly configurable formatchecker for Java. To fix formatting errors in a given project, Styler learnsfixes based on the Checkstyle ruleset defined in the project and predictsrepairs for the current errors using machine learning. In an empiricalevaluation, we found that Styler repaired 24% of 497 real Checkstyle errorsmined from five GitHub projects. Moreover, in a comparison of Styler with thestate-of-the-art machine learning code formatters Naturalize and CodeBuff, wefound that Styler is the tool that fixes more real Checkstyle errors and alsogenerates smaller repairs. Finally, we conclude that Styler is promising to beused in IDEs and in a Continuous Integration environment to repair Checkstyleerrors.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.01754"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.01740",
    "DOI": "arXiv:1904.01740v2",
    "Article_Title": "FaceQnet: Quality Assessment for Face Recognition based on Deep Learning",
    "Article_Abstract": "In this paper we develop a Quality Assessment approach for face recognitionbased on deep learning. The method consists of a Convolutional Neural Network,FaceQnet, that is used to predict the suitability of a specific input image forface recognition purposes. The training of FaceQnet is done using the VGGFace2database. We employ the BioLab-ICAO framework for labeling the VGGFace2 imageswith quality information related to their ICAO compliance level. Thegroundtruth quality labels are obtained using FaceNet to generate comparisonscores. We employ the groundtruth data to fine-tune a ResNet-based CNN, makingit capable of returning a numerical quality measure for each input image.Finally, we verify if the FaceQnet scores are suitable to predict the expectedperformance when employing a specific image for face recognition with a COTSface recognition system. Several conclusions can be drawn from this work, mostnotably: 1) we managed to employ an existing ICAO compliance framework and apretrained CNN to automatically label data with quality information, 2) wetrained FaceQnet for quality estimation by fine-tuning a pre-trained facerecognition network (ResNet-50), and 3) we have shown that the predictions fromFaceQnet are highly correlated with the face recognition accuracy of astate-of-the-art commercial system not used during development. FaceQnet ispublicly available in GitHub.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.01740"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.01738",
    "DOI": "arXiv:1904.01738v3",
    "Article_Title": "Adinkra Height Yielding Matrix Numbers: Eigenvalue Equivalence Classes for Minimal Four-Color Adinkras",
    "Article_Abstract": "An adinkra is a graph-theoretic representation of spacetime supersymmetry.Minimal four-color valise adinkras have been extensively studied due to theirrelations to minimal 4D, $\\cal N$ = 1 supermultiplets. Valise adinkras,although an important subclass, do not encode all the information present whena 4D supermultiplet is reduced to 1D. Eigenvalue equivalence classes for valiseadinkra matrices exist, known as $\u03c7_{\\rm o}$ equivalence classes, wherevalise adinkras within the same $\u03c7_{\\rm o}$ equivalence class are isomorphicin the sense that adinkras within a $\u03c7_{\\rm o}$-equivalence class can betransformed into each other via field redefinitions of the nodes. We extendthis to non-valise adinkras, via Python code, providing a complete eigenvalueclassification of \"node-lifting\" for all 36,864 valise adinkras associated withthe Coxeter group $BC{}_4$. We term the eigenvalues associated with thesenode-lifted adinkras Height Yielding Matrix Numbers (HYMNs) and introduce HYMNequivalence classes. These findings have been summarized in a $Mathematica$notebook that can found at the HEPTHools Data Repository(https://hepthools.github.io/Data/) on GitHub.",
    "Article_Subject": "High Energy Physics - Theory (hep-th); Representation Theory (math.RT)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.01738"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.00935",
    "DOI": "arXiv:1904.00935v1",
    "Article_Title": "STYLE-ANALYZER: fixing code style inconsistencies with interpretable unsupervised algorithms",
    "Article_Abstract": "Source code reviews are manual, time-consuming, and expensive. Humaninvolvement should be focused on analyzing the most relevant aspects of theprogram, such as logic and maintainability, rather than amending style, syntax,or formatting defects. Some tools with linting capabilities can format codeautomatically and report various stylistic violations for supported programminglanguages. They are based on rules written by domain experts, hence, theirconfiguration is often tedious, and it is impractical for the given set ofrules to cover all possible corner cases. Some machine learning-based solutionsexist, but they remain uninterpretable black boxes. This paper introducesSTYLE-ANALYZER, a new open source tool to automatically fix code formattingviolations using the decision tree forest model which adapts to each codebaseand is fully unsupervised. STYLE-ANALYZER is built on top of our novel assistedcode review framework, Lookout. It accurately mines the formatting style ofeach analyzed Git repository and expresses the found format patterns withcompact human-readable rules. STYLE-ANALYZER can then suggest styleinconsistency fixes in the form of code review comments. We evaluate the outputquality and practical relevance of STYLE-ANALYZER by demonstrating that it canreproduce the original style with high precision, measured on 19 popularJavaScript projects, and by showing that it yields promising results in fixingreal style mistakes. STYLE-ANALYZER includes a web application to visualize howthe rules are triggered. We release STYLE-ANALYZER as a reusable and extendableopen source software package on GitHub for the benefit of the community.",
    "Article_Subject": "Machine Learning (cs.LG); Software Engineering (cs.SE); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/01",
    "Article_PDF": "https://arxiv.org/pdf/1904.00935"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.00243",
    "DOI": "arXiv:1904.00243v3",
    "Article_Title": "Symmetry-Based Disentangled Representation Learning requires Interaction with Environments",
    "Article_Abstract": "Finding a generally accepted formal definition of a disentangledrepresentation in the context of an agent behaving in an environment is animportant challenge towards the construction of data-efficient autonomousagents. Higgins et al. recently proposed Symmetry-Based DisentangledRepresentation Learning, a definition based on a characterization of symmetriesin the environment using group theory. We build on their work and makeobservations, theoretical and empirical, that lead us to argue thatSymmetry-Based Disentangled Representation Learning cannot only be based onstatic observations: agents should interact with the environment to discoverits symmetries. Our experiments can be reproduced in Colab and the code isavailable on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/30",
    "Article_PDF": "https://arxiv.org/pdf/1904.00243"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.12180",
    "DOI": "arXiv:1903.12180v1",
    "Article_Title": "ACRONYM: Acronym CReatiON for You and Me",
    "Article_Abstract": "Each year, countless hours of productive research time is spent brainstormingcreative acronyms for surveys, simulations, codes, and conferences. We presentACRONYM, a command-line program developed specifically to assist astronomers inidentifying the best acronyms for ongoing projects. The code returns allapproximately-English-language words that appear within an input string oftext, regardless of whether the letters occur at the beginning of the componentwords (in true astronomer fashion).",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/03/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.12180"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.12112",
    "DOI": "arXiv:1903.12112v2",
    "Article_Title": "Merging Combinatorial Design and Optimization: the Oberwolfach Problem",
    "Article_Abstract": "The Oberwolfach Problem $OP(F)$, posed by Gerhard Ringel in 1967, is aparadigmatic Combinatorial Design problem asking whether the complete graph$K_v$ decomposes into edge-disjoint copies of a $2$-regular graph $F$ of order$v$. In Combinatorial Design Theory, so-called difference methods represent awell-known solution technique and construct solutions in infinitely many casesexploiting symmetric and balanced structures. This approach reduces the problemto finding a well-structured $2$-factor which allows us to build solutions thatwe call $1$- or $2$-rotational according to their symmetries. We tackle $OP$ bymodeling difference methods with Optimization tools, specifically ConstraintProgramming ($CP$) and Integer Programming ($IP$), and correspondingly solveinstances with up to $v=120$ within $60s$. In particular, we model the$2$-rotational method by solving in cascade two subproblems, namely the binaryand group labeling, respectively. A polynomial-time algorithm solves the binarylabeling, while $CP$ tackles the group labeling. Furthermore, we providenecessary conditions for the existence of some $1$-rotational solutions whichstem from computational results. This paper shows thereby that both theoreticaland empirical results may arise from the interaction between CombinatorialDesign Theory and Operation Research.",
    "Article_Subject": "Combinatorics (math.CO)",
    "Article_Date": "2019/03/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.12112"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.11914",
    "DOI": "arXiv:1903.11914v3",
    "Article_Title": "Improving convergence of volume penalized fluid-solid interactions",
    "Article_Abstract": "Boundary conditions on arbitrary geometries are a common issue in simulatingpartial differential equations. The conventional approach is to discretize on agrid conforming to the geometry. However grid construction is challenging, andthis difficulty is compounded for evolving domains. Several methods insteadaugment the equations themselves to implicitly enforce the boundary conditions.This paper examines the Volume Penalty Method, which approximates Dirichletboundary conditions in the Navier Stokes equations with rapid linear damping(non-dimensional time scale $\u03b7$) inside the object. This technique is provento converge to the true solution, and also leads to simple volume-integralforce and torque calculations. Unfortunately, previous analysis showedconvergence of only $\\mathcal{O}(\u03b7^{1/2})$. We analyze the source of thiserror using matched asymptotic expansions and show that it stems from adisplacement length, proportional to a Reynolds number Re dependent boundarylayer of size $\\mathcal{O}(\u03b7^{1/2}\\text{Re}^{-1/2})$. The relative size ofthe displacement length and damping time scale lead to the emergence ofmultiple asymptotic regimes. The key finding is that there is a simplecorrection that can be efficiently calculated to eliminate the displacementlength and promote the accuracy to $\\mathcal{O}(\u03b7)$. This improvement alsoextends to the force and torque calculations. We demonstrate these findings in1D planar Poiseuille flow, 2D steady flow past a viscous stagnation point, and2D unsteady flow past a rotating cylinder, and finally show that Richardsonextrapolation can be used with our correction to further improve convergence to$\\mathcal{O}(\u03b7^{2})$.",
    "Article_Subject": "Numerical Analysis (math.NA)",
    "Article_Date": "2019/03/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.11914"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.10729",
    "DOI": "arXiv:1903.10729v3",
    "Article_Title": "WGANSing: A Multi-Voice Singing Voice Synthesizer Based on the Wasserstein-GAN",
    "Article_Abstract": "We present a deep neural network based singing voice synthesizer, inspired bythe Deep Convolutions Generative Adversarial Networks (DCGAN) architecture andoptimized using the Wasserstein-GAN algorithm. We use vocoder parameters foracoustic modelling, to separate the influence of pitch and timbre. Thisfacilitates the modelling of the large variability of pitch in the singingvoice. Our network takes a block of consecutive frame-wise linguistic andfundamental frequency features, along with global singer identity as input andoutputs vocoder features, corresponding to the block of features. Thisblock-wise approach, along with the training methodology allows us to modeltemporal dependencies within the features of the input block. For inference,sequential blocks are concatenated using an overlap-add procedure. We show thatthe performance of our model is competitive with regards to thestate-of-the-art and the original sample using objective metrics and asubjective listening test. We also present examples of the synthesis on asupplementary website and the source code via GitHub.",
    "Article_Subject": "Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "Article_Date": "2019/03/26",
    "Article_PDF": "https://arxiv.org/pdf/1903.10729"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.10326",
    "DOI": "arXiv:1903.10326v1",
    "Article_Title": "topFiberM: Scalable and Efficient Boolean Matrix Factorization",
    "Article_Abstract": "Matrix Factorization has many applications such as clustering. When thematrix is Boolean it is favorable to have Boolean factors too. This will savethe efforts of quantizing the reconstructed data back, which usually is doneusing arbitrary thresholds. Here we introduce topFiberM a Boolean matrixfactorization algorithm. topFiberM chooses in a greedy way the fibers (rows orcolumns) to represent the entire matrix. Fibers are extended to rectanglesaccording to a threshold on precision. The search for these \"top fibers\" cancontinue beyond the required rank and according to an optional parameter thatdefines the limit for this search. A factor with a better gain replaces thefactor with minimum gain in \"top fibers\". We compared topFiberM to thestate-of-the-art methods, it achieved better quality for the set of datasetsusually used in literature. We also applied our algorithm to linked-data toshow its scalability. topFiberM was in average 128 times faster than the wellknown Asso method when applied to a set of matrices representing a realmultigraph although Asso is implemented in C and topFiberM is implemented in Rwhich is generally slower than C. topFiberM is publicly available from Github(https://github.com/dice-group/BMF).",
    "Article_Subject": "Data Structures and Algorithms (cs.DS)",
    "Article_Date": "2019/03/06",
    "Article_PDF": "https://arxiv.org/pdf/1903.10326"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08718",
    "DOI": "arXiv:1903.08718v1",
    "Article_Title": "CRAFT: A multifunction online platform for speech prosody visualisation",
    "Article_Abstract": "There are many research tools which are also used for teaching the acousticphonetics of speech rhythm and speech melody. But they were notpurpose-designed for teaching-learning situations, and some have a steeplearning curve. CRAFT (Creation and Recovery of Amplitude and Frequency Tracks)is custom-designed as a novel flexible online tool for visualisation andcritical comparison of functions and transforms, with implementations of theReaper, RAPT, PyRapt, YAAPT, YIN and PySWIPE F0 estimators, three Praatconfigurations, and two purpose-built estimators, PyAMDF, S0FT. Visualisationsof amplitude and frequency envelope spectra, spectral edge detection of rhythmzones, and a parametrised spectrogram are included. A selection of audio clipsfrom tone and intonation languages is provided for demonstration purposes. Themain advantages of online tools are consistency (users have the same versionand the same data selection), interoperability over different platforms, andease of maintenance. The code is available on GitHub.",
    "Article_Subject": "Sound (cs.SD); Computation and Language (cs.CL)",
    "Article_Date": "2019/03/18",
    "Article_PDF": "https://arxiv.org/pdf/1903.08718"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08621",
    "DOI": "arXiv:1903.08621v1",
    "Article_Title": "Column2Vec: Structural Understanding via Distributed Representations of Database Schemas",
    "Article_Abstract": "We present Column2Vec, a distributed representation of database columns basedon column metadata. Our distributed representation has several applications.Using known names for groups of columns (i.e., a table name), we train a modelto generate an appropriate name for columns in an unnamed table. We demonstratethe viability of our approach using schema information collected from opensource applications on GitHub.",
    "Article_Subject": "Databases (cs.DB); Machine Learning (cs.LG)",
    "Article_Date": "2019/03/20",
    "Article_PDF": "https://arxiv.org/pdf/1903.08621"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08215",
    "DOI": "arXiv:1903.08215v2",
    "Article_Title": "The Galaxy Cluster 'Pypeline' for X-ray Temperature Maps: ClusterPyXT",
    "Article_Abstract": "ClusterPyXT is a new software pipeline to generate spectral temperature,X-ray surface brightness, pressure, and density maps from X-ray observations ofgalaxy clusters. These data products help elucidate the physics of processesoccurring within clusters of galaxies, including turbulence, shock fronts,nonthermal phenomena, and the overall dynamics of cluster mergers. ClusterPyXTautomates the creation of these data products with minimal user interaction,and allows for rapid analyses of archival data with user defined parameters andthe ability to straightforwardly incorporate additional observations. In thispaper, we describe in detail the use of this code and release it as an opensource Python project on GitHub.",
    "Article_Subject": "High Energy Astrophysical Phenomena (astro-ph.HE); Cosmology and Nongalactic Astrophysics (astro-ph.CO); Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/03/19",
    "Article_PDF": "https://arxiv.org/pdf/1903.08215"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08186",
    "DOI": "arXiv:1903.08186v1",
    "Article_Title": "Spectroscopic Transit Search: a self-calibrating method for detecting planets around bright stars",
    "Article_Abstract": "We search for transiting exoplanets around the star $\u03b2$ Pictoris usinghigh resolution spectroscopy and Doppler imaging that removes the need forstandard star observations. These data were obtained on the VLT with UVESduring the course of an observing campaign throughout 2017 that monitored theHill sphere transit of the exoplanet $\u03b2$ Pictoris b. We utilize lineprofile tomography as a method for the discovery of transiting exoplanets. Bymeasuring the exoplanet distortion of the stellar line profile, we remove theneed for reference star measurements. We demonstrate the method with whitenoise simulations, and then look at the case of $\u03b2$ Pictoris, which is a$\u03b4$ Scuti pulsator. We describe a method to remove the stellar pulsationsand perform a search for any transiting exoplanets in the resultant data set.We inject fake planet transits with varying orbital periods and planet radiiinto the spectra and determine the recovery fraction. In the photon noiselimited case we can recover planets down to a Neptune radius with an $\\sim$80%success rate, using an 8 m telescope with a $R\\sim 100,000$ spectrograph and 20minutes of observations per night. The pulsations of $\u03b2$ Pictoris limit oursensitivity to Jupiter-sized planets, but a pulsation removal algorithmimproves this limit to Saturn-sized planets. We present two planet candidates,but argue that their signals are most likely caused by other phenomena. We havedemonstrated a method for searching for transiting exoplanets that (i) does notrequire ancillary calibration observations, (ii) can work on any star whoserotational broadening can be resolved with a high spectral dispersionspectrograph and (iii) provides the lowest limits so far on the radii oftransiting Jupiter-sized exoplanets around $\u03b2$ Pictoris with orbitalperiods from 15 days to 200 days with >50% coverage.",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/03/19",
    "Article_PDF": "https://arxiv.org/pdf/1903.08186"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08113",
    "DOI": "arXiv:1903.08113v1",
    "Article_Title": "Identifying Experts in Software Libraries and Frameworks among GitHub Users",
    "Article_Abstract": "Software development increasingly depends on libraries and frameworks toincrease productivity and reduce time-to-market. Despite this fact, we stilllack techniques to assess developers expertise in widely popular libraries andframeworks. In this paper, we evaluate the performance of unsupervised (basedon clustering) and supervised machine learning classifiers (Random Forest andSVM) to identify experts in three popular JavaScript libraries: facebook/react,mongodb/node-mongodb, and socketio/socket.io. First, we collect 13 featuresabout developers activity on GitHub projects, including commits on source codefiles that depend on these libraries. We also build a ground truth includingthe expertise of 575 developers on the studied libraries, as self-reported bythem in a survey. Based on our findings, we document the challenges of usingmachine learning classifiers to predict expertise in software libraries, usingfeatures extracted from GitHub. Then, we propose a method to identify libraryexperts based on clustering feature data from GitHub; by triangulating theresults of this method with information available on Linkedin profiles, we showthat it is able to recommend dozens of GitHub users with evidences of beingexperts in the studied JavaScript libraries. We also provide a public datasetwith the expertise of 575 developers on the studied libraries.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/03/19",
    "Article_PDF": "https://arxiv.org/pdf/1903.08113"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.07611",
    "DOI": "arXiv:1903.07611v1",
    "Article_Title": "Total Power Map to Visibilities (TP2VIS): Joint Deconvolution of ALMA 12m, 7m, and Total Power Array Data",
    "Article_Abstract": "We present a new package for joint deconvolution of ALMA 12m, 7m, and TotalPower (TP) data, dubbed ``Total Power Map to Visibilities (TP2VIS)\". Itconverts a TP (single-dish) map into visibilities on the CASA platform, whichcan be input into deconvolvers (e.g., CLEAN) along with 12m and 7mvisibilities. A manual is presented in the Github repository(https://github.com/tp2vis/distribute). Combining data from the different ALMAarrays is a driver for a number of science topics, namely those that probe sizescales of extended and compact structures simultaneously. We test TP2VIS usingmodel images, one with a single Gaussian and another that mimics the internalstructures of giant molecular clouds. The result shows that the better uvcoverage with TP2VIS visibilities helps the deconvolution process andreproduces the model image within errors of only 5% over two orders ofmagnitude in flux.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Earth and Planetary Astrophysics (astro-ph.EP); Astrophysics of Galaxies (astro-ph.GA); Solar and Stellar Astrophysics (astro-ph.SR)",
    "Article_Date": "2019/03/18",
    "Article_PDF": "https://arxiv.org/pdf/1903.07611"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.06768",
    "DOI": "arXiv:1903.06768v2",
    "Article_Title": "Joint Mean-Covariance Estimation via the Horseshoe with an Application in Genomic Data Analysis",
    "Article_Abstract": "Seemingly unrelated regression is a natural framework for regressing multiplecorrelated responses on multiple predictors. The model is very flexible, withmultiple linear regression and covariance selection models being special cases.However, its practical deployment in genomic data analysis under a Bayesianframework is limited due to both statistical and computational challenges. Thestatistical challenge is that one needs to infer both the mean vector and theinverse covariance matrix, a problem inherently more complex than separatelyestimating each. The computational challenge is due to the dimensionality ofthe parameter space that routinely exceeds the sample size. We propose the useof horseshoe priors on both the mean vector and the inverse covariance matrix.This prior has demonstrated excellent performance when estimating a mean vectoror inverse covariance matrix separately. The current work shows theseadvantages are also present when addressing both simultaneously. A fullBayesian treatment is proposed, with a sampling algorithm that is linear in thenumber of predictors. MATLAB code implementing the algorithm is freelyavailable from github at https://github.com/liyf1988/HS_GHS. Extensiveperformance comparisons are provided with both frequentist and Bayesianalternatives, and both estimation and prediction performances are verified on agenomic data set.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/03/15",
    "Article_PDF": "https://arxiv.org/pdf/1903.06768"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.06348",
    "DOI": "arXiv:1903.06348v1",
    "Article_Title": "Automatically Generating Documentation for Lambda Expressions in Java",
    "Article_Abstract": "When lambda expressions were introduced to the Java programming language aspart of the release of Java 8 in 2014, they were the language's first step intofunctional programming. Since lambda expressions are still relatively new, notall developers use or understand them. In this paper, we first present theresults of an empirical study to determine how frequently developers of GitHubrepositories make use of lambda expressions and how they are documented. Wefind that 11% of Java GitHub repositories use lambda expressions, and that only6% of the lambda expressions are accompanied by source code comments. We thenpresent a tool called LambdaDoc which can automatically detect lambdaexpressions in a Java repository and generate natural language documentationfor them. Our evaluation of LambdaDoc with 23 professional developers showsthat they perceive the generated documentation to be complete, concise, andexpressive, while the majority of the documentation produced by ourparticipants without tool support was inadequate. Our contribution builds animportant step towards automatically generating documentation for functionalprogramming constructs in an object-oriented language.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/03/15",
    "Article_PDF": "https://arxiv.org/pdf/1903.06348"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.05277",
    "DOI": "arXiv:1903.05277v1",
    "Article_Title": "Activity-Based Analysis of Open Source Software Contributors: Roles and Dynamics",
    "Article_Abstract": "Contributors to open source software (OSS) communities assume diverse rolesto take different responsibilities. One major limitation of the current OSStools and platforms is that they provide a uniform user interface regardless ofthe activities performed by the various types of contributors. This paperserves as a non-trivial first step towards resolving this challenge bydemonstrating a methodology and establishing knowledge to understand how thecontributors' roles and their dynamics, reflected in the activitiescontributors perform, are exhibited in OSS communities. Based on an analysis ofuser action data from 29 GitHub projects, we extracted six activities thatdistinguished four Active roles and five Supporting roles of OSS contributors,as well as patterns in role changes. Through the lens of the Activity Theory,these findings provided rich design guidelines for OSS tools to support diversecontributor roles.",
    "Article_Subject": "Software Engineering (cs.SE); Human-Computer Interaction (cs.HC)",
    "Article_Date": "2019/03/13",
    "Article_PDF": "https://arxiv.org/pdf/1903.05277"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.05084",
    "DOI": "arXiv:1903.05084v3",
    "Article_Title": "Decay Replay Mining to Predict Next Process Events",
    "Article_Abstract": "In complex processes, various events can happen in different sequences. Theprediction of the next event given an a-priori process state is of importancein such processes. Recent methods have proposed deep learning techniques suchas recurrent neural networks, developed on raw event logs, to predict the nextevent from a process state. However, such deep learning models by themselveslack a clear representation of the process states. At the same time, recentmethods have neglected the time feature of event instances. In this paper, wetake advantage of Petri nets as a powerful tool in modeling complex processbehaviors considering time as an elemental variable. We propose an approachwhich starts from a Petri net process model constructed by a process miningalgorithm. We enhance the Petri net model with time decay functions to createcontinuous process state samples. Finally, we use these samples in combinationwith discrete token movement counters and Petri net markings to train a deeplearning model that predicts the next event. We demonstrate significantperformance improvements and outperform the state-of-the-art methods on ninereal-world benchmark event logs.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/12",
    "Article_PDF": "https://arxiv.org/pdf/1903.05084"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.04042",
    "DOI": "arXiv:1903.04042v1",
    "Article_Title": "Algorithms for an Efficient Tensor Biclustering",
    "Article_Abstract": "Consider a data set collected by (individuals-features) pairs in differenttimes. It can be represented as a tensor of three dimensions (Individuals,features and times). The tensor biclustering problem computes a subset ofindividuals and a subset of features whose signal trajectories over time lie ina low-dimensional subspace, modeling similarity among the signal trajectorieswhile allowing different scalings across different individuals or differentfeatures. This approach are based on spectral decomposition in order to buildthe desired biclusters. We evaluate the quality of the results from eachalgorithms with both synthetic and real data set.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/10",
    "Article_PDF": "https://arxiv.org/pdf/1903.04042"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.03804",
    "DOI": "arXiv:1903.03804v1",
    "Article_Title": "Program Classification Using Gated Graph Attention Neural Network for Online Programming Service",
    "Article_Abstract": "The online programing services, such as Github,TopCoder, and EduCoder, havepromoted a lot of social interactions among the service users. However, theexisting social interactions is rather limited and inefficient due to the rapidincreasing of source-code repositories, which is difficult to explore manually.The emergence of source-code mining provides a promising way to analyze thosesource codes, so that those source codes can be relatively easy to understandand share among those service users. Among all the source-code miningattempts,program classification lays a foundation for various tasks related tosource-code understanding, because it is impossible for a machine to understanda computer program if it cannot classify the program correctly. Althoughnumerous machine learning models, such as the Natural Language Processing (NLP)based models and the Abstract Syntax Tree (AST) based models, have beenproposed to classify computer programs based on their corresponding sourcecodes, the existing works cannot fully characterize the source codes from theperspective of both the syntax and semantic information. To address thisproblem, we proposed a Graph Neural Network (GNN) based model, which integratesdata flow and function call information to the AST,and applies an improved GNNmodel to the integrated graph, so as to achieve the state-of-art programclassification accuracy. The experiment results have shown that the proposedwork can classify programs with accuracy over 97%.",
    "Article_Subject": "Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/03/09",
    "Article_PDF": "https://arxiv.org/pdf/1903.03804"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.03375",
    "DOI": "arXiv:1903.03375v1",
    "Article_Title": "Online division of labour: emergent structures in Open Source Software",
    "Article_Abstract": "The development Open Source Software fundamentally depends on theparticipation and commitment of volunteer developers to progress. Several workshave presented strategies to increase the on-boarding and engagement of newcontributors, but little is known on how these diverse groups of developersself-organise to work together. To understand this, one must consider that, onone hand, platforms like GitHub provide a virtually unlimited developmentframework: any number of actors can potentially join to contribute in adecentralised, distributed, remote, and asynchronous manner. On the other,however, it seems reasonable that some sort of hierarchy and division of labourmust be in place to meet human biological and cognitive limits, and also toachieve some level of efficiency. These latter features (hierarchy and divisionof labour) should translate into recognisable structural arrangements whenprojects are represented as developer-file bipartite networks. In this paper weanalyse a set of popular open source projects from GitHub, placing the accenton three key properties: nestedness, modularity and in-block nestedness -whichtypify the emergence of heterogeneities among contributors, the emergence ofsubgroups of developers working on specific subgroups of files, and a mixtureof the two previous, respectively. These analyses show that indeed projectsevolve into internally organised blocks. Furthermore, the distribution of sizesof such blocks is bounded, connecting our results to the celebrated Dunbarnumber both in off- and on-line environments. Our analyses create a linkbetween bio-cognitive constraints, group formation and online workingenvironments, opening up a rich scenario for future research on (online) workteam assembly.",
    "Article_Subject": "Physics and Society (physics.soc-ph); Computers and Society (cs.CY); Software Engineering (cs.SE)",
    "Article_Date": "2019/03/08",
    "Article_PDF": "https://arxiv.org/pdf/1903.03375"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.02904",
    "DOI": "arXiv:1903.02904v1",
    "Article_Title": "Halin graphs are 3-vertex-colorable except even wheels",
    "Article_Abstract": "A Halin graph is a graph obtained by embedding a tree having no nodes ofdegree two in the plane, and then adding a cycle to join the leaves of the treein such a way that the resulting graph is planar. According to the four colortheorem, Halin graphs are 4-vertex-colorable. On the other hand, they are not2-vertex-colorable because they have triangles. We show that all Halin graphsare 3-vertex-colorable except even wheels. We also show how to find the perfectelimination ordering of a chordal completion for a given Halin graph. Thealgorithms are implemented in Python using the graphtheory package. Generatorsof random Halin graphs (general or cubic) are included. The source code isavailable from the public GitHub repository.",
    "Article_Subject": "Data Structures and Algorithms (cs.DS)",
    "Article_Date": "2019/03/07",
    "Article_PDF": "https://arxiv.org/pdf/1903.02904"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.02779",
    "DOI": "arXiv:1903.02779v4",
    "Article_Title": "Deep neural networks for classifying complex features in diffraction images",
    "Article_Abstract": "Intense short-wavelength pulses from free-electron lasers andhigh-harmonic-generation sources enable diffractive imaging of individualnano-sized objects with a single x-ray laser shot. The enormous data sets withup to several million diffraction patterns represent a severe problem for dataanalysis, due to the high dimensionality of imaging data. Feature recognitionand selection is a crucial step to reduce the dimensionality. Usually,custom-made algorithms are developed at a considerable effort to approximatethe particular features connected to an individual specimen, but facingdifferent experimental conditions, these approaches do not generalize well. Onthe other hand, deep neural networks are the principal instrument for today'srevolution in automated image recognition, a development that has not beenadapted to its full potential for data analysis in science. We recentlypublished in Langbehn et al. (Phys. Rev. Lett. 121, 255301 (2018)) the firstapplication of a deep neural network as a feature extractor for wide-anglediffraction images of helium nanodroplets. Here we present the setup, ourmodifications and the training process of the deep neural network fordiffraction image classification and its systematic benchmarking. We find thatdeep neural networks significantly outperform previous attempts for sorting andclassifying complex diffraction patterns and are a significant improvement forthe much-needed assistance during post-processing of large amounts ofexperimental coherent diffraction imaging data.",
    "Article_Subject": "Data Analysis, Statistics and Probability (physics.data-an); Atomic and Molecular Clusters (physics.atm-clus)",
    "Article_Date": "2019/03/07",
    "Article_PDF": "https://arxiv.org/pdf/1903.02779"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.02557",
    "DOI": "arXiv:1903.02557v3",
    "Article_Title": "DASH: Deep Learning for the Automated Spectral Classification of Supernovae and their Hosts",
    "Article_Abstract": "We present DASH (Deep Automated Supernova and Host classifier), a novelsoftware package that automates the classification of the type, age, redshift,and host galaxy of supernova spectra. DASH makes use of a new approach thatdoes not rely on iterative template matching techniques like all previoussoftware, but instead classifies based on the learned features of eachsupernova's type and age. It has achieved this by employing a deepconvolutional neural network to train a matching algorithm. This approach hasenabled DASH to be orders of magnitude faster than previous tools, being ableto accurately classify hundreds or thousands of objects within seconds. We havetested its performance on four years of data from the Australian Dark EnergySurvey (OzDES). The deep learning models were developed using TensorFlow, andwere trained using over 4000 supernova spectra taken from the CfA SupernovaProgram and the Berkeley SN Ia Program as used in SNID (SupernovaIdentification software, Blondin & Tonry 2007). Unlike template matchingmethods, the trained models are independent of the number of spectra in thetraining data, which allows for DASH's unprecedented speed. We have developedboth a graphical interface for easy visual classification and analysis ofsupernovae, and a Python library for the autonomous and quick classification ofseveral supernova spectra. The speed, accuracy, user-friendliness, andversatility of DASH presents an advancement to existing spectral classificationtools. We have made the code publicly available on GitHub and PyPI (pip installastrodash) to allow for further contributions and development. The packagedocumentation is available at https://astrodash.readthedocs.io.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Article_Date": "2019/03/06",
    "Article_PDF": "https://arxiv.org/pdf/1903.02557"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01742",
    "DOI": "arXiv:1903.01742v2",
    "Article_Title": "SZZ Unleashed: An Open Implementation of the SZZ Algorithm -- Featuring Example Usage in a Study of Just-in-Time Bug Prediction for the Jenkins Project",
    "Article_Abstract": "Numerous empirical software engineering studies rely on detailed informationabout bugs. While issue trackers often contain information about when bugs werefixed, details about when they were introduced to the system are often absent.As a remedy, researchers often rely on the SZZ algorithm as a heuristicapproach to identify bug-introducing software changes. Unfortunately, asreported in a recent systematic literature review, few researchers have madetheir SZZ implementations publicly available. Consequently, there is a riskthat research effort is wasted as new projects based on SZZ output need toinitially reimplement the approach. Furthermore, there is a risk that newlydeveloped (closed source) SZZ implementations have not been properly tested,thus conducting research based on their output might introduce threats tovalidity. We present SZZ Unleashed, an open implementation of the SZZ algorithmfor git repositories. This paper describes our implementation along with ausage example for the Jenkins project, and conclude with an illustrative studyon just-in-time bug prediction. We hope to continue evolving SZZ Unleashed onGitHub, and warmly invite the community to contribute.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/03/05",
    "Article_PDF": "https://arxiv.org/pdf/1903.01742"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01698",
    "DOI": "arXiv:1903.01698v3",
    "Article_Title": "Improving Cross-Domain Chinese Word Segmentation with Word Embeddings",
    "Article_Abstract": "Cross-domain Chinese Word Segmentation (CWS) remains a challenge despiterecent progress in neural-based CWS. The limited amount of annotated data inthe target domain has been the key obstacle to a satisfactory performance. Inthis paper, we propose a semi-supervised word-based approach to improvingcross-domain CWS given a baseline segmenter. Particularly, our model onlydeploys word embeddings trained on raw text in the target domain, discardingcomplex hand-crafted features and domain-specific dictionaries. Innovativesubsampling and negative sampling methods are proposed to derive wordembeddings optimized for CWS. We conduct experiments on five datasets inspecial domains, covering domains in novels, medicine, and patent. Results showthat our model can obviously improve cross-domain CWS, especially in thesegmentation of domain-specific noun entities. The word F-measure increases byover 3.0% on four datasets, outperforming state-of-the-art semi-supervised andunsupervised cross-domain CWS approaches with a large margin. We make our codeand data available on Github.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/03/05",
    "Article_PDF": "https://arxiv.org/pdf/1903.01698"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01555",
    "DOI": "arXiv:1903.01555v1",
    "Article_Title": "An Explorative Study of GitHub Repositories of AI Papers",
    "Article_Abstract": "With the rapid development of AI technologies, thousands of AI papers arebeing published each year. Many of these papers have released sample code tofacilitate follow-up researchers. This paper presents an explorative study ofover 1700 code repositories of AI papers hosted on GitHub. We find that theserepositories are often poorly written, lack of documents, lack of maintenance,and hard to configure the underlying runtime environment. Thus, many coderepositories become inactive and abandoned. Such a situation makes follow-upresearchers hard to reproduce the results or do further research. In addition,these hard-to-reuse code makes a gap between academia and industry. Based onthe findings, we give some recommendations on how to improve the quality ofcode repositories of AI papers.",
    "Article_Subject": "Digital Libraries (cs.DL)",
    "Article_Date": "2019/02/16",
    "Article_PDF": "https://arxiv.org/pdf/1903.01555"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01284",
    "DOI": "arXiv:1903.01284v1",
    "Article_Title": "Relation Extraction Datasets in the Digital Humanities Domain and their Evaluation with Word Embeddings",
    "Article_Abstract": "In this research, we manually create high-quality datasets in the digitalhumanities domain for the evaluation of language models, specifically wordembedding models. The first step comprises the creation of unigram and n-gramdatasets for two fantasy novel book series for two task types each, analogy anddoesn't-match. This is followed by the training of models on the two bookseries with various popular word embedding model types such as word2vec, GloVe,fastText, or LexVec. Finally, we evaluate the suitability of word embeddingmodels for such specific relation extraction tasks in a situation of comparablysmall corpus sizes. In the evaluations, we also investigate and analyzeparticular aspects such as the impact of corpus term frequencies and taskdifficulty on accuracy. The datasets, and the underlying system and wordembedding models are available on github and can be easily extended with newdatasets and tasks, be used to reproduce the presented results, or betransferred to other domains.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/03/04",
    "Article_PDF": "https://arxiv.org/pdf/1903.01284"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.00904",
    "DOI": "arXiv:1903.00904v1",
    "Article_Title": "Self-adversarial Variational Autoencoder with Gaussian Anomaly Prior Distribution for Anomaly Detection",
    "Article_Abstract": "Recently, deep generative models have become increasingly popular inunsupervised anomaly detection. However, deep generative models aim atrecovering the data distribution rather than detecting anomalies. Besides, deepgenerative models have the risk of overfitting training samples, which hasdisastrous effects on anomaly detection performance. To solve the above twoproblems, we propose a Self-adversarial Variational Autoencoder with a Gaussiananomaly prior assumption. We assume that both the anomalous and the normalprior distribution are Gaussian and have overlaps in the latent space.Therefore, a Gaussian transformer net T is trained to synthesize anomalous butnear-normal latent variables. Keeping the original training objective ofVariational Autoencoder, besides, the generator G tries to distinguish betweenthe normal latent variables and the anomalous ones synthesized by T, and theencoder E is trained to discriminate whether the output of G is real. These newobjectives we added not only give both G and E the ability to discriminate butalso introduce additional regularization to prevent overfitting. Compared withthe SOTA baselines, the proposed model achieves significant improvements inextensive experiments. Datasets and our model are available at a Githubrepository.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/03",
    "Article_PDF": "https://arxiv.org/pdf/1903.00904"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.00037",
    "DOI": "arXiv:1903.00037v1",
    "Article_Title": "Distance-Based Independence Screening for Canonical Analysis",
    "Article_Abstract": "This paper introduces a new method named Distance-based IndependenceScreening for Canonical Analysis (DISCA) to reduce dimensions of two randomvectors with arbitrary dimensions. The objective of our method is to identifythe low dimensional linear projections of two random vectors, such that anydimension reduction based on linear projection with lower dimensions willsurely affect some dependent structure -- the removed components are notindependent. The essence of DISCA is to use the distance correlation toeliminate the \"redundant\" dimensions until infeasible. Unlike the existingcanonical analysis methods, DISCA does not require the dimensions of thereduced subspaces of the two random vectors to be equal, nor does it requirecertain distributional assumption on the random vectors. We show that undermild conditions, our approach does undercover the lowest possible lineardependency structures between two random vectors, and our conditions are weakerthan some sufficient linear subspace-based methods. Numerically, DISCA is tosolve a non-convex optimization problem. We formulate it as adifference-of-convex (DC) optimization problem, and then further adopt thealternating direction method of multipliers (ADMM) on the convex step of the DCalgorithms to parallelize/accelerate the computation. Some sufficient linearsubspace-based methods use potentially numerically-intensive bootstrap methodto determine the dimensions of the reduced subspaces in advance; our methodavoids this complexity. In simulations, we present cases that DISCA can solveeffectively, while other methods cannot. In both the simulation studies andreal data cases, when the other state-of-the-art dimension reduction methodsare applicable, we observe that DISCA performs either comparably or better thanmost of them. Codes and an R package can be found in GitHubhttps://github.com/ChuanpingYu/DISCA.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/02/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.00037"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.11108",
    "DOI": "arXiv:1902.11108v2",
    "Article_Title": "Artist Style Transfer Via Quadratic Potential",
    "Article_Abstract": "In this paper we address the problem of artist style transfer where thepainting style of a given artist is applied on a real world photograph. Wetrain our neural networks in adversarial setting via recently introducedquadratic potential divergence for stable learning process. To further improvethe quality of generated artist stylized images we also integrate some of therecently introduced deep learning techniques in our method. To our bestknowledge this is the first attempt towards artist style transfer via quadraticpotential divergence. We provide some stylized image samples in thesupplementary material. The source code for experimentation was written inPyTorch and is available online in my GitHub repository.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/02/14",
    "Article_PDF": "https://arxiv.org/pdf/1902.11108"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.10149",
    "DOI": "arXiv:1902.10149v2",
    "Article_Title": "Primordial power spectrum and cosmology from black-box galaxy surveys",
    "Article_Abstract": "We propose a new, likelihood-free approach to inferring the primordial matterpower spectrum and cosmological parameters from arbitrarily complex forwardmodels of galaxy surveys where all relevant statistics can be determined fromnumerical simulations, i.e. black-boxes. Our approach, which we call simulatorexpansion for likelihood-free inference (SELFI), builds upon approximateBayesian computation using a novel effective likelihood, and upon thelinearisation of black-box models around an expansion point. Consequently, weobtain simple \"filter equations\" for an effective posterior of the primordialpower spectrum, and a straightforward scheme for cosmological parameterinference. We demonstrate that the workload is computationally tractable, fixeda priori, and perfectly parallel. As a proof of concept, we apply our frameworkto a realistic synthetic galaxy survey, with a data model accounting forphysical structure formation and incomplete and noisy galaxy observations. Indoing so, we show that the use of non-linear numerical models allows the galaxypower spectrum to be safely fitted up to at least $k_\\mathrm{max} = 0.5$$h$/Mpc, outperforming state-of-the-art backward-modelling techniques by afactor of $\\sim 5$ in the number of modes used. The result is an unbiasedinference of the primordial matter power spectrum across the entire range ofscales considered, including a high-fidelity reconstruction of baryon acousticoscillations. It translates into an unbiased and robust inference ofcosmological parameters. Our results pave the path towards easy applications oflikelihood-free simulation-based inference in cosmology. We have made our codepySELFI and our data products publicly available athttp://pyselfi.florent-leclercq.eu.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/02/26",
    "Article_PDF": "https://arxiv.org/pdf/1902.10149"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.09386",
    "DOI": "arXiv:1902.09386v1",
    "Article_Title": "SMARTp: A SMART design for non-surgical treatments of chronic periodontitis with spatially-referenced and non-randomly missing skewed outcomes",
    "Article_Abstract": "This paper proposes dynamic treatment regimes for choosing individualizedeffective treatment strategies of chronic periodontal disease. R codes forimplementing the proposed sample size formula are available in GitHub.",
    "Article_Subject": "Applications (stat.AP)",
    "Article_Date": "2019/02/25",
    "Article_PDF": "https://arxiv.org/pdf/1902.09386"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.08702",
    "DOI": "arXiv:1902.08702v1",
    "Article_Title": "pyro: a framework for hydrodynamics explorations and prototyping",
    "Article_Abstract": "pyro is a Python-based simulation framework designed for ease ofimplementation and exploration of hydrodynamics methods. It is built in aobject-oriented fashion, allowing for the reuse of the core components and fastprototyping of new methods.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/02/22",
    "Article_PDF": "https://arxiv.org/pdf/1902.08702"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.08182",
    "DOI": "arXiv:1902.08182v1",
    "Article_Title": "Finding the Needle in a Haystack: Detrending Photometric Timeseries Data of Strictly Periodic Astrophysical Objects",
    "Article_Abstract": "Light curves of astrophysical objects frequently contain strictly periodicsignals. In those cases we can use that property to aid the detrendingalgorithm to fully disentangle an unknown periodic signal and an unknownbaseline signal with no power at that period. The periodic signal is modeled asa discrete probability distribution function (pdf), while the baseline signalis modeled as a residual timeseries. Those two components are disentangled byminimizing the length of the residual timeseries w.r.t. the per-bin pdf fluxes.We demonstrate the use of the algorithm on a synthetic case, on the eclipsingbinary KIC 3953981 and on the eccentric ellipsoidal variable KIC 3547874. Wefurther discuss the parameters and the limitations of the algorithm andspeculate on the two most common use cases: detrending the periodic signal ofinterest and measuring the dependence of instrumental response on controlledinstrumental variables. A more sophisticated version of the algorithm isreleased as open source on github and available via pip.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Solar and Stellar Astrophysics (astro-ph.SR)",
    "Article_Date": "2019/02/21",
    "Article_PDF": "https://arxiv.org/pdf/1902.08182"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.07740",
    "DOI": "arXiv:1902.07740v1",
    "Article_Title": "Nitrogen Oxide Concentrations in Natural Waters on Early Earth",
    "Article_Abstract": "A key challenge in origins-of-life studies is estimating the abundances ofspecies relevant to the chemical pathways proposed to have contributed to theemergence of life on early Earth. Dissolved nitrogen oxide anions(NO$_{X}^{-}$), in particular nitrate (NO$_{3}^{-}$) and nitrite(NO$_{2}^{-}$), have been invoked in diverse origins-of-life chemistry, fromthe oligomerization of RNA to the emergence of protometabolism. Recent work hascalculated the supply of NO$_{X}^{-}$ from the prebiotic atmosphere to theocean, and reported steady-state [NO$_{X}^{-}$] to be high across all plausibleparameter space. These findings rest on the assumption that NO$_{X}^{-}$ isstable in natural waters unless processed at a hydrothermal vent. Here, we showthat NO$_{X}^{-}$ is unstable in the reducing environment of early Earth. Sinksdue to UV photolysis and reactions with reduced iron (Fe$^{2+}$) suppress[NO$_{X}^{-}$] by several orders of magnitude relative to past predictions. ForpH$=6.5-8$ and $T=0-50^\\circ$C, we find that it is most probable thatNO$_{X}^{-}$]$<1~\u03bc$M in the prebiotic ocean. On the other hand, prebioticponds with favorable drainage characteristics may have sustained[NO$_{X}^{-}$]$\\geq 1~\u03bc$M. As on modern Earth, most NO$_{X}^{-}$ on prebioticEarth should have been present as NO$_{3}^{-}$, due to its much greaterstability. These findings inform the kind of prebiotic chemistries that wouldhave been possible on early Earth. We discuss the implications for proposedprebiotic chemistries, and highlight the need for further studies ofNO$_{X}^{-}$ kinetics to reduce the considerable uncertainties in predicting[NO$_{X}^{-}$] on early Earth.",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP)",
    "Article_Date": "2019/02/20",
    "Article_PDF": "https://arxiv.org/pdf/1902.07740"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.07704",
    "DOI": "arXiv:1902.07704v1",
    "Article_Title": "How Do the Open Source Communities Address Usability and UX Issues? An Exploratory Study",
    "Article_Abstract": "Usability and user experience (UX) issues are often not well emphasized andaddressed in open source software (OSS) development. There is an imperativeneed for supporting OSS communities to collaboratively identify, understand,and fix UX design issues in a distributed environment. In this paper, weprovide an initial step towards this effort and report on an exploratory studythat investigated how the OSS communities currently reported, discussed,negotiated, and eventually addressed usability and UX issues. We conductedin-depth qualitative analysis of selected issue tracking threads from three OSSprojects hosted on GitHub. Our findings indicated that discussions aboutusability and UX issues in OSS communities were largely influenced by thepersonal opinions and experiences of the participants. Moreover, thecharacteristics of the community may have greatly affected the focus of suchdiscussion.",
    "Article_Subject": "Human-Computer Interaction (cs.HC); Software Engineering (cs.SE)",
    "Article_Date": "2019/02/20",
    "Article_PDF": "https://arxiv.org/pdf/1902.07704"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.03867",
    "DOI": "arXiv:1910.03867v1",
    "Article_Title": "Loss Surface Sightseeing by Multi-Point Optimization",
    "Article_Abstract": "We present multi-point optimization: an optimization technique that allows totrain several models simultaneously without the need to keep the parameters ofeach one individually. The proposed method is used for a thorough empiricalanalysis of the loss landscape of neural networks. By extensive experiments onFashionMNIST and CIFAR10 datasets we demonstrate two things: 1) loss surface issurprisingly diverse and intricate in terms of landscape patterns it contains,and 2) adding batch normalization makes it more smooth. Source code toreproduce all the reported results is available on GitHub:https://github.com/universome/loss-patterns.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/10/09",
    "Article_PDF": "https://arxiv.org/pdf/1910.03867"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.02513",
    "DOI": "arXiv:1910.02513v1",
    "Article_Title": "Automated Isolation for White-box Test Generation",
    "Article_Abstract": "Context. White-box test generation is a technique used for automaticallyselecting test inputs using only the source or binary code. However, suchtechniques encounter challenges when applying them to complex programs. One ofthe main challenges is handling the dependencies of the unit under test.  Objective. Without proper actions, generated tests cannot cover all parts ofthe source code, or calling the dependencies may cause unexpected side effects(e.g., file system or network access). These issues should be tackled whilemaintaining the advantages of white-box test generation.  Method. In this paper, we present an automated source code transformationapproach tackling the dependency issue for white-box test generation. Thistechnique isolates the test execution by creating a parameterized sandboxwrapped around the transformed unit. We implemented the approach in aready-to-use tool using Microsoft Pex as a test generator, and evaluated it on10 open-source projects from GitHub having more than 38.000 lines of code intotal.  Results. The results from the evaluation indicate that if the lack ofisolation hinders white-box test generation, then our approach is able to help:it increases the code coverage reached by the automatically generated test,while it reduces unwanted side effects. Also, our results act as a uniquebaseline for the test generation performance of Microsoft Pex on open-sourceprojects.  Conclusion. Based on the results, our source code transformations might servewell for alleviating the isolation problem in white-box test generation as itincreases the coverage reached in such situations, while maintaining thepractical applicability of the tests generated on the isolated code.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/10/06",
    "Article_PDF": "https://arxiv.org/pdf/1910.02513"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01750",
    "DOI": "arXiv:1910.01750v2",
    "Article_Title": "PEXO: a global modeling framework for nanosecond timing, microsecond astrometry, and {\\mu}m/s radial velocities",
    "Article_Abstract": "The ability to make independent detections of the signatures of exoplanetswith complementary telescopes and instruments brings a new potential for robustidentification of exoplanets and precision characterization. We introduce PEXO,a package for Precise EXOplanetology to facilitate the efficient modeling oftiming, astrometry, and radial velocity data, which will benefit not onlyexoplanet science but also various astrophysical studies in general. PEXO isgeneral enough to account for binary motion and stellar reflex motions inducedby planetary companions and is precise enough to treat various relativisticeffects both in the solar system and in the target system. We also model thepost-Newtonian barycentric motion for future tests of general relativity inextrasolar systems. We benchmark PEXO with the pulsar timing package TEMPO2 andfind that PEXO produces numerically similar results with timing precision ofabout 1 ns, space-based astrometry to a precision of 1\u03bcas, and radialvelocity of 1 \u03bcm/s and improves on TEMPO2 for decade-long timing data ofnearby targets, due to its consideration of third-order terms of Roemer delay.PEXO is able to avoid the bias introduced by decoupling the target system andthe solar system and to account for the atmospheric effects which set apractical limit for ground-based radial velocities close to 1 cm/s. Consideringthe various caveats in barycentric correction and ancillary data required torealize cm/s modeling, we recommend the preservation of original observationaldata. The PEXO modeling package is available at GitHub(https://github.com/phillippro/pexo).",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM); Solar and Stellar Astrophysics (astro-ph.SR)",
    "Article_Date": "2019/10/03",
    "Article_PDF": "https://arxiv.org/pdf/1910.01750"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01321",
    "DOI": "arXiv:1910.01321v1",
    "Article_Title": "An Empirical Study of C++ Vulnerabilities in Crowd-Sourced Code Examples",
    "Article_Abstract": "Software developers share programming solutions in Q&A sites like StackOverflow. The reuse of crowd-sourced code snippets can facilitate rapidprototyping. However, recent research shows that the shared code snippets maybe of low quality and can even contain vulnerabilities. This paper aims tounderstand the nature and the prevalence of security vulnerabilities incrowd-sourced code examples. To achieve this goal, we investigate securityvulnerabilities in the C++ code snippets shared on Stack Overflow over a periodof 10 years. In collaborative sessions involving multiple human coders, wemanually assessed each code snippet for security vulnerabilities following CWE(Common Weakness Enumeration) guidelines. From the 72,483 reviewed codesnippets used in at least one project hosted on GitHub, we found a total of 69vulnerable code snippets categorized into 29 types. Many of the investigatedcode snippets are still not corrected on Stack Overflow. The 69 vulnerable codesnippets found in Stack Overflow were reused in a total of 2859 GitHubprojects. To help improve the quality of code snippets shared on StackOverflow, we developed a browser extension that allow Stack Overflow users tocheck for vulnerabilities in code snippets when they upload them on theplatform.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/10/03",
    "Article_PDF": "https://arxiv.org/pdf/1910.01321"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01212",
    "DOI": "arXiv:1910.01212v1",
    "Article_Title": "Social Influence and Radicalization: A Social Data Analytics Study",
    "Article_Abstract": "The confluence of technological and societal advances is changing the natureof global terrorism. For example, engagement with Web, social media, and smartdevices has the potential to affect the mental behavior of the individuals andinfluence extremist and criminal behaviors such as Radicalization. In thiscontext, social data analytics (i.e., the discovery, interpretation, andcommunication of meaningful patterns in social data) and influence maximization(i.e., the problem of finding a small subset of nodes in a social network whichcan maximize the propagation of influence) has the potential to become a vitalasset to explore the factors involved in influencing people to participate inextremist activities.  To address this challenge, we study and analyze the recent work done ininfluence maximization and social data analytics from effectiveness, efficiencyand scalability viewpoints. We introduce a social data analytics pipeline,namely iRadical, to enable analysts engage with social data to explore thepotential for online radicalization. In iRadical, we present algorithms toanalyse the social data as well as the user activity patterns to learn howinfluence flows in social networks. We implement iRadical as an extensiblearchitecture that is publicly available on GitHub and present the evaluationresults.",
    "Article_Subject": "Computers and Society (cs.CY); Machine Learning (cs.LG)",
    "Article_Date": "2019/09/04",
    "Article_PDF": "https://arxiv.org/pdf/1910.01212"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01078",
    "DOI": "arXiv:1910.01078v1",
    "Article_Title": "ROS Rescue : Fault Tolerance System for Robot Operating System",
    "Article_Abstract": "In this chapter we discuss the problem of master failure in ROS1.0 and itsimpact on robotic deployments in the real world. We address this issue in thistutorial chapter where we outline, design and demonstrate a fault tolerantmechanism associated with ROS master failure. Unlike previous solutions whichuse primary backup replication and external checkpointing libraries which areprocess heavy, our mechanism adds a lightweight functionality to the ROS masterto enable it to recover from failure.  We present a modified version of ROS master which is equipped with a loggingmechanism to record the meta information and network state of ROS nodes as wellas a recovery mechanism to go back to the previous state without having toabort or restart all the nodes. We also implement an additional master monitornode responsible for failure detection on the master by polling it for itsavailability. Our code is implemented in python and preliminary tests wereconducted successfully on a variety of land, aerial and underwater robots and atele-operating computer running ROS Kinetic on Ubuntu 16.04. The code ispublicly available under a creative commons license on github athttps://github.com/PushyamiKaveti/fault-tolerant-ros-master",
    "Article_Subject": "Robotics (cs.RO)",
    "Article_Date": "2019/10/02",
    "Article_PDF": "https://arxiv.org/pdf/1910.01078"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00725",
    "DOI": "arXiv:1910.00725v1",
    "Article_Title": "Cosmic Microwave Background Anisotropy numerical solution (CMBAns) I: An introduction to $C_l$ calculation",
    "Article_Abstract": "Cosmological Boltzmann codes are often used by researchers for calculatingthe CMB angular power spectra from different theoretical models, forcosmological parameter estimation, etc. Therefore, the accuracy of a Boltzmanncode is of utmost importance. Different Markov Chain Monte Carlo basedparameter estimation algorithms typically require 10^3 - 10^4 iterations ofBoltzmann code. This makes the time complexity of such codes another criticalfactor. In the last two decades, several Boltzmann packages, such as CMBFAST,CAMB, CMBEasy, CLASS etc., have been developed. In this paper, we present a newcosmological Boltzmann code, CMBAns, that can be used for accurate calculationof the CMB power spectrum. At present, CMBAns is developed for a flatbackground matrix. It is mostly written in the C language. However, we borrowedthe concept of class from C++. This gives researchers the flexibility todevelop their own independent package based on CMBAns, without an in-depthunderstanding of the source code. We also develop multiple stand-alonefacilities which can be directly compiled and run on a given parameter set. Inthis paper, we discuss all the mathematical formulation, approximation schemes,integration methods etc., that are used in CMBAns. The package will be madeavailable through github for public use in the near future.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); Instrumentation and Methods for Astrophysics (astro-ph.IM); General Relativity and Quantum Cosmology (gr-qc)",
    "Article_Date": "2019/10/02",
    "Article_PDF": "https://arxiv.org/pdf/1910.00725"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00536",
    "DOI": "arXiv:1910.00536v1",
    "Article_Title": "Scalable String Reconciliation by Recursive Content-Dependent Shingling",
    "Article_Abstract": "We consider the problem of reconciling similar, but remote, strings withminimum communication complexity. This \"string reconciliation\" problem is afundamental building block for a variety of networking applications, includingthose that maintain large-scale distributed networks and perform remote filesynchronization. We present the novel Recursive Content-Dependent Shingling(RCDS) protocol that is computationally practical for large strings and scaleslinearly with the edit distance between the remote strings. We providecomparisons to the performance of Rsync, one of the most popular filesynchronization tools in active use. Our experiments show that, with minimalengineering, RCDS outperforms the heavily optimized Rsync in reconcilingrelease revisions for about 51% of the 5000 top starred git repositories onGitHub. The improvement is particularly evident for repositories that seefrequent, but small, updates.",
    "Article_Subject": "Information Theory (cs.IT)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00536"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00286",
    "DOI": "arXiv:1910.00286v1",
    "Article_Title": "Ransomware Analysis using Feature Engineering and Deep Neural Networks",
    "Article_Abstract": "Detection and Analysis of a potential malware specifically, used for ransomis a challenging task. Recently, intruders are utilizing advance cryptographictechniques to get hold of digital assets and then demand ransom. It is believedthat generally, the files comprise of some attributes, states, and patternsthat can be recognized by a machine learning technique. This work thus focuseson detection of Ransomware by performing feature engineering, which helps inanalyzing vital attributes and behaviors of the malware. The main contributionof this work is the identification of important and distinct characteristics ofRansomware that can help in detecting them. Finally, based on the selectedfeatures, both conventional machine learning techniques and Transfer Learningbased Deep Convolutional Neural Networks have been used to detect Ransomware.In order to perform feature engineering and analysis, two separate datasets(static and dynamic) were generated. The static dataset has 3646 samples (1700Ransomware and 1946 Goodware). On the other hand, the dynamic dataset comprisedof 3444 samples (1455 Ransomware and 1989 Goodware). Through variousexperiments, it is observed that the Registry changes, API calls, and DLLs arethe most important features for Ransomware detection. Additionally, importantsequences are found with the help of N Gram technique. It is also observed thatin case of Registry Delete operation, if a malicious file tries to deleteregistries, it follows a specific and repeated sequence. However for the benignfile, it doesnt follow any specific sequence or repetition. Similarly, aninteresting observation made through this study is that there is no commonRegistry deleted sequence between malicious and benign file. And thus thisdiscernible fact can be readily exploited for Ransomware detection. Therelevant Python code and dataset are available at github.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00286"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00199",
    "DOI": "arXiv:1910.00199v1",
    "Article_Title": "Underwhelming Generalization Improvements From Controlling Feature Attribution",
    "Article_Abstract": "Overfitting is a common issue in machine learning, which can arise when themodel learns to predict class membership using convenient butspuriously-correlated image features instead of the true image features thatdenote a class. These are typically visualized using saliency maps. In someobject classification tasks such as for medical images, one may have someimages with masks, indicating a region of interest, i.e., which part of theimage contains the most relevant information for the classification. Wedescribe a simple method for taking advantage of such auxiliary labels, bytraining networks to ignore the distracting features which may be extractedoutside of the region of interest, on the training images for which such masksare available. This mask information is only used during training and has animpact on generalization accuracy in a dataset-dependent way. We observe anunderwhelming relationship between controlling saliency maps and improvinggeneralization performance.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00199"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00188",
    "DOI": "arXiv:1910.00188v1",
    "Article_Title": "Beyond Textual Issues: Understanding the Usage and Impact of GitHub Reactions",
    "Article_Abstract": "Recently, GitHub introduced a new social feature, named reactions, which are\"pictorial characters\" similar to emoji symbols widely used nowadays intext-based communications. Particularly, GitHub users can use a pre-defined setof such symbols to react to issues and pull requests. However, little is knownabout the real usage and impact of GitHub reactions. In this paper, we analyzethe reactions provided by developers to more than 2.5 million issues and 9.7million issue comments, in order to answer an extensive list of nine researchquestions about the usage and adoption of reactions. We show that reactions arebeing increasingly used by open source developers. Moreover, we also found thatissues with reactions usually take more time to be handled and have longerdiscussions.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00188"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00024",
    "DOI": "arXiv:1910.00024v1",
    "Article_Title": "Neural Canonical Transformation with Symplectic Flows",
    "Article_Abstract": "Canonical transformation plays a fundamental role in simplifying and solvingclassical Hamiltonian systems. We construct flexible and powerful canonicaltransformations as generative models using symplectic neural networks. Themodel transforms physical variables towards a latent representation with anindependent harmonic oscillator Hamiltonian. Correspondingly, the phase spacedensity of the physical system flows towards a factorized Gaussian distributionin the latent space. Since the canonical transformation preserves theHamiltonian evolution, the model captures nonlinear collective modes in thelearned latent representation. We present an efficient implementation ofsymplectic neural coordinate transformations and two ways to train the model.The variational free energy calculation is based on the analytical form ofphysical Hamiltonian. While the phase space density estimation only requiressamples in the coordinate space for separable Hamiltonians. We demonstrateappealing features of neural canonical transformation using toy problemsincluding two-dimensional ring potential and harmonic chain. Finally, we applythe approach to real-world problems such as identifying slow collective modesin alanine dipeptide and conceptual compression of the MNIST dataset.",
    "Article_Subject": "Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG); Computational Physics (physics.comp-ph); Machine Learning (stat.ML)",
    "Article_Date": "2019/09/30",
    "Article_PDF": "https://arxiv.org/pdf/1910.00024"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.13589",
    "DOI": "arXiv:1909.13589v1",
    "Article_Title": "Domain Adaptation for Semantic Segmentation with Maximum Squares Loss",
    "Article_Abstract": "Deep neural networks for semantic segmentation always require a large numberof samples with pixel-level labels, which becomes the major difficulty in theirreal-world applications. To reduce the labeling cost, unsupervised domainadaptation (UDA) approaches are proposed to transfer knowledge from labeledsynthesized datasets to unlabeled real-world datasets. Recently, somesemi-supervised learning methods have been applied to UDA and achievedstate-of-the-art performance. One of the most popular approaches insemi-supervised learning is the entropy minimization method. However, whenapplying the entropy minimization to UDA for semantic segmentation, thegradient of the entropy is biased towards samples that are easy to transfer. Tobalance the gradient of well-classified target samples, we propose the maximumsquares loss. Our maximum squares loss prevents the training process beingdominated by easy-to-transfer samples in the target domain. Besides, weintroduce the image-wise weighting ratio to alleviate the class imbalance inthe unlabeled target domain. Both synthetic-to-real and cross-city adaptationexperiments demonstrate the effectiveness of our proposed approach. The code isreleased at https://github. com/ZJULearning/MaxSquareLoss.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/30",
    "Article_PDF": "https://arxiv.org/pdf/1909.13589"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.13092",
    "DOI": "arXiv:1909.13092v1",
    "Article_Title": "GLA-Net: An Attention Network with Guided Loss for Mismatch Removal",
    "Article_Abstract": "Mismatch removal is a critical prerequisite in many feature-based tasks.Recent attempts cast the mismatch removal task as a binary classificationproblem and solve it through deep learning based methods. In these methods, theimbalance between positive and negative classes is important, which affectsnetwork performance, i.e., Fn-score. To establish the link between Fn-score andloss, we propose to guide the loss with the Fn-score directly. We theoreticallydemonstrate the direct link between our Guided Loss and Fn-score duringtraining. Moreover, we discover that outliers often impair global context inmismatch removal networks. To address this issue, we introduce the attentionmechanism to mismatch removal task and propose a novel Inlier Attention Block(IA Block). To evaluate the effectiveness of our loss and IA Block, we designan end-to-end network for mismatch removal, called GLA-Net \\footnote{Our codewill be available in Github later.}. Experiments have shown that our networkachieves the state-of-the-art performance on benchmark datasets.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/28",
    "Article_PDF": "https://arxiv.org/pdf/1909.13092"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.11977",
    "DOI": "arXiv:1909.11977v1",
    "Article_Title": "Stochastic Weight Matrix-based Regularization Methods for Deep Neural Networks",
    "Article_Abstract": "The aim of this paper is to introduce two widely applicable regularizationmethods based on the direct modification of weight matrices. The first method,Weight Reinitialization, utilizes a simplified Bayesian assumption withpartially resetting a sparse subset of the parameters. The second one, WeightShuffling, introduces an entropy- and weight distribution-invariant non-whitenoise to the parameters. The latter can also be interpreted as an ensembleapproach. The proposed methods are evaluated on benchmark datasets, such asMNIST, CIFAR-10 or the JSB Chorales database, and also on time series modelingtasks. We report gains both regarding performance and entropy of the analyzednetworks. We also made our code available as a GitHub repository(https://github.com/rpatrik96/lod-wmm-2019).",
    "Article_Subject": "Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)",
    "Article_Date": "2019/09/26",
    "Article_PDF": "https://arxiv.org/pdf/1909.11977"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.11811",
    "DOI": "arXiv:1909.11811v1",
    "Article_Title": "A fast, complete, point cloud based loop closure for LiDAR odometry and mapping",
    "Article_Abstract": "This paper presents a loop closure method to correct the long-term drift inLiDAR odometry and mapping (LOAM). Our proposed method computes the 2Dhistogram of keyframes, a local map patch, and uses the normalizedcross-correlation of the 2D histograms as the similarity metric between thecurrent keyframe and those in the map. We show that this method is fast,invariant to rotation, and produces reliable and accurate loop detection. Theproposed method is implemented with careful engineering and integrated into theLOAM algorithm, forming a complete and practical system ready to use. Tobenefit the community by serving a benchmark for loop closure, the entiresystem is made open source on Github",
    "Article_Subject": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/25",
    "Article_PDF": "https://arxiv.org/pdf/1909.11811"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.11544",
    "DOI": "arXiv:1909.11544v1",
    "Article_Title": "PyDEns: a Python Framework for Solving Differential Equations with Neural Networks",
    "Article_Abstract": "Recently, a lot of papers proposed to use neural networks to approximatelysolve partial differential equations (PDEs). Yet, there has been a lack offlexible framework for convenient experimentation. In an attempt to fill thegap, we introduce a PyDEns-module open-sourced on GitHub. Coupled withcapabilities of BatchFlow, open-source framework for convenient andreproducible deep learning, PyDEns-module allows to 1) solve partialdifferential equations from a large family, including heat equation and waveequation 2) easily search for the best neural-network architecture among thezoo, that includes ResNet and DenseNet 3) fully control the process ofmodel-training by testing different point-sampling schemes. With that in mind,our main contribution goes as follows: implementation of a ready-to-use andopen-source numerical solver of PDEs of a novel format, based on neuralnetworks.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/09/25",
    "Article_PDF": "https://arxiv.org/pdf/1909.11544"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.10051",
    "DOI": "arXiv:1909.10051v1",
    "Article_Title": "PyIT2FLS: A New Python Toolkit for Interval Type 2 Fuzzy Logic Systems",
    "Article_Abstract": "Fuzzy logic is an accepted and well-developed approach for constructingverbal models. Fuzzy based methods are getting more popular, while theengineers deal with more daily life tasks. This paper presents a new Pythontoolkit for Interval Type 2 Fuzzy Logic Systems (IT2FLS). Developing softwaretools is an important issue for facilitating the practical use of theoreticalresults. There are limited tools for implementing IT2FLSs in Python. Thedeveloped PyIT2FLS is providing a set of tools for fast and easy modeling offuzzy systems. This paper includes a brief description of how developed toolkitcan be used. Also, three examples are given showing the usage of the developedtoolkit for simulating IT2FLSs. First, a simple rule-based system is developedand it's codes are presented in the paper. The second example is the predictionof the Mackey-Glass chaotic time series using IT2FLS. In this example, theParticle Swarm Optimization (PSO) algorithm is used for determining systemparameters while minimizing the mean square error. In the last example, anIT2FPID is used in a linear time-delay system. The code for the examples areavailable on toolkit's GitHub page: https://github.com/Haghrah/PyIT2FLS. Thesimulations and their results confirm the ability of the developed toolkit tobe used in a wide range of the applications.",
    "Article_Subject": "Systems and Control (eess.SY); Mathematical Software (cs.MS)",
    "Article_Date": "2019/09/22",
    "Article_PDF": "https://arxiv.org/pdf/1909.10051"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.09029",
    "DOI": "arXiv:1909.09029v2",
    "Article_Title": "DIRE: A Neural Approach to Decompiled Identifier Naming",
    "Article_Abstract": "The decompiler is one of the most common tools for examining binaries withoutcorresponding source code. It transforms binaries into high-level code,reversing the compilation process. Decompilers can reconstruct much of theinformation that is lost during the compilation process (e.g., structure andtype information). Unfortunately, they do not reconstruct semanticallymeaningful variable names, which are known to increase code understandability.We propose the Decompiled Identifier Renaming Engine (DIRE), a novelprobabilistic technique for variable name recovery that uses both lexical andstructural information recovered by the decompiler. We also present a techniquefor generating corpora suitable for training and evaluating models ofdecompiled code renaming, which we use to create a corpus of 164,632 uniquex86-64 binaries generated from C projects mined from GitHub. Our results showthat on this corpus DIRE can predict variable names identical to the names inthe original source code up to 74.3% of the time.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/09/19",
    "Article_PDF": "https://arxiv.org/pdf/1909.09029"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.08766",
    "DOI": "arXiv:1909.08766v1",
    "Article_Title": "A High-Fidelity Open Embodied Avatar with Lip Syncing and Expression Capabilities",
    "Article_Abstract": "Embodied avatars as virtual agents have many applications and providebenefits over disembodied agents, allowing non-verbal social and interactionalcues to be leveraged, in a similar manner to how humans interact with eachother. We present an open embodied avatar built upon the Unreal Engine that canbe controlled via a simple python programming interface. The avatar has lipsyncing (phoneme control), head gesture and facial expression (using eitherfacial action units or cardinal emotion categories) capabilities. We releasecode and models to illustrate how the avatar can be controlled like a puppet orused to create a simple conversational agent using public applicationprogramming interfaces (APIs). GITHUB link:https://github.com/danmcduff/AvatarSim",
    "Article_Subject": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)",
    "Article_Date": "2019/09/19",
    "Article_PDF": "https://arxiv.org/pdf/1909.08766"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.06700",
    "DOI": "arXiv:1909.06700v1",
    "Article_Title": "Loam_livox: A fast, robust, high-precision LiDAR odometry and mapping package for LiDARs of small FoV",
    "Article_Abstract": "LiDAR odometry and mapping (LOAM) has been playing an important role inautonomous vehicles, due to its ability to simultaneously localize the robot'spose and build high-precision, high-resolution maps of the surroundingenvironment. This enables autonomous navigation and safe path planning ofautonomous vehicles. In this paper, we present a robust, real-time LOAMalgorithm for LiDARs with small FoV and irregular samplings. By taking efforton both front-end and back-end, we address several fundamental challengesarising from such LiDARs, and achieve better performance in both precision andefficiency compared to existing baselines. To share our findings and to makecontributions to the community, we open source our codes on Github",
    "Article_Subject": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/09/15",
    "Article_PDF": "https://arxiv.org/pdf/1909.06700"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.05983",
    "DOI": "arXiv:1909.05983v1",
    "Article_Title": "Content-Aware Unsupervised Deep Homography Estimation",
    "Article_Abstract": "Robust homography estimation between two images is a fundamental task whichhas been widely applied to various vision applications. Traditional featurebased methods often detect image features and fit a homography according tomatched features with RANSAC outlier removal. However, the quality ofhomography heavily relies on the quality of image features, which are prone toerrors with respect to low light and low texture images. On the other hand,previous deep homography approaches either synthesize images for supervisedlearning or adopt aerial images for unsupervised learning, both ignoring theimportance of depth disparities in homography estimation. Moreover, they treatthe image content equally, including regions of dynamic objects and near-rangeforegrounds, which further decreases the quality of estimation. In this work,to overcome such problems, we propose an unsupervised deep homography methodwith a new architecture design. We learn a mask during the estimation to rejectoutlier regions. In addition, we calculate loss with respect to our learneddeep features instead of directly comparing the image contents as didpreviously. Moreover, a comprehensive dataset is presented, covering bothregular and challenging cases, such as poor textures and non-planarinterferences. The effectiveness of our method is validated through comparisonswith both feature-based and previous deep-based methods. Code will be soonavailable at Github.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/12",
    "Article_PDF": "https://arxiv.org/pdf/1909.05983"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.05090",
    "DOI": "arXiv:1909.05090v1",
    "Article_Title": "DNANet: De-Normalized Attention Based Multi-Resolution Network for Human Pose Estimation",
    "Article_Abstract": "Recently, multi-resolution networks (such as Hourglass, CPN, HRNet, etc.)have achieved significant performance on the task of human pose estimation bycombining features from various resolutions. In this paper, we propose a noveltype of attention module, namely De-Normalized Attention (DNA) to deal with thefeature attenuations of conventional attention modules. Our method extends theoriginal HRNet with spatial, channel-wise and resolution-wise DNAs, which aimsat evaluating the importance of features from different locations, channels andresolutions to enhance the network capability for feature representation. Wealso propose to add fine-to-coarse connections across high-to-low resolutionsin-side each layer of HRNet to increase the maximum depth of network topology.In addition, we propose to modify the keypoint regressor at the end of HRNetfor accurate keypoint heatmap prediction. The effectiveness of our proposednetwork is demonstrated on COCO keypoint detection dataset, achievingstate-of-the-art performance at 76.9 AP score on COCO val2017 dataset withoutusing extra keypoint training data. Our paper will be accompanied with publiclyavailable codes at GitHub.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/09/11",
    "Article_PDF": "https://arxiv.org/pdf/1909.05090"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.04556",
    "DOI": "arXiv:1909.04556v1",
    "Article_Title": "Human Languages in Source Code: Auto-Translation for Localized Instruction",
    "Article_Abstract": "Computer science education has promised open access around the world, butaccess is largely determined by what human language you speak. As youngerstudents learn computer science it is less appropriate to assume that theyshould learn English beforehand. To that end we present CodeInternational, thefirst tool to translate code between human languages. To develop a theory ofnon-English code, and inform our translation decisions, we conduct a study ofpublic code repositories on GitHub. The study is to the best of our knowledgethe first on human-language in code and covers 2.9 million Java repositories.To demonstrate CodeInternational's educational utility, we build an interactiveversion of the popular English-language Karel reader and translate it into 100spoken languages. Our translations have already been used in classrooms aroundthe world, and represent a first step in an important open CS-educationproblem.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/09/10",
    "Article_PDF": "https://arxiv.org/pdf/1909.04556"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.04301",
    "DOI": "arXiv:1909.04301v1",
    "Article_Title": "Frequency domain variant of Velvet noise and its application to acoustic measurements",
    "Article_Abstract": "We propose a new family of test signals for acoustic measurements such asimpulse response, nonlinearity, and the effects of background noise. Theproposed family complements difficulties in existing families, the Swept-Sine(SS), pseudo-random noise such as the maximum length sequence (MLS). Theproposed family uses the frequency domain variant of the Velvet noise (FVN) asits building block. An FVN is an impulse response of an all-pass filter andyields the unit impulse when convolved with the time-reversed version ofitself. In this respect, FVN is a member of the time-stretched pulse (TSP) inthe broadest sense. The high degree of freedom in designing an FVN opens a vastrange of applications in acoustic measurement. We introduce the followingapplications and their specific procedures, among other possibilities. They areas follows. a) Spectrum shaping adaptive to background noise. b) Simultaneousmeasurement of impulse responses of multiple acoustic paths. d) Simultaneousmeasurement of linear and nonlinear components of an acoustic path. e)Automatic procedure for time axis alignment of the source and the receiver whenthey are using independent clocks in acoustic impulse response measurement. Weimplemented a reference measurement tool equipped with all these procedures.The MATLAB source code and related materials are open-sourced and placed in aGitHub repository.",
    "Article_Subject": "Audio and Speech Processing (eess.AS); Sound (cs.SD); Signal Processing (eess.SP)",
    "Article_Date": "2019/09/10",
    "Article_PDF": "https://arxiv.org/pdf/1909.04301"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.03650",
    "DOI": "arXiv:1909.03650v1",
    "Article_Title": "Real-time and interactive tools for vocal training based on an analytic signal with a cosine series envelope",
    "Article_Abstract": "We introduce real-time and interactive tools for assisting vocal training. Inthis presentation, we demonstrate mainly a tool based on real-time visualizerof fundamental frequency candidates to provide information-rich feedback tolearners. The visualizer uses an efficient algorithm using analytic signals forderiving phase-based attributes. We start using these tools in vocal trainingfor assisting learners to acquire the awareness of appropriate vocalization.The first author made the MATLAB implementation of the tools open-source. Thecode and associated video materials are accessible in the first author's GitHubrepository.",
    "Article_Subject": "Sound (cs.SD); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)",
    "Article_Date": "2019/09/09",
    "Article_PDF": "https://arxiv.org/pdf/1909.03650"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.03181",
    "DOI": "arXiv:1909.03181v2",
    "Article_Title": "Receding Horizon Control for Drinking Water Networks: The Case for Geometric Programming",
    "Article_Abstract": "Optimal, network-driven control of Water Distribution Network (WDN) is verydifficult: valve and pump models form non-trivial, combinatorial logic,hydraulic models are nonconvex, water demand patterns are uncertain, and WDNsare naturally large-scale. Prior research on control of WDNs addressed majorresearch challenges, yet mostly adopted simplified hydraulic models, WDNtopologies, and rudimentary valve/pump modeling.  The objective of this paper is to develop tractable computational algorithmsto manage WDN operation, while considering arbitrary topology, flow direction,an abundance of valve types, control objectives, hydraulic models, andoperational constraints. Specifically, we propose new Geometric Programming(GP)-based Model Predictive Control (MPC) algorithms, designed to solve thewater flow equations and obtain WDN controls---pump/valve schedules alongsideheads and flows. The proposed approach amounts to solving a series of convexoptimization problems that graciously scale to large networks. Under demanduncertainty, the proposed approach is tested using a 126-node network with manyvalves and pumps. The developed GP-based MPC algorithms, as well as thenumerical test results are all included on Github.",
    "Article_Subject": "Systems and Control (eess.SY); Optimization and Control (math.OC)",
    "Article_Date": "2019/09/07",
    "Article_PDF": "https://arxiv.org/pdf/1909.03181"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.03147",
    "DOI": "arXiv:1909.03147v1",
    "Article_Title": "Self Learning from Large Scale Code Corpus to Infer Structure of Method Invocations",
    "Article_Abstract": "Automatically generating code from a textual description of method invocationconfronts challenges. There were two current research directions for thisproblem. One direction focuses on considering a textual description of methodinvocations as a separate Natural Language query and do not consider thesurrounding context of the code. Another direction takes advantage of apractical large scale code corpus for providing a Machine Translation model togenerate code. However, this direction got very low accuracy. In this work, wetried to improve these drawbacks by proposing MethodInfoToCode, an approachthat embeds context information and optimizes the ability of learning oforiginal Phrase-based Statistical Machine Translation (PBMT) in NLP to inferimplementation of method invocation given method name and other contextinformation. We conduct an expression prediction models learned from 2.86million method invocations from the practical data of high qualities corpus onGithub that used 6 popular libraries: JDK, Android, GWT, Joda-Time, Hibernate,and Xstream. By the evaluation, we show that if the developers only write themethod name of a method invocation in a body of a method, MethodInfoToCode canpredict the generated expression correctly at 73% in F1 score.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/09/06",
    "Article_PDF": "https://arxiv.org/pdf/1909.03147"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.02548",
    "DOI": "arXiv:1909.02548v1",
    "Article_Title": "Explanation based Handwriting Verification",
    "Article_Abstract": "Deep learning system have drawback that their output is not accompanied withex-planation. In a domain such as forensic handwriting verification it isessential to provideexplanation to jurors. The goal of handwriting verificationis to find a measure of confi-dence whether the given handwritten samples arewritten by the same or different writer.We propose a method to generateexplanations for the confidence provided by convolu-tional neural network (CNN)which maps the input image to 15 annotations (features)provided by experts. Oursystem comprises of: (1) Feature learning network (FLN),a differentiablesystem, (2) Inference module for providing explanations. Furthermore,inferencemodule provides two types of explanations: (a) Based on cosinesimilaritybetween categorical probabilities of each feature, (b) Based onLog-Likelihood Ratio(LLR) using directed probabilistic graphical model. Weperform experiments using acombination of feature learning network (FLN) andeach inference module. We evaluateour system using XAI-AND dataset, containing13700 handwritten samples and 15 cor-responding expert examined features foreach sample. The dataset is released for publicuse and the methods can beextended to provide explanations on other verification taskslike faceverification and bio-medical comparison. This dataset can serve as the basisand benchmark for future research in explanation based handwritingverification. The code is available on github.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
    "Article_Date": "2019/08/14",
    "Article_PDF": "https://arxiv.org/pdf/1909.02548"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.02218",
    "DOI": "arXiv:1909.02218v1",
    "Article_Title": "A Better Way to Attend: Attention with Trees for Video Question Answering",
    "Article_Abstract": "We propose a new attention model for video question answering. The main ideaof the attention models is to locate on the most informative parts of thevisual data. The attention mechanisms are quite popular these days. However,most existing visual attention mechanisms regard the question as a whole. Theyignore the word-level semantics where each word can have different attentionsand some words need no attention. Neither do they consider the semanticstructure of the sentences. Although the Extended Soft Attention (E-SA) modelfor video question answering leverages the word-level attention, it performspoorly on long question sentences. In this paper, we propose the heterogeneoustree-structured memory network (HTreeMN) for video question answering. Ourproposed approach is based upon the syntax parse trees of the questionsentences. The HTreeMN treats the words differently where the \\textit{visual}words are processed with an attention module and the \\textit{verbal} ones not.It also utilizes the semantic structure of the sentences by combining theneighbors based on the recursive structure of the parse trees. Theunderstandings of the words and the videos are propagated and merged fromleaves to the root. Furthermore, we build a hierarchical attention mechanism todistill the attended features. We evaluate our approach on two datasets. Theexperimental results show the superiority of our HTreeMN model over the otherattention models especially on complex questions. Our code is available ongithub.  Our code is available at https://github.com/ZJULearning/TreeAttention",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Machine Learning (cs.LG)",
    "Article_Date": "2019/09/05",
    "Article_PDF": "https://arxiv.org/pdf/1909.02218"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.02203",
    "DOI": "arXiv:1909.02203v2",
    "Article_Title": "Elastic_HH: Tailored Elastic for Finding Heavy Hitters",
    "Article_Abstract": "Finding heavy hitters has been of vital importance in network measurement.Among all the recent works in finding heavy hitters, the Elastic sketchachieves the highest accuracy and fastest speed. However, we find that there isstill room for improvement of the Elastic sketch in finding heavy hitters. Inthis paper, we propose a tailored Elastic to enhance the sketch only forfinding heavy hitters at the cost of losing the generality of Elastic. Totailor Elastic, we abandon the light part, and improve the eviction strategy.Our experimental results show that compared with the standard Elastic, ourtailored Elastic reduces the error rate to 5.7~8.1 times and increases thespeed to 2.5 times. All the related source codes and datasets are available atGithub.",
    "Article_Subject": "Networking and Internet Architecture (cs.NI)",
    "Article_Date": "2019/09/05",
    "Article_PDF": "https://arxiv.org/pdf/1909.02203"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.01441",
    "DOI": "arXiv:1909.01441v1",
    "Article_Title": "CrossWeigh: Training Named Entity Tagger from Imperfect Annotations",
    "Article_Abstract": "Everyone makes mistakes. So do human annotators when curating labels fornamed entity recognition (NER). Such label mistakes might hurt model trainingand interfere model comparison. In this study, we dive deep into one of thewidely-adopted NER benchmark datasets, CoNLL03 NER. We are able to identifylabel mistakes in about 5.38% test sentences, which is a significant ratioconsidering that the state-of-the-art test F1 score is already around 93%.Therefore, we manually correct these label mistakes and form a cleaner testset. Our re-evaluation of popular models on this corrected test set leads tomore accurate assessments, compared to those on the original test set. Moreimportantly, we propose a simple yet effective framework, CrossWeigh, to handlelabel mistakes during NER model training. Specifically, it partitions thetraining data into several folds and train independent NER models to identifypotential mistakes in each fold. Then it adjusts the weights of training dataaccordingly to train the final NER model. Extensive experiments demonstratesignificant improvements of plugging various NER models into our proposedframework on three datasets. All implementations and corrected test set areavailable at our Github repo: https://github.com/ZihanWangKi/CrossWeigh.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/09/03",
    "Article_PDF": "https://arxiv.org/pdf/1909.01441"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.01377",
    "DOI": "arXiv:1909.01377v1",
    "Article_Title": "Deep Equilibrium Models",
    "Article_Abstract": "We present a new approach to modeling sequential data: the deep equilibriummodel (DEQ). Motivated by an observation that the hidden layers of manyexisting deep sequence models converge towards some fixed point, we propose theDEQ approach that directly finds these equilibrium points via root-finding.Such a method is equivalent to running an infinite depth (weight-tied)feedforward network, but has the notable advantage that we can analyticallybackpropagate through the equilibrium point using implicit differentiation.Using this approach, training and prediction in these networks require onlyconstant memory, regardless of the effective \"depth\" of the network. Wedemonstrate how DEQs can be applied to two state-of-the-art deep sequencemodels: self-attention transformers and trellis networks. On large-scalelanguage modeling tasks, such as the WikiText-103 benchmark, we show that DEQs1) often improve performance over these state-of-the-art models (for similarparameter counts); 2) have similar computational requirements as existingmodels; and 3) vastly reduce memory consumption (often the bottleneck fortraining large sequence models), demonstrating an up-to 88% memory reduction inour experiments. The code is available at https://github. com/locuslab/deq .",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/09/03",
    "Article_PDF": "https://arxiv.org/pdf/1909.01377"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.11527",
    "DOI": "arXiv:1908.11527v2",
    "Article_Title": "Implicit Deep Latent Variable Models for Text Generation",
    "Article_Abstract": "Deep latent variable models (LVM) such as variational auto-encoder (VAE) haverecently played an important role in text generation. One key factor is theexploitation of smooth latent structures to guide the generation. However, therepresentation power of VAEs is limited due to two reasons: (1) the Gaussianassumption is often made on the variational posteriors; and meanwhile (2) anotorious \"posterior collapse\" issue occurs. In this paper, we advocatesample-based representations of variational distributions for natural language,leading to implicit latent features, which can provide flexible representationpower compared with Gaussian-based posteriors. We further develop an LVM todirectly match the aggregated posterior to the prior. It can be viewed as anatural extension of VAEs with a regularization of maximizing mutualinformation, mitigating the \"posterior collapse\" issue. We demonstrate theeffectiveness and versatility of our models in various text generationscenarios, including language modeling, unaligned style transfer, and dialogresponse generation. The source code to reproduce our experimental results isavailable on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/30",
    "Article_PDF": "https://arxiv.org/pdf/1908.11527"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.10267",
    "DOI": "arXiv:1908.10267v2",
    "Article_Title": "DRD-Net: Detail-recovery Image Deraining via Context Aggregation Networks",
    "Article_Abstract": "Image deraining is a fundamental, yet not well-solved problem in computervision and graphics. The traditional image deraining approaches commonly behaveineffectively in medium and heavy rain removal, while the learning-based oneslead to image degradations such as the loss of image details, halo artifactsand/or color distortion. Unlike existing image deraining approaches that lackthe detail-recovery mechanism, we propose an end-to-end detail-recovery imagederaining network (termed a DRD-Net) for single images. We for the first timeintroduce two sub-networks with a comprehensive loss function which synergizeto derain and recover the lost details caused by deraining. We have three keycontributions. First, we present a rain residual network to remove rain streaksfrom the rainy images, which combines the squeeze-and-excitation (SE) operationwith residual blocks to make full advantage of spatial contextual information.Second, we design a new connection style block, named structure detail contextaggregation block (SDCAB), which aggregates context feature information and hasa large reception field. Third, benefiting from the SDCAB, we construct adetail repair network to encourage the lost details to return for eliminatingimage degradations. We have validated our approach on four recognized datasets(three synthetic and one real-world). Both quantitative and qualitativecomparisons show that our approach outperforms the state-of-the-art derainingmethods in terms of the deraining robustness and detail accuracy. The sourcecode has been available for public evaluation and use on GitHub.",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/27",
    "Article_PDF": "https://arxiv.org/pdf/1908.10267"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.09195",
    "DOI": "arXiv:1908.09195v1",
    "Article_Title": "Scalable Modeling of Spatiotemporal Data using the Variational Autoencoder: an Application in Glaucoma",
    "Article_Abstract": "As big spatial data becomes increasingly prevalent, classical spatiotemporal(ST) methods often do not scale well. While methods have been developed toaccount for high-dimensional spatial objects, the setting where there areexceedingly large samples of spatial observations has had less attention. Thevariational autoencoder (VAE), an unsupervised generative model based on deeplearning and approximate Bayesian inference, fills this void using a latentvariable specification that is inferred jointly across the large number ofsamples. In this manuscript, we compare the performance of the VAE with a moreclassical ST method when analyzing longitudinal visual fields from a largecohort of patients in a prospective glaucoma study. Through simulation and acase study, we demonstrate that the VAE is a scalable method for analyzing STdata, when the goal is to obtain accurate predictions. R code to implement theVAE can be found on GitHub: https://github.com/berchuck/vaeST.",
    "Article_Subject": "Applications (stat.AP); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/24",
    "Article_PDF": "https://arxiv.org/pdf/1908.09195"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08856",
    "DOI": "arXiv:1908.08856v1",
    "Article_Title": "Assessing Knee OA Severity with CNN attention-based end-to-end architectures",
    "Article_Abstract": "This work proposes a novel end-to-end convolutional neural network (CNN)architecture to automatically quantify the severity of knee osteoarthritis (OA)using X-Ray images, which incorporates trainable attention modules acting asunsupervised fine-grained detectors of the region of interest (ROI). Theproposed attention modules can be applied at different levels and scales acrossany CNN pipeline helping the network to learn relevant attention patterns overthe most informative parts of the image at different resolutions. We test theproposed attention mechanism on existing state-of-the-art CNN architectures asour base models, achieving promising results on the benchmark knee OA datasetsfrom the osteoarthritis initiative (OAI) and multicenter osteoarthritis study(MOST). All code from our experiments will be publicly available on the githubrepository: https://github.com/marc-gorriz/KneeOA-CNNAttention",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
    "Article_Date": "2019/08/23",
    "Article_PDF": "https://arxiv.org/pdf/1908.08856"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08584",
    "DOI": "arXiv:1908.08584v1",
    "Article_Title": "Feedbackward Decoding for Semantic Segmentation",
    "Article_Abstract": "We propose a novel approach for semantic segmentation that uses an encoder inthe reverse direction to decode. Many semantic segmentation networks adopt afeedforward encoder-decoder architecture. Typically, an input is firstdownsampled by the encoder to extract high-level semantic features andcontinues to be fed forward through the decoder module to recover low-levelspatial clues. Our method works in an alternative direction that letsinformation flow backward from the last layer of the encoder towards the first.The encoder performs encoding in the forward pass and the same network performsdecoding in the backward pass. Therefore, the encoder itself is also thedecoder. Compared to conventional encoder-decoder architectures, ours doesn'trequire additional layers for decoding and further reuses the encoder weightsthereby reducing the total number of parameters required for processing. Weshow by using only the 13 convolutional layers from VGG-16 plus one tinyclassification layer, our model significantly outperforms other frequentlycited models that are also adapted from VGG-16. On the Cityscapes semanticsegmentation benchmark, our model uses 50.0% less parameters than SegNet andachieves an 18.1% higher \"IoU class\" score; it uses 28.3% less parameters thanDeepLab LargeFOV and the achieved \"IoU class\" score is 3.9% higher; it uses89.1% fewer parameters than FCN-8s and the achieved \"IoU class\" score is 3.1%higher. Our code will be publicly available on Github later.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Image and Video Processing (eess.IV); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/22",
    "Article_PDF": "https://arxiv.org/pdf/1908.08584"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08196",
    "DOI": "arXiv:1908.08196v1",
    "Article_Title": "Unveiling Elite Developers' Activities in Open Source Projects",
    "Article_Abstract": "Open-source developers, particularly the elite developers, maintain a diverseportfolio of contributing activities. They do not only commit source code butalso spend a significant amount of effort on other communicative,organizational, and supportive activities. However, almost all prior researchfocuses on a limited number of specific activities and fails to analyze elitedevelopers' activities in a comprehensive way. To bridge this gap, we conductan empirical study with fine-grained event data from 20 large open-sourceprojects hosted on GitHub. Thus, we investigate elite developers' contributingactivities and their impacts on project outcomes. Our analyses reveal three keyfindings: (1) they participate in a variety of activities while technicalcontributions (e.g., coding) accounting for a small proportion only; (2) theytend to put more effort into supportive and communicative activities and lesseffort into coding as the project grows; (3) their participation innon-technical activities is negatively associated with the project's outcomesin term of productivity and software quality. These results provide a panoramicview of elite developers' activities and can inform an individual's decisionmaking about effort allocation, thus leading to finer project outcomes. Theresults also provide implications for supporting these elite developers.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/22",
    "Article_PDF": "https://arxiv.org/pdf/1908.08196"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08123",
    "DOI": "arXiv:1908.08123v3",
    "Article_Title": "Computing System Congestion Management Using Exponential Smoothing Forecasting",
    "Article_Abstract": "An overloaded computer must finish what it starts and not start what willfail or hang. A congestion management algorithm the author developed, andSiemens Corporation patented for telecom products, effectively manages trafficoverload with its unique formulation of Exponential Smoothing forecasting.Siemens filed for exclusive rights to this technique in 2003 and obtained USpatent US7301903B2 in 2007 with this author, an employee at the time of thefiling, the sole inventor. A computer program, written in C language, whichexercises the methodology is listed at the end of this document and availableon GitHub.",
    "Article_Subject": "Performance (cs.PF)",
    "Article_Date": "2019/08/21",
    "Article_PDF": "https://arxiv.org/pdf/1908.08123"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.07984",
    "DOI": "arXiv:1908.07984v1",
    "Article_Title": "Minimal residual multistep methods for large stiff non-autonomous linear problems",
    "Article_Abstract": "The purpose of this work is to introduce a new idea of how to avoid thefactorization of large matrices during the solution of stiff systems of ODEs.Starting from the general form of an explicit linear multistep method wesuggest to adaptively choose its coefficients on each integration step in orderto minimize the norm of the residual of an implicit BDF formula. Thereby wereduce the number of unknowns on each step from $n$ to $O(1)$, where $n$ is thedimension of the ODE system. We call this type of methods Minimal ResidualMultistep (MRMS) methods. In the case of linear non-autonomous problem, besidesthe evaluations of the right-hand side of ODE, the resulting numerical schemeadditionally requires one solution of a linear least-squares problem with athin matrix per step. We show that the order of the method and itszero-stability properties coincide with those of the used underlying BDFformula. For the simplest analog of the implicit Euler method the properties oflinear stability are investigated. Though the classical absolute stabilityanalysis is not fully relevant to the MRMS methods, it is shown that thisone-step method is applicable in stiff case. In the numerical experimentsection we consider the fixed-step integration of a two-dimensionalnon-autonomous heat equation using the MRMS methods and their classical BDFcounterparts. The starting values are taken from a preset slowly-varying exactsolution. The comparison showed that both methods give similar numericalsolutions, but in the case of large systems the MRMS methods are faster, andtheir advantage considerably increases with the growth of dimension. Pythoncode with the experimantal code can be downloaded from the GitHub repositoryhttps://github.com/bfaleichik/mrms.",
    "Article_Subject": "Numerical Analysis (math.NA)",
    "Article_Date": "2019/08/21",
    "Article_PDF": "https://arxiv.org/pdf/1908.07984"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.07883",
    "DOI": "arXiv:1908.07883v3",
    "Article_Title": "Scala Implicits are Everywhere: A large-scale study of the use of Implicits in the wild",
    "Article_Abstract": "The Scala programming language offers two distinctive language featuresimplicit parameters and implicit conversions, often referred together asimplicits. Announced without fanfare in 2004, implicits have quickly grown tobecome a widely and pervasively used feature of the language. They provide away to reduce the boilerplate code in Scala programs. They are also used toimplement certain language features without having to modify the compiler. Wereport on a large-scale study of the use of implicits in the wild. For this, weanalyzed 7,280 Scala projects hosted on GitHub, spanning over 8.1M call sitesinvolving implicits and 370.7K implicit declarations across 18.7M lines ofScala code.",
    "Article_Subject": "Programming Languages (cs.PL); Software Engineering (cs.SE)",
    "Article_Date": "2019/08/21",
    "Article_PDF": "https://arxiv.org/pdf/1908.07883"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.06473",
    "DOI": "arXiv:1908.06473v1",
    "Article_Title": "From Open Set to Closed Set: Counting Objects by Spatial Divide-and-Conquer",
    "Article_Abstract": "Visual counting, a task that predicts the number of objects from animage/video, is an open-set problem by nature, i.e., the number of populationcan vary in $[0,+\\infty)$ in theory. However, the collected images and labeledcount values are limited in reality, which means only a small closed set isobserved. Existing methods typically model this task in a regression manner,while they are likely to suffer from an unseen scene with counts out of thescope of the closed set. In fact, counting is decomposable. A dense region canalways be divided until sub-region counts are within the previously observedclosed set. Inspired by this idea, we propose a simple but effective approach,Spatial Divide-and- Conquer Network (S-DCNet). S-DCNet only learns from aclosed set but can generalize well to open-set scenarios via S-DC. S-DCNet isalso efficient. To avoid repeatedly computing sub-region convolutionalfeatures, S-DC is executed on the feature map instead of on the input image.S-DCNet achieves the state-of-the-art performance on three crowd countingdatasets (ShanghaiTech, UCF_CC_50 and UCF-QNRF), a vehicle counting dataset(TRANCOS) and a plant counting dataset (MTC). Compared to the previous bestmethods, S-DCNet brings a 20.2% relative improvement on the ShanghaiTech PartB, 20.9% on the UCF-QNRF, 22.5% on the TRANCOS and 15.1% on the MTC. Code hasbeen made available at: https://github. com/xhp-hust-2018-2011/S-DCNet.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/15",
    "Article_PDF": "https://arxiv.org/pdf/1908.06473"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.06412",
    "DOI": "arXiv:1908.06412v1",
    "Article_Title": "Characterizing the transition to Kotlin of Android apps: a study on F-Droid, Play Store and GitHub",
    "Article_Abstract": "Kotlin is a novel language that represents an alternative to Java, and hasbeen recently adopted as a first-class programming language for Androidapplications. Kotlin is achieving a significant diffusion among developers, andseveral studies have highlighted various advantages of the language whencompared to Java.  The objective of this paper is to analyze a set of open-source Android apps,to evaluate their transition to the Kotlin programming language throughouttheir lifespan and understand whether the adoption of Kotlin has impacts on thesuccess of Android apps.  We mined all the projects from the F-Droid repository of Android open-sourceapplications, and we found the corresponding projects on the official GooglePlay Store and on the GitHub platform. We defined a set of eight metrics toquantify the relevance of Kotlin code in the latest update and through allreleases of an application. Then, we statistically analyzed the correlationbetween the presence of Kotlin code in a project and popularity metrics minedfrom the platforms where the apps were released.  Of a set of 1232 projects that were updated after October 2017, near 20%adopted Kotlin and about 12% had more Kotlin code than Java; most of theprojects that adopted Kotlin quickly transitioned from Java to the newlanguage. The projects featuring Kotlin had on average higher popularitymetrics; a statistically significant correlation has been found between thepresence of Kotlin and the number of stars on the GitHub repository.  The Kotlin language seems able to guarantee a seamless migration from Javafor Android developers. With an inspection on a large set of open-sourceAndroid apps, we observed that the adoption of the Kotlin language is rapid(when compared to the average lifespan of an Android project) and seems to comeat no cost in terms of popularity among the users and other developers.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/18",
    "Article_PDF": "https://arxiv.org/pdf/1908.06412"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.06309",
    "DOI": "arXiv:1908.06309v1",
    "Article_Title": "ED2: Two-stage Active Learning for Error Detection -- Technical Report",
    "Article_Abstract": "Traditional error detection approaches require user-defined parameters andrules. Thus, the user has to know both the error detection system and the data.However, we can also formulate error detection as a semi-supervisedclassification problem that only requires domain expertise. The challenges forsuch an approach are twofold: (1) to represent the data in a way that enables aclassification model to identify various kinds of data errors, and (2) to pickthe most promising data values for learning. In this paper, we address thesechallenges with ED2, our new example-driven error detection method. First, wepresent a new two-dimensional multi-classifier sampling strategy for activelearning. Second, we propose novel multi-column features. The combinedapplication of these techniques provides fast convergence of the classificationtask with high detection accuracy. On several real-world datasets, ED2requires, on average, less than 1% labels to outperform existing errordetection approaches. This report extends the peer-reviewed paper \"ED2: A Casefor Active Learning in Error Detection\". All source code related to thisproject is available on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Databases (cs.DB); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/17",
    "Article_PDF": "https://arxiv.org/pdf/1908.06309"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05541",
    "DOI": "arXiv:1908.05541v1",
    "Article_Title": "Hamming Sentence Embeddings for Information Retrieval",
    "Article_Abstract": "In retrieval applications, binary hashes are known to offer significantimprovements in terms of both memory and speed. We investigate the compressionof sentence embeddings using a neural encoder-decoder architecture, which istrained by minimizing reconstruction error. Instead of employing the originalreal-valued embeddings, we use latent representations in Hamming space producedby the encoder for similarity calculations.  In quantitative experiments on several benchmarks for semantic similaritytasks, we show that our compressed hamming embeddings yield a comparableperformance to uncompressed embeddings (Sent2Vec, InferSent, Glove-BoW), atcompression ratios of up to 256:1. We further demonstrate that our modelstrongly decorrelates input features, and that the compressor generalizes wellwhen pre-trained on Wikipedia sentences. We publish the source code on Githuband all experimental results.",
    "Article_Subject": "Information Retrieval (cs.IR); Computation and Language (cs.CL); Machine Learning (cs.LG)",
    "Article_Date": "2019/08/15",
    "Article_PDF": "https://arxiv.org/pdf/1908.05541"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05437",
    "DOI": "arXiv:1908.05437v1",
    "Article_Title": "Massive Multi-Agent Data-Driven Simulations of the GitHub Ecosystem",
    "Article_Abstract": "Simulating and predicting planetary-scale techno-social systems poses heavycomputational and modeling challenges. The DARPA SocialSim program set thechallenge to model the evolution of GitHub, a large collaborativesoftware-development ecosystem, using massive multi-agent simulations. Wedescribe our best performing models and our agent-based simulation framework,which we are currently extending to allow simulating other planetary-scaletechno-social systems. The challenge problem measured participant's ability,given 30 months of meta-data on user activity on GitHub, to predict the nextmonths' activity as measured by a broad range of metrics applied to groundtruth, using agent-based simulation. The challenge required scaling to asimulation of roughly 3 million agents producing a combined 30 million actions,acting on 6 million repositories with commodity hardware. It was also importantto use the data optimally to predict the agent's next moves. We describe theagent framework and the data analysis employed by one of the winning teams inthe challenge. Six different agent models were tested based on a variety ofmachine learning and statistical methods. While no single method proved themost accurate on every metric, the broadly most successful sampled from astationary probability distribution of actions and repositories for each agent.Two reasons for the success of these agents were their use of a distinctcharacterization of each agent, and that GitHub users change their behaviorrelatively slowly.",
    "Article_Subject": "Multiagent Systems (cs.MA); Social and Information Networks (cs.SI)",
    "Article_Date": "2019/08/15",
    "Article_PDF": "https://arxiv.org/pdf/1908.05437"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05354",
    "DOI": "arXiv:1908.05354v2",
    "Article_Title": "Large-Scale-Exploit of GitHub Repository Metadata and Preventive Measures",
    "Article_Abstract": "When working with Git, a popular version-control system, email addresses arepart of the metadata for each individual commit. When those commits are pushedto remote hosting services like GitHub, those email addresses become visiblenot only to fellow developers, but also to malicious actors aiming to exploitthem.  As a part of our research we created a tool that leverages the publiclyavailable GitHub API to collect user data. Analysis of this data not only givesaccess to millions of email addresses in very little time, but is also powerfuland dense enough to create targeted phishing attacks posing a great threat toall GitHub users and their private, potentially sensitive data. Even worse,existing countermeasures fail to effectively protect against such exploits.  As a consequence and main conclusion of this paper, we suggest multiplepreventive measures that should be implemented as soon as possible. We alsoconsider it the duty of both companies like GitHub and well informed softwareengineers to inform fellow developers about the risk of exposing private emailaddresses in Git commits published publicly.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/08/14",
    "Article_PDF": "https://arxiv.org/pdf/1908.05354"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05097",
    "DOI": "arXiv:1908.05097v1",
    "Article_Title": "Causal discovery in heavy-tailed models",
    "Article_Abstract": "Causal questions are omnipresent in many scientific problems. While muchprogress has been made in the analysis of causal relationships between randomvariables, these methods are not well suited if the causal mechanisms manifestthemselves only in extremes. This work aims to connect the two fields of causalinference and extreme value theory. We define the causal tail coefficient thatcaptures asymmetries in the extremal dependence of two random variables. In thepopulation case, the causal tail coefficient is shown to reveal the causalstructure if the distribution follows a linear structural causal model. Thisholds even in the presence of latent common causes that have the same tailindex as the observed variables. Based on a consistent estimator of the causaltail coefficient, we propose a computationally highly efficient algorithm thatinfers causal structure from finitely many data. We prove that our methodconsistently estimates the causal order and compare it to otherwell-established and non-extremal approaches in causal discovery on syntheticdata. The code is available as an open-access R package on Github.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/08/14",
    "Article_PDF": "https://arxiv.org/pdf/1908.05097"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.04710",
    "DOI": "arXiv:1908.04710v1",
    "Article_Title": "metric-learn: Metric Learning Algorithms in Python",
    "Article_Abstract": "metric-learn is an open source Python package implementing supervised andweakly-supervised distance metric learning algorithms. As part ofscikit-learn-contrib, it provides a unified interface compatible withscikit-learn which allows to easily perform cross-validation, model selection,and pipelining with other machine learning estimators. metric-learn isthoroughly tested and available on PyPi under the MIT licence.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/13",
    "Article_PDF": "https://arxiv.org/pdf/1908.04710"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.04219",
    "DOI": "arXiv:1908.04219v1",
    "Article_Title": "How do Developers Promote Open Source Projects?",
    "Article_Abstract": "Open source projects have an increasing importance on modern softwaredevelopment. For this reason, these projects, as usual with commercial softwareprojects, should make use of promotion channels to communicate and establishcontact with users and contributors. In this article, we study the channelsused to promote a set of 100 popular GitHub projects. First, we reveal thatTwitter, user meetings, and blogs are the most common promotion channels usedby the studied projects. Second, we report a major difference between thestudied projects and a random sample of projects, regarding the use of theinvestigated promotion channels. Third, we show the importance of a popularnews aggregation site (Hacker News) on the promotion of open source. Weconclude by presenting a set of practical recommendation to open source projectmanagers and leaders, regarding the promotion of their projects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/12",
    "Article_PDF": "https://arxiv.org/pdf/1908.04219"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.03952",
    "DOI": "arXiv:1908.03952v2",
    "Article_Title": "Constraining new physics from Higgs measurements with Lilith: update to LHC Run 2 results",
    "Article_Abstract": "Lilith is a public Python library for constraining new physics from Higgssignal strength measurements. We here present version 2.0 of Lilith togetherwith an updated XML database which includes the current ATLAS and CMS Run 2Higgs results for 36/fb. Both the code and the database were extended from theordinary Gaussian approximation employed in Lilith-1.1 to using variableGaussian and Poisson likelihoods. Moreover, Lilith can now make use ofcorrelation matrices of arbitrary dimension. We provide detailed validations ofthe implemented experimental results as well as a status of global fits forreduced Higgs couplings, Two-Higgs-doublet models of Type I and Type II, andinvisible Higgs decays. Lilith-2.0 is available on GitHub and ready to be usedto constrain a wide class of new physics scenarios.",
    "Article_Subject": "High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Experiment (hep-ex)",
    "Article_Date": "2019/08/11",
    "Article_PDF": "https://arxiv.org/pdf/1908.03952"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.02320",
    "DOI": "arXiv:1908.02320v1",
    "Article_Title": "Do as I Do, Not as I Say: Do Contribution Guidelines Match the GitHub Contribution Process?",
    "Article_Abstract": "Developer contribution guidelines are used in social coding sites like GitHubto explain and shape the process a project expects contributors to follow. Theyset standards for all participants and \"save time and hassle caused byimproperly created pull requests or issues that have to be rejected andresubmitted\" (GitHub). Yet, we lack a systematic understanding of the contentof a typical contribution guideline, as well as the extent to which theseguidelines are followed in practice. Additionally, understanding how guidelinesmay impact projects that use Continuous Integration as part of the contributionprocess is of particular interest. To address this knowledge gap, we conducteda mixed-methods study of 53 GitHub projects with explicit contributionguidelines and coded the guidelines to extract key themes. We then created aprocess model using GitHub activity data (e.g., commit, new issue, new pullrequest) to compare the actual activity with the prescribed contributionguidelines. We show that approximately 68% of these projects divergesignificantly from the expected process.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/06",
    "Article_PDF": "https://arxiv.org/pdf/1908.02320"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.02116",
    "DOI": "arXiv:1908.02116v3",
    "Article_Title": "Teacher Supervises Students How to Learn From Partially Labeled Images for Facial Landmark Detection",
    "Article_Abstract": "Facial landmark detection aims to localize the anatomically defined points ofhuman faces. In this paper, we study facial landmark detection from partiallylabeled facial images. A typical approach is to (1) train a detector on thelabeled images; (2) generate new training samples using this detector'sprediction as pseudo labels of unlabeled images; (3) retrain the detector onthe labeled samples and partial pseudo labeled samples. In this way, thedetector can learn from both labeled and unlabeled data to become robust. Inthis paper, we propose an interaction mechanism between a teacher and twostudents to generate more reliable pseudo labels for unlabeled data, which arebeneficial to semi-supervised facial landmark detection. Specifically, the twostudents are instantiated as dual detectors. The teacher learns to judge thequality of the pseudo labels generated by the students and filter outunqualified samples before the retraining stage. In this way, the studentdetectors get feedback from their teacher and are retrained by premium datagenerated by itself. Since the two students are trained by different samples, acombination of their predictions will be more robust as the final predictioncompared to either prediction. Extensive experiments on 300-W and AFLWbenchmarks show that the interactions between teacher and students contributeto better utilization of the unlabeled data and achieves state-of-the-artperformance.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/06",
    "Article_PDF": "https://arxiv.org/pdf/1908.02116"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01711",
    "DOI": "arXiv:1908.01711v1",
    "Article_Title": "fgivenx: A Python package for functional posterior plotting",
    "Article_Abstract": "fgivenx is a Python package for functional posterior plotting, currently usedin astronomy, but will be of use to scientists performing any Bayesian analysiswhich has predictive posteriors that are functions. The source code for fgivenxis available on GitHub at https://github.com/williamjameshandley/fgivenx",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.01711"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01373",
    "DOI": "arXiv:1908.01373v2",
    "Article_Title": "Unsupervised Microvascular Image Segmentation Using an Active Contours Mimicking Neural Network",
    "Article_Abstract": "The task of blood vessel segmentation in microscopy images is crucial formany diagnostic and research applications. However, vessels can look vastlydifferent, depending on the transient imaging conditions, and collecting datafor supervised training is laborious. We present a novel deep learning methodfor unsupervised segmentation of blood vessels. The method is inspired by thefield of active contours and we introduce a new loss term, which is based onthe morphological Active Contours Without Edges (ACWE) optimization method. Therole of the morphological operators is played by novel pooling layers that areincorporated to the network's architecture. We demonstrate the challenges thatare faced by previous supervised learning solutions, when the imagingconditions shift. Our unsupervised method is able to outperform such previousmethods in both the labeled dataset, and when applied to similar but differentdatasets. Our code, as well as efficient PyTorch reimplementations of thebaseline methods VesselNN and DeepVess is available on GitHub -https://github.com/shirgur/UMIS.",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/04",
    "Article_PDF": "https://arxiv.org/pdf/1908.01373"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01242",
    "DOI": "arXiv:1908.01242v1",
    "Article_Title": "Kannada-MNIST: A new handwritten digits dataset for the Kannada language",
    "Article_Abstract": "In this paper, we disseminate a new handwritten digits-dataset, termedKannada-MNIST, for the Kannada script, that can potentially serve as a directdrop-in replacement for the original MNIST dataset. In addition to thisdataset, we disseminate an additional real world handwritten dataset (with$10k$ images), which we term as the Dig-MNIST dataset that can serve as anout-of-domain test dataset. We also duly open source all the code as well asthe raw scanned images along with the scanner settings so that researchers whowant to try out different signal processing pipelines can perform end-to-endcomparisons. We provide high level morphological comparisons with the MNISTdataset and provide baselines accuracies for the dataset disseminated. Theinitial baselines obtained using an oft-used CNN architecture ($96.8\\%$ for themain test-set and $76.1\\%$ for the Dig-MNIST test-set) indicate that thesedatasets do provide a sterner challenge with regards to generalizability thanMNIST or the KMNIST datasets. We also hope this dissemination will spur thecreation of similar datasets for all the languages that use different symbolsfor the numeral digits.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/03",
    "Article_PDF": "https://arxiv.org/pdf/1908.01242"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01031",
    "DOI": "arXiv:1908.01031v1",
    "Article_Title": "RuleKit: A Comprehensive Suite for Rule-Based Learning",
    "Article_Abstract": "Rule-based models are often used for data analysis as they combineinterpretability with predictive power. We present RuleKit, a versatile toolfor rule learning. Based on a sequential covering induction algorithm, it issuitable for classification, regression, and survival problems. The presence ofa user-guided induction facilitates verifying hypotheses concerning datadependencies which are expected or of interest. The powerful and flexibleexperimental environment allows straightforward investigation of differentinduction schemes. The analysis can be performed in batch mode, throughRapidMiner plug-in, or R package. A documented Java API is also provided forconvenience. The software is publicly available at GitHub under GNU AGPL-3.0license.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.01031"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.00867",
    "DOI": "arXiv:1908.00867v1",
    "Article_Title": "An Evaluation of Action Recognition Models on EPIC-Kitchens",
    "Article_Abstract": "We benchmark contemporary action recognition models (TSN, TRN, and TSM) onthe recently introduced EPIC-Kitchens dataset and release pretrained models onGitHub (https://github.com/epic-kitchens/action-models) for others to buildupon. In contrast to popular action recognition datasets like Kinetics,Something-Something, UCF101, and HMDB51, EPIC-Kitchens is shot from anegocentric perspective and captures daily actions in-situ. In this report, weaim to understand how well these models can tackle the challenges present inthis dataset, such as its long tail class distribution, unseen environment testset, and multiple tasks (verb, noun and, action classification). We discuss themodels' shortcomings and avenues for future research.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.00867"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.00717",
    "DOI": "arXiv:1908.00717v1",
    "Article_Title": "Lagrange2D: A Mathematica package for Lagrangian analysis of two-dimensional fluid flows",
    "Article_Abstract": "We introduce Lagrange2D, a Mathematica package for analysis andcharacterization of complex fluid flows using Lagrangian transport metrics.Lagrange2D includes built-in functions for integrating ensembles oftrajectories subject to time-varying two-dimensional flows, as well asutilities for calculating various quantities of interest, such as finite-timeLyapunov exponents, stretching vector fields, the fractal dimension, andflushing times. The package also includes tools for visualizing transport andpathlines, as well as for generating videos. This package aims to ease rapidcharacterization of arbitrary flows, by allowing identification of Lagrangiancoherent structures and other quantities of interest. The open-source code forthe package is available on GitHub at:\\url{https://github.com/williamgilpin/lagrange2d}",
    "Article_Subject": "Fluid Dynamics (physics.flu-dyn); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.00717"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.00614",
    "DOI": "arXiv:1908.00614v2",
    "Article_Title": "Learning to Identify Security-Related Issues Using Convolutional Neural Networks",
    "Article_Abstract": "Software security is becoming a high priority for both large companies andstart-ups alike due to the increasing potential for harm that vulnerabilitiesand breaches carry with them. However, attaining robust security assurancewhile delivering features requires a precarious balancing act in the context ofagile development practices. One path forward to help aid development teams insecuring their software products is through the design and development ofsecurity-focused automation. Ergo, we present a novel approach, calledSecureReqNet, for automatically identifying whether issues in software issuetracking systems describe security-related content. Our approach consists of atwo-phase neural net architecture that operates purely on the natural languagedescriptions of issues. The first phase of our approach learns high dimensionalword embeddings from hundreds of thousands of vulnerability descriptions listedin the CVE database and issue descriptions extracted from open source projects.The second phase then utilizes the semantic ontology represented by theseembeddings to train a convolutional neural network capable of predictingwhether a given issue is security-related. We evaluated SecureReqNet byapplying it to identify security-related issues from a dataset of thousands ofissues mined from popular projects on GitLab and GitHub. In addition, we alsoapplied our approach to identify security-related requirements from acommercial software project developed by a major telecommunication company. Ourpreliminary results are encouraging, with SecureReqNet achieving an accuracy of96% on open source issues and 71.6% on industrial requirements.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/01",
    "Article_PDF": "https://arxiv.org/pdf/1908.00614"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.13012",
    "DOI": "arXiv:1907.13012v1",
    "Article_Title": "An Empirical Study of GraphQL Schemas",
    "Article_Abstract": "GraphQL is a query language for APIs and a runtime to execute queries. UsingGraphQL queries, clients define precisely what data they wish to retrieve ormutate on a server, leading to fewer round trips and reduced response sizes.Although interest in GraphQL is on the rise, with increasing adoption at majororganizations, little is known about what GraphQL interfaces look like inpractice. This lack of knowledge makes it hard for providers to understand whatpractices promote idiomatic, easy-to-use APIs, and what pitfalls to avoid. Toaddress this gap, we study the design of GraphQL interfaces in practice byanalyzing their schemas - the descriptions of their exposed data types and thepossible operations on the underlying data. We base our study on two novelcorpuses of GraphQL schemas, one of 16 commercial GraphQL schemas and the otherof 8,399 GraphQL schemas mined from GitHub projects. We make both corpusesavailable to other researchers. Using these corpuses, we characterize the sizeof schemas and their use of GraphQL features and assess the use of bothprescribed and organic naming conventions. We also report that a majority ofAPIs are susceptible to denial of service through complex queries, posing realsecurity risks previously discussed only in theory. We also assess ways inwhich GraphQL APIs attempt to address these concerns.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/07/30",
    "Article_PDF": "https://arxiv.org/pdf/1907.13012"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.11017",
    "DOI": "arXiv:1907.11017v2",
    "Article_Title": "Particle Methods for Stochastic Differential Equation Mixed Effects Models",
    "Article_Abstract": "Parameter inference for stochastic differential equation mixed effects models(SDEMEMs) is a challenging problem. Analytical solutions for these models arerarely available, which means that the likelihood is also intractable. In thiscase, exact inference is possible using the pseudo-marginal method, where theintractable likelihood is replaced by its nonnegative unbiased estimate. Auseful application of this idea is particle MCMC, which uses a particle filterestimate of the likelihood. While the exact posterior is targeted by thesemethods, a naive implementation for SDEMEMs can be highly inefficient. Wedevelop three extensions to the naive approach which exploits specific aspectsof SDEMEMs and other advances such as correlated pseudo-marginal methods. Wecompare these methods on real and simulated data from a tumour xenography studyon mice.",
    "Article_Subject": "Computation (stat.CO); Methodology (stat.ME)",
    "Article_Date": "2019/07/25",
    "Article_PDF": "https://arxiv.org/pdf/1907.11017"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.10121",
    "DOI": "arXiv:1907.10121v1",
    "Article_Title": "SciPy 1.0--Fundamental Algorithms for Scientific Computing in Python",
    "Article_Abstract": "SciPy is an open source scientific computing library for the Pythonprogramming language. SciPy 1.0 was released in late 2017, about 16 years afterthe original version 0.1 release. SciPy has become a de facto standard forleveraging scientific algorithms in the Python programming language, with morethan 600 unique code contributors, thousands of dependent packages, over100,000 dependent repositories, and millions of downloads per year. Thisincludes usage of SciPy in almost half of all machine learning projects onGitHub, and usage by high profile projects including LIGO gravitational waveanalysis and creation of the first-ever image of a black hole (M87). Thelibrary includes functionality spanning clustering, Fourier transforms,integration, interpolation, file I/O, linear algebra, image processing,orthogonal distance regression, minimization algorithms, signal processing,sparse matrix handling, computational geometry, and statistics. In this work,we provide an overview of the capabilities and development practices of theSciPy library and highlight some recent technical developments.",
    "Article_Subject": "Mathematical Software (cs.MS); Data Structures and Algorithms (cs.DS); Software Engineering (cs.SE); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/07/23",
    "Article_PDF": "https://arxiv.org/pdf/1907.10121"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.09600",
    "DOI": "arXiv:1907.09600v2",
    "Article_Title": "Evaluation of Embeddings of Laboratory Test Codes for Patients at a Cancer Center",
    "Article_Abstract": "Laboratory test results are an important and generally high dimensionalcomponent of a patient's Electronic Health Record (EHR). We train embeddingrepresentations (via Word2Vec and GloVe) for LOINC codes of laboratory testsfrom the EHRs of about 80,000 patients at a cancer center. To includeinformation about lab test outcomes, we also train embeddings on theconcatenation of a LOINC code with a symbol indicating normality or abnormalityof the result. We observe several clinically meaningful similarities amongLOINC embeddings trained over our data. For the embeddings of the concatenationof LOINCs with abnormality codes, we evaluate the performance for mortalityprediction tasks and the ability to preserve ordinality properties: i.e. a labtest with normal outcome should be more similar to an abnormal one than to thea very abnormal one.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/22",
    "Article_PDF": "https://arxiv.org/pdf/1907.09600"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.08395",
    "DOI": "arXiv:1907.08395v2",
    "Article_Title": "Refractive Interstellar Scintillation of Extra-galactic Radio Sources I: Expectations",
    "Article_Abstract": "Surveys for transient and variable phenomena can be confounded by thepresence of extrinsic variability such as refractive interstellar scintillation(RISS). We have developed an all-sky model for RISS which can predictvariability on a variety of timescales, survey locations, and observingfrequencies. The model makes use of Halpha intensity maps to probe the emissionmeasure along the line of sight, convert this to a scattering measure, andfinally a scintillation strength. The model uses previously developed and longunderstood physics along with (indirect) measurements of the electron contentand distribution within the Milky Way. We develop a set of expectations thatare useful in the planning of future surveys for transient and radiovariability, and demonstrate that the 1-GHz sky is a poor predictor of thevariable nature of the $100$-MHz sky. Interestingly, the correlation betweenthe incidence of variability and Galactic latitude which has been seen at 1GHz,is reversed at 100MHz. We compare the predictions of our model to alow-frequency radio survey that was conducted with the Murchison WidefieldArray, and find good qualitative agreement. We discuss the implications,current limitations, and future development of the model. The model has beenimplemented in a Python code and is available on GitHub/Zenodo.",
    "Article_Subject": "Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/07/19",
    "Article_PDF": "https://arxiv.org/pdf/1907.08395"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.07951",
    "DOI": "arXiv:1907.07951v1",
    "Article_Title": "Automatic vocal tract landmark localization from midsagittal MRI data",
    "Article_Abstract": "The various speech sounds of a language are obtained by varying the shape andposition of the articulators surrounding the vocal tract. Analyzing theirvariability is crucial for understanding speech production, diagnosing speechand swallowing disorders and building intuitive applications forrehabilitation. Magnetic Resonance Imaging (MRI) is currently the most harmlesspowerful imaging modality used for this purpose. Identifying key anatomicallandmarks on it is a pre-requisite for further analyses. This is a challengingtask considering the high inter- and intra-speaker variability and the mutualinteraction between the articulators. This study intends to solve this issueautomatically for the first time. For this purpose, midsagittal anatomical MRIfor 9 speakers sustaining 62 articulations and annotated with the location of21 key anatomical landmarks are considered. Four state-of-the-art methods,including deep learning methods, are adapted from the literature for faciallandmark localization and human pose estimation and evaluated. Furthermore, anapproach based on the description of each landmark location as a heat-map imagestored in a channel of a single multi-channel image embedding all landmarks isproposed. The generation of such a multi-channel image from an input MRI imageis tested through two deep learning networks, one taken from the literature andone designed on purpose in this study, the flat-net. Results show that theflat-net approach outperforms the other methods, leading to an overall RootMean Square Error of 3.4~pixels/0.34~cm obtained in a leave-one-out procedureover the speakers. All of the codes are publicly available on GitHub.",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "Article_Date": "2019/07/18",
    "Article_PDF": "https://arxiv.org/pdf/1907.07951"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.06274",
    "DOI": "arXiv:1907.06274v1",
    "Article_Title": "Predicting Merge Conflicts in Collaborative Software Development",
    "Article_Abstract": "Background. During collaborative software development, developers often usebranches to add features or fix bugs. When merging changes from two branches,conflicts may occur if the changes are inconsistent. Developers need to resolvethese conflicts before completing the merge, which is an error-prone andtime-consuming process. Early detection of merge conflicts, which warnsdevelopers about resolving conflicts before they become large and complicated,is among the ways of dealing with this problem. Existing techniques do this bycontinuously pulling and merging all combinations of branches in the backgroundto notify developers as soon as a conflict occurs, which is a computationallyexpensive process. One potential way for reducing this cost is to use amachine-learning based conflict predictor that filters out the merge scenariosthat are not likely to have conflicts, ie safe merge scenarios. Aims. In thispaper, we assess if conflict prediction is feasible. Method. We design aclassifier for predicting merge conflicts, based on 9 light-weight Git featuresets. To evaluate our predictor, we perform a large-scale study on 267, 657merge scenarios from 744 GitHub repositories in seven programming languages.Results. Our results show that we achieve high f1-scores, varying from 0.95 to0.97 for different programming languages, when predicting safe merge scenarios.The f1-score is between 0.57 and 0.68 for the conflicting merge scenarios.Conclusions. Predicting merge conflicts is feasible in practice, especially inthe context of predicting safe merge scenarios as a pre-filtering step forspeculative merging.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/07/14",
    "Article_PDF": "https://arxiv.org/pdf/1907.06274"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.06146",
    "DOI": "arXiv:1907.06146v1",
    "Article_Title": "Satellite System Graph: Towards the Efficiency Up-Boundary of Graph-Based Approximate Nearest Neighbor Search",
    "Article_Abstract": "Approximate Nearest Neighbor Search (ANNS) in high dimensional space isessential in database and information retrieval. Recently, there has been asurge of interests in exploring efficient graph-based indices for the ANNSproblem. Among them, the NSG has resurrected the theory of Monotonic SearchNetworks (MSNET) and achieved the state-of-the-art performance. However, theperformance of the NSG deviates from a potentially optimal position due to thehigh sparsity of the graph. Specifically, though the average degree of thegraph is small, their search algorithm travels a longer way to reach the query.Integrating both factors, the total search complexity (i.e., the number ofdistance calculations) is not minimized as their wish. In addition, NSG suffersfrom a high indexing time complexity, which limits the efficiency and thescalability of their method. In this paper, we aim to further mine thepotential of the MSNETs. Inspired by the message transfer mechanism of thecommunication satellite system, we find a new family of MSNETs, namely theSatellite System Graphs (SSG). In particular, while inheriting the superiorANNS properties from the MSNET, we try to ensure the angles between the edgesto be no smaller than a given value. Consequently, each node in the graphbuilds effective connections to its neighborhood omnidirectionally, whichensures an efficient search-routing on the graph like the message transferamong the satellites. We also propose an approximation of the SSG, NavigatingSSG, to increase the efficiency of indexing. Both theoretical and extensiveexperimental analysis are provided to demonstrate the strengths of the proposedapproach over the existing state-of-the-art algorithms. Our code has beenreleased on GitHub.",
    "Article_Subject": "Information Retrieval (cs.IR); Databases (cs.DB)",
    "Article_Date": "2019/07/13",
    "Article_PDF": "https://arxiv.org/pdf/1907.06146"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.05062",
    "DOI": "arXiv:1907.05062v1",
    "Article_Title": "FIRE: Unsupervised bi-directional inter-modality registration using deep networks",
    "Article_Abstract": "Inter-modality image registration is an critical preprocessing step for manyapplications within the routine clinical pathway. This paper presents anunsupervised deep inter-modality registration network that can learn theoptimal affine and non-rigid transformations simultaneously.Inverse-consistency is an important property commonly ignored in recent deeplearning based inter-modality registration algorithms. We address this issuethrough the proposed multi-task architecture and the new comprehensivetransformation network. Specifically, the proposed model learns amodality-independent latent representation to perform cycle-consistentcross-modality synthesis, and use an inverse-consistent loss to learn a pair oftransformations to align the synthesized image with the target. We name thisproposed framework as FIRE due to the shape of its structure. Our method showscomparable and better performances with the popular baseline method inexperiments on multi-sequence brain MR data and intra-modality 4D cardiacCine-MR data.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/07/11",
    "Article_PDF": "https://arxiv.org/pdf/1907.05062"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04908",
    "DOI": "arXiv:1907.04908v1",
    "Article_Title": "Executability of Python Snippets in Stack Overflow",
    "Article_Abstract": "Online resources today contain an abundant amount of code snippets fordocumentation, collaboration, learning, and problem-solving purposes. Theirexecutability in a \"plug and play\" manner enables us to confirm their qualityand use them directly in projects. But, in practice that is often not the casedue to several requirements violations or incompleteness. However, it is adifficult task to investigate the executability on a large scale due todifferent possible errors during the execution. We have developed a scalableframework to investigate this for SOTorrent Python snippets. We found that withminor adjustments, 27.92% of snippets are executable. The executability has notchanged significantly over time. The code snippets referenced in GitHub aremore likely to be directly executable. But executability does not affect thechances of the answer to be selected as the accepted answer significantly.These properties help us understand and improve the interaction of users withonline resources that include code snippets.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/07/10",
    "Article_PDF": "https://arxiv.org/pdf/1907.04908"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04527",
    "DOI": "arXiv:1907.04527v1",
    "Article_Title": "Dynamics of Team Library Adoptions: An Exploration of GitHub Commit Logs",
    "Article_Abstract": "When a group of people strives to understand new information, struggle ensuesas various ideas compete for attention. Steep learning curves are surmounted asteams learn together. To understand how these team dynamics play out insoftware development, we explore Git logs, which provide a complete changehistory of software repositories. In these repositories, we observe codeadditions, which represent successfully implemented ideas, and code deletions,which represent ideas that have failed or been superseded. By examining thepatterns between these commit types, we can begin to understand how teams adoptnew information. We specifically study what happens after a software library isadopted by a project, i.e., when a library is used for the first time in theproject. We find that a variety of factors, including team size, librarypopularity, and prevalence on Stack Overflow are associated with how quicklyteams learn and successfully adopt new software libraries.",
    "Article_Subject": "Social and Information Networks (cs.SI); Software Engineering (cs.SE)",
    "Article_Date": "2019/07/10",
    "Article_PDF": "https://arxiv.org/pdf/1907.04527"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04433",
    "DOI": "arXiv:1907.04433v1",
    "Article_Title": "GluonCV and GluonNLP: Deep Learning in Computer Vision and Natural Language Processing",
    "Article_Abstract": "We present GluonCV and GluonNLP, the deep learning toolkits for computervision and natural language processing based on Apache MXNet (incubating).These toolkits provide state-of-the-art pre-trained models, training scripts,and training logs, to facilitate rapid prototyping and promote reproducibleresearch. We also provide modular APIs with flexible building blocks to enableefficient customization. Leveraging the MXNet ecosystem, the deep learningmodels in GluonCV and GluonNLP can be deployed onto a variety of platforms withdifferent programming languages. Benefiting from open source under the Apache2.0 license, GluonCV and GluonNLP have attracted 100 contributors worldwide onGitHub. Models of GluonCV and GluonNLP have been downloaded for more than 1.6million times in fewer than 10 months.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/09",
    "Article_PDF": "https://arxiv.org/pdf/1907.04433"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04002",
    "DOI": "arXiv:1907.04002v1",
    "Article_Title": "Characterizing Bitcoin donations to open source software on GitHub",
    "Article_Abstract": "Web-based hosting services for version control, such as GitHub, have made iteasier for people to develop, share, and donate money to software repositories.In this paper, we study the use of Bitcoin to make donations to open sourcerepositories on GitHub. In particular, we analyze the amount and volume ofdonations over time, in addition to its relationship to the age and popularityof a repository.  We scanned over three million repositories looking for donation addresses. Wethen extracted and analyzed their transactions from Bitcoin's publicblockchain. Overall, we found a limited adoption of Bitcoin as a payment methodfor receiving donations, with nearly 44 thousand deposits adding up to only 8.3million dollars in the last 10 years. We also found weak positive correlationbetween the amount of donations in dollars and the popularity of a repository,with highest correlation (r=0.013) associated with number of forks.",
    "Article_Subject": "Computers and Society (cs.CY); Cryptography and Security (cs.CR)",
    "Article_Date": "2019/07/09",
    "Article_PDF": "https://arxiv.org/pdf/1907.04002"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03892",
    "DOI": "arXiv:1907.03892v5",
    "Article_Title": "Fast Visual Object Tracking with Rotated Bounding Boxes",
    "Article_Abstract": "In this paper, we demonstrate a novel algorithm that uses ellipse fitting toestimate the bounding box rotation angle and size with the segmentation(mask)on the target for online and real-time visual object tracking. Our method,SiamMask_E, improves the bounding box fitting procedure of the state-of-the-artobject tracking algorithm SiamMask and still retains a fast-tracking frame rate(80 fps) on a system equipped with GPU (GeForce GTX 1080 Ti or higher). Wetested our approach on the visual object tracking datasets (VOT2016, VOT2018,and VOT2019) that were labeled with rotated bounding boxes. By comparing withthe original SiamMask, we achieved an improved Accuracy of 0.652 and 0.309 EAOon VOT2019, which is 0.056 and 0.026 higher than the original SiamMask. Theimplementation is available on GitHub:https://github.com/baoxinchen/siammask_e.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/07/08",
    "Article_PDF": "https://arxiv.org/pdf/1907.03892"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03660",
    "DOI": "arXiv:1907.03660v2",
    "Article_Title": "Can Dark Matter be Geometry? A Case Study with Mimetic Dark Matter",
    "Article_Abstract": "We investigate the possibility of dark matter being a pure geometricaleffect, rather than a particle or a compact object, by exploring a specificmodified gravity model: mimetic dark matter. We present an alternativeformulation of the theory, closer to the standard cosmological perturbationtheory framework. We make manifest the presence of arbitrary parameters andextra functions, both at background level and at first order in perturbationtheory. We present the full set of independent equations of motion for thismodel, and we discuss the amount of tuning needed to match predictions of thetheory to actual data. By using the matter power spectrum and cosmic microwavebackground angular power spectra as benchmark observables, we explicitly showthat since there is no natural mechanism to generate adiabatic initialconditions in this specific model, extra fine-tuning is required. We modify thepublicly available Boltzmann code \\texttt{CLASS} to make accurate predictionsfor the observables in mimetic dark matter. Our modified version of\\texttt{CLASS} is available on GitHub. We have used mimetic dark matter as anillustration of how much one is allowed to change the initial conditions beforecontradicting observations when modifying the laws of gravity as described byGeneral Relativity but we point out that modifying gravity without providing anatural mechanism to generate adiabatic initial conditions will always lead tohighly fine-tuned models.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); General Relativity and Quantum Cosmology (gr-qc); High Energy Physics - Theory (hep-th)",
    "Article_Date": "2019/07/08",
    "Article_PDF": "https://arxiv.org/pdf/1907.03660"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03407",
    "DOI": "arXiv:1907.03407v1",
    "Article_Title": "On The Lag of Library Vulnerability Updates: An Investigation into the Repackage and Delivery of Security Fixes Within The npm JavaScript Ecosystem",
    "Article_Abstract": "Vulnerabilities in third-party libraries is a growing concern for thesoftware developer, as it poses risks not only to the software client itselfbut to the entire software ecosystem. To mitigate these risks, developers arestrongly recommended to update their dependencies. Recent studies show thataffected developers are not likely to respond to the vulnerability threat.However, another reason for the lag of vulnerability updates is due to slowrepackaging (i.e., package the vulnerability fix into a new version) anddelivery (i.e., affected client adopt the new version) of the fix. Tounderstand these lags of updates, we use both qualitative and quantitativeapproaches to conduct an empirical study on how 188 fixes were repackaged anddelivered across over eight hundred thousand releases of npm software clientshosted on GitHub. We report two lags: (1) lags in repackaging occur asvulnerability fixes are more likely to be bundled with other non-relatedupdates (i.e., about 83.33\\% of commits are not related to the fix) and (2)lags in the delivery are caused by clients that are more likely to adopt theminor fix than adopt the patch fix. Furthermore, other factors such asdownstream dependencies and severity do have an impact. We also find thatfreshness of packages does not impact the amount of lags. The identification ofthese two lags opens up different avenues on how to facilitate faster fixdelivery throughout a library ecosystem.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/07/08",
    "Article_PDF": "https://arxiv.org/pdf/1907.03407"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03187",
    "DOI": "arXiv:1907.03187v1",
    "Article_Title": "Applying a Pre-trained Language Model to Spanish Twitter Humor Prediction",
    "Article_Abstract": "Our entry into the HAHA 2019 Challenge placed $3^{rd}$ in the classificationtask and $2^{nd}$ in the regression task. We describe our system andinnovations, as well as comparing our results to a Naive Bayes baseline. Alarge Twitter based corpus allowed us to train a language model from scratchfocused on Spanish and transfer that knowledge to our competition model. Toovercome the inherent errors in some labels we reduce our class confidence withlabel smoothing in the loss function. All the code for our project is includedin a GitHub repository for easy reference and to enable replication by others.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/07/06",
    "Article_PDF": "https://arxiv.org/pdf/1907.03187"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.02862",
    "DOI": "arXiv:1907.02862v1",
    "Article_Title": "Essential Motor Cortex Signal Processing: an ERP and functional connectivity MATLAB toolbox -- User Guide",
    "Article_Abstract": "The purpose of this document is to help individuals use the \"Essential MotorCortex Signal Processing MATLAB Toolbox\". The toolbox implements variousmethods for three major aspects of investigating human motor cortex fromNeuroscience view point: (1) ERP estimation and quantification, (2) CorticalFunctional Connectivity analysis and (3) EMG quantification. The toolbox --which is distributed under the terms of the GNU GENERAL PUBLIC LICENSE as a setof MATLAB R routines -- can be downloaded directly at the address:http://oset.ir/category.php?dir=Tools or from the public repository on GitHub,at address below: https://github.com/EsiSeraj/ERP Connectivity EMG Analysis  The purpose of this toolbox is threefold: 1. Extract theevent-related-potential (ERP) from preprocessed cerebral signals (i.e. EEG,MEG, etc.), identify and then quantify the event-relatedsynchronization/desynchronization (ERS/ERD) events. Both time-course dynamicsand time-frequency (TF) analyzes are included. 2. Measure, quantify anddemonstrate the cortical functional connectivity (CFC) across scalp electrodes.These set of functions can also be applied to various types of cerebral signals(i.e. electric and magnetic). 3. Quantify electromyogram (EMG) recorded fromactive muscles during performing motor tasks.",
    "Article_Subject": "Signal Processing (eess.SP); Computational Engineering, Finance, and Science (cs.CE); Image and Video Processing (eess.IV); Neurons and Cognition (q-bio.NC); Quantitative Methods (q-bio.QM)",
    "Article_Date": "2019/06/15",
    "Article_PDF": "https://arxiv.org/pdf/1907.02862"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.02202",
    "DOI": "arXiv:1907.02202v1",
    "Article_Title": "SEntiMoji: An Emoji-Powered Learning Approach for Sentiment Analysis in Software Engineering",
    "Article_Abstract": "Sentiment analysis has various application scenarios in software engineering(SE), such as detecting developers' emotions in commit messages and identifyingtheir opinions on Q&A forums. However, commonly used out-of-the-box sentimentanalysis tools cannot obtain reliable results on SE tasks and themisunderstanding of technical jargon is demonstrated to be the main reason.Then, researchers have to utilize labeled SE-related texts to customizesentiment analysis for SE tasks via a variety of algorithms. However, thescarce labeled data can cover only very limited expressions and thus cannotguarantee the analysis quality. To address such a problem, we turn to theeasily available emoji usage data for help. More specifically, we employemotional emojis as noisy labels of sentiments and propose a representationlearning approach that uses both Tweets and GitHub posts containing emojis tolearn sentiment-aware representations for SE-related texts. These emoji-labeledposts can not only supply the technical jargon, but also incorporate moregeneral sentiment patterns shared across domains. They as well as labeled dataare used to learn the final sentiment classifier. Compared to the existingsentiment analysis methods used in SE, the proposed approach can achievesignificant improvement on representative benchmark datasets. By furthercontrast experiments, we find that the Tweets make a key contribution to thepower of our approach. This finding informs future research not to unilaterallypursue the domain-specific resource, but try to transform knowledge from theopen domain through ubiquitous signals such as emojis.",
    "Article_Subject": "Software Engineering (cs.SE); Computation and Language (cs.CL)",
    "Article_Date": "2019/07/04",
    "Article_PDF": "https://arxiv.org/pdf/1907.02202"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00903",
    "DOI": "arXiv:1907.00903v1",
    "Article_Title": "Resolving the Multiple Withdrawal Attack on ERC20 Tokens",
    "Article_Abstract": "Custom tokens are an integral component of decentralized applications (dapps)deployed on Ethereum and other blockchain platforms. For Ethereum, the ERC20standard is a widely used token interface and is interoperable with manyexisting dapps, user interface platforms, and popular web applications (e.g.,exchange services). An ERC20 security issue, known as the \"multiple withdrawalattack\", was raised on GitHub and has been open since November 2016. The issueconcerns ERC20's defined method approve() which was envisioned as a way fortoken holders to give permission for other users and dapps to withdraw a cappednumber of tokens. The security issue arises when a token holder wants to adjustthe amount of approved tokens from N to M (this could be an increase ordecrease). If malicious, a user or dapp who is approved for N tokens canfront-run the adjustment transaction to first withdraw N tokens, then allow theapproval to be confirmed, and withdraw an additional M tokens. In this paper,we evaluate 10 proposed mitigations for this issues and find that no solutionis fully satisfactory. We then propose 2 new solutions that mitigate theattack, one of which fully fulfills constraints of the standard, and the secondone shows a general limitation in addressing this issue from ERC20's approvemethod.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00903"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00863",
    "DOI": "arXiv:1907.00863v1",
    "Article_Title": "Understanding GCC Builtins to Develop Better Tools",
    "Article_Abstract": "C programs can use compiler builtins to provide functionality that the Clanguage lacks. On Linux, GCC provides several thousands of builtins that arealso supported by other mature compilers, such as Clang and ICC. Maintainers ofother tools lack guidance on whether and which builtins should be implementedto support popular projects. To assist tool developers who want to support GCCbuiltins, we analyzed builtin use in 4,913 C projects from GitHub. We foundthat 37% of these projects relied on at least one builtin. Supporting anincreasing proportion of projects requires support of an exponentiallyincreasing number of builtins; however, implementing only 10 builtins alreadycovers over 30% of the projects. Since we found that many builtins in ourcorpus remained unused, the effort needed to support 90% of the projects ismoderate, requiring about 110 builtins to be implemented. For each project, weanalyzed the evolution of builtin use over time and found that the majority ofprojects mostly added builtins. This suggests that builtins are not a legacyfeature and must be supported in future tools. Systematic testing of builtinsupport in existing tools revealed that many lacked support for builtins eitherpartially or completely; we also discovered incorrect implementations invarious tools, including the formally verified CompCert compiler.",
    "Article_Subject": "Programming Languages (cs.PL); Software Engineering (cs.SE)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00863"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00652",
    "DOI": "arXiv:1907.00652v1",
    "Article_Title": "Avoiding Implementation Pitfalls of \"Matrix Capsules with EM Routing\" by Hinton et al",
    "Article_Abstract": "The recent progress on capsule networks by Hinton et al. has generatedconsiderable excitement in the machine learning community. The idea behind acapsule is inspired by a cortical minicolumn in the brain, whereby a verticallyorganised group of around 100 neurons receive common inputs, have commonoutputs, are interconnected, and may well constitute a fundamental computationunit of the cerebral cortex. However, Hinton's paper on \"Matrix Capsule with EMRouting'\" was unfortunately not accompanied by a release of source code, whichleft interested researchers attempting to implement the architecture andreproduce the benchmarks on their own. This has certainly slowed the progressof research building on this work. While writing our own implementation, wenoticed several common mistakes in other open source implementations that wecame across. In this paper we share some of these learnings, specificallyfocusing on three implementation pitfalls and how to avoid them: (1) parentcapsules with only one child; (2) normalising the amount of data assigned toparent capsules; (3) parent capsules at different positions compete for childcapsules. While our implementation is a considerable improvement over currentlyavailable implementations, it still falls slightly short of the performancereported by Hinton et al. (2018). The source code for this implementation isavailable on GitHub at the following URL:https://github.com/IBM/matrix-capsules-with-em-routing.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00652"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00558",
    "DOI": "arXiv:1907.00558v1",
    "Article_Title": "Improved Forecasting of Cryptocurrency Price using Social Signals",
    "Article_Abstract": "Social media signals have been successfully used to develop large-scalepredictive and anticipatory analytics. For example, forecasting stock marketprices and influenza outbreaks. Recently, social data has been explored toforecast price fluctuations of cryptocurrencies, which are a novel disruptivetechnology with significant political and economic implications. In this paperwe leverage and contrast the predictive power of social signals, specificallyuser behavior and communication patterns, from multiple social platforms GitHuband Reddit to forecast prices for three cyptocurrencies with high developer andcommunity interest - Bitcoin, Ethereum, and Monero. We evaluate the performanceof neural network models that rely on long short-term memory units (LSTMs)trained on historical price data and social data against price only LSTMs andbaseline autoregressive integrated moving average (ARIMA) models, commonly usedto predict stock prices. Our results not only demonstrate that social signalsreduce error when forecasting daily coin price, but also show that the languageused in comments within the official communities on Reddit (r/Bitcoin,r/Ethereum, and r/Monero) are the best predictors overall. We observe thatmodels are more accurate in forecasting price one day ahead for Bitcoin (4%root mean squared percent error) compared to Ethereum (7%) and Monero (8%).",
    "Article_Subject": "Statistical Finance (q-fin.ST); Machine Learning (cs.LG); Social and Information Networks (cs.SI); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00558"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.11976",
    "DOI": "arXiv:1906.11976v1",
    "Article_Title": "Multivariate Big Data Analysis for Intrusion Detection: 5 steps from the haystack to the needle",
    "Article_Abstract": "The research literature on cybersecurity incident detection & response isvery rich in automatic detection methodologies, in particular those based onthe anomaly detection paradigm. However, very little attention has been devotedto the diagnosis ability of the methods, aimed to provide useful information onthe causes of a given detected anomaly. This information is of utmostimportance for the security team to reduce the time from detection to response.In this paper, we present Multivariate Big Data Analysis (MBDA), a completeintrusion detection approach based on 5 steps to effectively handle massiveamounts of disparate data sources. The approach has been designed to deal withthe main characteristics of Big Data, that is, the high volume, velocity andvariety. The core of the approach is the Multivariate Statistical NetworkMonitoring (MSNM) technique proposed in a recent paper. Unlike in state of theart machine learning methodologies applied to the intrusion detection problem,when an anomaly is identified in MBDA the output of the system includes thedetail of the logs of raw information associated to this anomaly, so that thesecurity team can use this information to elucidate its root causes. MBDA isbased in two open software packages available in Github: the MEDA Toolbox andthe FCParser. We illustrate our approach with two case studies. The first onedemonstrates the application of MBDA to semistructured sources of information,using the data from the VAST 2012 mini challenge 2. This complete case study issupplied in a virtual machine available for download. In the second case studywe show the Big Data capabilities of the approach in data collected from a realnetwork with labeled attacks.",
    "Article_Subject": "Networking and Internet Architecture (cs.NI); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Other Statistics (stat.OT)",
    "Article_Date": "2019/06/27",
    "Article_PDF": "https://arxiv.org/pdf/1906.11976"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.11565",
    "DOI": "arXiv:1906.11565v2",
    "Article_Title": "EmotionX-KU: BERT-Max based Contextual Emotion Classifier",
    "Article_Abstract": "We propose a contextual emotion classifier based on a transferable languagemodel and dynamic max pooling, which predicts the emotion of each utterance ina dialogue. A representative emotion analysis task, EmotionX, requires toconsider contextual information from colloquial dialogues and to deal with aclass imbalance problem. To alleviate these problems, our model leverages theself-attention based transferable language model and the weighted cross entropyloss. Furthermore, we apply post-training and fine-tuning mechanisms to enhancethe domain adaptability of our model and utilize several machine learningtechniques to improve its performance. We conduct experiments on twoemotion-labeled datasets named Friends and EmotionPush. As a result, our modeloutperforms the previous state-of-the-art model and also shows competitiveperformance in the EmotionX 2019 challenge. The code will be available in theGithub page.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/06/27",
    "Article_PDF": "https://arxiv.org/pdf/1906.11565"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.11017",
    "DOI": "arXiv:1906.11017v1",
    "Article_Title": "A project-based course on software development for (engineering) research",
    "Article_Abstract": "This paper describes the motivation and design of a 10-week graduate coursethat teaches practices for developing research software; although offered by anengineering program, the content applies broadly to any field of scientificresearch where software may be developed. Topics taught in the course includelocal and remote version control, licensing and copyright, structuring Pythonmodules, testing and test coverage, continuous integration, packaging anddistribution, open science, software citation, and reproducibility basics,among others. Lectures are supplemented by in-class activities and discussions,and all course material is shared openly via GitHub. Coursework is heavilybased on a single, term-long project where students individually develop asoftware package targeted at their own research topic; all contributions mustbe submitted as pull requests and reviewed/merged by other students. The coursewas initially offered in Spring 2018 with 17 students enrolled, and will betaught again in Spring 2019.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/06/13",
    "Article_PDF": "https://arxiv.org/pdf/1906.11017"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.10506",
    "DOI": "arXiv:1906.10506v1",
    "Article_Title": "GaussPy+: A fully automated Gaussian decomposition package for emission line spectra",
    "Article_Abstract": "Our understanding of the dynamics of the interstellar medium is informed bythe study of the detailed velocity structure of emission line observations. Oneapproach to study the velocity structure is to decompose the spectra intoindividual velocity components; this leads to a description of the dataset thatis significantly reduced in complexity. However, this decomposition requiresfull automation lest it becomes prohibitive for large datasets, such asGalactic plane surveys. We developed GaussPy+, a fully automated Gaussiandecomposition package that can be applied to emission line datasets, especiallylarge surveys of HI and isotopologues of CO. We built our package upon theexisting GaussPy algorithm and significantly improved its performance for noisydata. New functionalities of GaussPy+ include: i) automated preparatory steps,such as an accurate noise estimation, which can also be used as standaloneapplications; ii) an improved fitting routine; iii) an automated spatialrefitting routine that can add spatial coherence to the decomposition resultsby refitting spectra based on neighbouring fit solutions. We thoroughly testedthe performance of GaussPy+ on synthetic spectra and a test field from theGalactic Ring Survey. We found that GaussPy+ can deal with cases of complexemission and even low to moderate signal-to-noise values.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Astrophysics of Galaxies (astro-ph.GA)",
    "Article_Date": "2019/06/25",
    "Article_PDF": "https://arxiv.org/pdf/1906.10506"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.10362",
    "DOI": "arXiv:1906.10362v1",
    "Article_Title": "EVulHunter: Detecting Fake Transfer Vulnerabilities for EOSIO's Smart Contracts at Webassembly-level",
    "Article_Abstract": "As one of the representative Delegated Proof-of-Stake (DPoS) blockchainplatforms, EOSIO's ecosystem grows rapidly in recent years. A number ofvulnerabilities and corresponding attacks of EOSIO's smart contracts have beendiscovered and observed in the wild, which caused a large amount of financialdamages. However, the majority of EOSIO's smart contracts are not open-sourced.As a result, the WebAssembly code may become the only available object to beanalyzed in most cases. Unfortunately, current tools are web-applicationoriented and cannot be applied to EOSIO WebAssembly code directly, which makesit more difficult to detect vulnerabilities from those smart contracts. In thispaper, we propose \\toolname, a static analysis tool that can be used to detectvulnerabilities from EOSIO WASM code automatically. We focus on one particulartype of vulnerabilities named \\textit{fake-transfer}, and the exploitation ofsuch vulnerabilities has led to millions of dollars in damages. To the best ofour knowledge, it is the first attempt to build an automatic tool to detectvulnerabilities of EOSIO's smart contracts. The experimental resultsdemonstrate that our tool is able to detect fake transfer vulnerabilitiesquickly and precisely. EVulHunter is available on GitHub\\footnote{Tool andbenchmarks: https://github.com/EVulHunter/EVulHunter} and YouTube\\footnote{Demovideo: https://youtu.be/5SJ0ZJKVZvw}.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/06/25",
    "Article_PDF": "https://arxiv.org/pdf/1906.10362"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.09808",
    "DOI": "arXiv:1906.09808v1",
    "Article_Title": "Recurrent Adversarial Service Times",
    "Article_Abstract": "Service system dynamics occur at the interplay between customer behaviour anda service provider's response. This kind of dynamics can effectively be modeledwithin the framework of queuing theory where customers' arrivals are describedby point process models. However, these approaches are limited by parametricassumptions as to, for example, inter-event time distributions. In this paper,we address these limitations and propose a novel, deep neural network solutionto the queuing problem. Our solution combines a recurrent neural network thatmodels the arrival process with a recurrent generative adversarial networkwhich models the service time distribution. We evaluate our methodology onvarious empirical datasets ranging from internet services (Blockchain, GitHub,Stackoverflow) to mobility service systems (New York taxi cab).",
    "Article_Subject": "Machine Learning (stat.ML); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/24",
    "Article_PDF": "https://arxiv.org/pdf/1906.09808"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08351",
    "DOI": "arXiv:1906.08351v1",
    "Article_Title": "Towards Lakosian Multilingual Software Design Principles",
    "Article_Abstract": "Large software systems often comprise programs written in differentprogramming languages. In the case when cross-language interoperability isaccomplished with a Foreign Function Interface (FFI), for example pybind11,Boost.Python, Emscripten, PyV8, or JNI, among many others, common softwareengineering tools, such as call-graph analysis, are obstructed by the opacityof the FFI. This complicates debugging and fosters potential inefficiency andsecurity problems. One contributing issue is that there is little rigoroussoftware design advice for multilingual software. In this paper, we present ourprogress towards a more rigorous design approach to multilingual software. Theapproach is based on the existing approach to the design of large-scale C++systems developed by Lakos. The Lakosian approach is one of the few designmethodologies to address physical design rather than just logical design. Usingthe MLSA toolkit developed in prior work for analysis of multilingual software,we focus in on one FFI -- the pybind11 FFI. An extension to the Lakosian C++design rules is proposed to address multilingual software that uses pybind11.Using a sample of 50 public GitHub repositories that use pybind11, we measurehow many repositories would currently satisfy these rules. We conclude with aproposed generalization of the pybind11-based rules for any multilingualsoftware using an FFI interface.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08351"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08101",
    "DOI": "arXiv:1906.08101v1",
    "Article_Title": "Pre-Training with Whole Word Masking for Chinese BERT",
    "Article_Abstract": "Bidirectional Encoder Representations from Transformers (BERT) has shownmarvelous improvements across various NLP tasks. Recently, an upgraded versionof BERT has been released with Whole Word Masking (WWM), which mitigate thedrawbacks of masking partial WordPiece tokens in pre-training BERT. In thistechnical report, we adapt whole word masking in Chinese text, that masking thewhole word instead of masking Chinese characters, which could bring anotherchallenge in Masked Language Model (MLM) pre-training task. The model wastrained on the latest Chinese Wikipedia dump. We aim to provide easyextensibility and better performance for Chinese BERT without changing anyneural architecture or even hyper-parameters. The model is verified on variousNLP tasks, across sentence-level to document-level, including sentimentclassification (ChnSentiCorp, Sina Weibo), named entity recognition (PeopleDaily, MSRA-NER), natural language inference (XNLI), sentence pair matching(LCQMC, BQ Corpus), and machine reading comprehension (CMRC 2018, DRCD, CAILRC). Experimental results on these datasets show that the whole word maskingcould bring another significant gain. Moreover, we also examine theeffectiveness of Chinese pre-trained models: BERT, ERNIE, BERT-wwm. We releasethe pre-trained model (both TensorFlow and PyTorch) on GitHub:https://github.com/ymcui/Chinese-BERT-wwm",
    "Article_Subject": "Computation and Language (cs.CL); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08101"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08085",
    "DOI": "arXiv:1906.08085v1",
    "Article_Title": "PLANE: An Extensible Open Source Framework for modeling the Internet of Drones",
    "Article_Abstract": "Python Library for simulating unManNed vehiclEs(PLANE) is an open sourcesoftware module, written in Python, that focuses on Unmanned Aerial Vehicles(UAVs), on their movements and on the mechanics of flight, thus devotingparticular attention to the equations that describe drones' movement. In thecontext of the Internet of Drones (IoD), the module can be widely used for thestudy of the mutual control of position/coordination in scenarios in whichdrones may find obstacles, as it happens in densely populated urban scenarios.Emphasis is put on ease of use, performance evaluation, documentation, andApplication Programming Interface (API) consistency. The software tool hasminimal dependencies and is distributed under MIT License. Source code,binaries, and documentation can be downloaded from GitHub.",
    "Article_Subject": "Robotics (cs.RO); Software Engineering (cs.SE)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08085"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08058",
    "DOI": "arXiv:1906.08058v1",
    "Article_Title": "On the abandonment and survival of open source projects: An empirical investigation",
    "Article_Abstract": "Background: Evolution of open source projects frequently depends on a smallnumber of core developers. The loss of such core developers might bedetrimental for projects and even threaten their entire continuation. However,it is possible that new core developers assume the project maintenance andallow the project to survive. Aims: The objective of this paper is to provideempirical evidence on: 1) the frequency of project abandonment and survival, 2)the differences between abandoned and surviving projects, and 3) the motivationand difficulties faced when assuming an abandoned project. Method: We adopt amixed-methods approach to investigate project abandonment and survival. Wecarefully select 1,932 popular GitHub projects and recover the abandoned andsurviving projects, and conduct a survey with developers that have beeninstrumental in the survival of the projects. Results: We found that 315projects (16%) were abandoned and 128 of these projects (41%) survived becauseof new core developers who assumed the project development. The surveyindicates that (i) in most cases the new maintainers were aware of the projectabandonment risks when they started to contribute; (ii) their own usage of thesystems is the main motivation to contribute to such projects; (iii) human andsocial factors played a key role when making these contributions; and (iv) lackof time and the difficulty to obtain push access to the repositories are themain barriers faced by them. Conclusions: Project abandonment is a reality evenin large open source projects and our work enables a better understanding ofsuch risks, as well as highlights ways in avoiding them.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08058"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.07771",
    "DOI": "arXiv:1906.07771v1",
    "Article_Title": "Crop Lodging Prediction from UAV-Acquired Images of Wheat and Canola using a DCNN Augmented with Handcrafted Texture Features",
    "Article_Abstract": "Lodging, the permanent bending over of food crops, leads to poor plant growthand development. Consequently, lodging results in reduced crop quality, lowerscrop yield, and makes harvesting difficult. Plant breeders routinely evaluateseveral thousand breeding lines, and therefore, automatic lodging detection andprediction is of great value aid in selection. In this paper, we propose a deepconvolutional neural network (DCNN) architecture for lodging classificationusing five spectral channel orthomosaic images from canola and wheat breedingtrials. Also, using transfer learning, we trained 10 lodging detection modelsusing well-established deep convolutional neural network architectures. Ourproposed model outperforms the state-of-the-art lodging detection methods inthe literature that use only handcrafted features. In comparison to 10 DCNNlodging detection models, our proposed model achieves comparable results whilehaving a substantially lower number of parameters. This makes the proposedmodel suitable for applications such as real-time classification usinginexpensive hardware for high-throughput phenotyping pipelines. The GitHubrepository at https://github.com/FarhadMaleki/LodgedNet contains code andmodels.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/06/18",
    "Article_PDF": "https://arxiv.org/pdf/1906.07771"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.07637",
    "DOI": "arXiv:1906.07637v2",
    "Article_Title": "Periphery Plots for Contextualizing Heterogeneous Time-Based Charts",
    "Article_Abstract": "Patterns in temporal data can often be found across different scales, such asdays, weeks, and months, making effective visualization of time-based datachallenging. Here we propose a new approach for providing focus and context intime-based charts to enable interpretation of patterns across time scales. Ourapproach employs a focus zone with a time and a second axis, that can eitherrepresent quantities or categories, as well as a set of adjacent peripheryplots that can aggregate data along the time, value, or both dimensions. Wepresent a framework for periphery plots and describe two use cases thatdemonstrate the utility of our approach.",
    "Article_Subject": "Human-Computer Interaction (cs.HC)",
    "Article_Date": "2019/06/18",
    "Article_PDF": "https://arxiv.org/pdf/1906.07637"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.07505",
    "DOI": "arXiv:1906.07505v1",
    "Article_Title": "A Model-Based General Alternative to the Standardised Precipitation Index",
    "Article_Abstract": "In this paper, we introduce two new model-based versions of the widely-usedstandardized precipitation index (SPI) for detecting and quantifying themagnitude of extreme hydro-climatic events. Our analytical approach is based ongeneralized additive models for location, scale and shape (GAMLSS), which helpsas to overcome some limitations of the SPI. We compare our model-basedstandardised indices (MBSIs) with the SPI using precipitation data collectedbetween January 2004 - December 2013 (522 weeks) in Caapiranga, a road-lessmunicipality of Amazonas State. As a result, it is shown that the MBSI-1 is anindex with similar properties to the SPI, but with improved methodology. Incomparison to the SPI, our MBSI-1 index allows for the use of differentzero-augmented distributions, it works with more flexible time-scales, can beapplied to shorter records of data and also takes into account temporaldependencies in known seasonal behaviours. Our approach is implemented in an Rpackage, mbsi, available from Github.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/06/18",
    "Article_PDF": "https://arxiv.org/pdf/1906.07505"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.06905",
    "DOI": "arXiv:1906.06905v2",
    "Article_Title": "Manipulating the Difficulty of C-Tests",
    "Article_Abstract": "We propose two novel manipulation strategies for increasing and decreasingthe difficulty of C-tests automatically. This is a crucial step towardsgenerating learner-adaptive exercises for self-directed language learning andpreparing language assessment tests. To reach the desired difficulty level, wemanipulate the size and the distribution of gaps based on absolute and relativegap difficulty predictions. We evaluate our approach in corpus-basedexperiments and in a user study with 60 participants. We find that bothstrategies are able to generate C-tests with the desired difficulty level.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/06/17",
    "Article_PDF": "https://arxiv.org/pdf/1906.06905"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.06583",
    "DOI": "arXiv:1906.06583v2",
    "Article_Title": "Linear regression with stationary errors : the R package slm",
    "Article_Abstract": "This paper introduces the R package slm which stands for Stationary LinearModels. The package contains a set of statistical procedures for linearregression in the general context where the error process is strictlystationary with short memory. We work in the setting of Hannan (1973), whoproved the asymptotic normality of the (normalized) least squares estimators(LSE) under very mild conditions on the error process. We propose differentways to estimate the asymptotic covariance matrix of the LSE, and then tocorrect the type I error rates of the usual tests on the parameters (as well asconfidence intervals). The procedures are evaluated through different sets ofsimulations, and two examples of real datasets are studied.",
    "Article_Subject": "Applications (stat.AP); Computation (stat.CO); Methodology (stat.ME)",
    "Article_Date": "2019/06/15",
    "Article_PDF": "https://arxiv.org/pdf/1906.06583"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.06317",
    "DOI": "arXiv:1906.06317v1",
    "Article_Title": "freud: A Software Suite for High Throughput Analysis of Particle Simulation Data",
    "Article_Abstract": "The freud Python package is a powerful library for analyzing simulation data.Written with modern simulation and data analysis workflows in mind, freudprovides a Python interface to fast, parallelized C++ routines that runefficiently on laptops, workstations, and supercomputing clusters. The packageprovides the core tools for finding particle neighbors in periodic systems, andoffers a uniform API to a wide variety of methods implemented using thesetools. As such, freud users can access standard methods such as the radialdistribution function as well as newer, more specialized methods such as thepotential of mean force and torque and local crystal environment analysis withequal ease. While many comparable tools place a heavy emphasis on reading andoperating on trajectory file formats, freud instead accepts numerical arrays ofdata directly as inputs. By remaining agnostic to its data source, freud issuitable for analyzing any coarse-grained particle simulation, regardless ofthe original data representation or simulation method. When used for on-the-flyanalysis in conjunction with scriptable simulation software such as HOOMD-blue,freud enables smart simulations that adapt to the current state of the system,allowing users to study phenomena such as nucleation and growth.",
    "Article_Subject": "Computational Physics (physics.comp-ph); Materials Science (cond-mat.mtrl-sci); Computational Engineering, Finance, and Science (cs.CE)",
    "Article_Date": "2019/06/14",
    "Article_PDF": "https://arxiv.org/pdf/1906.06317"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.05676",
    "DOI": "arXiv:1906.05676v1",
    "Article_Title": "Sionnx: Automatic Unit Test Generator for ONNX Conformance",
    "Article_Abstract": "Open Neural Network Exchange (ONNX) is an open format to represent AI modelsand is supported by many machine learning frameworks. While ONNX definesunified and portable computation operators across various frameworks, theconformance tests for those operators are insufficient, which makes itdifficult to verify if an operator's behavior in an ONNX backend implementationcomplies with the ONNX standard. In this paper, we present the first automaticunit test generator named Sionnx for verifying the compliance of ONNXimplementation. First, we propose a compact yet complete set of rules todescribe the operator's attributes and the properties of its operands. Second,we design an Operator Specification Language (OSL) to provide a high-leveldescription for the operator's syntax. Finally, through this easy-to-usespecification language, we are able to build a full testing specification whichleverages LLVM TableGen to automatically generate unit tests for ONNX operatorswith much large coverage. Sionnx is lightweight and flexible to supportcross-framework verification. The Sionnx framework is open-sourced in thegithub repository (https://github.com/alibaba/Sionnx).",
    "Article_Subject": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/06/12",
    "Article_PDF": "https://arxiv.org/pdf/1906.05676"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.05603",
    "DOI": "arXiv:1906.05603v1",
    "Article_Title": "A review of available software for adaptive clinical trial design",
    "Article_Abstract": "Background/Aims: The increasing expense of the drug development process hasseen interest in the use of adaptive designs (ADs) grow substantially in recentyears. Accordingly, much research has been conducted to identify potentialbarriers to increasing the use of ADs in practice, and several articles haveargued that the availability of user-friendly software will be an importantstep in making ADs easier to implement. Therefore, in this paper we present areview of the current state of software availability for AD. Methods: We firstreview articles from 31 journals published in 2013-17 that relate tomethodology for adaptive trials, in order to assess how often code and softwarefor implementing novel ADs is made available at the time of publication. Wecontrast our findings against these journals' current policies on codedistribution. Secondly, we conduct additional searches of popular coderepositories, such as CRAN and GitHub, to identify further existinguser-contributed software for ADs. From this, we are able to direct interestedparties towards solutions for their problem of interest by classifyingavailable code by type of adaptation. Results: Only 29% of included articlesmade their code available in some form. In many instances, articles publishedin journals that had mandatory requirements on code provision still did notmake code available. There are several areas in which available software iscurrently limited or saturated. In particular, many packages are available toaddress group sequential design, but comparatively little code is present inthe public domain to determine biomarker-guided ADs. Conclusions: There is muchroom for improvement in the provision of software alongside AD publications.Additionally, whilst progress has been made, well-established software forvarious types of trial adaptation remains sparsely available.",
    "Article_Subject": "Computation (stat.CO)",
    "Article_Date": "2019/06/13",
    "Article_PDF": "https://arxiv.org/pdf/1906.05603"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.04554",
    "DOI": "arXiv:1906.04554v1",
    "Article_Title": "Principled Training of Neural Networks with Direct Feedback Alignment",
    "Article_Abstract": "The backpropagation algorithm has long been the canonical training method forneural networks. Modern paradigms are implicitly optimized for it, and numerousguidelines exist to ensure its proper use. Recently, synthetic gradientsmethods -where the error gradient is only roughly approximated - have garneredinterest. These methods not only better portray how biological brains arelearning, but also open new computational possibilities, such as updatinglayers asynchronously. Even so, they have failed to scale past simple taskslike MNIST or CIFAR-10. This is in part due to a lack of standards, leading toill-suited models and practices forbidding such methods from performing to thebest of their abilities. In this work, we focus on direct feedback alignmentand present a set of best practices justified by observations of the alignmentangles. We characterize a bottleneck effect that prevents alignment in narrowlayers, and hypothesize it may explain why feedback alignment methods have yetto scale to large convolutional networks.",
    "Article_Subject": "Machine Learning (stat.ML); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)",
    "Article_Date": "2019/06/11",
    "Article_PDF": "https://arxiv.org/pdf/1906.04554"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.04281",
    "DOI": "arXiv:1906.04281v1",
    "Article_Title": "Towards Amortized Ranking-Critical Training for Collaborative Filtering",
    "Article_Abstract": "Collaborative filtering is widely used in modern recommender systems. Recentresearch shows that variational autoencoders (VAEs) yield state-of-the-artperformance by integrating flexible representations from deep neural networksinto latent variable models, mitigating limitations of traditional linearfactor models. VAEs are typically trained by maximizing the likelihood (MLE) ofusers interacting with ground-truth items. While simple and often effective,MLE-based training does not directly maximize the recommendation-qualitymetrics one typically cares about, such as top-N ranking. In this paper weinvestigate new methods for training collaborative filtering models based onactor-critic reinforcement learning, to directly optimize thenon-differentiable quality metrics of interest. Specifically, we train a criticnetwork to approximate ranking-based metrics, and then update the actor network(represented here by a VAE) to directly optimize against the learned metrics.In contrast to traditional learning-to-rank methods that require to re-run theoptimization procedure for new lists, our critic-based method amortizes thescoring process with a neural network, and can directly provide the(approximate) ranking scores for new lists. Empirically, we show that theproposed methods outperform several state-of-the-art baselines, includingrecently-proposed deep learning approaches, on three large-scale real-worlddatasets. The code to reproduce the experimental results and figure plots is onGithub: https://github.com/samlobel/RaCT_CF",
    "Article_Subject": "Machine Learning (cs.LG); Information Retrieval (cs.IR); Machine Learning (stat.ML)",
    "Article_Date": "2019/06/10",
    "Article_PDF": "https://arxiv.org/pdf/1906.04281"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03951",
    "DOI": "arXiv:1906.03951v1",
    "Article_Title": "SCAN: A Scalable Neural Networks Framework Towards Compact and Efficient Models",
    "Article_Abstract": "Remarkable achievements have been attained by deep neural networks in variousapplications. However, the increasing depth and width of such models also leadto explosive growth in both storage and computation, which has restricted thedeployment of deep neural networks on resource-limited edge devices. To addressthis problem, we propose the so-called SCAN framework for networks training andinference, which is orthogonal and complementary to existing acceleration andcompression methods. The proposed SCAN firstly divides neural networks intomultiple sections according to their depth and constructs shallow classifiersupon the intermediate features of different sections. Moreover, attentionmodules and knowledge distillation are utilized to enhance the accuracy ofshallow classifiers. Based on this architecture, we further propose a thresholdcontrolled scalable inference mechanism to approach human-like sample-specificinference. Experimental results show that SCAN can be easily equipped onvarious neural networks without any adjustment on hyper-parameters or neuralnetworks architectures, yielding significant performance gain on CIFAR100 andImageNet. Codes will be released on github soon.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/27",
    "Article_PDF": "https://arxiv.org/pdf/1906.03951"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03773",
    "DOI": "arXiv:1906.03773v1",
    "Article_Title": "DataLearner: A Data Mining and Knowledge Discovery Tool for Android Smartphones and Tablets",
    "Article_Abstract": "Smartphones have become the ultimate 'personal' computer, yet despite this,general-purpose data-mining and knowledge discovery tools for mobile devicesare surprisingly rare. DataLearner is a new data-mining application designedspecifically for Android devices that imports the Weka data-mining engine andaugments it with algorithms developed by Charles Sturt University. Moreover,DataLearner can be expanded with additional algorithms. Combined, DataLearnerdelivers 40 classification, clustering and association rule mining algorithmsfor model training and evaluation without need for cloud computing resources ornetwork connectivity. It provides the same classification accuracy as PCs andlaptops, while doing so with acceptable processing speed and consumingnegligible battery life. With its ability to provide easy-to-use data-mining ona phone-size screen, DataLearner is a new portable, self-contained data-miningtool for remote, personalised and learning applications alike. DataLearnerfeatures four elements - this paper, the app available on Google Play, theGPL3-licensed source code on GitHub and a short video on YouTube.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/06/10",
    "Article_PDF": "https://arxiv.org/pdf/1906.03773"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03277",
    "DOI": "arXiv:1906.03277v1",
    "Article_Title": "xBIT: an easy to use scanning tool with machine learning abilities",
    "Article_Abstract": "xBIT is a tool for performing parameter scans in beyond the Standard Modeltheories. It's written in Python and fully open source. The main purpose ofxBIT is to provide an easy to use tool to help phenomenologists with theirdaily task: exploring the parameter space of new models. It was developed underthe impression of the SARAH/SPheno framework, but should be use-able with othertools as well that use the SLHA format to transfer data. It also supports bydefault MicrOmegas for dark matter calculations, HiggsBounds and HiggsSignalsfor checking the Higgs properties, and Vevacious for testing the vacuumstability. Classes for other tools can be added if necessary. In order toimprove the efficiency of the parameter scans, the recently proposed 'MachineLearning Scan' approach is included. For this purpose, xBIT uses pyTorch todeal with artificial neural networks.",
    "Article_Subject": "High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Experiment (hep-ex)",
    "Article_Date": "2019/06/07",
    "Article_PDF": "https://arxiv.org/pdf/1906.03277"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03049",
    "DOI": "arXiv:1906.03049v1",
    "Article_Title": "Computing Exact Guarantees for Differential Privacy",
    "Article_Abstract": "Quantification of the privacy loss associated with a randomised algorithm hasbecome an active area of research and $(\\varepsilon,\u03b4)$-differentialprivacy has arisen as the standard measure of it. We propose a numerical methodfor evaluating the parameters of differential privacy for algorithms withcontinuous one dimensional output. In this way the parameters $\\varepsilon$ and$\u03b4$ can be evaluated, for example, for the subsampled multidimensionalGaussian mechanism which is also the underlying mechanism of differentiallyprivate stochastic gradient descent. The proposed method is based on anumerical approximation of an integral formula which gives the exact$(\\varepsilon,\u03b4)$-values. The approximation is carried out by discretisingthe integral and by evaluating discrete convolutions using a fast Fouriertransform algorithm. We give theoretical error bounds which show theconvergence of the approximation and guarantee its accuracy to an arbitrarydegree. Experimental comparisons with state-of-the-art techniques illustratethe efficacy of the method. Python code for the proposed method can be found inGithub (https://github.com/DPBayes/PLD-Accountant/).",
    "Article_Subject": "Machine Learning (stat.ML); Cryptography and Security (cs.CR); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/07",
    "Article_PDF": "https://arxiv.org/pdf/1906.03049"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03008",
    "DOI": "arXiv:1906.03008v2",
    "Article_Title": "RankQA: Neural Question Answering with Answer Re-Ranking",
    "Article_Abstract": "The conventional paradigm in neural question answering (QA) for narrativecontent is limited to a two-stage process: first, relevant text passages areretrieved and, subsequently, a neural network for machine comprehensionextracts the likeliest answer. However, both stages are largely isolated in thestatus quo and, hence, information from the two phases is never properly fused.In contrast, this work proposes RankQA: RankQA extends the conventionaltwo-stage process in neural QA with a third stage that performs an additionalanswer re-ranking. The re-ranking leverages different features that aredirectly extracted from the QA pipeline, i.e., a combination of retrieval andcomprehension features. While our intentionally simple design allows for anefficient, data-sparse estimation, it nevertheless outperforms more complex QAsystems by a significant margin: in fact, RankQA achieves state-of-the-artperformance on 3 out of 4 benchmark datasets. Furthermore, its performance isespecially superior in settings where the size of the corpus is dynamic. Herethe answer re-ranking provides an effective remedy against the underlyingnoise-information trade-off due to a variable corpus size. As a consequence,RankQA represents a novel, powerful, and thus challenging baseline for futureresearch in content-based QA.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/06/07",
    "Article_PDF": "https://arxiv.org/pdf/1906.03008"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.02126",
    "DOI": "arXiv:1906.02126v1",
    "Article_Title": "Extractive Summarization via Weighted Dissimilarity and Importance Aligned Key Iterative Algorithm",
    "Article_Abstract": "We present importance aligned key iterative algorithm for extractivesummarization that is faster than conventional algorithms keeping its accuracy.The computational complexity of our algorithm is O($SNlogN$) to summarizeoriginal $N$ sentences into final $S$ sentences. Our algorithm maximizes theweighted dissimilarity defined by the product of importance and cosinedissimilarity so that the summary represents the document and at the same timethe sentences of the summary are not similar to each other. The weighteddissimilarity is heuristically maximized by iterative greedy search and binarysearch to the sentences ordered by importance. We finally show a benchmarkscore based on summarization of customer reviews of products, which highlightsthe quality of our algorithm comparable to human and existing algorithms. Weprovide the source code of our algorithm on githubhttps://github.com/qhapaq-49/imakita .",
    "Article_Subject": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/05/15",
    "Article_PDF": "https://arxiv.org/pdf/1906.02126"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.01388",
    "DOI": "arXiv:1906.01388v1",
    "Article_Title": "A Comprehensive Study on Deep Learning Bug Characteristics",
    "Article_Abstract": "Deep learning has gained substantial popularity in recent years. Developersmainly rely on libraries and tools to add deep learning capabilities to theirsoftware. What kinds of bugs are frequently found in such software? What arethe root causes of such bugs? What impacts do such bugs have? Which stages ofdeep learning pipeline are more bug prone? Are there any antipatterns?Understanding such characteristics of bugs in deep learning software has thepotential to foster the development of better deep learning platforms,debugging mechanisms, development practices, and encourage the development ofanalysis and verification frameworks. Therefore, we study 2716 high-qualityposts from Stack Overflow and 500 bug fix commits from Github about fivepopular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch tounderstand the types of bugs, root causes of bugs, impacts of bugs, bug-pronestage of deep learning pipeline as well as whether there are some commonantipatterns found in this buggy software. The key findings of our studyinclude: data bug and logic bug are the most severe bug types in deep learningsoftware appearing more than 48% of the times, major root causes of these bugsare Incorrect Model Parameter (IPS) and Structural Inefficiency (SI) showing upmore than 43% of the times. We have also found that the bugs in the usage ofdeep learning libraries have some common antipatterns that lead to a strongcorrelation of bug types among the libraries.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.01388"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.01211",
    "DOI": "arXiv:1906.01211v3",
    "Article_Title": "Raising the Performance of the Tinker-HP Molecular Modeling Package [Article v1.0]",
    "Article_Abstract": "This living paper reviews the present High Performance Computing (HPC)capabilities of the Tinker-HP molecular modeling package. We focus here on thereference, double precision, massively parallel molecular dynamics enginepresent in Tinker-HP and dedicated to perform large scale simulations. We showhow it can be adapted to recent Intel Central Processing Unit (CPU) petascalearchitectures. First, we discuss the new set of Intel Advanced VectorExtensions 512 (Intel AVX-512) instructions present in recent Intel processors(e.g., the Intel Xeon Scalable and Intel Xeon Phi 2nd generation processors)allowing for larger vectorization enhancements. These instructions constitutethe central source of potential computational gains when using the latestprocessors, justifying important vectorization efforts for developers. We thenbriefly review the organization of the Tinker-HP code and identify thecomputational hotspots which require Intel AVX-512 optimization and we proposea general and optimal strategy to vectorize those particular parts of the code.We intended to present our optimization strategy in a pedagogical way so itcould benefit to other researchers and students interested in gainingperformances in their own software. Finally we present the performanceenhancements obtained compared to the unoptimized code both sequentially and atthe scaling limit in parallel for classical non-polarizable (CHARMM) andpolarizable force fields (AMOEBA). This paper never ceases to be updated as weaccumulate new data on the associated Github repository between new versions ofthis living paper.",
    "Article_Subject": "Mathematical Software (cs.MS); Chemical Physics (physics.chem-ph); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/06/04",
    "Article_PDF": "https://arxiv.org/pdf/1906.01211"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.01032",
    "DOI": "arXiv:1906.01032v1",
    "Article_Title": "A Language-Agnostic Model for Semantic Source Code Labeling",
    "Article_Abstract": "Code search and comprehension have become more difficult in recent years dueto the rapid expansion of available source code. Current tools lack a way tolabel arbitrary code at scale while maintaining up-to-date representations ofnew programming languages, libraries, and functionalities. Comprehensivelabeling of source code enables users to search for documents of interest andobtain a high-level understanding of their contents. We use Stack Overflow codesnippets and their tags to train a language-agnostic, deep convolutional neuralnetwork to automatically predict semantic labels for source code documents. OnStack Overflow code snippets, we demonstrate a mean area under ROC of 0.957over a long-tailed list of 4,508 tags. We also manually validate the modeloutputs on a diverse set of unlabeled source code documents retrieved fromGithub, and we obtain a top-1 accuracy of 86.6%. This strongly indicates thatthe model successfully transfers its knowledge from Stack Overflow snippets toarbitrary source code documents.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Software Engineering (cs.SE); Machine Learning (stat.ML)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.01032"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.00966",
    "DOI": "arXiv:1906.00966v3",
    "Article_Title": "Wotan: Comprehensive time-series de-trending in Python",
    "Article_Abstract": "The detection of transiting exoplanets in time-series photometry requires theremoval or modeling of instrumental and stellar noise. While instrumentalsystematics can be reduced using methods such as pixel level decorrelation,removing stellar trends while preserving transit signals proves challenging.Due to vast archives of light curves from recent transit surveys, there is astrong need for accurate automatic detrending, without human intervention. Alarge variety of detrending algorithms are in active use, but their comparativeperformance for transit discovery is unexplored. We benchmark all commonly useddetrending methods against hundreds of Kepler, K2, and TESS planets, selectedto represent the most difficult cases for systems with small planet-to-starradius ratios. The full parameter range is explored for each method todetermine the best choices for planet discovery. We conclude that the idealmethod is a time-windowed slider with an iterative robust location estimatorbased on Tukey's biweight. This method recovers 99% and 94% of the shallowestKepler and K2 planets, respectively. We include an additional analysis foryoung stars with extreme variability and conclude they are best treated using aspline-based method with a robust Huber estimator. All stellar detrendingmethods explored are available for public use in wotan, an open-source Pythonpackage on GitHub (see https://github.com/hippke/wotan).",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.00966"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.00925",
    "DOI": "arXiv:1906.00925v2",
    "Article_Title": "3D Appearance Super-Resolution with Deep Learning",
    "Article_Abstract": "We tackle the problem of retrieving high-resolution (HR) texture maps ofobjects that are captured from multiple view points. In the multi-view case,model-based super-resolution (SR) methods have been recently proved to recoverhigh quality texture maps. On the other hand, the advent of deep learning-basedmethods has already a significant impact on the problem of video and image SR.Yet, a deep learning-based approach to super-resolve the appearance of 3Dobjects is still missing. The main limitation of exploiting the power of deeplearning techniques in the multi-view case is the lack of data. We introduce a3D appearance SR (3DASR) dataset based on the existing ETH3D [42], SyB3R [31],MiddleBury, and our Collection of 3D scenes from TUM [21], Fountain [51] andRelief [53]. We provide the high- and low-resolution texture maps, the 3Dgeometric model, images and projection matrices. We exploit the power of 2Dlearning-based SR methods and design networks suitable for the 3D multi-viewcase. We incorporate the geometric information by introducing normal maps andfurther improve the learning process. Experimental results demonstrate that ourproposed networks successfully incorporate the 3D geometric information andsuper-resolve the texture maps.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.00925"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.00657",
    "DOI": "arXiv:1906.00657v1",
    "Article_Title": "Kandinsky Patterns",
    "Article_Abstract": "Kandinsky Figures and Kandinsky Patterns are mathematically describable,simple self-contained hence controllable test data sets for the development,validation and training of explainability in artificial intelligence. WhilstKandinsky Patterns have these computationally manageable properties, they areat the same time easily distinguishable from human observers. Consequently,controlled patterns can be described by both humans and computers. We define aKandinsky Pattern as a set of Kandinsky Figures, where for each figure an\"infallible authority\" defines that the figure belongs to the KandinskyPattern. With this simple principle we build training and validation data setsfor automatic interpretability and context learning. In this paper we describethe basic idea and some underlying principles of Kandinsky Patterns and providea Github repository to invite the international machine learning researchcommunity to a challenge to experiment with our Kandinsky Patterns to expandand thus make progress in the field of explainable AI and to contribute to theupcoming field of explainability and causability.",
    "Article_Subject": "Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.00657"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.13658",
    "DOI": "arXiv:1905.13658v1",
    "Article_Title": "Ordinal Regression as Structured Classification",
    "Article_Abstract": "This paper extends the class of ordinal regression models with a structuredinterpretation of the problem by applying a novel treatment of encoded labels.The net effect of this is to transform the underlying problem from an ordinalregression task to a (structured) classification task which we solve withconditional random fields, thereby achieving a coherent and probabilistic modelin which all model parameters are jointly learnt. Importantly, we show thatalthough we have cast ordinal regression to classification, our method stillfall within the class of decomposition methods in the ordinal regressionontology. This is an important link since our experience is that manyapplications of machine learning to healthcare ignores completely the importantnature of the label ordering, and hence these approaches should considerednaive in this ontology. We also show that our model is flexible both in how itadapts to data manifolds and in terms of the operations that are available forpractitioner to execute. Our empirical evaluation demonstrates that theproposed approach overwhelmingly produces superior and often statisticallysignificant results over baseline approaches on forty popular ordinalregression models, and demonstrate that the proposed model significantlyout-performs baselines on synthetic and real datasets. Our implementation,together with scripts to reproduce the results of this work, will be availableon a public GitHub repository.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/31",
    "Article_PDF": "https://arxiv.org/pdf/1905.13658"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.13313",
    "DOI": "arXiv:1905.13313v5",
    "Article_Title": "Technical Report of the Video Event Reconstruction and Analysis (VERA) System -- Shooter Localization, Models, Interface, and Beyond",
    "Article_Abstract": "Every minute, hundreds of hours of video are uploaded to social media sitesand the Internet from around the world. This material creates a visual recordof the experiences of a significant percentage of humanity and can helpilluminate how we live in the present moment. When properly analyzed, thisvideo can also help analysts to reconstruct events of interest, including warcrimes, human rights violations, and terrorist acts. Machine learning andcomputer vision can play a crucial role in this process. In this technicalreport, we describe the Video Event Reconstruction and Analysis (VERA) system.This new tool brings together a variety of capabilities we have developed overthe past few years (including video synchronization and geolocation to orderunstructured videos lacking metadata over time and space, and sound recognitionalgorithms) to enable the reconstruction and analysis of events captured onvideo. Among other uses, VERA enables the localization of a shooter from just afew videos that include the sound of gunshots. To demonstrate the efficacy ofthis suite of tools, we present the results of estimating the shooter'slocation of the Las Vegas Shooting in 2017 and show that VERA accuratelypredicts the shooter's location using only the first few gunshots. We thenpoint out future directions that can help improve the system and further reduceunnecessary human labor in the process. All of the components of VERA runthrough a web interface that enables human-in-the-loop verification to ensureaccurate estimations. All relevant source code, including the web interface andmachine learning models, is freely available on Github. We hope thatresearchers and software developers will be inspired to improve and expand thissystem moving forward to better meet the needs of human rights and publicsafety.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multimedia (cs.MM)",
    "Article_Date": "2019/05/26",
    "Article_PDF": "https://arxiv.org/pdf/1905.13313"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.12768",
    "DOI": "arXiv:1905.12768v2",
    "Article_Title": "Using Propensity Scores to Develop and Evaluate Treatment Rules with Observational Data",
    "Article_Abstract": "In this paper, we outline a principled approach to estimate an individualizedtreatment rule that is appropriate for data from observational studies where,in addition to treatment assignment not being independent of individualcharacteristics, some characteristics may affect treatment assignment in thecurrent study but not be available in future clinical settings where theestimated rule would be applied. The estimation framework is quite flexible andaccommodates any prediction method that uses observation weights, where theobservation weights themselves are a ratio of two flexibly estimated propensityscores. We also discuss how to obtain a trustworthy estimate of the rule'spopulation benefit based on simple propensity-score-based estimators of averagetreatment effect. We implement our approach in the R package DevTreatRules andshare the code needed to reproduce our results on GitHub.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/05/29",
    "Article_PDF": "https://arxiv.org/pdf/1905.12768"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.12111",
    "DOI": "arXiv:1905.12111v1",
    "Article_Title": "Analyzing and Supporting Adaptation of Online Code Examples",
    "Article_Abstract": "Developers often resort to online Q&A forums such as Stack Overflow (SO) forfilling their programming needs. Although code examples on those forums aregood starting points, they are often incomplete and inadequate for developers'local program contexts; adaptation of those examples is necessary to integratethem to production code. As a consequence, the process of adapting online codeexamples is done over and over again, by multiple developers independently. Ourwork extensively studies these adaptations and variations, serving as the basisfor a tool that helps integrate these online code examples in a target contextin an interactive manner.  We perform a large-scale empirical study about the nature and extent ofadaptations and variations of SO snippets. We construct a comprehensive datasetlinking SO posts to GitHub counterparts based on clone detection, time stampanalysis, and explicit URL references. We then qualitatively inspect 400 SOexamples and their GitHub counterparts and develop a taxonomy of 24 adaptationtypes. Using this taxonomy, we build an automated adaptation analysis techniqueon top of GumTree to classify the entire dataset into these types. We build aChrome extension called ExampleStack that automatically lifts anadaptation-aware template from each SO example and its GitHub counterparts toidentify hot spots where most changes happen. A user study with sixteenprogrammers shows that seeing the commonalities and variations in similarGitHub counterparts increases their confidence about the given SO example, andhelps them grasp a more comprehensive view about how to reuse the exampledifferently and avoid common pitfalls.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/28",
    "Article_PDF": "https://arxiv.org/pdf/1905.12111"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.11830",
    "DOI": "arXiv:1905.11830v2",
    "Article_Title": "A Graph Theoretic Additive Approximation of Optimal Transport",
    "Article_Abstract": "Transportation cost is an attractive similarity measure between probabilitydistributions due to its many useful theoretical properties. However, solvingoptimal transport exactly can be prohibitively expensive. Therefore, there hasbeen significant effort towards the design of scalable approximationalgorithms. Previous combinatorial results [Sharathkumar, Agarwal STOC '12,Agarwal, Sharathkumar STOC '14] have focused primarily on the design ofstrongly polynomial multiplicative approximation algorithms. There has alsobeen an effort to design approximate solutions with additive errors [CuturiNIPS '13, Altschuler et. al NIPS '17, Dvurechensky et al., ICML '18, Quanrud,SOSA '19] within a time bound that is linear in the size of the cost matrix andpolynomial in $C/\u03b4$; here $C$ is the largest value in the cost matrix and$\u03b4$ is the additive error. We present an adaptation of the classical graphalgorithm of Gabow and Tarjan and provide a novel analysis of this algorithmthat bounds its execution time by $O(\\frac{n^2 C}\u03b4+\\frac{nC^2}{\u03b4^2})$. Our algorithm is extremely simple and executes, for anarbitrarily small constant $\\varepsilon$, only $\\lfloor\\frac{2C}{(1-\\varepsilon)\u03b4}\\rfloor + 1$ iterations, where each iterationconsists only of a Dijkstra search followed by a depth-first search. We alsoprovide empirical results that suggest our algorithm significantly outperformsexisting approaches in execution time.",
    "Article_Subject": "Machine Learning (cs.LG); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/28",
    "Article_PDF": "https://arxiv.org/pdf/1905.11830"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.11681",
    "DOI": "arXiv:1905.11681v2",
    "Article_Title": "Validating the Validation: Reanalyzing a large-scale comparison of Deep Learning and Machine Learning models for bioactivity prediction",
    "Article_Abstract": "Machine learning methods may have the potential to significantly acceleratedrug discovery. However, the increasing rate of new methodological approachesbeing published in the literature raises the fundamental question of how modelsshould be benchmarked and validated. We reanalyze the data generated by arecently published large-scale comparison of machine learning models forbioactivity prediction and arrive at a somewhat different conclusion. We showthat the performance of support vector machines is competitive with that ofdeep learning methods. Additionally, using a series of numerical experiments,we question the relevance of area under the receiver operating characteristiccurve as a metric in virtual screening, and instead suggest that area under theprecision-recall curve should be used in conjunction with the receiveroperating characteristic. Our numerical experiments also highlight challengesin estimating the uncertainty in model performance via scaffold-split nestedcross validation.",
    "Article_Subject": "Machine Learning (cs.LG); Chemical Physics (physics.chem-ph); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/28",
    "Article_PDF": "https://arxiv.org/pdf/1905.11681"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.11127",
    "DOI": "arXiv:1905.11127v1",
    "Article_Title": "DockerizeMe: Automatic Inference of Environment Dependencies for Python Code Snippets",
    "Article_Abstract": "Platforms like Stack Overflow and GitHub's gist system promote the sharing ofideas and programming techniques via the distribution of code snippets designedto illustrate particular tasks. Python, a popular and fast-growing programminglanguage, sees heavy use on both sites, with nearly one million questions askedon Stack Overflow and 400 thousand public gists on GitHub. Unfortunately,around 75% of the Python example code shared through these sites cannot bedirectly executed. When run in a clean environment, over 50% of public Pythongists fail due to an import error for a missing library.  We present DockerizeMe, a technique for inferring the dependencies needed toexecute a Python code snippet without import error. DockerizeMe starts withoffline knowledge acquisition of the resources and dependencies for popularPython packages from the Python Package Index (PyPI). It then builds Dockerspecifications using a graph-based inference procedure. Our inference procedureresolves import errors in 892 out of nearly 3,000 gists from the Gistabledataset for which Gistable's baseline approach could not find and install alldependencies.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/27",
    "Article_PDF": "https://arxiv.org/pdf/1905.11127"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.10536",
    "DOI": "arXiv:1905.10536v1",
    "Article_Title": "DeepRec: An Open-source Toolkit for Deep Learning based Recommendation",
    "Article_Abstract": "Deep learning based recommender systems have been extensively explored inrecent years. However, the large number of models proposed each year poses abig challenge for both researchers and practitioners in reproducing the resultsfor further comparisons. Although a portion of papers provides source code,they adopted different programming languages or different deep learningpackages, which also raises the bar in grasping the ideas. To alleviate thisproblem, we released the open source project: \\textbf{DeepRec}. In thistoolkit, we have implemented a number of deep learning based recommendationalgorithms using Python and the widely used deep learning package - Tensorflow.Three major recommendation scenarios: rating prediction, top-N recommendation(item ranking) and sequential recommendation, were considered. Meanwhile,DeepRec maintains good modularity and extensibility to easily incorporate newmodels into the framework. It is distributed under the terms of the GNU GeneralPublic License. The source code is available at github:\\url{https://github.com/cheungdaven/DeepRec}",
    "Article_Subject": "Information Retrieval (cs.IR); Machine Learning (cs.LG)",
    "Article_Date": "2019/05/25",
    "Article_PDF": "https://arxiv.org/pdf/1905.10536"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.09907",
    "DOI": "arXiv:1905.09907v1",
    "Article_Title": "Multi-level Texture Encoding and Representation (MuLTER) based on Deep Neural Networks",
    "Article_Abstract": "In this paper, we propose a multi-level texture encoding and representationnetwork (MuLTER) for texture-related applications. Based on a multi-levelpooling architecture, the MuLTER network simultaneously leverages low- andhigh-level features to maintain both texture details and spatial information.Such a pooling architecture involves few extra parameters and keeps featuredimensions fixed despite of the changes of image sizes. In comparison withstate-of-the-art texture descriptors, the MuLTER network yields higherrecognition accuracy on typical texture datasets such as MINC-2500 andGTOS-mobile with a discriminative and compact representation. In addition, weanalyze the impact of combining features from different levels, which supportsour claim that the fusion of multi-level features efficiently enhancesrecognition performance. Our source code will be published on GitHub(https://github.com/olivesgatech).",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/05/23",
    "Article_PDF": "https://arxiv.org/pdf/1905.09907"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.09717",
    "DOI": "arXiv:1905.09717v2",
    "Article_Title": "Network Pruning via Transformable Architecture Search",
    "Article_Abstract": "Network pruning reduces the computation costs of an over-parameterizednetwork without performance damage. Prevailing pruning algorithms pre-definethe width and depth of the pruned networks, and then transfer parameters fromthe unpruned network to pruned networks. To break the structure limitation ofthe pruned networks, we propose to apply neural architecture search to searchdirectly for a network with flexible channel and layer sizes. The number of thechannels/layers is learned by minimizing the loss of the pruned networks. Thefeature map of the pruned network is an aggregation of K feature map fragments(generated by K networks of different sizes), which are sampled based on theprobability distribution.The loss can be back-propagated not only to thenetwork weights, but also to the parameterized distribution to explicitly tunethe size of the channels/layers. Specifically, we apply channel-wiseinterpolation to keep the feature map with different channel sizes aligned inthe aggregation procedure. The maximum probability for the size in eachdistribution serves as the width and depth of the pruned network, whoseparameters are learned by knowledge transfer, e.g., knowledge distillation,from the original networks. Experiments on CIFAR-10, CIFAR-100 and ImageNetdemonstrate the effectiveness of our new perspective of network pruningcompared to traditional network pruning algorithms. Various searching andknowledge transfer approaches are conducted to show the effectiveness of thetwo components.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/05/23",
    "Article_PDF": "https://arxiv.org/pdf/1905.09717"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.09263",
    "DOI": "arXiv:1905.09263v4",
    "Article_Title": "FastSpeech: Fast, Robust and Controllable Text to Speech",
    "Article_Abstract": "Neural network based end-to-end text to speech (TTS) has significantlyimproved the quality of synthesized speech. Prominent methods (e.g., Tacotron2) usually first generate mel-spectrogram from text, and then synthesize speechfrom mel-spectrogram using vocoder such as WaveNet. Compared with traditionalconcatenative and statistical parametric approaches, neural network basedend-to-end models suffer from slow inference speed, and the synthesized speechis usually not robust (i.e., some words are skipped or repeated) and lack ofcontrollability (voice speed or prosody control). In this work, we propose anovel feed-forward network based on Transformer to generate mel-spectrogram inparallel for TTS. Specifically, we extract attention alignments from anencoder-decoder based teacher model for phoneme duration prediction, which isused by a length regulator to expand the source phoneme sequence to match thelength of target mel-spectrogram sequence for parallel mel-spectrogramgeneration. Experiments on the LJSpeech dataset show that our parallel modelmatches autoregressive models in terms of speech quality, nearly eliminates theproblem of word skipping and repeating in particularly hard cases, and canadjust voice speed smoothly. Most importantly, compared with autoregressiveTransformer TTS, our model speeds up the mel-spectrogram generation by 270x andthe end-to-end speech synthesis by 38x. Therefore, we call our modelFastSpeech. We will release the code on Github. Synthesized speech samples canbe found in https://speechresearch.github.io/fastspeech/.",
    "Article_Subject": "Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "Article_Date": "2019/05/22",
    "Article_PDF": "https://arxiv.org/pdf/1905.09263"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08880",
    "DOI": "arXiv:1905.08880v1",
    "Article_Title": "A Scalable Hybrid Research Paper Recommender System for Microsoft Academic",
    "Article_Abstract": "We present the design and methodology for the large scale hybrid paperrecommender system used by Microsoft Academic. The system providesrecommendations for approximately 160 million English research papers andpatents. Our approach handles incomplete citation information while alsoalleviating the cold-start problem that often affects other recommendersystems. We use the Microsoft Academic Graph (MAG), titles, and availableabstracts of research papers to build a recommendation list for all documents,thereby combining co-citation and content based approaches. Tuning systemparameters also allows for blending and prioritization of each approach which,in turn, allows us to balance paper novelty versus authority in recommendationresults. We evaluate the generated recommendations via a user study of 40participants, with over 2400 recommendation pairs graded and discuss thequality of the results using P@10 and nDCG scores. We see that there is astrong correlation between participant scores and the similarity rankingsproduced by our system but that additional focus needs to be put towardsimproving recommender precision, particularly for content basedrecommendations. The results of the user survey and associated analysis scriptsare made available via GitHub and the recommendations produced by our systemare available as part of the MAG on Azure to facilitate further research andlight up novel research paper recommendation applications.",
    "Article_Subject": "Digital Libraries (cs.DL); Information Retrieval (cs.IR); Machine Learning (cs.LG)",
    "Article_Date": "2019/05/21",
    "Article_PDF": "https://arxiv.org/pdf/1905.08880"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08667",
    "DOI": "arXiv:1905.08667v1",
    "Article_Title": "Legacy Archive for Microwave Background Data Analysis (LAMBDA): An Overview",
    "Article_Abstract": "This is an overview of the data products and other resources availablethrough NASA's LAMBDA site https://lambda.gsfc.nasa.gov/. An up-to-date versionof this document, along with code tools actively maintained and developed byLAMBDA staff, can be found on the LAMBDA GitHub page athttps://github.com/nasa-lambda/lambda_overview. New data products and otherupdates are announced on LAMBDA's twitter account athttps://twitter.com/NASA_LAMBDA. If you have questions or suggestions relatingto LAMBDA, or are interested in joining a LAMBDA advisory group, please contactus using the form here: https://lambda.gsfc.nasa.gov/contact/contact.cfm.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Article_Date": "2019/05/21",
    "Article_PDF": "https://arxiv.org/pdf/1905.08667"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08628",
    "DOI": "arXiv:1905.08628v1",
    "Article_Title": "Constraining the Parameters of High-Dimensional Models with Active Learning",
    "Article_Abstract": "Constraining the parameters of physical models with $>5-10$ parameters is awidespread problem in fields like particle physics and astronomy. In this paperwe show that this problem can be alleviated by the use of active learning. Weillustrate this with examples from high energy physics, a field wherecomputationally expensive simulations and large parameter spaces are common. Weshow that the active learning techniques query-by-committee andquery-by-dropout-committee allow for the identification of model points ininteresting regions of high-dimensional parameter spaces (e.g. around decisionboundaries). This makes it possible to constrain model parameters moreefficiently than is currently done with the most common sampling algorithms.Code implementing active learning can be found on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Instrumentation and Methods for Astrophysics (astro-ph.IM); High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Theory (hep-th)",
    "Article_Date": "2019/05/19",
    "Article_PDF": "https://arxiv.org/pdf/1905.08628"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08094",
    "DOI": "arXiv:1905.08094v1",
    "Article_Title": "Be Your Own Teacher: Improve the Performance of Convolutional Neural Networks via Self Distillation",
    "Article_Abstract": "Convolutional neural networks have been widely deployed in variousapplication scenarios. In order to extend the applications' boundaries to someaccuracy-crucial domains, researchers have been investigating approaches toboost accuracy through either deeper or wider network structures, which bringswith them the exponential increment of the computational and storage cost,delaying the responding time. In this paper, we propose a general trainingframework named self distillation, which notably enhances the performance(accuracy) of convolutional neural networks through shrinking the size of thenetwork rather than aggrandizing it. Different from traditional knowledgedistillation - a knowledge transformation methodology among networks, whichforces student neural networks to approximate the softmax layer outputs ofpre-trained teacher neural networks, the proposed self distillation frameworkdistills knowledge within network itself. The networks are firstly divided intoseveral sections. Then the knowledge in the deeper portion of the networks issqueezed into the shallow ones. Experiments further prove the generalization ofthe proposed self distillation framework: enhancement of accuracy at averagelevel is 2.65%, varying from 0.61% in ResNeXt as minimum to 4.07% in VGG19 asmaximum. In addition, it can also provide flexibility of depth-wise scalableinference on resource-limited edge devices.Our codes will be released on githubsoon.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/17",
    "Article_PDF": "https://arxiv.org/pdf/1905.08094"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.07650",
    "DOI": "arXiv:1905.07650v1",
    "Article_Title": "SAWNet: A Spatially Aware Deep Neural Network for 3D Point Cloud Processing",
    "Article_Abstract": "Deep neural networks have established themselves as the state-of-the-artmethodology in almost all computer vision tasks to date. But their applicationto processing data lying on non-Euclidean domains is still a very active areaof research. One such area is the analysis of point cloud data which poses achallenge due to its lack of order. Many recent techniques have been proposed,spearheaded by the PointNet architecture. These techniques use either global orlocal information from the point clouds to extract a latent representation forthe points, which is then used for the task at hand(classification/segmentation). In our work, we introduce a neural network layerthat combines both global and local information to produce better embeddings ofthese points. We enhance our architecture with residual connections, to passinformation between the layers, which also makes the network easier to train.We achieve state-of-the-art results on the ModelNet40 dataset with ourarchitecture, and our results are also highly competitive with thestate-of-the-art on the ShapeNet part segmentation dataset and the indoor scenesegmentation dataset. We plan to open source our pre-trained models on githubto encourage the research community to test our networks on their data, orsimply use them for benchmarking purposes.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/05/18",
    "Article_PDF": "https://arxiv.org/pdf/1905.07650"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.06280",
    "DOI": "arXiv:1905.06280v1",
    "Article_Title": "Trustee: Full Privacy Preserving Vickrey Auction on top of Ethereum",
    "Article_Abstract": "The wide deployment of tokens for digital assets on top of Ethereum impliesthe need for powerful trading platforms. Vickrey auctions have been known todetermine the real market price of items as bidders are motivated to submittheir own monetary valuations without leaking their information to thecompetitors. Recent constructions have utilized various cryptographic protocolssuch as ZKP and MPC, however, these approaches either are partiallyprivacy-preserving or require complex computations with several rounds. In thispaper, we overcome these limits by presenting Trustee as a Vickrey auction onEthereum which fully preserves bids' privacy at relatively much lower fees.Trustee consists of three components: a front-end smart contract deployed onEthereum, an Intel SGX enclave, and a relay to redirect messages between them.Initially, the enclave generates an Ethereum account and ECDH key-pair.Subsequently, the relay publishes the account's address and ECDH public key onthe smart contract. As a prerequisite, bidders are encouraged to verify theauthenticity and security of Trustee by using the SGX remote attestationservice. To participate in the auction, bidders utilize the ECDH public key toencrypt their bids and submit them to the smart contract. Once the biddinginterval is closed, the relay retrieves the encrypted bids and feeds them tothe enclave that autonomously generates a signed transaction indicating theauction winner. Finally, the relay submits the transaction to the smartcontract which verifies the transaction's authenticity and the parameters'consistency before accepting the claimed auction winner. As part of ourcontributions, we have made a prototype for Trustee available on Github for thecommunity to review and inspect it. Additionally, we analyze the securityfeatures of Trustee and report on the transactions' gas cost incurred onTrustee smart contract.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/05/15",
    "Article_PDF": "https://arxiv.org/pdf/1905.06280"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.04482",
    "DOI": "arXiv:1905.04482v1",
    "Article_Title": "GE852: A Dataset of 852 Game Engines",
    "Article_Abstract": "Game engines provide a platform for developers to build games with aninterface tailored to handle the complexity during game development. To reduceeffort and improve quality of game development, there is a strong need tounderstand and analyze the quality of game engines and their various aspectssuch as API usability, code quality, code reuse and so on. To the best ourknowledge, we are not aware of any dataset that caters to game engines in theliterature. To this end, we present GE852, a dataset of 852 game enginerepositories mined from GitHub in two languages, namely Java and C++. Thedataset contains metadata of all the mined repositories including commits, pullrequests, issues and so on. We believe that our dataset can lay foundation forempirical investigation in the area of game engines.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/11",
    "Article_PDF": "https://arxiv.org/pdf/1905.04482"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.04303",
    "DOI": "arXiv:1905.04303v1",
    "Article_Title": "Using Convolutional Neural Networks to identify Gravitational Lenses in Astronomical images",
    "Article_Abstract": "The Euclid telescope, due for launch in 2021, will perform an imaging andslitless spectroscopy survey over half the sky, to map baryon wiggles and weaklensing. During the survey Euclid is expected to resolve 100,000 stronggravitational lens systems. This is ideal to find rare lens configurations,provided they can be identified reliably and on a reasonable timescale. Forthis reason we have developed a Convolutional Neural Network (CNN) that can beused to identify images containing lensing systems. CNNs have already been usedfor image and digit classification as well as being used in astronomy forstar-galaxy classification. Here our CNN is trained and tested on Euclid-likeand KiDS-like simulations from the Euclid Strong Lensing Group, successfullyclassifying 77% of lenses, with an area under the ROC curve of up to 0.96. OurCNN also attempts to classify the lenses in COSMOS HST F814W-band images. Afterconvolution to the Euclid resolution, we find we can recover most systems thatare identifiable by eye. The Python code is available on Github.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Astrophysics of Galaxies (astro-ph.GA)",
    "Article_Date": "2019/05/10",
    "Article_PDF": "https://arxiv.org/pdf/1905.04303"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.04294",
    "DOI": "arXiv:1905.04294v1",
    "Article_Title": "Fruitbat: A Python Package for Estimating Redshifts of Fast Radio Bursts",
    "Article_Abstract": "Fruitbat is an open source Python 2/3 package for estimating redshifts,energies and the galactic dispersion measure contributions of fast radio bursts(FRBs). Fruitbat combines various dispersion measure (DM) and redshiftrelations with the YMW16 galactic dispersion measure model into a single easyto use API.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); High Energy Astrophysical Phenomena (astro-ph.HE)",
    "Article_Date": "2019/05/10",
    "Article_PDF": "https://arxiv.org/pdf/1905.04294"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.03593",
    "DOI": "arXiv:1905.03593v3",
    "Article_Title": "A Topological Analysis of Communication Channels for Knowledge Sharing in Contemporary GitHub Projects",
    "Article_Abstract": "With over 28 million developers, success of the GitHub collaborative platformis highlighted through an abundance of communication channels amongcontemporary software projects. Knowledge is broken into two forms and itssharing (through communication channels) can be described as externalization orcombination by the SECI model. Such platforms have revolutionized the waydevelopers work, introducing new channels to share knowledge in the form ofpull requests, issues and wikis. It is unclear how these channels capture andshare knowledge. In this research, our goal is to analyze these communicationchannels in GitHub. First, using the SECI model, we are able to map howknowledge is shared through the communication channels. Then in a large-scaletopology analysis of seven library package projects (i.e., involving over 70thousand projects), we extracted insights of the different communicationchannels within GitHub. Using two research questions, we explored the evolutionof the channels and adoption of channels by both popular and unpopular librarypackage projects. Results show that (i) contemporary GitHub Projects tend toadopt multiple communication channels, (ii) communication channels change overtime and (iii) communication channels are used to both capture new knowledge(i.e., externalization) and updating existing knowledge (i.e., combination).",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/09",
    "Article_PDF": "https://arxiv.org/pdf/1905.03593"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.02050",
    "DOI": "arXiv:1905.02050v1",
    "Article_Title": "Analyzing Code Comments to Boost Program Comprehension",
    "Article_Abstract": "We are trying to find source code comments that help programmers understand anontrivial part of source code. One of such examples would be explaining toassign a zero as a way to \"clear\" a buffer. Such comments are invaluable toprogrammers and identifying them correctly would be of great help. Toward thisgoal, we developed a method to discover explanatory code comments in a sourcecode. We first propose eleven distinct categories of code comments. We thendeveloped a decision-tree based classifier that can identify explanatorycomments with 60% precision and 80% recall. We analyzed 2,000 GitHub projectsthat are written in two languages: Java and Python. This task is novel in thatit focuses on a microscopic comment (\"local comment\") within a method orfunction, in contrast to the prior efforts that focused on API- or method-levelcomments. We also investigated how different category of comments is used indifferent projects. Our key finding is that there are two dominant types ofcomments: preconditional and postconditional. Our findings also suggest thatmany English code comments have a certain grammatical structure that areconsistent across different projects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/06",
    "Article_PDF": "https://arxiv.org/pdf/1905.02050"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.02005",
    "DOI": "arXiv:1905.02005v2",
    "Article_Title": "Deep Ordinal Reinforcement Learning",
    "Article_Abstract": "Reinforcement learning usually makes use of numerical rewards, which havenice properties but also come with drawbacks and difficulties. Using rewards onan ordinal scale (ordinal rewards) is an alternative to numerical rewards thathas received more attention in recent years. In this paper, a general approachto adapting reinforcement learning problems to the use of ordinal rewards ispresented and motivated. We show how to convert common reinforcement learningalgorithms to an ordinal variation by the example of Q-learning and introduceOrdinal Deep Q-Networks, which adapt deep reinforcement learning to ordinalrewards. Additionally, we run evaluations on problems provided by the OpenAIGym framework, showing that our ordinal variants exhibit a performance that iscomparable to the numerical variations for a number of problems. We also givefirst evidence that our ordinal variant is able to produce better results forproblems with less engineered and simpler-to-design reward signals.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/06",
    "Article_PDF": "https://arxiv.org/pdf/1905.02005"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.01833",
    "DOI": "arXiv:1905.01833v3",
    "Article_Title": "Characterizing and Detecting CUDA Program Bugs",
    "Article_Abstract": "While CUDA has become a major parallel computing platform and programmingmodel for general-purpose GPU computing, CUDA-induced bug patterns have not yetbeen well explored. In this paper, we conduct the first empirical study toreveal important categories of CUDA program bug patterns based on 319 bugsidentified within 5 popular CUDA projects in GitHub. Our findings demonstratethat CUDA-specific characteristics may cause program bugs such assynchronization bugs that are rather difficult to detect. To efficiently detectsuch synchronization bugs, we establish the first lightweight general CUDA bugdetection framework, namely Simulee, to simulate CUDA program execution byinterpreting the corresponding llvm bytecode and collecting the memory-accessinformation to automatically detect CUDA synchronization bugs. To evaluate theeffectiveness and efficiency of Simulee, we conduct a set of experiments andthe experimental results suggest that Simulee can detect 20 out of the 27studied synchronization bugs and successfully detects 26 previously unknownsynchronization bugs, 10 of which have been confirmed by the developers.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/06",
    "Article_PDF": "https://arxiv.org/pdf/1905.01833"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.00976",
    "DOI": "arXiv:1905.00976v2",
    "Article_Title": "Collaborative Evolutionary Reinforcement Learning",
    "Article_Abstract": "Deep reinforcement learning algorithms have been successfully applied to arange of challenging control tasks. However, these methods typically strugglewith achieving effective exploration and are extremely sensitive to the choiceof hyperparameters. One reason is that most approaches use a noisy version oftheir operating policy to explore - thereby limiting the range of exploration.In this paper, we introduce Collaborative Evolutionary Reinforcement Learning(CERL), a scalable framework that comprises a portfolio of policies thatsimultaneously explore and exploit diverse regions of the solution space. Acollection of learners - typically proven algorithms like TD3 - optimize overvarying time-horizons leading to this diverse portfolio. All learnerscontribute to and use a shared replay buffer to achieve greater sampleefficiency. Computational resources are dynamically distributed to favor thebest learners as a form of online algorithm selection. Neuroevolution bindsthis entire process to generate a single emergent learner that exceeds thecapabilities of any individual learner. Experiments in a range of continuouscontrol benchmarks demonstrate that the emergent learner significantlyoutperforms its composite learners while remaining overall moresample-efficient - notably solving the Mujoco Humanoid benchmark where all ofits composite learners (TD3) fail entirely in isolation.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/02",
    "Article_PDF": "https://arxiv.org/pdf/1905.00976"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.00221",
    "DOI": "arXiv:1905.00221v1",
    "Article_Title": "Concerns about the reliability of publicly available SNe Ia data",
    "Article_Abstract": "I highlight several concerns regarding the consistency of Type Ia supernovadata in the publicly available Pantheon and JLA compilations. The measuredheliocentric redshifts (zhel) of $\\sim$150 SNe Ia as reported in the Pantheoncatalogue are significantly discrepant from those in JLA - with 58 havingdifferences amounting to between 5 and 137 times the quoted measurementuncertainty. The discrepancy seems to have been introduced in the process ofrectifying a previously reported issue. The Pantheon catalogue until veryrecently had the redshifts of all SNe Ia up to z $\\sim$ 0.3 modified under theguise of 'peculiar velocity corrections' - although there is no information onpeculiar velocities at such high redshifts. While this has reportedly beenrectified on Github by removing peculiar velocity corrections for z > 0.08, theimpact of this on the published cosmological analysis of the Pantheon catalogueis not stated. In JLA, the effect of these 'corrections' is to significantlybias the inferred value of $\u03a9_\u039b$ towards higher values, while theequivalent effect on Pantheon cannot be ascertained due to the unavailabilityof the individual components of the covariance matrix in the public domain. Iprovide Jupyter notebooks and URLs in order to allow the reader to ascertainthe veracity of these assertions.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Article_Date": "2019/05/01",
    "Article_PDF": "https://arxiv.org/pdf/1905.00221"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.12903",
    "DOI": "arXiv:1904.12903v1",
    "Article_Title": "Modified Gravity Away from a $\\Lambda$CDM Background",
    "Article_Abstract": "Within the effective field theory approach to cosmic acceleration, thebackground expansion can be specified separately from the gravitationalmodifications. We explore the impact of modified gravity in a backgrounddifferent from a cosmological constant plus cold dark matter ($\u039b$CDM) onthe stability and cosmological observables, including covariance betweengravity and expansion parameters. In No Slip Gravity the more generalbackground allows more gravitational freedom, including both positive andnegative Planck mass running. We examine the effects on cosmic structuregrowth, as well as showing that a viable positive integrated Sachs-Wolfe effectcrosscorrelation easily arises from this modified gravity theory. Using currentdata we constrain parameters with a Monte Carlo analysis, finding a maximumrunning $|\u03b1_M|\\lesssim 0.03$. We provide the modified {\\tt hi\\_class} codepublicly on GitHub, now enabling computation and inclusion of the redshiftspace distortion observable $f\u03c3_8$ as well as the No Slip Gravitymodifications.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); General Relativity and Quantum Cosmology (gr-qc)",
    "Article_Date": "2019/04/29",
    "Article_PDF": "https://arxiv.org/pdf/1904.12903"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.11603",
    "DOI": "arXiv:1904.11603v1",
    "Article_Title": "Bayesian Factor Analysis for Inference on Interactions",
    "Article_Abstract": "This article is motivated by the problem of inference on interactions amongchemical exposures impacting human health outcomes. Chemicals often co-occur inthe environment or in synthetic mixtures and as a result exposure levels can behighly correlated. We propose a latent factor joint model, which includesshared factors in both the predictor and response components while assumingconditional independence. By including a quadratic regression in the latentvariables in the response component, we induce flexible dimension reduction incharacterizing main effects and interactions. We propose a Bayesian approach toinference under this Factor analysis for INteractions (FIN) framework. Throughappropriate modifications of the factor modeling structure, FIN can accommodatehigher order interactions and multivariate outcomes. We provide theory onposterior consistency and the impact of misspecifying the number of factors. Weevaluate the performance using a simulation study and data from the NationalHealth and Nutrition Examination Survey (NHANES). Code is available on GitHub.",
    "Article_Subject": "Methodology (stat.ME); Applications (stat.AP)",
    "Article_Date": "2019/04/25",
    "Article_PDF": "https://arxiv.org/pdf/1904.11603"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.11164",
    "DOI": "arXiv:1904.11164v1",
    "Article_Title": "PHANTOM: Curating GitHub for engineered software projects using time-series clustering",
    "Article_Abstract": "Context: Within the field of Mining Software Repositories, there are numerousmethods employed to filter datasets in order to avoid analysing low-qualityprojects. Unfortunately, the existing filtering methods have not kept up withthe growth of existing data sources, such as GitHub, and researchers often relyon quick and dirty techniques to curate datasets.  Objective: The objective of this study is to develop a method capable offiltering large quantities of software projects in a time-efficient way.  Method: This study follows the Design Science Research (DSR) methodology. Theproposed method, PHANTOM, extracts five measures from Git logs. Each measure istransformed into a time-series, which is represented as a feature vector forclustering using the k-means algorithm.  Results: Using the ground truth from a previous study, PHANTOM was shown tobe able to rediscover the ground truth with up to 0.87 Precision or 0.94Recall, and be able to identify \"well-engineered\" projects with up to 0.87Precision and 0.94 Recall on the validation dataset. PHANTOM downloaded andprocessed the metadata of 1,786,601 GitHub repositories in 21.5 days, which isover 33\\% faster than a similar study, which used a computer cluster of 200nodes.  Conclusions: It is possible to use an unsupervised approach to identifywell-engineering projects. PHANTOM was shown to be competitive compared to theexisting supervised approaches while reducing the hardware requirements by twoorders of magnitude.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/25",
    "Article_PDF": "https://arxiv.org/pdf/1904.11164"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10581",
    "DOI": "arXiv:1904.10581v2",
    "Article_Title": "Quantifying Correlated Truncation Errors in Effective Field Theory",
    "Article_Abstract": "Effective field theories (EFTs) organize the description of complex systemsinto an infinite sequence of decreasing importance. Predictions are made with afinite number of terms, which induces a truncation error that is often leftunquantified. We formalize the notion of EFT convergence and propose a Bayesiantruncation error model for predictions that are correlated across theindependent variables, e.g., energy or scattering angle. Central to ourapproach are Gaussian processes that encode both the naturalness andcorrelation structure of EFT coefficients. Our use of Gaussian processespermits efficient and accurate assessment of credible intervals, allows EFTfits to easily include correlated theory errors, and provides analyticposteriors for physical EFT-related quantities such as the expansion parameter.We demonstrate that model-checking diagnostics---applied to the case ofmultiple curves---are powerful tools for EFT validation. As an example, weassess a set of nucleon-nucleon scattering observables in chiral EFT. In aneffort to be self contained, appendices include thorough derivations of ourstatistical results. Our methods are packaged in Python code, called gsum, thatis available for download on GitHub.",
    "Article_Subject": "Nuclear Theory (nucl-th); High Energy Physics - Phenomenology (hep-ph); Nuclear Experiment (nucl-ex); Data Analysis, Statistics and Probability (physics.data-an)",
    "Article_Date": "2019/04/24",
    "Article_PDF": "https://arxiv.org/pdf/1904.10581"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10464",
    "DOI": "arXiv:1904.10464v1",
    "Article_Title": "$\\mathtt{bimEX}$: A Mathematica package for exact computations in 3$+$1 bimetric relativity",
    "Article_Abstract": "We present $\\mathtt{bimEX}$, a Mathematica package for exact computations in3$+$1 bimetric relativity. It is based on the $\\mathtt{xAct}$ bundle, which canhandle computations involving both abstract tensors and their components. Inthis communication, we refer to the latter case as concrete computations. Thepackage consists of two main parts. The first part involves the abstracttensors, and focuses on how to deal with multiple metrics in $\\mathtt{xAct}$.The second part takes an ansatz for the primary variables in a chart as theinput, and returns the covariant BSSN bimetric equations in components in thatchart. Several functions are implemented to make this process as fast anduser-friendly as possible. The package has been used and tested extensively inspherical symmetry and was the workhorse in obtaining the bimetric covariantBSSN equations and reproducing the bimetric 3$+$1 equations in the sphericalpolar chart.",
    "Article_Subject": "Symbolic Computation (cs.SC); Cosmology and Nongalactic Astrophysics (astro-ph.CO); Mathematical Software (cs.MS); General Relativity and Quantum Cosmology (gr-qc)",
    "Article_Date": "2019/04/23",
    "Article_PDF": "https://arxiv.org/pdf/1904.10464"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10255",
    "DOI": "arXiv:1904.10255v1",
    "Article_Title": "End-to-end Sleep Staging with Raw Single Channel EEG using Deep Residual ConvNets",
    "Article_Abstract": "Humans approximately spend a third of their life sleeping, which makesmonitoring sleep an integral part of well-being. In this paper, a 34-layer deepresidual ConvNet architecture for end-to-end sleep staging is proposed. Thenetwork takes raw single channel electroencephalogram (Fpz-Cz) signal as inputand yields hypnogram annotations for each 30s segments as output. Experimentsare carried out for two different scoring standards (5 and 6 stageclassification) on the expanded PhysioNet Sleep-EDF dataset, which containsmulti-source data from hospital and household polysomnography setups. Theperformance of the proposed network is compared with that of thestate-of-the-art algorithms in patient independent validation tasks. Theexperimental results demonstrate the superiority of the proposed networkcompared to the best existing method, providing a relative improvement inepoch-wise average accuracy of 6.8% and 6.3% on the household data andmulti-source data, respectively. Codes are made publicly available on Github.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/23",
    "Article_PDF": "https://arxiv.org/pdf/1904.10255"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10247",
    "DOI": "arXiv:1904.10247v3",
    "Article_Title": "Free-form Video Inpainting with 3D Gated Convolution and Temporal PatchGAN",
    "Article_Abstract": "Free-form video inpainting is a very challenging task that could be widelyused for video editing such as text removal. Existing patch-based methods couldnot handle non-repetitive structures such as faces, while directly applyingimage-based inpainting models to videos will result in temporal inconsistency(see http://bit.ly/2Fu1n6b ). In this paper, we introduce a deep learn-ingbased free-form video inpainting model, with proposed 3D gated convolutions totackle the uncertainty of free-form masks and a novel Temporal PatchGAN loss toenhance temporal consistency. In addition, we collect videos and design afree-form mask generation algorithm to build the free-form video inpainting(FVI) dataset for training and evaluation of video inpainting models. Wedemonstrate the benefits of these components and experiments on both theFaceForensics and our FVI dataset suggest that our method is superior toexisting ones. Related source code, full-resolution result videos and the FVIdataset could be found on Githubhttps://github.com/amjltc295/Free-Form-Video-Inpainting .",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/04/23",
    "Article_PDF": "https://arxiv.org/pdf/1904.10247"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.09954",
    "DOI": "arXiv:1904.09954v1",
    "Article_Title": "Why Software Projects need Heroes (Lessons Learned from 1100+ Projects)",
    "Article_Abstract": "A \"hero\" project is one where 80% or more of the contributions are made bythe 20% of the developers. In the literature, such projects are deprecatedsince they might cause bottlenecks in development and communication. However,there is little empirical evidence on this matter. Further, recent studies showthat such hero projects are very prevalent. Accordingly, this paper exploresthe effect of having heroes in project, from a code quality perspective. Weidentify the heroes developer communities in 1100+ open source GitHub projects.Based on the analysis, we find that (a) hero projects are majorly all projects;and (b) the commits from \"hero developers\" (who contribute most to the code)result in far fewer bugs than other developers. That is, contrary to theliterature, heroes are standard and very useful part of modern open sourceprojects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/22",
    "Article_PDF": "https://arxiv.org/pdf/1904.09954"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.09416",
    "DOI": "arXiv:1904.09416v2",
    "Article_Title": "An Analysis of 35+ Million Jobs of Travis CI",
    "Article_Abstract": "Travis CI handles automatically thousands of builds every day to, amongstother things, provide valuable feedback to thousands of open-source developers.In this paper, we investigate Travis CI to firstly understand who is using it,and when they start to use it. Secondly, we investigate how the developers useTravis CI and finally, how frequently the developers change the Travis CIconfigurations. We observed during our analysis that the main users of TravisCI are corporate users such as Microsoft. And the programming languages used inTravis CI by those users do not follow the same popularity trend than onGitHub, for example, Python is the most popular language on Travis CI, but itis only the third one on GitHub. We also observe that Travis CI is set up onaverage seven days after the creation of the repository and the jobs are stillmainly used (60%) to run tests. And finally, we observe that 7.34% of thecommits modify the Travis CI configuration. We share the biggest benchmark ofTravis CI jobs (to our knowledge): it contains 35,793,144 jobs from 272,917different GitHub projects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/20",
    "Article_PDF": "https://arxiv.org/pdf/1904.09416"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.09355",
    "DOI": "arXiv:1904.09355v2",
    "Article_Title": "Exoplanet Reflected Light Spectroscopy with PICASO",
    "Article_Abstract": "Here we present the first open-source radiative transfer model for computingthe reflected light of exoplanets at any phase geometry, called PICASO:Planetary Intensity Code for Atmospheric Scattering Observations. This code,written in Python, has heritage from a decades old, well-known Fortran modelused for several studies of planetary objects within the Solar System andbeyond. We have adopted it to include several methodologies for computing bothdirect and diffuse scattering phase functions, and have added several updatesincluding the ability to compute Raman scattering spectral features. Here webenchmark PICASO against two independent codes and discuss the degree to whichthe model is sensitive to a user's specification for various phase functions.Then, we conduct a full information content study of the model across a wideparameter space in temperature, cloud profile, SNR and resolving power.",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP)",
    "Article_Date": "2019/04/19",
    "Article_PDF": "https://arxiv.org/pdf/1904.09355"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.08315",
    "DOI": "arXiv:1904.08315v1",
    "Article_Title": "Multi-Level Mesa",
    "Article_Abstract": "Multi-level Mesa is an extension to support the Python based Agents BasedModel (ABM) library Mesa. Multi-level Mesa provides ABM infrastructure to allowfor the inclusion of complex networks, which have modules (groups) andhierarchies (layers) of agents. This approach allows for users to define andsimulate multi-layered adaptions of complex networks. This study reviews othermulti-level libraries currently in the field, describes the main functions andclasses of the Multi-level Mesa, and describes its implementation and impact innumerous varieties using the seminal ABM - Sugarscape. Multi-level Mesa andSugarscape examples are available on GitHub athttps://github.com/tpike3/multilevel_mesa andhttps://github.com/tpike3/SugarScape.",
    "Article_Subject": "Multiagent Systems (cs.MA)",
    "Article_Date": "2019/03/22",
    "Article_PDF": "https://arxiv.org/pdf/1904.08315"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07577",
    "DOI": "arXiv:1904.07577v1",
    "Article_Title": "ASD-DiagNet: A hybrid learning approach for detection of Autism Spectrum Disorder using fMRI data",
    "Article_Abstract": "Mental disorders such as Autism Spectrum Disorders (ASD) are heterogeneousdisorders that are notoriously difficult to diagnose, especially in children.The current psychiatric diagnostic process is based purely on the behaviouralobservation of symptomology (DSM-5/ICD-10) and may be prone to over-prescribingof drugs due to misdiagnosis. In order to move the field towards morequantitative fashion, we need advanced and scalable machine learninginfrastructure that will allow us to identify reliable biomarkers of mentalhealth disorders. In this paper, we propose a framework called ASD-DiagNet forclassifying subjects with ASD from healthy subjects by using only fMRI data. Wedesigned and implemented a joint learning procedure using an autoencoder and asingle layer perceptron which results in improved quality of extracted featuresand optimized parameters for the model. Further, we designed and implemented adata augmentation strategy, based on linear interpolation on available featurevectors, that allows us to produce synthetic datasets needed for training ofmachine learning models. The proposed approach is evaluated on a public datasetprovided by Autism Brain Imaging Data Exchange including 1035 subjects comingfrom 17 different brain imaging centers. Our machine learning model outperformsother state of the art methods from 13 imaging centers with increase inclassification accuracy up to 20% with maximum accuracy of 80%. The machinelearning technique presented in this paper, in addition to yielding betterquality, gives enormous advantages in terms of execution time (40 minutes vs. 6hours on other methods). The implemented code is available as GPL license onGitHub portal of our lab (https://github.com/pcdslab/ASD-DiagNet).",
    "Article_Subject": "Machine Learning (cs.LG); Image and Video Processing (eess.IV); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/16",
    "Article_PDF": "https://arxiv.org/pdf/1904.07577"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07387",
    "DOI": "arXiv:1904.07387v2",
    "Article_Title": "Predicting Fluid Intelligence of Children using T1-weighted MR Images and a StackNet",
    "Article_Abstract": "In this work, we utilize T1-weighted MR images and StackNet to predict fluidintelligence in adolescents. Our framework includes feature extraction, featurenormalization, feature denoising, feature selection, training a StackNet, andpredicting fluid intelligence. The extracted feature is the distribution ofdifferent brain tissues in different brain parcellation regions. The proposedStackNet consists of three layers and 11 models. Each layer uses thepredictions from all previous layers including the input layer. The proposedStackNet is tested on a public benchmark Adolescent Brain Cognitive DevelopmentNeurocognitive Prediction Challenge 2019 and achieves a mean squared error of82.42 on the combined training and validation set with 10-foldcross-validation. In addition, the proposed StackNet also achieves a meansquared error of 94.25 on the testing data. The source code is available onGitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/16",
    "Article_PDF": "https://arxiv.org/pdf/1904.07387"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07197",
    "DOI": "arXiv:1904.07197v1",
    "Article_Title": "Identification of Parameters for Large-scale Models in Systems Biology",
    "Article_Abstract": "Inverse problem for the identification of the parameters for large-scalesystems of nonlinear ordinary differential equations (ODEs) arising in systemsbiology is analyzed. In a recent paper in \\textit{Mathematical Biosciences,305(2018), 133-145}, the authors implemented the numerical method suggested byone of the authors in \\textit{J. Optim. Theory Appl., 85, 3(1995), 509-526} foridentification of parameters in moderate scale models of systems biology. Thismethod combines Pontryagin optimization or Bellman's quasilinearization withsensitivity analysis and Tikhonov regularization. We suggest modification ofthe method by embedding a method of staggered corrector for sensitivityanalysis and by enhancing multi-objective optimization which enablesapplication of the method to large-scale models with practicallynon-identifiable parameters based on multiple data sets, possibly with partialand noisy measurements. We apply the modified method to a benchmark model of athree-step pathway modeled by 8 nonlinear ODEs with 36 unknown parameters andtwo control input parameters. The numerical results demonstrate geometricconvergence with a minimum of five data sets and with minimum measurements perdata set. Software package \\textit{qlopt} is developed and posted in GitHub.MATLAB package AMIGO2 is used to demonstrate advantage of \\textit{qlopt} overmost popular methods/software such as \\textit{lsqnonlin}, \\textit{fmincon} and\\textit{nl2sol}.",
    "Article_Subject": "Quantitative Methods (q-bio.QM); Numerical Analysis (math.NA)",
    "Article_Date": "2019/04/15",
    "Article_PDF": "https://arxiv.org/pdf/1904.07197"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07088",
    "DOI": "arXiv:1904.07088v1",
    "Article_Title": "P4-MACsec: Dynamic Topology Monitoring and Data Layer Protection with MACsec in P4-SDN",
    "Article_Abstract": "We propose P4-MACsec to protect network links between P4 switches throughautomated deployment of MACsec, a widespread IEEE standard for securing Layer 2infrastructures. It is supported by switches and routers from majormanufacturers and has only little performance limitations compared to VPNtechnologies such as IPsec. P4-MACsec introduces a data plane implementation ofMACsec including AES-GCM encryption and decryption directly on P4 switches.P4-MACsec features a two-tier control plane structure where local controllersrunning on the P4 switches interact with a central controller. We propose anovel secure link discovery mechanism that leverages protected LLDP frames andthe two-tier control plane structure for secure and efficient management of aglobal link map. Automated deployment of MACsec creates secure channel,generates keying material, and configures the P4 switches for each detectedlink between two P4 switches. It detects link changes and performs rekeying toprovide a secure, configuration-free operation of MACsec. In this paper, wereview the technological background of P4-MACsec and explain its architecture.To demonstrate the feasibility of P4-MACsec, we implement it on the BMv2 P4software switch and validate the prototype through experiments. We evaluate itsperformance through experiments that focus on TCP throughput and round-triptime. We publish the prototype and experiment setups on Github.",
    "Article_Subject": "Networking and Internet Architecture (cs.NI)",
    "Article_Date": "2019/04/15",
    "Article_PDF": "https://arxiv.org/pdf/1904.07088"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.05257",
    "DOI": "arXiv:1904.05257v1",
    "Article_Title": "Instance Segmentation of Biological Images Using Harmonic Embeddings",
    "Article_Abstract": "We present a new instance segmentation approach tailored to biologicalimages, where instances may correspond to individual cells, organisms or plantparts. Unlike instance segmentation for user photographs or road scenes, inbiological data object instances may be particularly densely packed, theappearance variation may be particularly low, the processing power may berestricted, while, on the other hand, the variability of sizes of individualinstances may be limited. These peculiarities are successfully addressed andexploited by the proposed approach.  Our approach describes each object instance using an expectation of a limitednumber of sine waves with frequencies and phases adjusted to particular objectsizes and densities. At train time, a fully-convolutional network is learned topredict the object embeddings at each pixel using a simple pixelwise regressionloss, while at test time the instances are recovered using clustering in theembeddings space. In the experiments, we show that our approach outperformsprevious embedding-based instance segmentation approaches on a number ofbiological datasets, achieving state-of-the-art on a popular CVPPP benchmark.Notably, this excellent performance is combined with computational efficiencythat is needed for deployment to domain specialists.  The source code is publicly available at Github:https://github.com/kulikovv/harmonic",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/04/10",
    "Article_PDF": "https://arxiv.org/pdf/1904.05257"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.03801",
    "DOI": "arXiv:1904.03801v1",
    "Article_Title": "pdbmine: A Node.js API for the RCSB Protein Data Bank (PDB)",
    "Article_Abstract": "Summary: The advent of Web-based tools that assist in the analysis andvisualization of macromolecules require application programming interfaces(APIs) designed for modern web frameworks. To this end, we have developed aNode.js module pdbmine that allows any user to generate faster data-requestqueries to the RCSB Protein Data Bank (PDB). This JavaScript API acts as alayer over the XML-based RCSB PDB RESTful API. The relatively simple nature ofthe function calls within this module allows the user to easily implement andintegrate pdbmine into larger Node.js web applications.  Availability: This module can be installed via the Node Package Manager (NPM)at https://www.npmjs.com/package/pdbmine/, and is hosted on GitHub under theopen-source MIT license at https://github.com/nnj1/pdbmine/. Relevantdocumentation is detailed at https://nnj1.github.io/pdbmine/",
    "Article_Subject": "Genomics (q-bio.GN)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.03801"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.02724",
    "DOI": "arXiv:1904.02724v1",
    "Article_Title": "Bounties in Open Source Development on GitHub: A Case Study of Bountysource Bounties",
    "Article_Abstract": "Due to the voluntary nature of open source software, it can be hard to find adeveloper to work on a particular task. For example, some issue reports may betoo cumbersome and unexciting for someone to volunteer to do them, yet theseissue reports may be of high priority to the success of a project. To providean incentive for implementing such issue reports, one can propose a monetaryreward, i.e., a bounty, to the developer who completes that particular task. Inthis paper, we study bounties in open source projects on GitHub to betterunderstand how bounties can be leveraged to evolve such projects in terms ofaddressing issue reports. We investigated 5,445 bounties for GitHub projects.These bounties were proposed through the Bountysource platform with a totalbounty value of $406,425. We find that 1) in general, the timing of proposingbounties and the bounty-usage frequency are the most important factors thatimpact the likelihood of an issue being addressed. More specifically, issuereports are more likely to be addressed if they are for projects in whichbounties are used more frequently and if they are proposed earlier. 2) Thebounty value that an issue report has is the most important factor that impactsthe issue-addressing likelihood in the projects in which no bounties were usedbefore. Backers in such projects proposed higher bounty values to get issuesaddressed. 3) There is a risk of wasting money for backers who invest money onlong-standing issue reports.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/04",
    "Article_PDF": "https://arxiv.org/pdf/1904.02724"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.02414",
    "DOI": "arXiv:1904.02414v1",
    "Article_Title": "\"Won't We Fix this Issue?\" Qualitative Characterization and Automated Identification of Wontfix Issues on GitHub",
    "Article_Abstract": "Addressing users requests in the form of bug reports and Github issuesrepresents a crucial task of any successful software project. However,user-submitted issue reports tend to widely differ in their quality, anddevelopers spend a considerable amount of time handling these reports.Moreover, an inefficient prioritization of requested changes could have anegative impact on the developers' workloads. By collecting a dataset of around6,000 issues from the history of 323 GitHub projects, we observe thatdevelopers spend a long time (i.e., about five months, on average) beforelabeling an issue as a wontfix. For this reason, in this paper, we empiricallyinvestigate the nature of wontfix issues, by manually analyzing a sample of 800issues of this kind, extracted from heterogeneous projects. We explore thecommon reasons behind a \"wontfix decision\", the main characteristics of wontfixissues and the potential factors that could be connected with the time to closethem. Furthermore, we experiment approaches for just-in-time prediction ofwontfix issues using machine learning techniques to analyze the titles anddescriptions of reported issues. Our investigation shed some light on thewontfix issues' characteristics, as well as the potential factors that mayaffect the time required to make a \"wontfix decision\". Our results alsodemonstrate that it is possible to predict whether an issue will be closed as awontfix with average values of precision, recall, and F-measure close to 99%,confirming the practical usefulness of the proposed approach for improving theissue management practices on GitHub.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/04",
    "Article_PDF": "https://arxiv.org/pdf/1904.02414"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.01754",
    "DOI": "arXiv:1904.01754v1",
    "Article_Title": "Styler: Learning Formatting Conventions to Repair Checkstyle Errors",
    "Article_Abstract": "Formatting coding conventions play an important role on code readability. Inthis paper, we present Styler, an automatic repair tool dedicated to fixformatting-related errors raised by Checkstyle, a highly configurable formatchecker for Java. To fix formatting errors in a given project, Styler learnsfixes based on the Checkstyle ruleset defined in the project and predictsrepairs for the current errors using machine learning. In an empiricalevaluation, we found that Styler repaired 24% of 497 real Checkstyle errorsmined from five GitHub projects. Moreover, in a comparison of Styler with thestate-of-the-art machine learning code formatters Naturalize and CodeBuff, wefound that Styler is the tool that fixes more real Checkstyle errors and alsogenerates smaller repairs. Finally, we conclude that Styler is promising to beused in IDEs and in a Continuous Integration environment to repair Checkstyleerrors.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.01754"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.01740",
    "DOI": "arXiv:1904.01740v2",
    "Article_Title": "FaceQnet: Quality Assessment for Face Recognition based on Deep Learning",
    "Article_Abstract": "In this paper we develop a Quality Assessment approach for face recognitionbased on deep learning. The method consists of a Convolutional Neural Network,FaceQnet, that is used to predict the suitability of a specific input image forface recognition purposes. The training of FaceQnet is done using the VGGFace2database. We employ the BioLab-ICAO framework for labeling the VGGFace2 imageswith quality information related to their ICAO compliance level. Thegroundtruth quality labels are obtained using FaceNet to generate comparisonscores. We employ the groundtruth data to fine-tune a ResNet-based CNN, makingit capable of returning a numerical quality measure for each input image.Finally, we verify if the FaceQnet scores are suitable to predict the expectedperformance when employing a specific image for face recognition with a COTSface recognition system. Several conclusions can be drawn from this work, mostnotably: 1) we managed to employ an existing ICAO compliance framework and apretrained CNN to automatically label data with quality information, 2) wetrained FaceQnet for quality estimation by fine-tuning a pre-trained facerecognition network (ResNet-50), and 3) we have shown that the predictions fromFaceQnet are highly correlated with the face recognition accuracy of astate-of-the-art commercial system not used during development. FaceQnet ispublicly available in GitHub.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.01740"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.01738",
    "DOI": "arXiv:1904.01738v3",
    "Article_Title": "Adinkra Height Yielding Matrix Numbers: Eigenvalue Equivalence Classes for Minimal Four-Color Adinkras",
    "Article_Abstract": "An adinkra is a graph-theoretic representation of spacetime supersymmetry.Minimal four-color valise adinkras have been extensively studied due to theirrelations to minimal 4D, $\\cal N$ = 1 supermultiplets. Valise adinkras,although an important subclass, do not encode all the information present whena 4D supermultiplet is reduced to 1D. Eigenvalue equivalence classes for valiseadinkra matrices exist, known as $\u03c7_{\\rm o}$ equivalence classes, wherevalise adinkras within the same $\u03c7_{\\rm o}$ equivalence class are isomorphicin the sense that adinkras within a $\u03c7_{\\rm o}$-equivalence class can betransformed into each other via field redefinitions of the nodes. We extendthis to non-valise adinkras, via Python code, providing a complete eigenvalueclassification of \"node-lifting\" for all 36,864 valise adinkras associated withthe Coxeter group $BC{}_4$. We term the eigenvalues associated with thesenode-lifted adinkras Height Yielding Matrix Numbers (HYMNs) and introduce HYMNequivalence classes. These findings have been summarized in a $Mathematica$notebook that can found at the HEPTHools Data Repository(https://hepthools.github.io/Data/) on GitHub.",
    "Article_Subject": "High Energy Physics - Theory (hep-th); Representation Theory (math.RT)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.01738"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.00935",
    "DOI": "arXiv:1904.00935v1",
    "Article_Title": "STYLE-ANALYZER: fixing code style inconsistencies with interpretable unsupervised algorithms",
    "Article_Abstract": "Source code reviews are manual, time-consuming, and expensive. Humaninvolvement should be focused on analyzing the most relevant aspects of theprogram, such as logic and maintainability, rather than amending style, syntax,or formatting defects. Some tools with linting capabilities can format codeautomatically and report various stylistic violations for supported programminglanguages. They are based on rules written by domain experts, hence, theirconfiguration is often tedious, and it is impractical for the given set ofrules to cover all possible corner cases. Some machine learning-based solutionsexist, but they remain uninterpretable black boxes. This paper introducesSTYLE-ANALYZER, a new open source tool to automatically fix code formattingviolations using the decision tree forest model which adapts to each codebaseand is fully unsupervised. STYLE-ANALYZER is built on top of our novel assistedcode review framework, Lookout. It accurately mines the formatting style ofeach analyzed Git repository and expresses the found format patterns withcompact human-readable rules. STYLE-ANALYZER can then suggest styleinconsistency fixes in the form of code review comments. We evaluate the outputquality and practical relevance of STYLE-ANALYZER by demonstrating that it canreproduce the original style with high precision, measured on 19 popularJavaScript projects, and by showing that it yields promising results in fixingreal style mistakes. STYLE-ANALYZER includes a web application to visualize howthe rules are triggered. We release STYLE-ANALYZER as a reusable and extendableopen source software package on GitHub for the benefit of the community.",
    "Article_Subject": "Machine Learning (cs.LG); Software Engineering (cs.SE); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/01",
    "Article_PDF": "https://arxiv.org/pdf/1904.00935"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.00243",
    "DOI": "arXiv:1904.00243v3",
    "Article_Title": "Symmetry-Based Disentangled Representation Learning requires Interaction with Environments",
    "Article_Abstract": "Finding a generally accepted formal definition of a disentangledrepresentation in the context of an agent behaving in an environment is animportant challenge towards the construction of data-efficient autonomousagents. Higgins et al. recently proposed Symmetry-Based DisentangledRepresentation Learning, a definition based on a characterization of symmetriesin the environment using group theory. We build on their work and makeobservations, theoretical and empirical, that lead us to argue thatSymmetry-Based Disentangled Representation Learning cannot only be based onstatic observations: agents should interact with the environment to discoverits symmetries. Our experiments can be reproduced in Colab and the code isavailable on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/30",
    "Article_PDF": "https://arxiv.org/pdf/1904.00243"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.12180",
    "DOI": "arXiv:1903.12180v1",
    "Article_Title": "ACRONYM: Acronym CReatiON for You and Me",
    "Article_Abstract": "Each year, countless hours of productive research time is spent brainstormingcreative acronyms for surveys, simulations, codes, and conferences. We presentACRONYM, a command-line program developed specifically to assist astronomers inidentifying the best acronyms for ongoing projects. The code returns allapproximately-English-language words that appear within an input string oftext, regardless of whether the letters occur at the beginning of the componentwords (in true astronomer fashion).",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/03/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.12180"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.12112",
    "DOI": "arXiv:1903.12112v2",
    "Article_Title": "Merging Combinatorial Design and Optimization: the Oberwolfach Problem",
    "Article_Abstract": "The Oberwolfach Problem $OP(F)$, posed by Gerhard Ringel in 1967, is aparadigmatic Combinatorial Design problem asking whether the complete graph$K_v$ decomposes into edge-disjoint copies of a $2$-regular graph $F$ of order$v$. In Combinatorial Design Theory, so-called difference methods represent awell-known solution technique and construct solutions in infinitely many casesexploiting symmetric and balanced structures. This approach reduces the problemto finding a well-structured $2$-factor which allows us to build solutions thatwe call $1$- or $2$-rotational according to their symmetries. We tackle $OP$ bymodeling difference methods with Optimization tools, specifically ConstraintProgramming ($CP$) and Integer Programming ($IP$), and correspondingly solveinstances with up to $v=120$ within $60s$. In particular, we model the$2$-rotational method by solving in cascade two subproblems, namely the binaryand group labeling, respectively. A polynomial-time algorithm solves the binarylabeling, while $CP$ tackles the group labeling. Furthermore, we providenecessary conditions for the existence of some $1$-rotational solutions whichstem from computational results. This paper shows thereby that both theoreticaland empirical results may arise from the interaction between CombinatorialDesign Theory and Operation Research.",
    "Article_Subject": "Combinatorics (math.CO)",
    "Article_Date": "2019/03/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.12112"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.11914",
    "DOI": "arXiv:1903.11914v3",
    "Article_Title": "Improving convergence of volume penalized fluid-solid interactions",
    "Article_Abstract": "Boundary conditions on arbitrary geometries are a common issue in simulatingpartial differential equations. The conventional approach is to discretize on agrid conforming to the geometry. However grid construction is challenging, andthis difficulty is compounded for evolving domains. Several methods insteadaugment the equations themselves to implicitly enforce the boundary conditions.This paper examines the Volume Penalty Method, which approximates Dirichletboundary conditions in the Navier Stokes equations with rapid linear damping(non-dimensional time scale $\u03b7$) inside the object. This technique is provento converge to the true solution, and also leads to simple volume-integralforce and torque calculations. Unfortunately, previous analysis showedconvergence of only $\\mathcal{O}(\u03b7^{1/2})$. We analyze the source of thiserror using matched asymptotic expansions and show that it stems from adisplacement length, proportional to a Reynolds number Re dependent boundarylayer of size $\\mathcal{O}(\u03b7^{1/2}\\text{Re}^{-1/2})$. The relative size ofthe displacement length and damping time scale lead to the emergence ofmultiple asymptotic regimes. The key finding is that there is a simplecorrection that can be efficiently calculated to eliminate the displacementlength and promote the accuracy to $\\mathcal{O}(\u03b7)$. This improvement alsoextends to the force and torque calculations. We demonstrate these findings in1D planar Poiseuille flow, 2D steady flow past a viscous stagnation point, and2D unsteady flow past a rotating cylinder, and finally show that Richardsonextrapolation can be used with our correction to further improve convergence to$\\mathcal{O}(\u03b7^{2})$.",
    "Article_Subject": "Numerical Analysis (math.NA)",
    "Article_Date": "2019/03/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.11914"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.10729",
    "DOI": "arXiv:1903.10729v3",
    "Article_Title": "WGANSing: A Multi-Voice Singing Voice Synthesizer Based on the Wasserstein-GAN",
    "Article_Abstract": "We present a deep neural network based singing voice synthesizer, inspired bythe Deep Convolutions Generative Adversarial Networks (DCGAN) architecture andoptimized using the Wasserstein-GAN algorithm. We use vocoder parameters foracoustic modelling, to separate the influence of pitch and timbre. Thisfacilitates the modelling of the large variability of pitch in the singingvoice. Our network takes a block of consecutive frame-wise linguistic andfundamental frequency features, along with global singer identity as input andoutputs vocoder features, corresponding to the block of features. Thisblock-wise approach, along with the training methodology allows us to modeltemporal dependencies within the features of the input block. For inference,sequential blocks are concatenated using an overlap-add procedure. We show thatthe performance of our model is competitive with regards to thestate-of-the-art and the original sample using objective metrics and asubjective listening test. We also present examples of the synthesis on asupplementary website and the source code via GitHub.",
    "Article_Subject": "Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "Article_Date": "2019/03/26",
    "Article_PDF": "https://arxiv.org/pdf/1903.10729"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.10326",
    "DOI": "arXiv:1903.10326v1",
    "Article_Title": "topFiberM: Scalable and Efficient Boolean Matrix Factorization",
    "Article_Abstract": "Matrix Factorization has many applications such as clustering. When thematrix is Boolean it is favorable to have Boolean factors too. This will savethe efforts of quantizing the reconstructed data back, which usually is doneusing arbitrary thresholds. Here we introduce topFiberM a Boolean matrixfactorization algorithm. topFiberM chooses in a greedy way the fibers (rows orcolumns) to represent the entire matrix. Fibers are extended to rectanglesaccording to a threshold on precision. The search for these \"top fibers\" cancontinue beyond the required rank and according to an optional parameter thatdefines the limit for this search. A factor with a better gain replaces thefactor with minimum gain in \"top fibers\". We compared topFiberM to thestate-of-the-art methods, it achieved better quality for the set of datasetsusually used in literature. We also applied our algorithm to linked-data toshow its scalability. topFiberM was in average 128 times faster than the wellknown Asso method when applied to a set of matrices representing a realmultigraph although Asso is implemented in C and topFiberM is implemented in Rwhich is generally slower than C. topFiberM is publicly available from Github(https://github.com/dice-group/BMF).",
    "Article_Subject": "Data Structures and Algorithms (cs.DS)",
    "Article_Date": "2019/03/06",
    "Article_PDF": "https://arxiv.org/pdf/1903.10326"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08718",
    "DOI": "arXiv:1903.08718v1",
    "Article_Title": "CRAFT: A multifunction online platform for speech prosody visualisation",
    "Article_Abstract": "There are many research tools which are also used for teaching the acousticphonetics of speech rhythm and speech melody. But they were notpurpose-designed for teaching-learning situations, and some have a steeplearning curve. CRAFT (Creation and Recovery of Amplitude and Frequency Tracks)is custom-designed as a novel flexible online tool for visualisation andcritical comparison of functions and transforms, with implementations of theReaper, RAPT, PyRapt, YAAPT, YIN and PySWIPE F0 estimators, three Praatconfigurations, and two purpose-built estimators, PyAMDF, S0FT. Visualisationsof amplitude and frequency envelope spectra, spectral edge detection of rhythmzones, and a parametrised spectrogram are included. A selection of audio clipsfrom tone and intonation languages is provided for demonstration purposes. Themain advantages of online tools are consistency (users have the same versionand the same data selection), interoperability over different platforms, andease of maintenance. The code is available on GitHub.",
    "Article_Subject": "Sound (cs.SD); Computation and Language (cs.CL)",
    "Article_Date": "2019/03/18",
    "Article_PDF": "https://arxiv.org/pdf/1903.08718"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08621",
    "DOI": "arXiv:1903.08621v1",
    "Article_Title": "Column2Vec: Structural Understanding via Distributed Representations of Database Schemas",
    "Article_Abstract": "We present Column2Vec, a distributed representation of database columns basedon column metadata. Our distributed representation has several applications.Using known names for groups of columns (i.e., a table name), we train a modelto generate an appropriate name for columns in an unnamed table. We demonstratethe viability of our approach using schema information collected from opensource applications on GitHub.",
    "Article_Subject": "Databases (cs.DB); Machine Learning (cs.LG)",
    "Article_Date": "2019/03/20",
    "Article_PDF": "https://arxiv.org/pdf/1903.08621"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08215",
    "DOI": "arXiv:1903.08215v2",
    "Article_Title": "The Galaxy Cluster 'Pypeline' for X-ray Temperature Maps: ClusterPyXT",
    "Article_Abstract": "ClusterPyXT is a new software pipeline to generate spectral temperature,X-ray surface brightness, pressure, and density maps from X-ray observations ofgalaxy clusters. These data products help elucidate the physics of processesoccurring within clusters of galaxies, including turbulence, shock fronts,nonthermal phenomena, and the overall dynamics of cluster mergers. ClusterPyXTautomates the creation of these data products with minimal user interaction,and allows for rapid analyses of archival data with user defined parameters andthe ability to straightforwardly incorporate additional observations. In thispaper, we describe in detail the use of this code and release it as an opensource Python project on GitHub.",
    "Article_Subject": "High Energy Astrophysical Phenomena (astro-ph.HE); Cosmology and Nongalactic Astrophysics (astro-ph.CO); Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/03/19",
    "Article_PDF": "https://arxiv.org/pdf/1903.08215"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08186",
    "DOI": "arXiv:1903.08186v1",
    "Article_Title": "Spectroscopic Transit Search: a self-calibrating method for detecting planets around bright stars",
    "Article_Abstract": "We search for transiting exoplanets around the star $\u03b2$ Pictoris usinghigh resolution spectroscopy and Doppler imaging that removes the need forstandard star observations. These data were obtained on the VLT with UVESduring the course of an observing campaign throughout 2017 that monitored theHill sphere transit of the exoplanet $\u03b2$ Pictoris b. We utilize lineprofile tomography as a method for the discovery of transiting exoplanets. Bymeasuring the exoplanet distortion of the stellar line profile, we remove theneed for reference star measurements. We demonstrate the method with whitenoise simulations, and then look at the case of $\u03b2$ Pictoris, which is a$\u03b4$ Scuti pulsator. We describe a method to remove the stellar pulsationsand perform a search for any transiting exoplanets in the resultant data set.We inject fake planet transits with varying orbital periods and planet radiiinto the spectra and determine the recovery fraction. In the photon noiselimited case we can recover planets down to a Neptune radius with an $\\sim$80%success rate, using an 8 m telescope with a $R\\sim 100,000$ spectrograph and 20minutes of observations per night. The pulsations of $\u03b2$ Pictoris limit oursensitivity to Jupiter-sized planets, but a pulsation removal algorithmimproves this limit to Saturn-sized planets. We present two planet candidates,but argue that their signals are most likely caused by other phenomena. We havedemonstrated a method for searching for transiting exoplanets that (i) does notrequire ancillary calibration observations, (ii) can work on any star whoserotational broadening can be resolved with a high spectral dispersionspectrograph and (iii) provides the lowest limits so far on the radii oftransiting Jupiter-sized exoplanets around $\u03b2$ Pictoris with orbitalperiods from 15 days to 200 days with >50% coverage.",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/03/19",
    "Article_PDF": "https://arxiv.org/pdf/1903.08186"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08113",
    "DOI": "arXiv:1903.08113v1",
    "Article_Title": "Identifying Experts in Software Libraries and Frameworks among GitHub Users",
    "Article_Abstract": "Software development increasingly depends on libraries and frameworks toincrease productivity and reduce time-to-market. Despite this fact, we stilllack techniques to assess developers expertise in widely popular libraries andframeworks. In this paper, we evaluate the performance of unsupervised (basedon clustering) and supervised machine learning classifiers (Random Forest andSVM) to identify experts in three popular JavaScript libraries: facebook/react,mongodb/node-mongodb, and socketio/socket.io. First, we collect 13 featuresabout developers activity on GitHub projects, including commits on source codefiles that depend on these libraries. We also build a ground truth includingthe expertise of 575 developers on the studied libraries, as self-reported bythem in a survey. Based on our findings, we document the challenges of usingmachine learning classifiers to predict expertise in software libraries, usingfeatures extracted from GitHub. Then, we propose a method to identify libraryexperts based on clustering feature data from GitHub; by triangulating theresults of this method with information available on Linkedin profiles, we showthat it is able to recommend dozens of GitHub users with evidences of beingexperts in the studied JavaScript libraries. We also provide a public datasetwith the expertise of 575 developers on the studied libraries.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/03/19",
    "Article_PDF": "https://arxiv.org/pdf/1903.08113"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.07611",
    "DOI": "arXiv:1903.07611v1",
    "Article_Title": "Total Power Map to Visibilities (TP2VIS): Joint Deconvolution of ALMA 12m, 7m, and Total Power Array Data",
    "Article_Abstract": "We present a new package for joint deconvolution of ALMA 12m, 7m, and TotalPower (TP) data, dubbed ``Total Power Map to Visibilities (TP2VIS)\". Itconverts a TP (single-dish) map into visibilities on the CASA platform, whichcan be input into deconvolvers (e.g., CLEAN) along with 12m and 7mvisibilities. A manual is presented in the Github repository(https://github.com/tp2vis/distribute). Combining data from the different ALMAarrays is a driver for a number of science topics, namely those that probe sizescales of extended and compact structures simultaneously. We test TP2VIS usingmodel images, one with a single Gaussian and another that mimics the internalstructures of giant molecular clouds. The result shows that the better uvcoverage with TP2VIS visibilities helps the deconvolution process andreproduces the model image within errors of only 5% over two orders ofmagnitude in flux.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Earth and Planetary Astrophysics (astro-ph.EP); Astrophysics of Galaxies (astro-ph.GA); Solar and Stellar Astrophysics (astro-ph.SR)",
    "Article_Date": "2019/03/18",
    "Article_PDF": "https://arxiv.org/pdf/1903.07611"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.06768",
    "DOI": "arXiv:1903.06768v2",
    "Article_Title": "Joint Mean-Covariance Estimation via the Horseshoe with an Application in Genomic Data Analysis",
    "Article_Abstract": "Seemingly unrelated regression is a natural framework for regressing multiplecorrelated responses on multiple predictors. The model is very flexible, withmultiple linear regression and covariance selection models being special cases.However, its practical deployment in genomic data analysis under a Bayesianframework is limited due to both statistical and computational challenges. Thestatistical challenge is that one needs to infer both the mean vector and theinverse covariance matrix, a problem inherently more complex than separatelyestimating each. The computational challenge is due to the dimensionality ofthe parameter space that routinely exceeds the sample size. We propose the useof horseshoe priors on both the mean vector and the inverse covariance matrix.This prior has demonstrated excellent performance when estimating a mean vectoror inverse covariance matrix separately. The current work shows theseadvantages are also present when addressing both simultaneously. A fullBayesian treatment is proposed, with a sampling algorithm that is linear in thenumber of predictors. MATLAB code implementing the algorithm is freelyavailable from github at https://github.com/liyf1988/HS_GHS. Extensiveperformance comparisons are provided with both frequentist and Bayesianalternatives, and both estimation and prediction performances are verified on agenomic data set.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/03/15",
    "Article_PDF": "https://arxiv.org/pdf/1903.06768"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.06348",
    "DOI": "arXiv:1903.06348v1",
    "Article_Title": "Automatically Generating Documentation for Lambda Expressions in Java",
    "Article_Abstract": "When lambda expressions were introduced to the Java programming language aspart of the release of Java 8 in 2014, they were the language's first step intofunctional programming. Since lambda expressions are still relatively new, notall developers use or understand them. In this paper, we first present theresults of an empirical study to determine how frequently developers of GitHubrepositories make use of lambda expressions and how they are documented. Wefind that 11% of Java GitHub repositories use lambda expressions, and that only6% of the lambda expressions are accompanied by source code comments. We thenpresent a tool called LambdaDoc which can automatically detect lambdaexpressions in a Java repository and generate natural language documentationfor them. Our evaluation of LambdaDoc with 23 professional developers showsthat they perceive the generated documentation to be complete, concise, andexpressive, while the majority of the documentation produced by ourparticipants without tool support was inadequate. Our contribution builds animportant step towards automatically generating documentation for functionalprogramming constructs in an object-oriented language.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/03/15",
    "Article_PDF": "https://arxiv.org/pdf/1903.06348"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.05277",
    "DOI": "arXiv:1903.05277v1",
    "Article_Title": "Activity-Based Analysis of Open Source Software Contributors: Roles and Dynamics",
    "Article_Abstract": "Contributors to open source software (OSS) communities assume diverse rolesto take different responsibilities. One major limitation of the current OSStools and platforms is that they provide a uniform user interface regardless ofthe activities performed by the various types of contributors. This paperserves as a non-trivial first step towards resolving this challenge bydemonstrating a methodology and establishing knowledge to understand how thecontributors' roles and their dynamics, reflected in the activitiescontributors perform, are exhibited in OSS communities. Based on an analysis ofuser action data from 29 GitHub projects, we extracted six activities thatdistinguished four Active roles and five Supporting roles of OSS contributors,as well as patterns in role changes. Through the lens of the Activity Theory,these findings provided rich design guidelines for OSS tools to support diversecontributor roles.",
    "Article_Subject": "Software Engineering (cs.SE); Human-Computer Interaction (cs.HC)",
    "Article_Date": "2019/03/13",
    "Article_PDF": "https://arxiv.org/pdf/1903.05277"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.05084",
    "DOI": "arXiv:1903.05084v3",
    "Article_Title": "Decay Replay Mining to Predict Next Process Events",
    "Article_Abstract": "In complex processes, various events can happen in different sequences. Theprediction of the next event given an a-priori process state is of importancein such processes. Recent methods have proposed deep learning techniques suchas recurrent neural networks, developed on raw event logs, to predict the nextevent from a process state. However, such deep learning models by themselveslack a clear representation of the process states. At the same time, recentmethods have neglected the time feature of event instances. In this paper, wetake advantage of Petri nets as a powerful tool in modeling complex processbehaviors considering time as an elemental variable. We propose an approachwhich starts from a Petri net process model constructed by a process miningalgorithm. We enhance the Petri net model with time decay functions to createcontinuous process state samples. Finally, we use these samples in combinationwith discrete token movement counters and Petri net markings to train a deeplearning model that predicts the next event. We demonstrate significantperformance improvements and outperform the state-of-the-art methods on ninereal-world benchmark event logs.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/12",
    "Article_PDF": "https://arxiv.org/pdf/1903.05084"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.04042",
    "DOI": "arXiv:1903.04042v1",
    "Article_Title": "Algorithms for an Efficient Tensor Biclustering",
    "Article_Abstract": "Consider a data set collected by (individuals-features) pairs in differenttimes. It can be represented as a tensor of three dimensions (Individuals,features and times). The tensor biclustering problem computes a subset ofindividuals and a subset of features whose signal trajectories over time lie ina low-dimensional subspace, modeling similarity among the signal trajectorieswhile allowing different scalings across different individuals or differentfeatures. This approach are based on spectral decomposition in order to buildthe desired biclusters. We evaluate the quality of the results from eachalgorithms with both synthetic and real data set.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/10",
    "Article_PDF": "https://arxiv.org/pdf/1903.04042"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.03804",
    "DOI": "arXiv:1903.03804v1",
    "Article_Title": "Program Classification Using Gated Graph Attention Neural Network for Online Programming Service",
    "Article_Abstract": "The online programing services, such as Github,TopCoder, and EduCoder, havepromoted a lot of social interactions among the service users. However, theexisting social interactions is rather limited and inefficient due to the rapidincreasing of source-code repositories, which is difficult to explore manually.The emergence of source-code mining provides a promising way to analyze thosesource codes, so that those source codes can be relatively easy to understandand share among those service users. Among all the source-code miningattempts,program classification lays a foundation for various tasks related tosource-code understanding, because it is impossible for a machine to understanda computer program if it cannot classify the program correctly. Althoughnumerous machine learning models, such as the Natural Language Processing (NLP)based models and the Abstract Syntax Tree (AST) based models, have beenproposed to classify computer programs based on their corresponding sourcecodes, the existing works cannot fully characterize the source codes from theperspective of both the syntax and semantic information. To address thisproblem, we proposed a Graph Neural Network (GNN) based model, which integratesdata flow and function call information to the AST,and applies an improved GNNmodel to the integrated graph, so as to achieve the state-of-art programclassification accuracy. The experiment results have shown that the proposedwork can classify programs with accuracy over 97%.",
    "Article_Subject": "Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/03/09",
    "Article_PDF": "https://arxiv.org/pdf/1903.03804"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.03375",
    "DOI": "arXiv:1903.03375v1",
    "Article_Title": "Online division of labour: emergent structures in Open Source Software",
    "Article_Abstract": "The development Open Source Software fundamentally depends on theparticipation and commitment of volunteer developers to progress. Several workshave presented strategies to increase the on-boarding and engagement of newcontributors, but little is known on how these diverse groups of developersself-organise to work together. To understand this, one must consider that, onone hand, platforms like GitHub provide a virtually unlimited developmentframework: any number of actors can potentially join to contribute in adecentralised, distributed, remote, and asynchronous manner. On the other,however, it seems reasonable that some sort of hierarchy and division of labourmust be in place to meet human biological and cognitive limits, and also toachieve some level of efficiency. These latter features (hierarchy and divisionof labour) should translate into recognisable structural arrangements whenprojects are represented as developer-file bipartite networks. In this paper weanalyse a set of popular open source projects from GitHub, placing the accenton three key properties: nestedness, modularity and in-block nestedness -whichtypify the emergence of heterogeneities among contributors, the emergence ofsubgroups of developers working on specific subgroups of files, and a mixtureof the two previous, respectively. These analyses show that indeed projectsevolve into internally organised blocks. Furthermore, the distribution of sizesof such blocks is bounded, connecting our results to the celebrated Dunbarnumber both in off- and on-line environments. Our analyses create a linkbetween bio-cognitive constraints, group formation and online workingenvironments, opening up a rich scenario for future research on (online) workteam assembly.",
    "Article_Subject": "Physics and Society (physics.soc-ph); Computers and Society (cs.CY); Software Engineering (cs.SE)",
    "Article_Date": "2019/03/08",
    "Article_PDF": "https://arxiv.org/pdf/1903.03375"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.02904",
    "DOI": "arXiv:1903.02904v1",
    "Article_Title": "Halin graphs are 3-vertex-colorable except even wheels",
    "Article_Abstract": "A Halin graph is a graph obtained by embedding a tree having no nodes ofdegree two in the plane, and then adding a cycle to join the leaves of the treein such a way that the resulting graph is planar. According to the four colortheorem, Halin graphs are 4-vertex-colorable. On the other hand, they are not2-vertex-colorable because they have triangles. We show that all Halin graphsare 3-vertex-colorable except even wheels. We also show how to find the perfectelimination ordering of a chordal completion for a given Halin graph. Thealgorithms are implemented in Python using the graphtheory package. Generatorsof random Halin graphs (general or cubic) are included. The source code isavailable from the public GitHub repository.",
    "Article_Subject": "Data Structures and Algorithms (cs.DS)",
    "Article_Date": "2019/03/07",
    "Article_PDF": "https://arxiv.org/pdf/1903.02904"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.02779",
    "DOI": "arXiv:1903.02779v4",
    "Article_Title": "Deep neural networks for classifying complex features in diffraction images",
    "Article_Abstract": "Intense short-wavelength pulses from free-electron lasers andhigh-harmonic-generation sources enable diffractive imaging of individualnano-sized objects with a single x-ray laser shot. The enormous data sets withup to several million diffraction patterns represent a severe problem for dataanalysis, due to the high dimensionality of imaging data. Feature recognitionand selection is a crucial step to reduce the dimensionality. Usually,custom-made algorithms are developed at a considerable effort to approximatethe particular features connected to an individual specimen, but facingdifferent experimental conditions, these approaches do not generalize well. Onthe other hand, deep neural networks are the principal instrument for today'srevolution in automated image recognition, a development that has not beenadapted to its full potential for data analysis in science. We recentlypublished in Langbehn et al. (Phys. Rev. Lett. 121, 255301 (2018)) the firstapplication of a deep neural network as a feature extractor for wide-anglediffraction images of helium nanodroplets. Here we present the setup, ourmodifications and the training process of the deep neural network fordiffraction image classification and its systematic benchmarking. We find thatdeep neural networks significantly outperform previous attempts for sorting andclassifying complex diffraction patterns and are a significant improvement forthe much-needed assistance during post-processing of large amounts ofexperimental coherent diffraction imaging data.",
    "Article_Subject": "Data Analysis, Statistics and Probability (physics.data-an); Atomic and Molecular Clusters (physics.atm-clus)",
    "Article_Date": "2019/03/07",
    "Article_PDF": "https://arxiv.org/pdf/1903.02779"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.02557",
    "DOI": "arXiv:1903.02557v3",
    "Article_Title": "DASH: Deep Learning for the Automated Spectral Classification of Supernovae and their Hosts",
    "Article_Abstract": "We present DASH (Deep Automated Supernova and Host classifier), a novelsoftware package that automates the classification of the type, age, redshift,and host galaxy of supernova spectra. DASH makes use of a new approach thatdoes not rely on iterative template matching techniques like all previoussoftware, but instead classifies based on the learned features of eachsupernova's type and age. It has achieved this by employing a deepconvolutional neural network to train a matching algorithm. This approach hasenabled DASH to be orders of magnitude faster than previous tools, being ableto accurately classify hundreds or thousands of objects within seconds. We havetested its performance on four years of data from the Australian Dark EnergySurvey (OzDES). The deep learning models were developed using TensorFlow, andwere trained using over 4000 supernova spectra taken from the CfA SupernovaProgram and the Berkeley SN Ia Program as used in SNID (SupernovaIdentification software, Blondin & Tonry 2007). Unlike template matchingmethods, the trained models are independent of the number of spectra in thetraining data, which allows for DASH's unprecedented speed. We have developedboth a graphical interface for easy visual classification and analysis ofsupernovae, and a Python library for the autonomous and quick classification ofseveral supernova spectra. The speed, accuracy, user-friendliness, andversatility of DASH presents an advancement to existing spectral classificationtools. We have made the code publicly available on GitHub and PyPI (pip installastrodash) to allow for further contributions and development. The packagedocumentation is available at https://astrodash.readthedocs.io.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Article_Date": "2019/03/06",
    "Article_PDF": "https://arxiv.org/pdf/1903.02557"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01742",
    "DOI": "arXiv:1903.01742v2",
    "Article_Title": "SZZ Unleashed: An Open Implementation of the SZZ Algorithm -- Featuring Example Usage in a Study of Just-in-Time Bug Prediction for the Jenkins Project",
    "Article_Abstract": "Numerous empirical software engineering studies rely on detailed informationabout bugs. While issue trackers often contain information about when bugs werefixed, details about when they were introduced to the system are often absent.As a remedy, researchers often rely on the SZZ algorithm as a heuristicapproach to identify bug-introducing software changes. Unfortunately, asreported in a recent systematic literature review, few researchers have madetheir SZZ implementations publicly available. Consequently, there is a riskthat research effort is wasted as new projects based on SZZ output need toinitially reimplement the approach. Furthermore, there is a risk that newlydeveloped (closed source) SZZ implementations have not been properly tested,thus conducting research based on their output might introduce threats tovalidity. We present SZZ Unleashed, an open implementation of the SZZ algorithmfor git repositories. This paper describes our implementation along with ausage example for the Jenkins project, and conclude with an illustrative studyon just-in-time bug prediction. We hope to continue evolving SZZ Unleashed onGitHub, and warmly invite the community to contribute.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/03/05",
    "Article_PDF": "https://arxiv.org/pdf/1903.01742"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01698",
    "DOI": "arXiv:1903.01698v3",
    "Article_Title": "Improving Cross-Domain Chinese Word Segmentation with Word Embeddings",
    "Article_Abstract": "Cross-domain Chinese Word Segmentation (CWS) remains a challenge despiterecent progress in neural-based CWS. The limited amount of annotated data inthe target domain has been the key obstacle to a satisfactory performance. Inthis paper, we propose a semi-supervised word-based approach to improvingcross-domain CWS given a baseline segmenter. Particularly, our model onlydeploys word embeddings trained on raw text in the target domain, discardingcomplex hand-crafted features and domain-specific dictionaries. Innovativesubsampling and negative sampling methods are proposed to derive wordembeddings optimized for CWS. We conduct experiments on five datasets inspecial domains, covering domains in novels, medicine, and patent. Results showthat our model can obviously improve cross-domain CWS, especially in thesegmentation of domain-specific noun entities. The word F-measure increases byover 3.0% on four datasets, outperforming state-of-the-art semi-supervised andunsupervised cross-domain CWS approaches with a large margin. We make our codeand data available on Github.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/03/05",
    "Article_PDF": "https://arxiv.org/pdf/1903.01698"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01555",
    "DOI": "arXiv:1903.01555v1",
    "Article_Title": "An Explorative Study of GitHub Repositories of AI Papers",
    "Article_Abstract": "With the rapid development of AI technologies, thousands of AI papers arebeing published each year. Many of these papers have released sample code tofacilitate follow-up researchers. This paper presents an explorative study ofover 1700 code repositories of AI papers hosted on GitHub. We find that theserepositories are often poorly written, lack of documents, lack of maintenance,and hard to configure the underlying runtime environment. Thus, many coderepositories become inactive and abandoned. Such a situation makes follow-upresearchers hard to reproduce the results or do further research. In addition,these hard-to-reuse code makes a gap between academia and industry. Based onthe findings, we give some recommendations on how to improve the quality ofcode repositories of AI papers.",
    "Article_Subject": "Digital Libraries (cs.DL)",
    "Article_Date": "2019/02/16",
    "Article_PDF": "https://arxiv.org/pdf/1903.01555"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01284",
    "DOI": "arXiv:1903.01284v1",
    "Article_Title": "Relation Extraction Datasets in the Digital Humanities Domain and their Evaluation with Word Embeddings",
    "Article_Abstract": "In this research, we manually create high-quality datasets in the digitalhumanities domain for the evaluation of language models, specifically wordembedding models. The first step comprises the creation of unigram and n-gramdatasets for two fantasy novel book series for two task types each, analogy anddoesn't-match. This is followed by the training of models on the two bookseries with various popular word embedding model types such as word2vec, GloVe,fastText, or LexVec. Finally, we evaluate the suitability of word embeddingmodels for such specific relation extraction tasks in a situation of comparablysmall corpus sizes. In the evaluations, we also investigate and analyzeparticular aspects such as the impact of corpus term frequencies and taskdifficulty on accuracy. The datasets, and the underlying system and wordembedding models are available on github and can be easily extended with newdatasets and tasks, be used to reproduce the presented results, or betransferred to other domains.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/03/04",
    "Article_PDF": "https://arxiv.org/pdf/1903.01284"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.00904",
    "DOI": "arXiv:1903.00904v1",
    "Article_Title": "Self-adversarial Variational Autoencoder with Gaussian Anomaly Prior Distribution for Anomaly Detection",
    "Article_Abstract": "Recently, deep generative models have become increasingly popular inunsupervised anomaly detection. However, deep generative models aim atrecovering the data distribution rather than detecting anomalies. Besides, deepgenerative models have the risk of overfitting training samples, which hasdisastrous effects on anomaly detection performance. To solve the above twoproblems, we propose a Self-adversarial Variational Autoencoder with a Gaussiananomaly prior assumption. We assume that both the anomalous and the normalprior distribution are Gaussian and have overlaps in the latent space.Therefore, a Gaussian transformer net T is trained to synthesize anomalous butnear-normal latent variables. Keeping the original training objective ofVariational Autoencoder, besides, the generator G tries to distinguish betweenthe normal latent variables and the anomalous ones synthesized by T, and theencoder E is trained to discriminate whether the output of G is real. These newobjectives we added not only give both G and E the ability to discriminate butalso introduce additional regularization to prevent overfitting. Compared withthe SOTA baselines, the proposed model achieves significant improvements inextensive experiments. Datasets and our model are available at a Githubrepository.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/03",
    "Article_PDF": "https://arxiv.org/pdf/1903.00904"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.00037",
    "DOI": "arXiv:1903.00037v1",
    "Article_Title": "Distance-Based Independence Screening for Canonical Analysis",
    "Article_Abstract": "This paper introduces a new method named Distance-based IndependenceScreening for Canonical Analysis (DISCA) to reduce dimensions of two randomvectors with arbitrary dimensions. The objective of our method is to identifythe low dimensional linear projections of two random vectors, such that anydimension reduction based on linear projection with lower dimensions willsurely affect some dependent structure -- the removed components are notindependent. The essence of DISCA is to use the distance correlation toeliminate the \"redundant\" dimensions until infeasible. Unlike the existingcanonical analysis methods, DISCA does not require the dimensions of thereduced subspaces of the two random vectors to be equal, nor does it requirecertain distributional assumption on the random vectors. We show that undermild conditions, our approach does undercover the lowest possible lineardependency structures between two random vectors, and our conditions are weakerthan some sufficient linear subspace-based methods. Numerically, DISCA is tosolve a non-convex optimization problem. We formulate it as adifference-of-convex (DC) optimization problem, and then further adopt thealternating direction method of multipliers (ADMM) on the convex step of the DCalgorithms to parallelize/accelerate the computation. Some sufficient linearsubspace-based methods use potentially numerically-intensive bootstrap methodto determine the dimensions of the reduced subspaces in advance; our methodavoids this complexity. In simulations, we present cases that DISCA can solveeffectively, while other methods cannot. In both the simulation studies andreal data cases, when the other state-of-the-art dimension reduction methodsare applicable, we observe that DISCA performs either comparably or better thanmost of them. Codes and an R package can be found in GitHubhttps://github.com/ChuanpingYu/DISCA.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/02/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.00037"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.11108",
    "DOI": "arXiv:1902.11108v2",
    "Article_Title": "Artist Style Transfer Via Quadratic Potential",
    "Article_Abstract": "In this paper we address the problem of artist style transfer where thepainting style of a given artist is applied on a real world photograph. Wetrain our neural networks in adversarial setting via recently introducedquadratic potential divergence for stable learning process. To further improvethe quality of generated artist stylized images we also integrate some of therecently introduced deep learning techniques in our method. To our bestknowledge this is the first attempt towards artist style transfer via quadraticpotential divergence. We provide some stylized image samples in thesupplementary material. The source code for experimentation was written inPyTorch and is available online in my GitHub repository.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/02/14",
    "Article_PDF": "https://arxiv.org/pdf/1902.11108"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.10149",
    "DOI": "arXiv:1902.10149v2",
    "Article_Title": "Primordial power spectrum and cosmology from black-box galaxy surveys",
    "Article_Abstract": "We propose a new, likelihood-free approach to inferring the primordial matterpower spectrum and cosmological parameters from arbitrarily complex forwardmodels of galaxy surveys where all relevant statistics can be determined fromnumerical simulations, i.e. black-boxes. Our approach, which we call simulatorexpansion for likelihood-free inference (SELFI), builds upon approximateBayesian computation using a novel effective likelihood, and upon thelinearisation of black-box models around an expansion point. Consequently, weobtain simple \"filter equations\" for an effective posterior of the primordialpower spectrum, and a straightforward scheme for cosmological parameterinference. We demonstrate that the workload is computationally tractable, fixeda priori, and perfectly parallel. As a proof of concept, we apply our frameworkto a realistic synthetic galaxy survey, with a data model accounting forphysical structure formation and incomplete and noisy galaxy observations. Indoing so, we show that the use of non-linear numerical models allows the galaxypower spectrum to be safely fitted up to at least $k_\\mathrm{max} = 0.5$$h$/Mpc, outperforming state-of-the-art backward-modelling techniques by afactor of $\\sim 5$ in the number of modes used. The result is an unbiasedinference of the primordial matter power spectrum across the entire range ofscales considered, including a high-fidelity reconstruction of baryon acousticoscillations. It translates into an unbiased and robust inference ofcosmological parameters. Our results pave the path towards easy applications oflikelihood-free simulation-based inference in cosmology. We have made our codepySELFI and our data products publicly available athttp://pyselfi.florent-leclercq.eu.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/02/26",
    "Article_PDF": "https://arxiv.org/pdf/1902.10149"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.09386",
    "DOI": "arXiv:1902.09386v1",
    "Article_Title": "SMARTp: A SMART design for non-surgical treatments of chronic periodontitis with spatially-referenced and non-randomly missing skewed outcomes",
    "Article_Abstract": "This paper proposes dynamic treatment regimes for choosing individualizedeffective treatment strategies of chronic periodontal disease. R codes forimplementing the proposed sample size formula are available in GitHub.",
    "Article_Subject": "Applications (stat.AP)",
    "Article_Date": "2019/02/25",
    "Article_PDF": "https://arxiv.org/pdf/1902.09386"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.08702",
    "DOI": "arXiv:1902.08702v1",
    "Article_Title": "pyro: a framework for hydrodynamics explorations and prototyping",
    "Article_Abstract": "pyro is a Python-based simulation framework designed for ease ofimplementation and exploration of hydrodynamics methods. It is built in aobject-oriented fashion, allowing for the reuse of the core components and fastprototyping of new methods.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/02/22",
    "Article_PDF": "https://arxiv.org/pdf/1902.08702"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.08182",
    "DOI": "arXiv:1902.08182v1",
    "Article_Title": "Finding the Needle in a Haystack: Detrending Photometric Timeseries Data of Strictly Periodic Astrophysical Objects",
    "Article_Abstract": "Light curves of astrophysical objects frequently contain strictly periodicsignals. In those cases we can use that property to aid the detrendingalgorithm to fully disentangle an unknown periodic signal and an unknownbaseline signal with no power at that period. The periodic signal is modeled asa discrete probability distribution function (pdf), while the baseline signalis modeled as a residual timeseries. Those two components are disentangled byminimizing the length of the residual timeseries w.r.t. the per-bin pdf fluxes.We demonstrate the use of the algorithm on a synthetic case, on the eclipsingbinary KIC 3953981 and on the eccentric ellipsoidal variable KIC 3547874. Wefurther discuss the parameters and the limitations of the algorithm andspeculate on the two most common use cases: detrending the periodic signal ofinterest and measuring the dependence of instrumental response on controlledinstrumental variables. A more sophisticated version of the algorithm isreleased as open source on github and available via pip.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Solar and Stellar Astrophysics (astro-ph.SR)",
    "Article_Date": "2019/02/21",
    "Article_PDF": "https://arxiv.org/pdf/1902.08182"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.07740",
    "DOI": "arXiv:1902.07740v1",
    "Article_Title": "Nitrogen Oxide Concentrations in Natural Waters on Early Earth",
    "Article_Abstract": "A key challenge in origins-of-life studies is estimating the abundances ofspecies relevant to the chemical pathways proposed to have contributed to theemergence of life on early Earth. Dissolved nitrogen oxide anions(NO$_{X}^{-}$), in particular nitrate (NO$_{3}^{-}$) and nitrite(NO$_{2}^{-}$), have been invoked in diverse origins-of-life chemistry, fromthe oligomerization of RNA to the emergence of protometabolism. Recent work hascalculated the supply of NO$_{X}^{-}$ from the prebiotic atmosphere to theocean, and reported steady-state [NO$_{X}^{-}$] to be high across all plausibleparameter space. These findings rest on the assumption that NO$_{X}^{-}$ isstable in natural waters unless processed at a hydrothermal vent. Here, we showthat NO$_{X}^{-}$ is unstable in the reducing environment of early Earth. Sinksdue to UV photolysis and reactions with reduced iron (Fe$^{2+}$) suppress[NO$_{X}^{-}$] by several orders of magnitude relative to past predictions. ForpH$=6.5-8$ and $T=0-50^\\circ$C, we find that it is most probable thatNO$_{X}^{-}$]$<1~\u03bc$M in the prebiotic ocean. On the other hand, prebioticponds with favorable drainage characteristics may have sustained[NO$_{X}^{-}$]$\\geq 1~\u03bc$M. As on modern Earth, most NO$_{X}^{-}$ on prebioticEarth should have been present as NO$_{3}^{-}$, due to its much greaterstability. These findings inform the kind of prebiotic chemistries that wouldhave been possible on early Earth. We discuss the implications for proposedprebiotic chemistries, and highlight the need for further studies ofNO$_{X}^{-}$ kinetics to reduce the considerable uncertainties in predicting[NO$_{X}^{-}$] on early Earth.",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP)",
    "Article_Date": "2019/02/20",
    "Article_PDF": "https://arxiv.org/pdf/1902.07740"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.07704",
    "DOI": "arXiv:1902.07704v1",
    "Article_Title": "How Do the Open Source Communities Address Usability and UX Issues? An Exploratory Study",
    "Article_Abstract": "Usability and user experience (UX) issues are often not well emphasized andaddressed in open source software (OSS) development. There is an imperativeneed for supporting OSS communities to collaboratively identify, understand,and fix UX design issues in a distributed environment. In this paper, weprovide an initial step towards this effort and report on an exploratory studythat investigated how the OSS communities currently reported, discussed,negotiated, and eventually addressed usability and UX issues. We conductedin-depth qualitative analysis of selected issue tracking threads from three OSSprojects hosted on GitHub. Our findings indicated that discussions aboutusability and UX issues in OSS communities were largely influenced by thepersonal opinions and experiences of the participants. Moreover, thecharacteristics of the community may have greatly affected the focus of suchdiscussion.",
    "Article_Subject": "Human-Computer Interaction (cs.HC); Software Engineering (cs.SE)",
    "Article_Date": "2019/02/20",
    "Article_PDF": "https://arxiv.org/pdf/1902.07704"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.03867",
    "DOI": "arXiv:1910.03867v1",
    "Article_Title": "Loss Surface Sightseeing by Multi-Point Optimization",
    "Article_Abstract": "We present multi-point optimization: an optimization technique that allows totrain several models simultaneously without the need to keep the parameters ofeach one individually. The proposed method is used for a thorough empiricalanalysis of the loss landscape of neural networks. By extensive experiments onFashionMNIST and CIFAR10 datasets we demonstrate two things: 1) loss surface issurprisingly diverse and intricate in terms of landscape patterns it contains,and 2) adding batch normalization makes it more smooth. Source code toreproduce all the reported results is available on GitHub:https://github.com/universome/loss-patterns.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/10/09",
    "Article_PDF": "https://arxiv.org/pdf/1910.03867"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.02513",
    "DOI": "arXiv:1910.02513v1",
    "Article_Title": "Automated Isolation for White-box Test Generation",
    "Article_Abstract": "Context. White-box test generation is a technique used for automaticallyselecting test inputs using only the source or binary code. However, suchtechniques encounter challenges when applying them to complex programs. One ofthe main challenges is handling the dependencies of the unit under test.  Objective. Without proper actions, generated tests cannot cover all parts ofthe source code, or calling the dependencies may cause unexpected side effects(e.g., file system or network access). These issues should be tackled whilemaintaining the advantages of white-box test generation.  Method. In this paper, we present an automated source code transformationapproach tackling the dependency issue for white-box test generation. Thistechnique isolates the test execution by creating a parameterized sandboxwrapped around the transformed unit. We implemented the approach in aready-to-use tool using Microsoft Pex as a test generator, and evaluated it on10 open-source projects from GitHub having more than 38.000 lines of code intotal.  Results. The results from the evaluation indicate that if the lack ofisolation hinders white-box test generation, then our approach is able to help:it increases the code coverage reached by the automatically generated test,while it reduces unwanted side effects. Also, our results act as a uniquebaseline for the test generation performance of Microsoft Pex on open-sourceprojects.  Conclusion. Based on the results, our source code transformations might servewell for alleviating the isolation problem in white-box test generation as itincreases the coverage reached in such situations, while maintaining thepractical applicability of the tests generated on the isolated code.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/10/06",
    "Article_PDF": "https://arxiv.org/pdf/1910.02513"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01750",
    "DOI": "arXiv:1910.01750v2",
    "Article_Title": "PEXO: a global modeling framework for nanosecond timing, microsecond astrometry, and {\\mu}m/s radial velocities",
    "Article_Abstract": "The ability to make independent detections of the signatures of exoplanetswith complementary telescopes and instruments brings a new potential for robustidentification of exoplanets and precision characterization. We introduce PEXO,a package for Precise EXOplanetology to facilitate the efficient modeling oftiming, astrometry, and radial velocity data, which will benefit not onlyexoplanet science but also various astrophysical studies in general. PEXO isgeneral enough to account for binary motion and stellar reflex motions inducedby planetary companions and is precise enough to treat various relativisticeffects both in the solar system and in the target system. We also model thepost-Newtonian barycentric motion for future tests of general relativity inextrasolar systems. We benchmark PEXO with the pulsar timing package TEMPO2 andfind that PEXO produces numerically similar results with timing precision ofabout 1 ns, space-based astrometry to a precision of 1\u03bcas, and radialvelocity of 1 \u03bcm/s and improves on TEMPO2 for decade-long timing data ofnearby targets, due to its consideration of third-order terms of Roemer delay.PEXO is able to avoid the bias introduced by decoupling the target system andthe solar system and to account for the atmospheric effects which set apractical limit for ground-based radial velocities close to 1 cm/s. Consideringthe various caveats in barycentric correction and ancillary data required torealize cm/s modeling, we recommend the preservation of original observationaldata. The PEXO modeling package is available at GitHub(https://github.com/phillippro/pexo).",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM); Solar and Stellar Astrophysics (astro-ph.SR)",
    "Article_Date": "2019/10/03",
    "Article_PDF": "https://arxiv.org/pdf/1910.01750"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01321",
    "DOI": "arXiv:1910.01321v1",
    "Article_Title": "An Empirical Study of C++ Vulnerabilities in Crowd-Sourced Code Examples",
    "Article_Abstract": "Software developers share programming solutions in Q&A sites like StackOverflow. The reuse of crowd-sourced code snippets can facilitate rapidprototyping. However, recent research shows that the shared code snippets maybe of low quality and can even contain vulnerabilities. This paper aims tounderstand the nature and the prevalence of security vulnerabilities incrowd-sourced code examples. To achieve this goal, we investigate securityvulnerabilities in the C++ code snippets shared on Stack Overflow over a periodof 10 years. In collaborative sessions involving multiple human coders, wemanually assessed each code snippet for security vulnerabilities following CWE(Common Weakness Enumeration) guidelines. From the 72,483 reviewed codesnippets used in at least one project hosted on GitHub, we found a total of 69vulnerable code snippets categorized into 29 types. Many of the investigatedcode snippets are still not corrected on Stack Overflow. The 69 vulnerable codesnippets found in Stack Overflow were reused in a total of 2859 GitHubprojects. To help improve the quality of code snippets shared on StackOverflow, we developed a browser extension that allow Stack Overflow users tocheck for vulnerabilities in code snippets when they upload them on theplatform.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/10/03",
    "Article_PDF": "https://arxiv.org/pdf/1910.01321"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01212",
    "DOI": "arXiv:1910.01212v1",
    "Article_Title": "Social Influence and Radicalization: A Social Data Analytics Study",
    "Article_Abstract": "The confluence of technological and societal advances is changing the natureof global terrorism. For example, engagement with Web, social media, and smartdevices has the potential to affect the mental behavior of the individuals andinfluence extremist and criminal behaviors such as Radicalization. In thiscontext, social data analytics (i.e., the discovery, interpretation, andcommunication of meaningful patterns in social data) and influence maximization(i.e., the problem of finding a small subset of nodes in a social network whichcan maximize the propagation of influence) has the potential to become a vitalasset to explore the factors involved in influencing people to participate inextremist activities.  To address this challenge, we study and analyze the recent work done ininfluence maximization and social data analytics from effectiveness, efficiencyand scalability viewpoints. We introduce a social data analytics pipeline,namely iRadical, to enable analysts engage with social data to explore thepotential for online radicalization. In iRadical, we present algorithms toanalyse the social data as well as the user activity patterns to learn howinfluence flows in social networks. We implement iRadical as an extensiblearchitecture that is publicly available on GitHub and present the evaluationresults.",
    "Article_Subject": "Computers and Society (cs.CY); Machine Learning (cs.LG)",
    "Article_Date": "2019/09/04",
    "Article_PDF": "https://arxiv.org/pdf/1910.01212"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01078",
    "DOI": "arXiv:1910.01078v1",
    "Article_Title": "ROS Rescue : Fault Tolerance System for Robot Operating System",
    "Article_Abstract": "In this chapter we discuss the problem of master failure in ROS1.0 and itsimpact on robotic deployments in the real world. We address this issue in thistutorial chapter where we outline, design and demonstrate a fault tolerantmechanism associated with ROS master failure. Unlike previous solutions whichuse primary backup replication and external checkpointing libraries which areprocess heavy, our mechanism adds a lightweight functionality to the ROS masterto enable it to recover from failure.  We present a modified version of ROS master which is equipped with a loggingmechanism to record the meta information and network state of ROS nodes as wellas a recovery mechanism to go back to the previous state without having toabort or restart all the nodes. We also implement an additional master monitornode responsible for failure detection on the master by polling it for itsavailability. Our code is implemented in python and preliminary tests wereconducted successfully on a variety of land, aerial and underwater robots and atele-operating computer running ROS Kinetic on Ubuntu 16.04. The code ispublicly available under a creative commons license on github athttps://github.com/PushyamiKaveti/fault-tolerant-ros-master",
    "Article_Subject": "Robotics (cs.RO)",
    "Article_Date": "2019/10/02",
    "Article_PDF": "https://arxiv.org/pdf/1910.01078"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00725",
    "DOI": "arXiv:1910.00725v1",
    "Article_Title": "Cosmic Microwave Background Anisotropy numerical solution (CMBAns) I: An introduction to $C_l$ calculation",
    "Article_Abstract": "Cosmological Boltzmann codes are often used by researchers for calculatingthe CMB angular power spectra from different theoretical models, forcosmological parameter estimation, etc. Therefore, the accuracy of a Boltzmanncode is of utmost importance. Different Markov Chain Monte Carlo basedparameter estimation algorithms typically require 10^3 - 10^4 iterations ofBoltzmann code. This makes the time complexity of such codes another criticalfactor. In the last two decades, several Boltzmann packages, such as CMBFAST,CAMB, CMBEasy, CLASS etc., have been developed. In this paper, we present a newcosmological Boltzmann code, CMBAns, that can be used for accurate calculationof the CMB power spectrum. At present, CMBAns is developed for a flatbackground matrix. It is mostly written in the C language. However, we borrowedthe concept of class from C++. This gives researchers the flexibility todevelop their own independent package based on CMBAns, without an in-depthunderstanding of the source code. We also develop multiple stand-alonefacilities which can be directly compiled and run on a given parameter set. Inthis paper, we discuss all the mathematical formulation, approximation schemes,integration methods etc., that are used in CMBAns. The package will be madeavailable through github for public use in the near future.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); Instrumentation and Methods for Astrophysics (astro-ph.IM); General Relativity and Quantum Cosmology (gr-qc)",
    "Article_Date": "2019/10/02",
    "Article_PDF": "https://arxiv.org/pdf/1910.00725"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00536",
    "DOI": "arXiv:1910.00536v1",
    "Article_Title": "Scalable String Reconciliation by Recursive Content-Dependent Shingling",
    "Article_Abstract": "We consider the problem of reconciling similar, but remote, strings withminimum communication complexity. This \"string reconciliation\" problem is afundamental building block for a variety of networking applications, includingthose that maintain large-scale distributed networks and perform remote filesynchronization. We present the novel Recursive Content-Dependent Shingling(RCDS) protocol that is computationally practical for large strings and scaleslinearly with the edit distance between the remote strings. We providecomparisons to the performance of Rsync, one of the most popular filesynchronization tools in active use. Our experiments show that, with minimalengineering, RCDS outperforms the heavily optimized Rsync in reconcilingrelease revisions for about 51% of the 5000 top starred git repositories onGitHub. The improvement is particularly evident for repositories that seefrequent, but small, updates.",
    "Article_Subject": "Information Theory (cs.IT)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00536"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00286",
    "DOI": "arXiv:1910.00286v1",
    "Article_Title": "Ransomware Analysis using Feature Engineering and Deep Neural Networks",
    "Article_Abstract": "Detection and Analysis of a potential malware specifically, used for ransomis a challenging task. Recently, intruders are utilizing advance cryptographictechniques to get hold of digital assets and then demand ransom. It is believedthat generally, the files comprise of some attributes, states, and patternsthat can be recognized by a machine learning technique. This work thus focuseson detection of Ransomware by performing feature engineering, which helps inanalyzing vital attributes and behaviors of the malware. The main contributionof this work is the identification of important and distinct characteristics ofRansomware that can help in detecting them. Finally, based on the selectedfeatures, both conventional machine learning techniques and Transfer Learningbased Deep Convolutional Neural Networks have been used to detect Ransomware.In order to perform feature engineering and analysis, two separate datasets(static and dynamic) were generated. The static dataset has 3646 samples (1700Ransomware and 1946 Goodware). On the other hand, the dynamic dataset comprisedof 3444 samples (1455 Ransomware and 1989 Goodware). Through variousexperiments, it is observed that the Registry changes, API calls, and DLLs arethe most important features for Ransomware detection. Additionally, importantsequences are found with the help of N Gram technique. It is also observed thatin case of Registry Delete operation, if a malicious file tries to deleteregistries, it follows a specific and repeated sequence. However for the benignfile, it doesnt follow any specific sequence or repetition. Similarly, aninteresting observation made through this study is that there is no commonRegistry deleted sequence between malicious and benign file. And thus thisdiscernible fact can be readily exploited for Ransomware detection. Therelevant Python code and dataset are available at github.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00286"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00199",
    "DOI": "arXiv:1910.00199v1",
    "Article_Title": "Underwhelming Generalization Improvements From Controlling Feature Attribution",
    "Article_Abstract": "Overfitting is a common issue in machine learning, which can arise when themodel learns to predict class membership using convenient butspuriously-correlated image features instead of the true image features thatdenote a class. These are typically visualized using saliency maps. In someobject classification tasks such as for medical images, one may have someimages with masks, indicating a region of interest, i.e., which part of theimage contains the most relevant information for the classification. Wedescribe a simple method for taking advantage of such auxiliary labels, bytraining networks to ignore the distracting features which may be extractedoutside of the region of interest, on the training images for which such masksare available. This mask information is only used during training and has animpact on generalization accuracy in a dataset-dependent way. We observe anunderwhelming relationship between controlling saliency maps and improvinggeneralization performance.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00199"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00188",
    "DOI": "arXiv:1910.00188v1",
    "Article_Title": "Beyond Textual Issues: Understanding the Usage and Impact of GitHub Reactions",
    "Article_Abstract": "Recently, GitHub introduced a new social feature, named reactions, which are\"pictorial characters\" similar to emoji symbols widely used nowadays intext-based communications. Particularly, GitHub users can use a pre-defined setof such symbols to react to issues and pull requests. However, little is knownabout the real usage and impact of GitHub reactions. In this paper, we analyzethe reactions provided by developers to more than 2.5 million issues and 9.7million issue comments, in order to answer an extensive list of nine researchquestions about the usage and adoption of reactions. We show that reactions arebeing increasingly used by open source developers. Moreover, we also found thatissues with reactions usually take more time to be handled and have longerdiscussions.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00188"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00024",
    "DOI": "arXiv:1910.00024v1",
    "Article_Title": "Neural Canonical Transformation with Symplectic Flows",
    "Article_Abstract": "Canonical transformation plays a fundamental role in simplifying and solvingclassical Hamiltonian systems. We construct flexible and powerful canonicaltransformations as generative models using symplectic neural networks. Themodel transforms physical variables towards a latent representation with anindependent harmonic oscillator Hamiltonian. Correspondingly, the phase spacedensity of the physical system flows towards a factorized Gaussian distributionin the latent space. Since the canonical transformation preserves theHamiltonian evolution, the model captures nonlinear collective modes in thelearned latent representation. We present an efficient implementation ofsymplectic neural coordinate transformations and two ways to train the model.The variational free energy calculation is based on the analytical form ofphysical Hamiltonian. While the phase space density estimation only requiressamples in the coordinate space for separable Hamiltonians. We demonstrateappealing features of neural canonical transformation using toy problemsincluding two-dimensional ring potential and harmonic chain. Finally, we applythe approach to real-world problems such as identifying slow collective modesin alanine dipeptide and conceptual compression of the MNIST dataset.",
    "Article_Subject": "Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG); Computational Physics (physics.comp-ph); Machine Learning (stat.ML)",
    "Article_Date": "2019/09/30",
    "Article_PDF": "https://arxiv.org/pdf/1910.00024"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.13589",
    "DOI": "arXiv:1909.13589v1",
    "Article_Title": "Domain Adaptation for Semantic Segmentation with Maximum Squares Loss",
    "Article_Abstract": "Deep neural networks for semantic segmentation always require a large numberof samples with pixel-level labels, which becomes the major difficulty in theirreal-world applications. To reduce the labeling cost, unsupervised domainadaptation (UDA) approaches are proposed to transfer knowledge from labeledsynthesized datasets to unlabeled real-world datasets. Recently, somesemi-supervised learning methods have been applied to UDA and achievedstate-of-the-art performance. One of the most popular approaches insemi-supervised learning is the entropy minimization method. However, whenapplying the entropy minimization to UDA for semantic segmentation, thegradient of the entropy is biased towards samples that are easy to transfer. Tobalance the gradient of well-classified target samples, we propose the maximumsquares loss. Our maximum squares loss prevents the training process beingdominated by easy-to-transfer samples in the target domain. Besides, weintroduce the image-wise weighting ratio to alleviate the class imbalance inthe unlabeled target domain. Both synthetic-to-real and cross-city adaptationexperiments demonstrate the effectiveness of our proposed approach. The code isreleased at https://github. com/ZJULearning/MaxSquareLoss.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/30",
    "Article_PDF": "https://arxiv.org/pdf/1909.13589"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.13092",
    "DOI": "arXiv:1909.13092v1",
    "Article_Title": "GLA-Net: An Attention Network with Guided Loss for Mismatch Removal",
    "Article_Abstract": "Mismatch removal is a critical prerequisite in many feature-based tasks.Recent attempts cast the mismatch removal task as a binary classificationproblem and solve it through deep learning based methods. In these methods, theimbalance between positive and negative classes is important, which affectsnetwork performance, i.e., Fn-score. To establish the link between Fn-score andloss, we propose to guide the loss with the Fn-score directly. We theoreticallydemonstrate the direct link between our Guided Loss and Fn-score duringtraining. Moreover, we discover that outliers often impair global context inmismatch removal networks. To address this issue, we introduce the attentionmechanism to mismatch removal task and propose a novel Inlier Attention Block(IA Block). To evaluate the effectiveness of our loss and IA Block, we designan end-to-end network for mismatch removal, called GLA-Net \\footnote{Our codewill be available in Github later.}. Experiments have shown that our networkachieves the state-of-the-art performance on benchmark datasets.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/28",
    "Article_PDF": "https://arxiv.org/pdf/1909.13092"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.11977",
    "DOI": "arXiv:1909.11977v1",
    "Article_Title": "Stochastic Weight Matrix-based Regularization Methods for Deep Neural Networks",
    "Article_Abstract": "The aim of this paper is to introduce two widely applicable regularizationmethods based on the direct modification of weight matrices. The first method,Weight Reinitialization, utilizes a simplified Bayesian assumption withpartially resetting a sparse subset of the parameters. The second one, WeightShuffling, introduces an entropy- and weight distribution-invariant non-whitenoise to the parameters. The latter can also be interpreted as an ensembleapproach. The proposed methods are evaluated on benchmark datasets, such asMNIST, CIFAR-10 or the JSB Chorales database, and also on time series modelingtasks. We report gains both regarding performance and entropy of the analyzednetworks. We also made our code available as a GitHub repository(https://github.com/rpatrik96/lod-wmm-2019).",
    "Article_Subject": "Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)",
    "Article_Date": "2019/09/26",
    "Article_PDF": "https://arxiv.org/pdf/1909.11977"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.11811",
    "DOI": "arXiv:1909.11811v1",
    "Article_Title": "A fast, complete, point cloud based loop closure for LiDAR odometry and mapping",
    "Article_Abstract": "This paper presents a loop closure method to correct the long-term drift inLiDAR odometry and mapping (LOAM). Our proposed method computes the 2Dhistogram of keyframes, a local map patch, and uses the normalizedcross-correlation of the 2D histograms as the similarity metric between thecurrent keyframe and those in the map. We show that this method is fast,invariant to rotation, and produces reliable and accurate loop detection. Theproposed method is implemented with careful engineering and integrated into theLOAM algorithm, forming a complete and practical system ready to use. Tobenefit the community by serving a benchmark for loop closure, the entiresystem is made open source on Github",
    "Article_Subject": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/25",
    "Article_PDF": "https://arxiv.org/pdf/1909.11811"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.11544",
    "DOI": "arXiv:1909.11544v1",
    "Article_Title": "PyDEns: a Python Framework for Solving Differential Equations with Neural Networks",
    "Article_Abstract": "Recently, a lot of papers proposed to use neural networks to approximatelysolve partial differential equations (PDEs). Yet, there has been a lack offlexible framework for convenient experimentation. In an attempt to fill thegap, we introduce a PyDEns-module open-sourced on GitHub. Coupled withcapabilities of BatchFlow, open-source framework for convenient andreproducible deep learning, PyDEns-module allows to 1) solve partialdifferential equations from a large family, including heat equation and waveequation 2) easily search for the best neural-network architecture among thezoo, that includes ResNet and DenseNet 3) fully control the process ofmodel-training by testing different point-sampling schemes. With that in mind,our main contribution goes as follows: implementation of a ready-to-use andopen-source numerical solver of PDEs of a novel format, based on neuralnetworks.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/09/25",
    "Article_PDF": "https://arxiv.org/pdf/1909.11544"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.10051",
    "DOI": "arXiv:1909.10051v1",
    "Article_Title": "PyIT2FLS: A New Python Toolkit for Interval Type 2 Fuzzy Logic Systems",
    "Article_Abstract": "Fuzzy logic is an accepted and well-developed approach for constructingverbal models. Fuzzy based methods are getting more popular, while theengineers deal with more daily life tasks. This paper presents a new Pythontoolkit for Interval Type 2 Fuzzy Logic Systems (IT2FLS). Developing softwaretools is an important issue for facilitating the practical use of theoreticalresults. There are limited tools for implementing IT2FLSs in Python. Thedeveloped PyIT2FLS is providing a set of tools for fast and easy modeling offuzzy systems. This paper includes a brief description of how developed toolkitcan be used. Also, three examples are given showing the usage of the developedtoolkit for simulating IT2FLSs. First, a simple rule-based system is developedand it's codes are presented in the paper. The second example is the predictionof the Mackey-Glass chaotic time series using IT2FLS. In this example, theParticle Swarm Optimization (PSO) algorithm is used for determining systemparameters while minimizing the mean square error. In the last example, anIT2FPID is used in a linear time-delay system. The code for the examples areavailable on toolkit's GitHub page: https://github.com/Haghrah/PyIT2FLS. Thesimulations and their results confirm the ability of the developed toolkit tobe used in a wide range of the applications.",
    "Article_Subject": "Systems and Control (eess.SY); Mathematical Software (cs.MS)",
    "Article_Date": "2019/09/22",
    "Article_PDF": "https://arxiv.org/pdf/1909.10051"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.09029",
    "DOI": "arXiv:1909.09029v2",
    "Article_Title": "DIRE: A Neural Approach to Decompiled Identifier Naming",
    "Article_Abstract": "The decompiler is one of the most common tools for examining binaries withoutcorresponding source code. It transforms binaries into high-level code,reversing the compilation process. Decompilers can reconstruct much of theinformation that is lost during the compilation process (e.g., structure andtype information). Unfortunately, they do not reconstruct semanticallymeaningful variable names, which are known to increase code understandability.We propose the Decompiled Identifier Renaming Engine (DIRE), a novelprobabilistic technique for variable name recovery that uses both lexical andstructural information recovered by the decompiler. We also present a techniquefor generating corpora suitable for training and evaluating models ofdecompiled code renaming, which we use to create a corpus of 164,632 uniquex86-64 binaries generated from C projects mined from GitHub. Our results showthat on this corpus DIRE can predict variable names identical to the names inthe original source code up to 74.3% of the time.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/09/19",
    "Article_PDF": "https://arxiv.org/pdf/1909.09029"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.08766",
    "DOI": "arXiv:1909.08766v1",
    "Article_Title": "A High-Fidelity Open Embodied Avatar with Lip Syncing and Expression Capabilities",
    "Article_Abstract": "Embodied avatars as virtual agents have many applications and providebenefits over disembodied agents, allowing non-verbal social and interactionalcues to be leveraged, in a similar manner to how humans interact with eachother. We present an open embodied avatar built upon the Unreal Engine that canbe controlled via a simple python programming interface. The avatar has lipsyncing (phoneme control), head gesture and facial expression (using eitherfacial action units or cardinal emotion categories) capabilities. We releasecode and models to illustrate how the avatar can be controlled like a puppet orused to create a simple conversational agent using public applicationprogramming interfaces (APIs). GITHUB link:https://github.com/danmcduff/AvatarSim",
    "Article_Subject": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)",
    "Article_Date": "2019/09/19",
    "Article_PDF": "https://arxiv.org/pdf/1909.08766"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.06700",
    "DOI": "arXiv:1909.06700v1",
    "Article_Title": "Loam_livox: A fast, robust, high-precision LiDAR odometry and mapping package for LiDARs of small FoV",
    "Article_Abstract": "LiDAR odometry and mapping (LOAM) has been playing an important role inautonomous vehicles, due to its ability to simultaneously localize the robot'spose and build high-precision, high-resolution maps of the surroundingenvironment. This enables autonomous navigation and safe path planning ofautonomous vehicles. In this paper, we present a robust, real-time LOAMalgorithm for LiDARs with small FoV and irregular samplings. By taking efforton both front-end and back-end, we address several fundamental challengesarising from such LiDARs, and achieve better performance in both precision andefficiency compared to existing baselines. To share our findings and to makecontributions to the community, we open source our codes on Github",
    "Article_Subject": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/09/15",
    "Article_PDF": "https://arxiv.org/pdf/1909.06700"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.05983",
    "DOI": "arXiv:1909.05983v1",
    "Article_Title": "Content-Aware Unsupervised Deep Homography Estimation",
    "Article_Abstract": "Robust homography estimation between two images is a fundamental task whichhas been widely applied to various vision applications. Traditional featurebased methods often detect image features and fit a homography according tomatched features with RANSAC outlier removal. However, the quality ofhomography heavily relies on the quality of image features, which are prone toerrors with respect to low light and low texture images. On the other hand,previous deep homography approaches either synthesize images for supervisedlearning or adopt aerial images for unsupervised learning, both ignoring theimportance of depth disparities in homography estimation. Moreover, they treatthe image content equally, including regions of dynamic objects and near-rangeforegrounds, which further decreases the quality of estimation. In this work,to overcome such problems, we propose an unsupervised deep homography methodwith a new architecture design. We learn a mask during the estimation to rejectoutlier regions. In addition, we calculate loss with respect to our learneddeep features instead of directly comparing the image contents as didpreviously. Moreover, a comprehensive dataset is presented, covering bothregular and challenging cases, such as poor textures and non-planarinterferences. The effectiveness of our method is validated through comparisonswith both feature-based and previous deep-based methods. Code will be soonavailable at Github.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/12",
    "Article_PDF": "https://arxiv.org/pdf/1909.05983"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.05090",
    "DOI": "arXiv:1909.05090v1",
    "Article_Title": "DNANet: De-Normalized Attention Based Multi-Resolution Network for Human Pose Estimation",
    "Article_Abstract": "Recently, multi-resolution networks (such as Hourglass, CPN, HRNet, etc.)have achieved significant performance on the task of human pose estimation bycombining features from various resolutions. In this paper, we propose a noveltype of attention module, namely De-Normalized Attention (DNA) to deal with thefeature attenuations of conventional attention modules. Our method extends theoriginal HRNet with spatial, channel-wise and resolution-wise DNAs, which aimsat evaluating the importance of features from different locations, channels andresolutions to enhance the network capability for feature representation. Wealso propose to add fine-to-coarse connections across high-to-low resolutionsin-side each layer of HRNet to increase the maximum depth of network topology.In addition, we propose to modify the keypoint regressor at the end of HRNetfor accurate keypoint heatmap prediction. The effectiveness of our proposednetwork is demonstrated on COCO keypoint detection dataset, achievingstate-of-the-art performance at 76.9 AP score on COCO val2017 dataset withoutusing extra keypoint training data. Our paper will be accompanied with publiclyavailable codes at GitHub.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/09/11",
    "Article_PDF": "https://arxiv.org/pdf/1909.05090"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.04556",
    "DOI": "arXiv:1909.04556v1",
    "Article_Title": "Human Languages in Source Code: Auto-Translation for Localized Instruction",
    "Article_Abstract": "Computer science education has promised open access around the world, butaccess is largely determined by what human language you speak. As youngerstudents learn computer science it is less appropriate to assume that theyshould learn English beforehand. To that end we present CodeInternational, thefirst tool to translate code between human languages. To develop a theory ofnon-English code, and inform our translation decisions, we conduct a study ofpublic code repositories on GitHub. The study is to the best of our knowledgethe first on human-language in code and covers 2.9 million Java repositories.To demonstrate CodeInternational's educational utility, we build an interactiveversion of the popular English-language Karel reader and translate it into 100spoken languages. Our translations have already been used in classrooms aroundthe world, and represent a first step in an important open CS-educationproblem.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/09/10",
    "Article_PDF": "https://arxiv.org/pdf/1909.04556"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.04301",
    "DOI": "arXiv:1909.04301v1",
    "Article_Title": "Frequency domain variant of Velvet noise and its application to acoustic measurements",
    "Article_Abstract": "We propose a new family of test signals for acoustic measurements such asimpulse response, nonlinearity, and the effects of background noise. Theproposed family complements difficulties in existing families, the Swept-Sine(SS), pseudo-random noise such as the maximum length sequence (MLS). Theproposed family uses the frequency domain variant of the Velvet noise (FVN) asits building block. An FVN is an impulse response of an all-pass filter andyields the unit impulse when convolved with the time-reversed version ofitself. In this respect, FVN is a member of the time-stretched pulse (TSP) inthe broadest sense. The high degree of freedom in designing an FVN opens a vastrange of applications in acoustic measurement. We introduce the followingapplications and their specific procedures, among other possibilities. They areas follows. a) Spectrum shaping adaptive to background noise. b) Simultaneousmeasurement of impulse responses of multiple acoustic paths. d) Simultaneousmeasurement of linear and nonlinear components of an acoustic path. e)Automatic procedure for time axis alignment of the source and the receiver whenthey are using independent clocks in acoustic impulse response measurement. Weimplemented a reference measurement tool equipped with all these procedures.The MATLAB source code and related materials are open-sourced and placed in aGitHub repository.",
    "Article_Subject": "Audio and Speech Processing (eess.AS); Sound (cs.SD); Signal Processing (eess.SP)",
    "Article_Date": "2019/09/10",
    "Article_PDF": "https://arxiv.org/pdf/1909.04301"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.03650",
    "DOI": "arXiv:1909.03650v1",
    "Article_Title": "Real-time and interactive tools for vocal training based on an analytic signal with a cosine series envelope",
    "Article_Abstract": "We introduce real-time and interactive tools for assisting vocal training. Inthis presentation, we demonstrate mainly a tool based on real-time visualizerof fundamental frequency candidates to provide information-rich feedback tolearners. The visualizer uses an efficient algorithm using analytic signals forderiving phase-based attributes. We start using these tools in vocal trainingfor assisting learners to acquire the awareness of appropriate vocalization.The first author made the MATLAB implementation of the tools open-source. Thecode and associated video materials are accessible in the first author's GitHubrepository.",
    "Article_Subject": "Sound (cs.SD); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)",
    "Article_Date": "2019/09/09",
    "Article_PDF": "https://arxiv.org/pdf/1909.03650"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.03181",
    "DOI": "arXiv:1909.03181v2",
    "Article_Title": "Receding Horizon Control for Drinking Water Networks: The Case for Geometric Programming",
    "Article_Abstract": "Optimal, network-driven control of Water Distribution Network (WDN) is verydifficult: valve and pump models form non-trivial, combinatorial logic,hydraulic models are nonconvex, water demand patterns are uncertain, and WDNsare naturally large-scale. Prior research on control of WDNs addressed majorresearch challenges, yet mostly adopted simplified hydraulic models, WDNtopologies, and rudimentary valve/pump modeling.  The objective of this paper is to develop tractable computational algorithmsto manage WDN operation, while considering arbitrary topology, flow direction,an abundance of valve types, control objectives, hydraulic models, andoperational constraints. Specifically, we propose new Geometric Programming(GP)-based Model Predictive Control (MPC) algorithms, designed to solve thewater flow equations and obtain WDN controls---pump/valve schedules alongsideheads and flows. The proposed approach amounts to solving a series of convexoptimization problems that graciously scale to large networks. Under demanduncertainty, the proposed approach is tested using a 126-node network with manyvalves and pumps. The developed GP-based MPC algorithms, as well as thenumerical test results are all included on Github.",
    "Article_Subject": "Systems and Control (eess.SY); Optimization and Control (math.OC)",
    "Article_Date": "2019/09/07",
    "Article_PDF": "https://arxiv.org/pdf/1909.03181"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.03147",
    "DOI": "arXiv:1909.03147v1",
    "Article_Title": "Self Learning from Large Scale Code Corpus to Infer Structure of Method Invocations",
    "Article_Abstract": "Automatically generating code from a textual description of method invocationconfronts challenges. There were two current research directions for thisproblem. One direction focuses on considering a textual description of methodinvocations as a separate Natural Language query and do not consider thesurrounding context of the code. Another direction takes advantage of apractical large scale code corpus for providing a Machine Translation model togenerate code. However, this direction got very low accuracy. In this work, wetried to improve these drawbacks by proposing MethodInfoToCode, an approachthat embeds context information and optimizes the ability of learning oforiginal Phrase-based Statistical Machine Translation (PBMT) in NLP to inferimplementation of method invocation given method name and other contextinformation. We conduct an expression prediction models learned from 2.86million method invocations from the practical data of high qualities corpus onGithub that used 6 popular libraries: JDK, Android, GWT, Joda-Time, Hibernate,and Xstream. By the evaluation, we show that if the developers only write themethod name of a method invocation in a body of a method, MethodInfoToCode canpredict the generated expression correctly at 73% in F1 score.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/09/06",
    "Article_PDF": "https://arxiv.org/pdf/1909.03147"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.02548",
    "DOI": "arXiv:1909.02548v1",
    "Article_Title": "Explanation based Handwriting Verification",
    "Article_Abstract": "Deep learning system have drawback that their output is not accompanied withex-planation. In a domain such as forensic handwriting verification it isessential to provideexplanation to jurors. The goal of handwriting verificationis to find a measure of confi-dence whether the given handwritten samples arewritten by the same or different writer.We propose a method to generateexplanations for the confidence provided by convolu-tional neural network (CNN)which maps the input image to 15 annotations (features)provided by experts. Oursystem comprises of: (1) Feature learning network (FLN),a differentiablesystem, (2) Inference module for providing explanations. Furthermore,inferencemodule provides two types of explanations: (a) Based on cosinesimilaritybetween categorical probabilities of each feature, (b) Based onLog-Likelihood Ratio(LLR) using directed probabilistic graphical model. Weperform experiments using acombination of feature learning network (FLN) andeach inference module. We evaluateour system using XAI-AND dataset, containing13700 handwritten samples and 15 cor-responding expert examined features foreach sample. The dataset is released for publicuse and the methods can beextended to provide explanations on other verification taskslike faceverification and bio-medical comparison. This dataset can serve as the basisand benchmark for future research in explanation based handwritingverification. The code is available on github.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
    "Article_Date": "2019/08/14",
    "Article_PDF": "https://arxiv.org/pdf/1909.02548"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.02218",
    "DOI": "arXiv:1909.02218v1",
    "Article_Title": "A Better Way to Attend: Attention with Trees for Video Question Answering",
    "Article_Abstract": "We propose a new attention model for video question answering. The main ideaof the attention models is to locate on the most informative parts of thevisual data. The attention mechanisms are quite popular these days. However,most existing visual attention mechanisms regard the question as a whole. Theyignore the word-level semantics where each word can have different attentionsand some words need no attention. Neither do they consider the semanticstructure of the sentences. Although the Extended Soft Attention (E-SA) modelfor video question answering leverages the word-level attention, it performspoorly on long question sentences. In this paper, we propose the heterogeneoustree-structured memory network (HTreeMN) for video question answering. Ourproposed approach is based upon the syntax parse trees of the questionsentences. The HTreeMN treats the words differently where the \\textit{visual}words are processed with an attention module and the \\textit{verbal} ones not.It also utilizes the semantic structure of the sentences by combining theneighbors based on the recursive structure of the parse trees. Theunderstandings of the words and the videos are propagated and merged fromleaves to the root. Furthermore, we build a hierarchical attention mechanism todistill the attended features. We evaluate our approach on two datasets. Theexperimental results show the superiority of our HTreeMN model over the otherattention models especially on complex questions. Our code is available ongithub.  Our code is available at https://github.com/ZJULearning/TreeAttention",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Machine Learning (cs.LG)",
    "Article_Date": "2019/09/05",
    "Article_PDF": "https://arxiv.org/pdf/1909.02218"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.02203",
    "DOI": "arXiv:1909.02203v2",
    "Article_Title": "Elastic_HH: Tailored Elastic for Finding Heavy Hitters",
    "Article_Abstract": "Finding heavy hitters has been of vital importance in network measurement.Among all the recent works in finding heavy hitters, the Elastic sketchachieves the highest accuracy and fastest speed. However, we find that there isstill room for improvement of the Elastic sketch in finding heavy hitters. Inthis paper, we propose a tailored Elastic to enhance the sketch only forfinding heavy hitters at the cost of losing the generality of Elastic. Totailor Elastic, we abandon the light part, and improve the eviction strategy.Our experimental results show that compared with the standard Elastic, ourtailored Elastic reduces the error rate to 5.7~8.1 times and increases thespeed to 2.5 times. All the related source codes and datasets are available atGithub.",
    "Article_Subject": "Networking and Internet Architecture (cs.NI)",
    "Article_Date": "2019/09/05",
    "Article_PDF": "https://arxiv.org/pdf/1909.02203"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.01441",
    "DOI": "arXiv:1909.01441v1",
    "Article_Title": "CrossWeigh: Training Named Entity Tagger from Imperfect Annotations",
    "Article_Abstract": "Everyone makes mistakes. So do human annotators when curating labels fornamed entity recognition (NER). Such label mistakes might hurt model trainingand interfere model comparison. In this study, we dive deep into one of thewidely-adopted NER benchmark datasets, CoNLL03 NER. We are able to identifylabel mistakes in about 5.38% test sentences, which is a significant ratioconsidering that the state-of-the-art test F1 score is already around 93%.Therefore, we manually correct these label mistakes and form a cleaner testset. Our re-evaluation of popular models on this corrected test set leads tomore accurate assessments, compared to those on the original test set. Moreimportantly, we propose a simple yet effective framework, CrossWeigh, to handlelabel mistakes during NER model training. Specifically, it partitions thetraining data into several folds and train independent NER models to identifypotential mistakes in each fold. Then it adjusts the weights of training dataaccordingly to train the final NER model. Extensive experiments demonstratesignificant improvements of plugging various NER models into our proposedframework on three datasets. All implementations and corrected test set areavailable at our Github repo: https://github.com/ZihanWangKi/CrossWeigh.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/09/03",
    "Article_PDF": "https://arxiv.org/pdf/1909.01441"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.01377",
    "DOI": "arXiv:1909.01377v1",
    "Article_Title": "Deep Equilibrium Models",
    "Article_Abstract": "We present a new approach to modeling sequential data: the deep equilibriummodel (DEQ). Motivated by an observation that the hidden layers of manyexisting deep sequence models converge towards some fixed point, we propose theDEQ approach that directly finds these equilibrium points via root-finding.Such a method is equivalent to running an infinite depth (weight-tied)feedforward network, but has the notable advantage that we can analyticallybackpropagate through the equilibrium point using implicit differentiation.Using this approach, training and prediction in these networks require onlyconstant memory, regardless of the effective \"depth\" of the network. Wedemonstrate how DEQs can be applied to two state-of-the-art deep sequencemodels: self-attention transformers and trellis networks. On large-scalelanguage modeling tasks, such as the WikiText-103 benchmark, we show that DEQs1) often improve performance over these state-of-the-art models (for similarparameter counts); 2) have similar computational requirements as existingmodels; and 3) vastly reduce memory consumption (often the bottleneck fortraining large sequence models), demonstrating an up-to 88% memory reduction inour experiments. The code is available at https://github. com/locuslab/deq .",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/09/03",
    "Article_PDF": "https://arxiv.org/pdf/1909.01377"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.11527",
    "DOI": "arXiv:1908.11527v2",
    "Article_Title": "Implicit Deep Latent Variable Models for Text Generation",
    "Article_Abstract": "Deep latent variable models (LVM) such as variational auto-encoder (VAE) haverecently played an important role in text generation. One key factor is theexploitation of smooth latent structures to guide the generation. However, therepresentation power of VAEs is limited due to two reasons: (1) the Gaussianassumption is often made on the variational posteriors; and meanwhile (2) anotorious \"posterior collapse\" issue occurs. In this paper, we advocatesample-based representations of variational distributions for natural language,leading to implicit latent features, which can provide flexible representationpower compared with Gaussian-based posteriors. We further develop an LVM todirectly match the aggregated posterior to the prior. It can be viewed as anatural extension of VAEs with a regularization of maximizing mutualinformation, mitigating the \"posterior collapse\" issue. We demonstrate theeffectiveness and versatility of our models in various text generationscenarios, including language modeling, unaligned style transfer, and dialogresponse generation. The source code to reproduce our experimental results isavailable on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/30",
    "Article_PDF": "https://arxiv.org/pdf/1908.11527"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.10267",
    "DOI": "arXiv:1908.10267v2",
    "Article_Title": "DRD-Net: Detail-recovery Image Deraining via Context Aggregation Networks",
    "Article_Abstract": "Image deraining is a fundamental, yet not well-solved problem in computervision and graphics. The traditional image deraining approaches commonly behaveineffectively in medium and heavy rain removal, while the learning-based oneslead to image degradations such as the loss of image details, halo artifactsand/or color distortion. Unlike existing image deraining approaches that lackthe detail-recovery mechanism, we propose an end-to-end detail-recovery imagederaining network (termed a DRD-Net) for single images. We for the first timeintroduce two sub-networks with a comprehensive loss function which synergizeto derain and recover the lost details caused by deraining. We have three keycontributions. First, we present a rain residual network to remove rain streaksfrom the rainy images, which combines the squeeze-and-excitation (SE) operationwith residual blocks to make full advantage of spatial contextual information.Second, we design a new connection style block, named structure detail contextaggregation block (SDCAB), which aggregates context feature information and hasa large reception field. Third, benefiting from the SDCAB, we construct adetail repair network to encourage the lost details to return for eliminatingimage degradations. We have validated our approach on four recognized datasets(three synthetic and one real-world). Both quantitative and qualitativecomparisons show that our approach outperforms the state-of-the-art derainingmethods in terms of the deraining robustness and detail accuracy. The sourcecode has been available for public evaluation and use on GitHub.",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/27",
    "Article_PDF": "https://arxiv.org/pdf/1908.10267"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.09195",
    "DOI": "arXiv:1908.09195v1",
    "Article_Title": "Scalable Modeling of Spatiotemporal Data using the Variational Autoencoder: an Application in Glaucoma",
    "Article_Abstract": "As big spatial data becomes increasingly prevalent, classical spatiotemporal(ST) methods often do not scale well. While methods have been developed toaccount for high-dimensional spatial objects, the setting where there areexceedingly large samples of spatial observations has had less attention. Thevariational autoencoder (VAE), an unsupervised generative model based on deeplearning and approximate Bayesian inference, fills this void using a latentvariable specification that is inferred jointly across the large number ofsamples. In this manuscript, we compare the performance of the VAE with a moreclassical ST method when analyzing longitudinal visual fields from a largecohort of patients in a prospective glaucoma study. Through simulation and acase study, we demonstrate that the VAE is a scalable method for analyzing STdata, when the goal is to obtain accurate predictions. R code to implement theVAE can be found on GitHub: https://github.com/berchuck/vaeST.",
    "Article_Subject": "Applications (stat.AP); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/24",
    "Article_PDF": "https://arxiv.org/pdf/1908.09195"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08856",
    "DOI": "arXiv:1908.08856v1",
    "Article_Title": "Assessing Knee OA Severity with CNN attention-based end-to-end architectures",
    "Article_Abstract": "This work proposes a novel end-to-end convolutional neural network (CNN)architecture to automatically quantify the severity of knee osteoarthritis (OA)using X-Ray images, which incorporates trainable attention modules acting asunsupervised fine-grained detectors of the region of interest (ROI). Theproposed attention modules can be applied at different levels and scales acrossany CNN pipeline helping the network to learn relevant attention patterns overthe most informative parts of the image at different resolutions. We test theproposed attention mechanism on existing state-of-the-art CNN architectures asour base models, achieving promising results on the benchmark knee OA datasetsfrom the osteoarthritis initiative (OAI) and multicenter osteoarthritis study(MOST). All code from our experiments will be publicly available on the githubrepository: https://github.com/marc-gorriz/KneeOA-CNNAttention",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
    "Article_Date": "2019/08/23",
    "Article_PDF": "https://arxiv.org/pdf/1908.08856"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08584",
    "DOI": "arXiv:1908.08584v1",
    "Article_Title": "Feedbackward Decoding for Semantic Segmentation",
    "Article_Abstract": "We propose a novel approach for semantic segmentation that uses an encoder inthe reverse direction to decode. Many semantic segmentation networks adopt afeedforward encoder-decoder architecture. Typically, an input is firstdownsampled by the encoder to extract high-level semantic features andcontinues to be fed forward through the decoder module to recover low-levelspatial clues. Our method works in an alternative direction that letsinformation flow backward from the last layer of the encoder towards the first.The encoder performs encoding in the forward pass and the same network performsdecoding in the backward pass. Therefore, the encoder itself is also thedecoder. Compared to conventional encoder-decoder architectures, ours doesn'trequire additional layers for decoding and further reuses the encoder weightsthereby reducing the total number of parameters required for processing. Weshow by using only the 13 convolutional layers from VGG-16 plus one tinyclassification layer, our model significantly outperforms other frequentlycited models that are also adapted from VGG-16. On the Cityscapes semanticsegmentation benchmark, our model uses 50.0% less parameters than SegNet andachieves an 18.1% higher \"IoU class\" score; it uses 28.3% less parameters thanDeepLab LargeFOV and the achieved \"IoU class\" score is 3.9% higher; it uses89.1% fewer parameters than FCN-8s and the achieved \"IoU class\" score is 3.1%higher. Our code will be publicly available on Github later.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Image and Video Processing (eess.IV); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/22",
    "Article_PDF": "https://arxiv.org/pdf/1908.08584"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08196",
    "DOI": "arXiv:1908.08196v1",
    "Article_Title": "Unveiling Elite Developers' Activities in Open Source Projects",
    "Article_Abstract": "Open-source developers, particularly the elite developers, maintain a diverseportfolio of contributing activities. They do not only commit source code butalso spend a significant amount of effort on other communicative,organizational, and supportive activities. However, almost all prior researchfocuses on a limited number of specific activities and fails to analyze elitedevelopers' activities in a comprehensive way. To bridge this gap, we conductan empirical study with fine-grained event data from 20 large open-sourceprojects hosted on GitHub. Thus, we investigate elite developers' contributingactivities and their impacts on project outcomes. Our analyses reveal three keyfindings: (1) they participate in a variety of activities while technicalcontributions (e.g., coding) accounting for a small proportion only; (2) theytend to put more effort into supportive and communicative activities and lesseffort into coding as the project grows; (3) their participation innon-technical activities is negatively associated with the project's outcomesin term of productivity and software quality. These results provide a panoramicview of elite developers' activities and can inform an individual's decisionmaking about effort allocation, thus leading to finer project outcomes. Theresults also provide implications for supporting these elite developers.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/22",
    "Article_PDF": "https://arxiv.org/pdf/1908.08196"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08123",
    "DOI": "arXiv:1908.08123v3",
    "Article_Title": "Computing System Congestion Management Using Exponential Smoothing Forecasting",
    "Article_Abstract": "An overloaded computer must finish what it starts and not start what willfail or hang. A congestion management algorithm the author developed, andSiemens Corporation patented for telecom products, effectively manages trafficoverload with its unique formulation of Exponential Smoothing forecasting.Siemens filed for exclusive rights to this technique in 2003 and obtained USpatent US7301903B2 in 2007 with this author, an employee at the time of thefiling, the sole inventor. A computer program, written in C language, whichexercises the methodology is listed at the end of this document and availableon GitHub.",
    "Article_Subject": "Performance (cs.PF)",
    "Article_Date": "2019/08/21",
    "Article_PDF": "https://arxiv.org/pdf/1908.08123"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.07984",
    "DOI": "arXiv:1908.07984v1",
    "Article_Title": "Minimal residual multistep methods for large stiff non-autonomous linear problems",
    "Article_Abstract": "The purpose of this work is to introduce a new idea of how to avoid thefactorization of large matrices during the solution of stiff systems of ODEs.Starting from the general form of an explicit linear multistep method wesuggest to adaptively choose its coefficients on each integration step in orderto minimize the norm of the residual of an implicit BDF formula. Thereby wereduce the number of unknowns on each step from $n$ to $O(1)$, where $n$ is thedimension of the ODE system. We call this type of methods Minimal ResidualMultistep (MRMS) methods. In the case of linear non-autonomous problem, besidesthe evaluations of the right-hand side of ODE, the resulting numerical schemeadditionally requires one solution of a linear least-squares problem with athin matrix per step. We show that the order of the method and itszero-stability properties coincide with those of the used underlying BDFformula. For the simplest analog of the implicit Euler method the properties oflinear stability are investigated. Though the classical absolute stabilityanalysis is not fully relevant to the MRMS methods, it is shown that thisone-step method is applicable in stiff case. In the numerical experimentsection we consider the fixed-step integration of a two-dimensionalnon-autonomous heat equation using the MRMS methods and their classical BDFcounterparts. The starting values are taken from a preset slowly-varying exactsolution. The comparison showed that both methods give similar numericalsolutions, but in the case of large systems the MRMS methods are faster, andtheir advantage considerably increases with the growth of dimension. Pythoncode with the experimantal code can be downloaded from the GitHub repositoryhttps://github.com/bfaleichik/mrms.",
    "Article_Subject": "Numerical Analysis (math.NA)",
    "Article_Date": "2019/08/21",
    "Article_PDF": "https://arxiv.org/pdf/1908.07984"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.07883",
    "DOI": "arXiv:1908.07883v3",
    "Article_Title": "Scala Implicits are Everywhere: A large-scale study of the use of Implicits in the wild",
    "Article_Abstract": "The Scala programming language offers two distinctive language featuresimplicit parameters and implicit conversions, often referred together asimplicits. Announced without fanfare in 2004, implicits have quickly grown tobecome a widely and pervasively used feature of the language. They provide away to reduce the boilerplate code in Scala programs. They are also used toimplement certain language features without having to modify the compiler. Wereport on a large-scale study of the use of implicits in the wild. For this, weanalyzed 7,280 Scala projects hosted on GitHub, spanning over 8.1M call sitesinvolving implicits and 370.7K implicit declarations across 18.7M lines ofScala code.",
    "Article_Subject": "Programming Languages (cs.PL); Software Engineering (cs.SE)",
    "Article_Date": "2019/08/21",
    "Article_PDF": "https://arxiv.org/pdf/1908.07883"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.06473",
    "DOI": "arXiv:1908.06473v1",
    "Article_Title": "From Open Set to Closed Set: Counting Objects by Spatial Divide-and-Conquer",
    "Article_Abstract": "Visual counting, a task that predicts the number of objects from animage/video, is an open-set problem by nature, i.e., the number of populationcan vary in $[0,+\\infty)$ in theory. However, the collected images and labeledcount values are limited in reality, which means only a small closed set isobserved. Existing methods typically model this task in a regression manner,while they are likely to suffer from an unseen scene with counts out of thescope of the closed set. In fact, counting is decomposable. A dense region canalways be divided until sub-region counts are within the previously observedclosed set. Inspired by this idea, we propose a simple but effective approach,Spatial Divide-and- Conquer Network (S-DCNet). S-DCNet only learns from aclosed set but can generalize well to open-set scenarios via S-DC. S-DCNet isalso efficient. To avoid repeatedly computing sub-region convolutionalfeatures, S-DC is executed on the feature map instead of on the input image.S-DCNet achieves the state-of-the-art performance on three crowd countingdatasets (ShanghaiTech, UCF_CC_50 and UCF-QNRF), a vehicle counting dataset(TRANCOS) and a plant counting dataset (MTC). Compared to the previous bestmethods, S-DCNet brings a 20.2% relative improvement on the ShanghaiTech PartB, 20.9% on the UCF-QNRF, 22.5% on the TRANCOS and 15.1% on the MTC. Code hasbeen made available at: https://github. com/xhp-hust-2018-2011/S-DCNet.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/15",
    "Article_PDF": "https://arxiv.org/pdf/1908.06473"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.06412",
    "DOI": "arXiv:1908.06412v1",
    "Article_Title": "Characterizing the transition to Kotlin of Android apps: a study on F-Droid, Play Store and GitHub",
    "Article_Abstract": "Kotlin is a novel language that represents an alternative to Java, and hasbeen recently adopted as a first-class programming language for Androidapplications. Kotlin is achieving a significant diffusion among developers, andseveral studies have highlighted various advantages of the language whencompared to Java.  The objective of this paper is to analyze a set of open-source Android apps,to evaluate their transition to the Kotlin programming language throughouttheir lifespan and understand whether the adoption of Kotlin has impacts on thesuccess of Android apps.  We mined all the projects from the F-Droid repository of Android open-sourceapplications, and we found the corresponding projects on the official GooglePlay Store and on the GitHub platform. We defined a set of eight metrics toquantify the relevance of Kotlin code in the latest update and through allreleases of an application. Then, we statistically analyzed the correlationbetween the presence of Kotlin code in a project and popularity metrics minedfrom the platforms where the apps were released.  Of a set of 1232 projects that were updated after October 2017, near 20%adopted Kotlin and about 12% had more Kotlin code than Java; most of theprojects that adopted Kotlin quickly transitioned from Java to the newlanguage. The projects featuring Kotlin had on average higher popularitymetrics; a statistically significant correlation has been found between thepresence of Kotlin and the number of stars on the GitHub repository.  The Kotlin language seems able to guarantee a seamless migration from Javafor Android developers. With an inspection on a large set of open-sourceAndroid apps, we observed that the adoption of the Kotlin language is rapid(when compared to the average lifespan of an Android project) and seems to comeat no cost in terms of popularity among the users and other developers.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/18",
    "Article_PDF": "https://arxiv.org/pdf/1908.06412"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.06309",
    "DOI": "arXiv:1908.06309v1",
    "Article_Title": "ED2: Two-stage Active Learning for Error Detection -- Technical Report",
    "Article_Abstract": "Traditional error detection approaches require user-defined parameters andrules. Thus, the user has to know both the error detection system and the data.However, we can also formulate error detection as a semi-supervisedclassification problem that only requires domain expertise. The challenges forsuch an approach are twofold: (1) to represent the data in a way that enables aclassification model to identify various kinds of data errors, and (2) to pickthe most promising data values for learning. In this paper, we address thesechallenges with ED2, our new example-driven error detection method. First, wepresent a new two-dimensional multi-classifier sampling strategy for activelearning. Second, we propose novel multi-column features. The combinedapplication of these techniques provides fast convergence of the classificationtask with high detection accuracy. On several real-world datasets, ED2requires, on average, less than 1% labels to outperform existing errordetection approaches. This report extends the peer-reviewed paper \"ED2: A Casefor Active Learning in Error Detection\". All source code related to thisproject is available on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Databases (cs.DB); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/17",
    "Article_PDF": "https://arxiv.org/pdf/1908.06309"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05541",
    "DOI": "arXiv:1908.05541v1",
    "Article_Title": "Hamming Sentence Embeddings for Information Retrieval",
    "Article_Abstract": "In retrieval applications, binary hashes are known to offer significantimprovements in terms of both memory and speed. We investigate the compressionof sentence embeddings using a neural encoder-decoder architecture, which istrained by minimizing reconstruction error. Instead of employing the originalreal-valued embeddings, we use latent representations in Hamming space producedby the encoder for similarity calculations.  In quantitative experiments on several benchmarks for semantic similaritytasks, we show that our compressed hamming embeddings yield a comparableperformance to uncompressed embeddings (Sent2Vec, InferSent, Glove-BoW), atcompression ratios of up to 256:1. We further demonstrate that our modelstrongly decorrelates input features, and that the compressor generalizes wellwhen pre-trained on Wikipedia sentences. We publish the source code on Githuband all experimental results.",
    "Article_Subject": "Information Retrieval (cs.IR); Computation and Language (cs.CL); Machine Learning (cs.LG)",
    "Article_Date": "2019/08/15",
    "Article_PDF": "https://arxiv.org/pdf/1908.05541"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05437",
    "DOI": "arXiv:1908.05437v1",
    "Article_Title": "Massive Multi-Agent Data-Driven Simulations of the GitHub Ecosystem",
    "Article_Abstract": "Simulating and predicting planetary-scale techno-social systems poses heavycomputational and modeling challenges. The DARPA SocialSim program set thechallenge to model the evolution of GitHub, a large collaborativesoftware-development ecosystem, using massive multi-agent simulations. Wedescribe our best performing models and our agent-based simulation framework,which we are currently extending to allow simulating other planetary-scaletechno-social systems. The challenge problem measured participant's ability,given 30 months of meta-data on user activity on GitHub, to predict the nextmonths' activity as measured by a broad range of metrics applied to groundtruth, using agent-based simulation. The challenge required scaling to asimulation of roughly 3 million agents producing a combined 30 million actions,acting on 6 million repositories with commodity hardware. It was also importantto use the data optimally to predict the agent's next moves. We describe theagent framework and the data analysis employed by one of the winning teams inthe challenge. Six different agent models were tested based on a variety ofmachine learning and statistical methods. While no single method proved themost accurate on every metric, the broadly most successful sampled from astationary probability distribution of actions and repositories for each agent.Two reasons for the success of these agents were their use of a distinctcharacterization of each agent, and that GitHub users change their behaviorrelatively slowly.",
    "Article_Subject": "Multiagent Systems (cs.MA); Social and Information Networks (cs.SI)",
    "Article_Date": "2019/08/15",
    "Article_PDF": "https://arxiv.org/pdf/1908.05437"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05354",
    "DOI": "arXiv:1908.05354v2",
    "Article_Title": "Large-Scale-Exploit of GitHub Repository Metadata and Preventive Measures",
    "Article_Abstract": "When working with Git, a popular version-control system, email addresses arepart of the metadata for each individual commit. When those commits are pushedto remote hosting services like GitHub, those email addresses become visiblenot only to fellow developers, but also to malicious actors aiming to exploitthem.  As a part of our research we created a tool that leverages the publiclyavailable GitHub API to collect user data. Analysis of this data not only givesaccess to millions of email addresses in very little time, but is also powerfuland dense enough to create targeted phishing attacks posing a great threat toall GitHub users and their private, potentially sensitive data. Even worse,existing countermeasures fail to effectively protect against such exploits.  As a consequence and main conclusion of this paper, we suggest multiplepreventive measures that should be implemented as soon as possible. We alsoconsider it the duty of both companies like GitHub and well informed softwareengineers to inform fellow developers about the risk of exposing private emailaddresses in Git commits published publicly.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/08/14",
    "Article_PDF": "https://arxiv.org/pdf/1908.05354"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05097",
    "DOI": "arXiv:1908.05097v1",
    "Article_Title": "Causal discovery in heavy-tailed models",
    "Article_Abstract": "Causal questions are omnipresent in many scientific problems. While muchprogress has been made in the analysis of causal relationships between randomvariables, these methods are not well suited if the causal mechanisms manifestthemselves only in extremes. This work aims to connect the two fields of causalinference and extreme value theory. We define the causal tail coefficient thatcaptures asymmetries in the extremal dependence of two random variables. In thepopulation case, the causal tail coefficient is shown to reveal the causalstructure if the distribution follows a linear structural causal model. Thisholds even in the presence of latent common causes that have the same tailindex as the observed variables. Based on a consistent estimator of the causaltail coefficient, we propose a computationally highly efficient algorithm thatinfers causal structure from finitely many data. We prove that our methodconsistently estimates the causal order and compare it to otherwell-established and non-extremal approaches in causal discovery on syntheticdata. The code is available as an open-access R package on Github.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/08/14",
    "Article_PDF": "https://arxiv.org/pdf/1908.05097"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.04710",
    "DOI": "arXiv:1908.04710v1",
    "Article_Title": "metric-learn: Metric Learning Algorithms in Python",
    "Article_Abstract": "metric-learn is an open source Python package implementing supervised andweakly-supervised distance metric learning algorithms. As part ofscikit-learn-contrib, it provides a unified interface compatible withscikit-learn which allows to easily perform cross-validation, model selection,and pipelining with other machine learning estimators. metric-learn isthoroughly tested and available on PyPi under the MIT licence.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/13",
    "Article_PDF": "https://arxiv.org/pdf/1908.04710"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.04219",
    "DOI": "arXiv:1908.04219v1",
    "Article_Title": "How do Developers Promote Open Source Projects?",
    "Article_Abstract": "Open source projects have an increasing importance on modern softwaredevelopment. For this reason, these projects, as usual with commercial softwareprojects, should make use of promotion channels to communicate and establishcontact with users and contributors. In this article, we study the channelsused to promote a set of 100 popular GitHub projects. First, we reveal thatTwitter, user meetings, and blogs are the most common promotion channels usedby the studied projects. Second, we report a major difference between thestudied projects and a random sample of projects, regarding the use of theinvestigated promotion channels. Third, we show the importance of a popularnews aggregation site (Hacker News) on the promotion of open source. Weconclude by presenting a set of practical recommendation to open source projectmanagers and leaders, regarding the promotion of their projects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/12",
    "Article_PDF": "https://arxiv.org/pdf/1908.04219"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.03952",
    "DOI": "arXiv:1908.03952v2",
    "Article_Title": "Constraining new physics from Higgs measurements with Lilith: update to LHC Run 2 results",
    "Article_Abstract": "Lilith is a public Python library for constraining new physics from Higgssignal strength measurements. We here present version 2.0 of Lilith togetherwith an updated XML database which includes the current ATLAS and CMS Run 2Higgs results for 36/fb. Both the code and the database were extended from theordinary Gaussian approximation employed in Lilith-1.1 to using variableGaussian and Poisson likelihoods. Moreover, Lilith can now make use ofcorrelation matrices of arbitrary dimension. We provide detailed validations ofthe implemented experimental results as well as a status of global fits forreduced Higgs couplings, Two-Higgs-doublet models of Type I and Type II, andinvisible Higgs decays. Lilith-2.0 is available on GitHub and ready to be usedto constrain a wide class of new physics scenarios.",
    "Article_Subject": "High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Experiment (hep-ex)",
    "Article_Date": "2019/08/11",
    "Article_PDF": "https://arxiv.org/pdf/1908.03952"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.02320",
    "DOI": "arXiv:1908.02320v1",
    "Article_Title": "Do as I Do, Not as I Say: Do Contribution Guidelines Match the GitHub Contribution Process?",
    "Article_Abstract": "Developer contribution guidelines are used in social coding sites like GitHubto explain and shape the process a project expects contributors to follow. Theyset standards for all participants and \"save time and hassle caused byimproperly created pull requests or issues that have to be rejected andresubmitted\" (GitHub). Yet, we lack a systematic understanding of the contentof a typical contribution guideline, as well as the extent to which theseguidelines are followed in practice. Additionally, understanding how guidelinesmay impact projects that use Continuous Integration as part of the contributionprocess is of particular interest. To address this knowledge gap, we conducteda mixed-methods study of 53 GitHub projects with explicit contributionguidelines and coded the guidelines to extract key themes. We then created aprocess model using GitHub activity data (e.g., commit, new issue, new pullrequest) to compare the actual activity with the prescribed contributionguidelines. We show that approximately 68% of these projects divergesignificantly from the expected process.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/06",
    "Article_PDF": "https://arxiv.org/pdf/1908.02320"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.02116",
    "DOI": "arXiv:1908.02116v3",
    "Article_Title": "Teacher Supervises Students How to Learn From Partially Labeled Images for Facial Landmark Detection",
    "Article_Abstract": "Facial landmark detection aims to localize the anatomically defined points ofhuman faces. In this paper, we study facial landmark detection from partiallylabeled facial images. A typical approach is to (1) train a detector on thelabeled images; (2) generate new training samples using this detector'sprediction as pseudo labels of unlabeled images; (3) retrain the detector onthe labeled samples and partial pseudo labeled samples. In this way, thedetector can learn from both labeled and unlabeled data to become robust. Inthis paper, we propose an interaction mechanism between a teacher and twostudents to generate more reliable pseudo labels for unlabeled data, which arebeneficial to semi-supervised facial landmark detection. Specifically, the twostudents are instantiated as dual detectors. The teacher learns to judge thequality of the pseudo labels generated by the students and filter outunqualified samples before the retraining stage. In this way, the studentdetectors get feedback from their teacher and are retrained by premium datagenerated by itself. Since the two students are trained by different samples, acombination of their predictions will be more robust as the final predictioncompared to either prediction. Extensive experiments on 300-W and AFLWbenchmarks show that the interactions between teacher and students contributeto better utilization of the unlabeled data and achieves state-of-the-artperformance.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/06",
    "Article_PDF": "https://arxiv.org/pdf/1908.02116"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01711",
    "DOI": "arXiv:1908.01711v1",
    "Article_Title": "fgivenx: A Python package for functional posterior plotting",
    "Article_Abstract": "fgivenx is a Python package for functional posterior plotting, currently usedin astronomy, but will be of use to scientists performing any Bayesian analysiswhich has predictive posteriors that are functions. The source code for fgivenxis available on GitHub at https://github.com/williamjameshandley/fgivenx",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.01711"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01373",
    "DOI": "arXiv:1908.01373v2",
    "Article_Title": "Unsupervised Microvascular Image Segmentation Using an Active Contours Mimicking Neural Network",
    "Article_Abstract": "The task of blood vessel segmentation in microscopy images is crucial formany diagnostic and research applications. However, vessels can look vastlydifferent, depending on the transient imaging conditions, and collecting datafor supervised training is laborious. We present a novel deep learning methodfor unsupervised segmentation of blood vessels. The method is inspired by thefield of active contours and we introduce a new loss term, which is based onthe morphological Active Contours Without Edges (ACWE) optimization method. Therole of the morphological operators is played by novel pooling layers that areincorporated to the network's architecture. We demonstrate the challenges thatare faced by previous supervised learning solutions, when the imagingconditions shift. Our unsupervised method is able to outperform such previousmethods in both the labeled dataset, and when applied to similar but differentdatasets. Our code, as well as efficient PyTorch reimplementations of thebaseline methods VesselNN and DeepVess is available on GitHub -https://github.com/shirgur/UMIS.",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/04",
    "Article_PDF": "https://arxiv.org/pdf/1908.01373"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01242",
    "DOI": "arXiv:1908.01242v1",
    "Article_Title": "Kannada-MNIST: A new handwritten digits dataset for the Kannada language",
    "Article_Abstract": "In this paper, we disseminate a new handwritten digits-dataset, termedKannada-MNIST, for the Kannada script, that can potentially serve as a directdrop-in replacement for the original MNIST dataset. In addition to thisdataset, we disseminate an additional real world handwritten dataset (with$10k$ images), which we term as the Dig-MNIST dataset that can serve as anout-of-domain test dataset. We also duly open source all the code as well asthe raw scanned images along with the scanner settings so that researchers whowant to try out different signal processing pipelines can perform end-to-endcomparisons. We provide high level morphological comparisons with the MNISTdataset and provide baselines accuracies for the dataset disseminated. Theinitial baselines obtained using an oft-used CNN architecture ($96.8\\%$ for themain test-set and $76.1\\%$ for the Dig-MNIST test-set) indicate that thesedatasets do provide a sterner challenge with regards to generalizability thanMNIST or the KMNIST datasets. We also hope this dissemination will spur thecreation of similar datasets for all the languages that use different symbolsfor the numeral digits.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/03",
    "Article_PDF": "https://arxiv.org/pdf/1908.01242"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01031",
    "DOI": "arXiv:1908.01031v1",
    "Article_Title": "RuleKit: A Comprehensive Suite for Rule-Based Learning",
    "Article_Abstract": "Rule-based models are often used for data analysis as they combineinterpretability with predictive power. We present RuleKit, a versatile toolfor rule learning. Based on a sequential covering induction algorithm, it issuitable for classification, regression, and survival problems. The presence ofa user-guided induction facilitates verifying hypotheses concerning datadependencies which are expected or of interest. The powerful and flexibleexperimental environment allows straightforward investigation of differentinduction schemes. The analysis can be performed in batch mode, throughRapidMiner plug-in, or R package. A documented Java API is also provided forconvenience. The software is publicly available at GitHub under GNU AGPL-3.0license.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.01031"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.00867",
    "DOI": "arXiv:1908.00867v1",
    "Article_Title": "An Evaluation of Action Recognition Models on EPIC-Kitchens",
    "Article_Abstract": "We benchmark contemporary action recognition models (TSN, TRN, and TSM) onthe recently introduced EPIC-Kitchens dataset and release pretrained models onGitHub (https://github.com/epic-kitchens/action-models) for others to buildupon. In contrast to popular action recognition datasets like Kinetics,Something-Something, UCF101, and HMDB51, EPIC-Kitchens is shot from anegocentric perspective and captures daily actions in-situ. In this report, weaim to understand how well these models can tackle the challenges present inthis dataset, such as its long tail class distribution, unseen environment testset, and multiple tasks (verb, noun and, action classification). We discuss themodels' shortcomings and avenues for future research.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.00867"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.00717",
    "DOI": "arXiv:1908.00717v1",
    "Article_Title": "Lagrange2D: A Mathematica package for Lagrangian analysis of two-dimensional fluid flows",
    "Article_Abstract": "We introduce Lagrange2D, a Mathematica package for analysis andcharacterization of complex fluid flows using Lagrangian transport metrics.Lagrange2D includes built-in functions for integrating ensembles oftrajectories subject to time-varying two-dimensional flows, as well asutilities for calculating various quantities of interest, such as finite-timeLyapunov exponents, stretching vector fields, the fractal dimension, andflushing times. The package also includes tools for visualizing transport andpathlines, as well as for generating videos. This package aims to ease rapidcharacterization of arbitrary flows, by allowing identification of Lagrangiancoherent structures and other quantities of interest. The open-source code forthe package is available on GitHub at:\\url{https://github.com/williamgilpin/lagrange2d}",
    "Article_Subject": "Fluid Dynamics (physics.flu-dyn); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.00717"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.00614",
    "DOI": "arXiv:1908.00614v2",
    "Article_Title": "Learning to Identify Security-Related Issues Using Convolutional Neural Networks",
    "Article_Abstract": "Software security is becoming a high priority for both large companies andstart-ups alike due to the increasing potential for harm that vulnerabilitiesand breaches carry with them. However, attaining robust security assurancewhile delivering features requires a precarious balancing act in the context ofagile development practices. One path forward to help aid development teams insecuring their software products is through the design and development ofsecurity-focused automation. Ergo, we present a novel approach, calledSecureReqNet, for automatically identifying whether issues in software issuetracking systems describe security-related content. Our approach consists of atwo-phase neural net architecture that operates purely on the natural languagedescriptions of issues. The first phase of our approach learns high dimensionalword embeddings from hundreds of thousands of vulnerability descriptions listedin the CVE database and issue descriptions extracted from open source projects.The second phase then utilizes the semantic ontology represented by theseembeddings to train a convolutional neural network capable of predictingwhether a given issue is security-related. We evaluated SecureReqNet byapplying it to identify security-related issues from a dataset of thousands ofissues mined from popular projects on GitLab and GitHub. In addition, we alsoapplied our approach to identify security-related requirements from acommercial software project developed by a major telecommunication company. Ourpreliminary results are encouraging, with SecureReqNet achieving an accuracy of96% on open source issues and 71.6% on industrial requirements.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/01",
    "Article_PDF": "https://arxiv.org/pdf/1908.00614"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.13012",
    "DOI": "arXiv:1907.13012v1",
    "Article_Title": "An Empirical Study of GraphQL Schemas",
    "Article_Abstract": "GraphQL is a query language for APIs and a runtime to execute queries. UsingGraphQL queries, clients define precisely what data they wish to retrieve ormutate on a server, leading to fewer round trips and reduced response sizes.Although interest in GraphQL is on the rise, with increasing adoption at majororganizations, little is known about what GraphQL interfaces look like inpractice. This lack of knowledge makes it hard for providers to understand whatpractices promote idiomatic, easy-to-use APIs, and what pitfalls to avoid. Toaddress this gap, we study the design of GraphQL interfaces in practice byanalyzing their schemas - the descriptions of their exposed data types and thepossible operations on the underlying data. We base our study on two novelcorpuses of GraphQL schemas, one of 16 commercial GraphQL schemas and the otherof 8,399 GraphQL schemas mined from GitHub projects. We make both corpusesavailable to other researchers. Using these corpuses, we characterize the sizeof schemas and their use of GraphQL features and assess the use of bothprescribed and organic naming conventions. We also report that a majority ofAPIs are susceptible to denial of service through complex queries, posing realsecurity risks previously discussed only in theory. We also assess ways inwhich GraphQL APIs attempt to address these concerns.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/07/30",
    "Article_PDF": "https://arxiv.org/pdf/1907.13012"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.11017",
    "DOI": "arXiv:1907.11017v2",
    "Article_Title": "Particle Methods for Stochastic Differential Equation Mixed Effects Models",
    "Article_Abstract": "Parameter inference for stochastic differential equation mixed effects models(SDEMEMs) is a challenging problem. Analytical solutions for these models arerarely available, which means that the likelihood is also intractable. In thiscase, exact inference is possible using the pseudo-marginal method, where theintractable likelihood is replaced by its nonnegative unbiased estimate. Auseful application of this idea is particle MCMC, which uses a particle filterestimate of the likelihood. While the exact posterior is targeted by thesemethods, a naive implementation for SDEMEMs can be highly inefficient. Wedevelop three extensions to the naive approach which exploits specific aspectsof SDEMEMs and other advances such as correlated pseudo-marginal methods. Wecompare these methods on real and simulated data from a tumour xenography studyon mice.",
    "Article_Subject": "Computation (stat.CO); Methodology (stat.ME)",
    "Article_Date": "2019/07/25",
    "Article_PDF": "https://arxiv.org/pdf/1907.11017"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.10121",
    "DOI": "arXiv:1907.10121v1",
    "Article_Title": "SciPy 1.0--Fundamental Algorithms for Scientific Computing in Python",
    "Article_Abstract": "SciPy is an open source scientific computing library for the Pythonprogramming language. SciPy 1.0 was released in late 2017, about 16 years afterthe original version 0.1 release. SciPy has become a de facto standard forleveraging scientific algorithms in the Python programming language, with morethan 600 unique code contributors, thousands of dependent packages, over100,000 dependent repositories, and millions of downloads per year. Thisincludes usage of SciPy in almost half of all machine learning projects onGitHub, and usage by high profile projects including LIGO gravitational waveanalysis and creation of the first-ever image of a black hole (M87). Thelibrary includes functionality spanning clustering, Fourier transforms,integration, interpolation, file I/O, linear algebra, image processing,orthogonal distance regression, minimization algorithms, signal processing,sparse matrix handling, computational geometry, and statistics. In this work,we provide an overview of the capabilities and development practices of theSciPy library and highlight some recent technical developments.",
    "Article_Subject": "Mathematical Software (cs.MS); Data Structures and Algorithms (cs.DS); Software Engineering (cs.SE); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/07/23",
    "Article_PDF": "https://arxiv.org/pdf/1907.10121"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.09600",
    "DOI": "arXiv:1907.09600v2",
    "Article_Title": "Evaluation of Embeddings of Laboratory Test Codes for Patients at a Cancer Center",
    "Article_Abstract": "Laboratory test results are an important and generally high dimensionalcomponent of a patient's Electronic Health Record (EHR). We train embeddingrepresentations (via Word2Vec and GloVe) for LOINC codes of laboratory testsfrom the EHRs of about 80,000 patients at a cancer center. To includeinformation about lab test outcomes, we also train embeddings on theconcatenation of a LOINC code with a symbol indicating normality or abnormalityof the result. We observe several clinically meaningful similarities amongLOINC embeddings trained over our data. For the embeddings of the concatenationof LOINCs with abnormality codes, we evaluate the performance for mortalityprediction tasks and the ability to preserve ordinality properties: i.e. a labtest with normal outcome should be more similar to an abnormal one than to thea very abnormal one.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/22",
    "Article_PDF": "https://arxiv.org/pdf/1907.09600"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.08395",
    "DOI": "arXiv:1907.08395v2",
    "Article_Title": "Refractive Interstellar Scintillation of Extra-galactic Radio Sources I: Expectations",
    "Article_Abstract": "Surveys for transient and variable phenomena can be confounded by thepresence of extrinsic variability such as refractive interstellar scintillation(RISS). We have developed an all-sky model for RISS which can predictvariability on a variety of timescales, survey locations, and observingfrequencies. The model makes use of Halpha intensity maps to probe the emissionmeasure along the line of sight, convert this to a scattering measure, andfinally a scintillation strength. The model uses previously developed and longunderstood physics along with (indirect) measurements of the electron contentand distribution within the Milky Way. We develop a set of expectations thatare useful in the planning of future surveys for transient and radiovariability, and demonstrate that the 1-GHz sky is a poor predictor of thevariable nature of the $100$-MHz sky. Interestingly, the correlation betweenthe incidence of variability and Galactic latitude which has been seen at 1GHz,is reversed at 100MHz. We compare the predictions of our model to alow-frequency radio survey that was conducted with the Murchison WidefieldArray, and find good qualitative agreement. We discuss the implications,current limitations, and future development of the model. The model has beenimplemented in a Python code and is available on GitHub/Zenodo.",
    "Article_Subject": "Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/07/19",
    "Article_PDF": "https://arxiv.org/pdf/1907.08395"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.07951",
    "DOI": "arXiv:1907.07951v1",
    "Article_Title": "Automatic vocal tract landmark localization from midsagittal MRI data",
    "Article_Abstract": "The various speech sounds of a language are obtained by varying the shape andposition of the articulators surrounding the vocal tract. Analyzing theirvariability is crucial for understanding speech production, diagnosing speechand swallowing disorders and building intuitive applications forrehabilitation. Magnetic Resonance Imaging (MRI) is currently the most harmlesspowerful imaging modality used for this purpose. Identifying key anatomicallandmarks on it is a pre-requisite for further analyses. This is a challengingtask considering the high inter- and intra-speaker variability and the mutualinteraction between the articulators. This study intends to solve this issueautomatically for the first time. For this purpose, midsagittal anatomical MRIfor 9 speakers sustaining 62 articulations and annotated with the location of21 key anatomical landmarks are considered. Four state-of-the-art methods,including deep learning methods, are adapted from the literature for faciallandmark localization and human pose estimation and evaluated. Furthermore, anapproach based on the description of each landmark location as a heat-map imagestored in a channel of a single multi-channel image embedding all landmarks isproposed. The generation of such a multi-channel image from an input MRI imageis tested through two deep learning networks, one taken from the literature andone designed on purpose in this study, the flat-net. Results show that theflat-net approach outperforms the other methods, leading to an overall RootMean Square Error of 3.4~pixels/0.34~cm obtained in a leave-one-out procedureover the speakers. All of the codes are publicly available on GitHub.",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "Article_Date": "2019/07/18",
    "Article_PDF": "https://arxiv.org/pdf/1907.07951"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.06274",
    "DOI": "arXiv:1907.06274v1",
    "Article_Title": "Predicting Merge Conflicts in Collaborative Software Development",
    "Article_Abstract": "Background. During collaborative software development, developers often usebranches to add features or fix bugs. When merging changes from two branches,conflicts may occur if the changes are inconsistent. Developers need to resolvethese conflicts before completing the merge, which is an error-prone andtime-consuming process. Early detection of merge conflicts, which warnsdevelopers about resolving conflicts before they become large and complicated,is among the ways of dealing with this problem. Existing techniques do this bycontinuously pulling and merging all combinations of branches in the backgroundto notify developers as soon as a conflict occurs, which is a computationallyexpensive process. One potential way for reducing this cost is to use amachine-learning based conflict predictor that filters out the merge scenariosthat are not likely to have conflicts, ie safe merge scenarios. Aims. In thispaper, we assess if conflict prediction is feasible. Method. We design aclassifier for predicting merge conflicts, based on 9 light-weight Git featuresets. To evaluate our predictor, we perform a large-scale study on 267, 657merge scenarios from 744 GitHub repositories in seven programming languages.Results. Our results show that we achieve high f1-scores, varying from 0.95 to0.97 for different programming languages, when predicting safe merge scenarios.The f1-score is between 0.57 and 0.68 for the conflicting merge scenarios.Conclusions. Predicting merge conflicts is feasible in practice, especially inthe context of predicting safe merge scenarios as a pre-filtering step forspeculative merging.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/07/14",
    "Article_PDF": "https://arxiv.org/pdf/1907.06274"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.06146",
    "DOI": "arXiv:1907.06146v1",
    "Article_Title": "Satellite System Graph: Towards the Efficiency Up-Boundary of Graph-Based Approximate Nearest Neighbor Search",
    "Article_Abstract": "Approximate Nearest Neighbor Search (ANNS) in high dimensional space isessential in database and information retrieval. Recently, there has been asurge of interests in exploring efficient graph-based indices for the ANNSproblem. Among them, the NSG has resurrected the theory of Monotonic SearchNetworks (MSNET) and achieved the state-of-the-art performance. However, theperformance of the NSG deviates from a potentially optimal position due to thehigh sparsity of the graph. Specifically, though the average degree of thegraph is small, their search algorithm travels a longer way to reach the query.Integrating both factors, the total search complexity (i.e., the number ofdistance calculations) is not minimized as their wish. In addition, NSG suffersfrom a high indexing time complexity, which limits the efficiency and thescalability of their method. In this paper, we aim to further mine thepotential of the MSNETs. Inspired by the message transfer mechanism of thecommunication satellite system, we find a new family of MSNETs, namely theSatellite System Graphs (SSG). In particular, while inheriting the superiorANNS properties from the MSNET, we try to ensure the angles between the edgesto be no smaller than a given value. Consequently, each node in the graphbuilds effective connections to its neighborhood omnidirectionally, whichensures an efficient search-routing on the graph like the message transferamong the satellites. We also propose an approximation of the SSG, NavigatingSSG, to increase the efficiency of indexing. Both theoretical and extensiveexperimental analysis are provided to demonstrate the strengths of the proposedapproach over the existing state-of-the-art algorithms. Our code has beenreleased on GitHub.",
    "Article_Subject": "Information Retrieval (cs.IR); Databases (cs.DB)",
    "Article_Date": "2019/07/13",
    "Article_PDF": "https://arxiv.org/pdf/1907.06146"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.05062",
    "DOI": "arXiv:1907.05062v1",
    "Article_Title": "FIRE: Unsupervised bi-directional inter-modality registration using deep networks",
    "Article_Abstract": "Inter-modality image registration is an critical preprocessing step for manyapplications within the routine clinical pathway. This paper presents anunsupervised deep inter-modality registration network that can learn theoptimal affine and non-rigid transformations simultaneously.Inverse-consistency is an important property commonly ignored in recent deeplearning based inter-modality registration algorithms. We address this issuethrough the proposed multi-task architecture and the new comprehensivetransformation network. Specifically, the proposed model learns amodality-independent latent representation to perform cycle-consistentcross-modality synthesis, and use an inverse-consistent loss to learn a pair oftransformations to align the synthesized image with the target. We name thisproposed framework as FIRE due to the shape of its structure. Our method showscomparable and better performances with the popular baseline method inexperiments on multi-sequence brain MR data and intra-modality 4D cardiacCine-MR data.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/07/11",
    "Article_PDF": "https://arxiv.org/pdf/1907.05062"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04908",
    "DOI": "arXiv:1907.04908v1",
    "Article_Title": "Executability of Python Snippets in Stack Overflow",
    "Article_Abstract": "Online resources today contain an abundant amount of code snippets fordocumentation, collaboration, learning, and problem-solving purposes. Theirexecutability in a \"plug and play\" manner enables us to confirm their qualityand use them directly in projects. But, in practice that is often not the casedue to several requirements violations or incompleteness. However, it is adifficult task to investigate the executability on a large scale due todifferent possible errors during the execution. We have developed a scalableframework to investigate this for SOTorrent Python snippets. We found that withminor adjustments, 27.92% of snippets are executable. The executability has notchanged significantly over time. The code snippets referenced in GitHub aremore likely to be directly executable. But executability does not affect thechances of the answer to be selected as the accepted answer significantly.These properties help us understand and improve the interaction of users withonline resources that include code snippets.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/07/10",
    "Article_PDF": "https://arxiv.org/pdf/1907.04908"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04527",
    "DOI": "arXiv:1907.04527v1",
    "Article_Title": "Dynamics of Team Library Adoptions: An Exploration of GitHub Commit Logs",
    "Article_Abstract": "When a group of people strives to understand new information, struggle ensuesas various ideas compete for attention. Steep learning curves are surmounted asteams learn together. To understand how these team dynamics play out insoftware development, we explore Git logs, which provide a complete changehistory of software repositories. In these repositories, we observe codeadditions, which represent successfully implemented ideas, and code deletions,which represent ideas that have failed or been superseded. By examining thepatterns between these commit types, we can begin to understand how teams adoptnew information. We specifically study what happens after a software library isadopted by a project, i.e., when a library is used for the first time in theproject. We find that a variety of factors, including team size, librarypopularity, and prevalence on Stack Overflow are associated with how quicklyteams learn and successfully adopt new software libraries.",
    "Article_Subject": "Social and Information Networks (cs.SI); Software Engineering (cs.SE)",
    "Article_Date": "2019/07/10",
    "Article_PDF": "https://arxiv.org/pdf/1907.04527"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04433",
    "DOI": "arXiv:1907.04433v1",
    "Article_Title": "GluonCV and GluonNLP: Deep Learning in Computer Vision and Natural Language Processing",
    "Article_Abstract": "We present GluonCV and GluonNLP, the deep learning toolkits for computervision and natural language processing based on Apache MXNet (incubating).These toolkits provide state-of-the-art pre-trained models, training scripts,and training logs, to facilitate rapid prototyping and promote reproducibleresearch. We also provide modular APIs with flexible building blocks to enableefficient customization. Leveraging the MXNet ecosystem, the deep learningmodels in GluonCV and GluonNLP can be deployed onto a variety of platforms withdifferent programming languages. Benefiting from open source under the Apache2.0 license, GluonCV and GluonNLP have attracted 100 contributors worldwide onGitHub. Models of GluonCV and GluonNLP have been downloaded for more than 1.6million times in fewer than 10 months.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/09",
    "Article_PDF": "https://arxiv.org/pdf/1907.04433"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04002",
    "DOI": "arXiv:1907.04002v1",
    "Article_Title": "Characterizing Bitcoin donations to open source software on GitHub",
    "Article_Abstract": "Web-based hosting services for version control, such as GitHub, have made iteasier for people to develop, share, and donate money to software repositories.In this paper, we study the use of Bitcoin to make donations to open sourcerepositories on GitHub. In particular, we analyze the amount and volume ofdonations over time, in addition to its relationship to the age and popularityof a repository.  We scanned over three million repositories looking for donation addresses. Wethen extracted and analyzed their transactions from Bitcoin's publicblockchain. Overall, we found a limited adoption of Bitcoin as a payment methodfor receiving donations, with nearly 44 thousand deposits adding up to only 8.3million dollars in the last 10 years. We also found weak positive correlationbetween the amount of donations in dollars and the popularity of a repository,with highest correlation (r=0.013) associated with number of forks.",
    "Article_Subject": "Computers and Society (cs.CY); Cryptography and Security (cs.CR)",
    "Article_Date": "2019/07/09",
    "Article_PDF": "https://arxiv.org/pdf/1907.04002"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03892",
    "DOI": "arXiv:1907.03892v5",
    "Article_Title": "Fast Visual Object Tracking with Rotated Bounding Boxes",
    "Article_Abstract": "In this paper, we demonstrate a novel algorithm that uses ellipse fitting toestimate the bounding box rotation angle and size with the segmentation(mask)on the target for online and real-time visual object tracking. Our method,SiamMask_E, improves the bounding box fitting procedure of the state-of-the-artobject tracking algorithm SiamMask and still retains a fast-tracking frame rate(80 fps) on a system equipped with GPU (GeForce GTX 1080 Ti or higher). Wetested our approach on the visual object tracking datasets (VOT2016, VOT2018,and VOT2019) that were labeled with rotated bounding boxes. By comparing withthe original SiamMask, we achieved an improved Accuracy of 0.652 and 0.309 EAOon VOT2019, which is 0.056 and 0.026 higher than the original SiamMask. Theimplementation is available on GitHub:https://github.com/baoxinchen/siammask_e.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/07/08",
    "Article_PDF": "https://arxiv.org/pdf/1907.03892"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03660",
    "DOI": "arXiv:1907.03660v2",
    "Article_Title": "Can Dark Matter be Geometry? A Case Study with Mimetic Dark Matter",
    "Article_Abstract": "We investigate the possibility of dark matter being a pure geometricaleffect, rather than a particle or a compact object, by exploring a specificmodified gravity model: mimetic dark matter. We present an alternativeformulation of the theory, closer to the standard cosmological perturbationtheory framework. We make manifest the presence of arbitrary parameters andextra functions, both at background level and at first order in perturbationtheory. We present the full set of independent equations of motion for thismodel, and we discuss the amount of tuning needed to match predictions of thetheory to actual data. By using the matter power spectrum and cosmic microwavebackground angular power spectra as benchmark observables, we explicitly showthat since there is no natural mechanism to generate adiabatic initialconditions in this specific model, extra fine-tuning is required. We modify thepublicly available Boltzmann code \\texttt{CLASS} to make accurate predictionsfor the observables in mimetic dark matter. Our modified version of\\texttt{CLASS} is available on GitHub. We have used mimetic dark matter as anillustration of how much one is allowed to change the initial conditions beforecontradicting observations when modifying the laws of gravity as described byGeneral Relativity but we point out that modifying gravity without providing anatural mechanism to generate adiabatic initial conditions will always lead tohighly fine-tuned models.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); General Relativity and Quantum Cosmology (gr-qc); High Energy Physics - Theory (hep-th)",
    "Article_Date": "2019/07/08",
    "Article_PDF": "https://arxiv.org/pdf/1907.03660"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03407",
    "DOI": "arXiv:1907.03407v1",
    "Article_Title": "On The Lag of Library Vulnerability Updates: An Investigation into the Repackage and Delivery of Security Fixes Within The npm JavaScript Ecosystem",
    "Article_Abstract": "Vulnerabilities in third-party libraries is a growing concern for thesoftware developer, as it poses risks not only to the software client itselfbut to the entire software ecosystem. To mitigate these risks, developers arestrongly recommended to update their dependencies. Recent studies show thataffected developers are not likely to respond to the vulnerability threat.However, another reason for the lag of vulnerability updates is due to slowrepackaging (i.e., package the vulnerability fix into a new version) anddelivery (i.e., affected client adopt the new version) of the fix. Tounderstand these lags of updates, we use both qualitative and quantitativeapproaches to conduct an empirical study on how 188 fixes were repackaged anddelivered across over eight hundred thousand releases of npm software clientshosted on GitHub. We report two lags: (1) lags in repackaging occur asvulnerability fixes are more likely to be bundled with other non-relatedupdates (i.e., about 83.33\\% of commits are not related to the fix) and (2)lags in the delivery are caused by clients that are more likely to adopt theminor fix than adopt the patch fix. Furthermore, other factors such asdownstream dependencies and severity do have an impact. We also find thatfreshness of packages does not impact the amount of lags. The identification ofthese two lags opens up different avenues on how to facilitate faster fixdelivery throughout a library ecosystem.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/07/08",
    "Article_PDF": "https://arxiv.org/pdf/1907.03407"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03187",
    "DOI": "arXiv:1907.03187v1",
    "Article_Title": "Applying a Pre-trained Language Model to Spanish Twitter Humor Prediction",
    "Article_Abstract": "Our entry into the HAHA 2019 Challenge placed $3^{rd}$ in the classificationtask and $2^{nd}$ in the regression task. We describe our system andinnovations, as well as comparing our results to a Naive Bayes baseline. Alarge Twitter based corpus allowed us to train a language model from scratchfocused on Spanish and transfer that knowledge to our competition model. Toovercome the inherent errors in some labels we reduce our class confidence withlabel smoothing in the loss function. All the code for our project is includedin a GitHub repository for easy reference and to enable replication by others.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/07/06",
    "Article_PDF": "https://arxiv.org/pdf/1907.03187"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.02862",
    "DOI": "arXiv:1907.02862v1",
    "Article_Title": "Essential Motor Cortex Signal Processing: an ERP and functional connectivity MATLAB toolbox -- User Guide",
    "Article_Abstract": "The purpose of this document is to help individuals use the \"Essential MotorCortex Signal Processing MATLAB Toolbox\". The toolbox implements variousmethods for three major aspects of investigating human motor cortex fromNeuroscience view point: (1) ERP estimation and quantification, (2) CorticalFunctional Connectivity analysis and (3) EMG quantification. The toolbox --which is distributed under the terms of the GNU GENERAL PUBLIC LICENSE as a setof MATLAB R routines -- can be downloaded directly at the address:http://oset.ir/category.php?dir=Tools or from the public repository on GitHub,at address below: https://github.com/EsiSeraj/ERP Connectivity EMG Analysis  The purpose of this toolbox is threefold: 1. Extract theevent-related-potential (ERP) from preprocessed cerebral signals (i.e. EEG,MEG, etc.), identify and then quantify the event-relatedsynchronization/desynchronization (ERS/ERD) events. Both time-course dynamicsand time-frequency (TF) analyzes are included. 2. Measure, quantify anddemonstrate the cortical functional connectivity (CFC) across scalp electrodes.These set of functions can also be applied to various types of cerebral signals(i.e. electric and magnetic). 3. Quantify electromyogram (EMG) recorded fromactive muscles during performing motor tasks.",
    "Article_Subject": "Signal Processing (eess.SP); Computational Engineering, Finance, and Science (cs.CE); Image and Video Processing (eess.IV); Neurons and Cognition (q-bio.NC); Quantitative Methods (q-bio.QM)",
    "Article_Date": "2019/06/15",
    "Article_PDF": "https://arxiv.org/pdf/1907.02862"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.02202",
    "DOI": "arXiv:1907.02202v1",
    "Article_Title": "SEntiMoji: An Emoji-Powered Learning Approach for Sentiment Analysis in Software Engineering",
    "Article_Abstract": "Sentiment analysis has various application scenarios in software engineering(SE), such as detecting developers' emotions in commit messages and identifyingtheir opinions on Q&A forums. However, commonly used out-of-the-box sentimentanalysis tools cannot obtain reliable results on SE tasks and themisunderstanding of technical jargon is demonstrated to be the main reason.Then, researchers have to utilize labeled SE-related texts to customizesentiment analysis for SE tasks via a variety of algorithms. However, thescarce labeled data can cover only very limited expressions and thus cannotguarantee the analysis quality. To address such a problem, we turn to theeasily available emoji usage data for help. More specifically, we employemotional emojis as noisy labels of sentiments and propose a representationlearning approach that uses both Tweets and GitHub posts containing emojis tolearn sentiment-aware representations for SE-related texts. These emoji-labeledposts can not only supply the technical jargon, but also incorporate moregeneral sentiment patterns shared across domains. They as well as labeled dataare used to learn the final sentiment classifier. Compared to the existingsentiment analysis methods used in SE, the proposed approach can achievesignificant improvement on representative benchmark datasets. By furthercontrast experiments, we find that the Tweets make a key contribution to thepower of our approach. This finding informs future research not to unilaterallypursue the domain-specific resource, but try to transform knowledge from theopen domain through ubiquitous signals such as emojis.",
    "Article_Subject": "Software Engineering (cs.SE); Computation and Language (cs.CL)",
    "Article_Date": "2019/07/04",
    "Article_PDF": "https://arxiv.org/pdf/1907.02202"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00903",
    "DOI": "arXiv:1907.00903v1",
    "Article_Title": "Resolving the Multiple Withdrawal Attack on ERC20 Tokens",
    "Article_Abstract": "Custom tokens are an integral component of decentralized applications (dapps)deployed on Ethereum and other blockchain platforms. For Ethereum, the ERC20standard is a widely used token interface and is interoperable with manyexisting dapps, user interface platforms, and popular web applications (e.g.,exchange services). An ERC20 security issue, known as the \"multiple withdrawalattack\", was raised on GitHub and has been open since November 2016. The issueconcerns ERC20's defined method approve() which was envisioned as a way fortoken holders to give permission for other users and dapps to withdraw a cappednumber of tokens. The security issue arises when a token holder wants to adjustthe amount of approved tokens from N to M (this could be an increase ordecrease). If malicious, a user or dapp who is approved for N tokens canfront-run the adjustment transaction to first withdraw N tokens, then allow theapproval to be confirmed, and withdraw an additional M tokens. In this paper,we evaluate 10 proposed mitigations for this issues and find that no solutionis fully satisfactory. We then propose 2 new solutions that mitigate theattack, one of which fully fulfills constraints of the standard, and the secondone shows a general limitation in addressing this issue from ERC20's approvemethod.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00903"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00863",
    "DOI": "arXiv:1907.00863v1",
    "Article_Title": "Understanding GCC Builtins to Develop Better Tools",
    "Article_Abstract": "C programs can use compiler builtins to provide functionality that the Clanguage lacks. On Linux, GCC provides several thousands of builtins that arealso supported by other mature compilers, such as Clang and ICC. Maintainers ofother tools lack guidance on whether and which builtins should be implementedto support popular projects. To assist tool developers who want to support GCCbuiltins, we analyzed builtin use in 4,913 C projects from GitHub. We foundthat 37% of these projects relied on at least one builtin. Supporting anincreasing proportion of projects requires support of an exponentiallyincreasing number of builtins; however, implementing only 10 builtins alreadycovers over 30% of the projects. Since we found that many builtins in ourcorpus remained unused, the effort needed to support 90% of the projects ismoderate, requiring about 110 builtins to be implemented. For each project, weanalyzed the evolution of builtin use over time and found that the majority ofprojects mostly added builtins. This suggests that builtins are not a legacyfeature and must be supported in future tools. Systematic testing of builtinsupport in existing tools revealed that many lacked support for builtins eitherpartially or completely; we also discovered incorrect implementations invarious tools, including the formally verified CompCert compiler.",
    "Article_Subject": "Programming Languages (cs.PL); Software Engineering (cs.SE)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00863"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00652",
    "DOI": "arXiv:1907.00652v1",
    "Article_Title": "Avoiding Implementation Pitfalls of \"Matrix Capsules with EM Routing\" by Hinton et al",
    "Article_Abstract": "The recent progress on capsule networks by Hinton et al. has generatedconsiderable excitement in the machine learning community. The idea behind acapsule is inspired by a cortical minicolumn in the brain, whereby a verticallyorganised group of around 100 neurons receive common inputs, have commonoutputs, are interconnected, and may well constitute a fundamental computationunit of the cerebral cortex. However, Hinton's paper on \"Matrix Capsule with EMRouting'\" was unfortunately not accompanied by a release of source code, whichleft interested researchers attempting to implement the architecture andreproduce the benchmarks on their own. This has certainly slowed the progressof research building on this work. While writing our own implementation, wenoticed several common mistakes in other open source implementations that wecame across. In this paper we share some of these learnings, specificallyfocusing on three implementation pitfalls and how to avoid them: (1) parentcapsules with only one child; (2) normalising the amount of data assigned toparent capsules; (3) parent capsules at different positions compete for childcapsules. While our implementation is a considerable improvement over currentlyavailable implementations, it still falls slightly short of the performancereported by Hinton et al. (2018). The source code for this implementation isavailable on GitHub at the following URL:https://github.com/IBM/matrix-capsules-with-em-routing.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00652"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00558",
    "DOI": "arXiv:1907.00558v1",
    "Article_Title": "Improved Forecasting of Cryptocurrency Price using Social Signals",
    "Article_Abstract": "Social media signals have been successfully used to develop large-scalepredictive and anticipatory analytics. For example, forecasting stock marketprices and influenza outbreaks. Recently, social data has been explored toforecast price fluctuations of cryptocurrencies, which are a novel disruptivetechnology with significant political and economic implications. In this paperwe leverage and contrast the predictive power of social signals, specificallyuser behavior and communication patterns, from multiple social platforms GitHuband Reddit to forecast prices for three cyptocurrencies with high developer andcommunity interest - Bitcoin, Ethereum, and Monero. We evaluate the performanceof neural network models that rely on long short-term memory units (LSTMs)trained on historical price data and social data against price only LSTMs andbaseline autoregressive integrated moving average (ARIMA) models, commonly usedto predict stock prices. Our results not only demonstrate that social signalsreduce error when forecasting daily coin price, but also show that the languageused in comments within the official communities on Reddit (r/Bitcoin,r/Ethereum, and r/Monero) are the best predictors overall. We observe thatmodels are more accurate in forecasting price one day ahead for Bitcoin (4%root mean squared percent error) compared to Ethereum (7%) and Monero (8%).",
    "Article_Subject": "Statistical Finance (q-fin.ST); Machine Learning (cs.LG); Social and Information Networks (cs.SI); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00558"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.11976",
    "DOI": "arXiv:1906.11976v1",
    "Article_Title": "Multivariate Big Data Analysis for Intrusion Detection: 5 steps from the haystack to the needle",
    "Article_Abstract": "The research literature on cybersecurity incident detection & response isvery rich in automatic detection methodologies, in particular those based onthe anomaly detection paradigm. However, very little attention has been devotedto the diagnosis ability of the methods, aimed to provide useful information onthe causes of a given detected anomaly. This information is of utmostimportance for the security team to reduce the time from detection to response.In this paper, we present Multivariate Big Data Analysis (MBDA), a completeintrusion detection approach based on 5 steps to effectively handle massiveamounts of disparate data sources. The approach has been designed to deal withthe main characteristics of Big Data, that is, the high volume, velocity andvariety. The core of the approach is the Multivariate Statistical NetworkMonitoring (MSNM) technique proposed in a recent paper. Unlike in state of theart machine learning methodologies applied to the intrusion detection problem,when an anomaly is identified in MBDA the output of the system includes thedetail of the logs of raw information associated to this anomaly, so that thesecurity team can use this information to elucidate its root causes. MBDA isbased in two open software packages available in Github: the MEDA Toolbox andthe FCParser. We illustrate our approach with two case studies. The first onedemonstrates the application of MBDA to semistructured sources of information,using the data from the VAST 2012 mini challenge 2. This complete case study issupplied in a virtual machine available for download. In the second case studywe show the Big Data capabilities of the approach in data collected from a realnetwork with labeled attacks.",
    "Article_Subject": "Networking and Internet Architecture (cs.NI); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Other Statistics (stat.OT)",
    "Article_Date": "2019/06/27",
    "Article_PDF": "https://arxiv.org/pdf/1906.11976"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.11565",
    "DOI": "arXiv:1906.11565v2",
    "Article_Title": "EmotionX-KU: BERT-Max based Contextual Emotion Classifier",
    "Article_Abstract": "We propose a contextual emotion classifier based on a transferable languagemodel and dynamic max pooling, which predicts the emotion of each utterance ina dialogue. A representative emotion analysis task, EmotionX, requires toconsider contextual information from colloquial dialogues and to deal with aclass imbalance problem. To alleviate these problems, our model leverages theself-attention based transferable language model and the weighted cross entropyloss. Furthermore, we apply post-training and fine-tuning mechanisms to enhancethe domain adaptability of our model and utilize several machine learningtechniques to improve its performance. We conduct experiments on twoemotion-labeled datasets named Friends and EmotionPush. As a result, our modeloutperforms the previous state-of-the-art model and also shows competitiveperformance in the EmotionX 2019 challenge. The code will be available in theGithub page.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/06/27",
    "Article_PDF": "https://arxiv.org/pdf/1906.11565"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.11017",
    "DOI": "arXiv:1906.11017v1",
    "Article_Title": "A project-based course on software development for (engineering) research",
    "Article_Abstract": "This paper describes the motivation and design of a 10-week graduate coursethat teaches practices for developing research software; although offered by anengineering program, the content applies broadly to any field of scientificresearch where software may be developed. Topics taught in the course includelocal and remote version control, licensing and copyright, structuring Pythonmodules, testing and test coverage, continuous integration, packaging anddistribution, open science, software citation, and reproducibility basics,among others. Lectures are supplemented by in-class activities and discussions,and all course material is shared openly via GitHub. Coursework is heavilybased on a single, term-long project where students individually develop asoftware package targeted at their own research topic; all contributions mustbe submitted as pull requests and reviewed/merged by other students. The coursewas initially offered in Spring 2018 with 17 students enrolled, and will betaught again in Spring 2019.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/06/13",
    "Article_PDF": "https://arxiv.org/pdf/1906.11017"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.10506",
    "DOI": "arXiv:1906.10506v1",
    "Article_Title": "GaussPy+: A fully automated Gaussian decomposition package for emission line spectra",
    "Article_Abstract": "Our understanding of the dynamics of the interstellar medium is informed bythe study of the detailed velocity structure of emission line observations. Oneapproach to study the velocity structure is to decompose the spectra intoindividual velocity components; this leads to a description of the dataset thatis significantly reduced in complexity. However, this decomposition requiresfull automation lest it becomes prohibitive for large datasets, such asGalactic plane surveys. We developed GaussPy+, a fully automated Gaussiandecomposition package that can be applied to emission line datasets, especiallylarge surveys of HI and isotopologues of CO. We built our package upon theexisting GaussPy algorithm and significantly improved its performance for noisydata. New functionalities of GaussPy+ include: i) automated preparatory steps,such as an accurate noise estimation, which can also be used as standaloneapplications; ii) an improved fitting routine; iii) an automated spatialrefitting routine that can add spatial coherence to the decomposition resultsby refitting spectra based on neighbouring fit solutions. We thoroughly testedthe performance of GaussPy+ on synthetic spectra and a test field from theGalactic Ring Survey. We found that GaussPy+ can deal with cases of complexemission and even low to moderate signal-to-noise values.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Astrophysics of Galaxies (astro-ph.GA)",
    "Article_Date": "2019/06/25",
    "Article_PDF": "https://arxiv.org/pdf/1906.10506"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.10362",
    "DOI": "arXiv:1906.10362v1",
    "Article_Title": "EVulHunter: Detecting Fake Transfer Vulnerabilities for EOSIO's Smart Contracts at Webassembly-level",
    "Article_Abstract": "As one of the representative Delegated Proof-of-Stake (DPoS) blockchainplatforms, EOSIO's ecosystem grows rapidly in recent years. A number ofvulnerabilities and corresponding attacks of EOSIO's smart contracts have beendiscovered and observed in the wild, which caused a large amount of financialdamages. However, the majority of EOSIO's smart contracts are not open-sourced.As a result, the WebAssembly code may become the only available object to beanalyzed in most cases. Unfortunately, current tools are web-applicationoriented and cannot be applied to EOSIO WebAssembly code directly, which makesit more difficult to detect vulnerabilities from those smart contracts. In thispaper, we propose \\toolname, a static analysis tool that can be used to detectvulnerabilities from EOSIO WASM code automatically. We focus on one particulartype of vulnerabilities named \\textit{fake-transfer}, and the exploitation ofsuch vulnerabilities has led to millions of dollars in damages. To the best ofour knowledge, it is the first attempt to build an automatic tool to detectvulnerabilities of EOSIO's smart contracts. The experimental resultsdemonstrate that our tool is able to detect fake transfer vulnerabilitiesquickly and precisely. EVulHunter is available on GitHub\\footnote{Tool andbenchmarks: https://github.com/EVulHunter/EVulHunter} and YouTube\\footnote{Demovideo: https://youtu.be/5SJ0ZJKVZvw}.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/06/25",
    "Article_PDF": "https://arxiv.org/pdf/1906.10362"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.09808",
    "DOI": "arXiv:1906.09808v1",
    "Article_Title": "Recurrent Adversarial Service Times",
    "Article_Abstract": "Service system dynamics occur at the interplay between customer behaviour anda service provider's response. This kind of dynamics can effectively be modeledwithin the framework of queuing theory where customers' arrivals are describedby point process models. However, these approaches are limited by parametricassumptions as to, for example, inter-event time distributions. In this paper,we address these limitations and propose a novel, deep neural network solutionto the queuing problem. Our solution combines a recurrent neural network thatmodels the arrival process with a recurrent generative adversarial networkwhich models the service time distribution. We evaluate our methodology onvarious empirical datasets ranging from internet services (Blockchain, GitHub,Stackoverflow) to mobility service systems (New York taxi cab).",
    "Article_Subject": "Machine Learning (stat.ML); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/24",
    "Article_PDF": "https://arxiv.org/pdf/1906.09808"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08351",
    "DOI": "arXiv:1906.08351v1",
    "Article_Title": "Towards Lakosian Multilingual Software Design Principles",
    "Article_Abstract": "Large software systems often comprise programs written in differentprogramming languages. In the case when cross-language interoperability isaccomplished with a Foreign Function Interface (FFI), for example pybind11,Boost.Python, Emscripten, PyV8, or JNI, among many others, common softwareengineering tools, such as call-graph analysis, are obstructed by the opacityof the FFI. This complicates debugging and fosters potential inefficiency andsecurity problems. One contributing issue is that there is little rigoroussoftware design advice for multilingual software. In this paper, we present ourprogress towards a more rigorous design approach to multilingual software. Theapproach is based on the existing approach to the design of large-scale C++systems developed by Lakos. The Lakosian approach is one of the few designmethodologies to address physical design rather than just logical design. Usingthe MLSA toolkit developed in prior work for analysis of multilingual software,we focus in on one FFI -- the pybind11 FFI. An extension to the Lakosian C++design rules is proposed to address multilingual software that uses pybind11.Using a sample of 50 public GitHub repositories that use pybind11, we measurehow many repositories would currently satisfy these rules. We conclude with aproposed generalization of the pybind11-based rules for any multilingualsoftware using an FFI interface.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08351"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08101",
    "DOI": "arXiv:1906.08101v1",
    "Article_Title": "Pre-Training with Whole Word Masking for Chinese BERT",
    "Article_Abstract": "Bidirectional Encoder Representations from Transformers (BERT) has shownmarvelous improvements across various NLP tasks. Recently, an upgraded versionof BERT has been released with Whole Word Masking (WWM), which mitigate thedrawbacks of masking partial WordPiece tokens in pre-training BERT. In thistechnical report, we adapt whole word masking in Chinese text, that masking thewhole word instead of masking Chinese characters, which could bring anotherchallenge in Masked Language Model (MLM) pre-training task. The model wastrained on the latest Chinese Wikipedia dump. We aim to provide easyextensibility and better performance for Chinese BERT without changing anyneural architecture or even hyper-parameters. The model is verified on variousNLP tasks, across sentence-level to document-level, including sentimentclassification (ChnSentiCorp, Sina Weibo), named entity recognition (PeopleDaily, MSRA-NER), natural language inference (XNLI), sentence pair matching(LCQMC, BQ Corpus), and machine reading comprehension (CMRC 2018, DRCD, CAILRC). Experimental results on these datasets show that the whole word maskingcould bring another significant gain. Moreover, we also examine theeffectiveness of Chinese pre-trained models: BERT, ERNIE, BERT-wwm. We releasethe pre-trained model (both TensorFlow and PyTorch) on GitHub:https://github.com/ymcui/Chinese-BERT-wwm",
    "Article_Subject": "Computation and Language (cs.CL); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08101"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08085",
    "DOI": "arXiv:1906.08085v1",
    "Article_Title": "PLANE: An Extensible Open Source Framework for modeling the Internet of Drones",
    "Article_Abstract": "Python Library for simulating unManNed vehiclEs(PLANE) is an open sourcesoftware module, written in Python, that focuses on Unmanned Aerial Vehicles(UAVs), on their movements and on the mechanics of flight, thus devotingparticular attention to the equations that describe drones' movement. In thecontext of the Internet of Drones (IoD), the module can be widely used for thestudy of the mutual control of position/coordination in scenarios in whichdrones may find obstacles, as it happens in densely populated urban scenarios.Emphasis is put on ease of use, performance evaluation, documentation, andApplication Programming Interface (API) consistency. The software tool hasminimal dependencies and is distributed under MIT License. Source code,binaries, and documentation can be downloaded from GitHub.",
    "Article_Subject": "Robotics (cs.RO); Software Engineering (cs.SE)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08085"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08058",
    "DOI": "arXiv:1906.08058v1",
    "Article_Title": "On the abandonment and survival of open source projects: An empirical investigation",
    "Article_Abstract": "Background: Evolution of open source projects frequently depends on a smallnumber of core developers. The loss of such core developers might bedetrimental for projects and even threaten their entire continuation. However,it is possible that new core developers assume the project maintenance andallow the project to survive. Aims: The objective of this paper is to provideempirical evidence on: 1) the frequency of project abandonment and survival, 2)the differences between abandoned and surviving projects, and 3) the motivationand difficulties faced when assuming an abandoned project. Method: We adopt amixed-methods approach to investigate project abandonment and survival. Wecarefully select 1,932 popular GitHub projects and recover the abandoned andsurviving projects, and conduct a survey with developers that have beeninstrumental in the survival of the projects. Results: We found that 315projects (16%) were abandoned and 128 of these projects (41%) survived becauseof new core developers who assumed the project development. The surveyindicates that (i) in most cases the new maintainers were aware of the projectabandonment risks when they started to contribute; (ii) their own usage of thesystems is the main motivation to contribute to such projects; (iii) human andsocial factors played a key role when making these contributions; and (iv) lackof time and the difficulty to obtain push access to the repositories are themain barriers faced by them. Conclusions: Project abandonment is a reality evenin large open source projects and our work enables a better understanding ofsuch risks, as well as highlights ways in avoiding them.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08058"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.07771",
    "DOI": "arXiv:1906.07771v1",
    "Article_Title": "Crop Lodging Prediction from UAV-Acquired Images of Wheat and Canola using a DCNN Augmented with Handcrafted Texture Features",
    "Article_Abstract": "Lodging, the permanent bending over of food crops, leads to poor plant growthand development. Consequently, lodging results in reduced crop quality, lowerscrop yield, and makes harvesting difficult. Plant breeders routinely evaluateseveral thousand breeding lines, and therefore, automatic lodging detection andprediction is of great value aid in selection. In this paper, we propose a deepconvolutional neural network (DCNN) architecture for lodging classificationusing five spectral channel orthomosaic images from canola and wheat breedingtrials. Also, using transfer learning, we trained 10 lodging detection modelsusing well-established deep convolutional neural network architectures. Ourproposed model outperforms the state-of-the-art lodging detection methods inthe literature that use only handcrafted features. In comparison to 10 DCNNlodging detection models, our proposed model achieves comparable results whilehaving a substantially lower number of parameters. This makes the proposedmodel suitable for applications such as real-time classification usinginexpensive hardware for high-throughput phenotyping pipelines. The GitHubrepository at https://github.com/FarhadMaleki/LodgedNet contains code andmodels.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/06/18",
    "Article_PDF": "https://arxiv.org/pdf/1906.07771"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.07637",
    "DOI": "arXiv:1906.07637v2",
    "Article_Title": "Periphery Plots for Contextualizing Heterogeneous Time-Based Charts",
    "Article_Abstract": "Patterns in temporal data can often be found across different scales, such asdays, weeks, and months, making effective visualization of time-based datachallenging. Here we propose a new approach for providing focus and context intime-based charts to enable interpretation of patterns across time scales. Ourapproach employs a focus zone with a time and a second axis, that can eitherrepresent quantities or categories, as well as a set of adjacent peripheryplots that can aggregate data along the time, value, or both dimensions. Wepresent a framework for periphery plots and describe two use cases thatdemonstrate the utility of our approach.",
    "Article_Subject": "Human-Computer Interaction (cs.HC)",
    "Article_Date": "2019/06/18",
    "Article_PDF": "https://arxiv.org/pdf/1906.07637"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.07505",
    "DOI": "arXiv:1906.07505v1",
    "Article_Title": "A Model-Based General Alternative to the Standardised Precipitation Index",
    "Article_Abstract": "In this paper, we introduce two new model-based versions of the widely-usedstandardized precipitation index (SPI) for detecting and quantifying themagnitude of extreme hydro-climatic events. Our analytical approach is based ongeneralized additive models for location, scale and shape (GAMLSS), which helpsas to overcome some limitations of the SPI. We compare our model-basedstandardised indices (MBSIs) with the SPI using precipitation data collectedbetween January 2004 - December 2013 (522 weeks) in Caapiranga, a road-lessmunicipality of Amazonas State. As a result, it is shown that the MBSI-1 is anindex with similar properties to the SPI, but with improved methodology. Incomparison to the SPI, our MBSI-1 index allows for the use of differentzero-augmented distributions, it works with more flexible time-scales, can beapplied to shorter records of data and also takes into account temporaldependencies in known seasonal behaviours. Our approach is implemented in an Rpackage, mbsi, available from Github.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/06/18",
    "Article_PDF": "https://arxiv.org/pdf/1906.07505"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.06905",
    "DOI": "arXiv:1906.06905v2",
    "Article_Title": "Manipulating the Difficulty of C-Tests",
    "Article_Abstract": "We propose two novel manipulation strategies for increasing and decreasingthe difficulty of C-tests automatically. This is a crucial step towardsgenerating learner-adaptive exercises for self-directed language learning andpreparing language assessment tests. To reach the desired difficulty level, wemanipulate the size and the distribution of gaps based on absolute and relativegap difficulty predictions. We evaluate our approach in corpus-basedexperiments and in a user study with 60 participants. We find that bothstrategies are able to generate C-tests with the desired difficulty level.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/06/17",
    "Article_PDF": "https://arxiv.org/pdf/1906.06905"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.06583",
    "DOI": "arXiv:1906.06583v2",
    "Article_Title": "Linear regression with stationary errors : the R package slm",
    "Article_Abstract": "This paper introduces the R package slm which stands for Stationary LinearModels. The package contains a set of statistical procedures for linearregression in the general context where the error process is strictlystationary with short memory. We work in the setting of Hannan (1973), whoproved the asymptotic normality of the (normalized) least squares estimators(LSE) under very mild conditions on the error process. We propose differentways to estimate the asymptotic covariance matrix of the LSE, and then tocorrect the type I error rates of the usual tests on the parameters (as well asconfidence intervals). The procedures are evaluated through different sets ofsimulations, and two examples of real datasets are studied.",
    "Article_Subject": "Applications (stat.AP); Computation (stat.CO); Methodology (stat.ME)",
    "Article_Date": "2019/06/15",
    "Article_PDF": "https://arxiv.org/pdf/1906.06583"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.06317",
    "DOI": "arXiv:1906.06317v1",
    "Article_Title": "freud: A Software Suite for High Throughput Analysis of Particle Simulation Data",
    "Article_Abstract": "The freud Python package is a powerful library for analyzing simulation data.Written with modern simulation and data analysis workflows in mind, freudprovides a Python interface to fast, parallelized C++ routines that runefficiently on laptops, workstations, and supercomputing clusters. The packageprovides the core tools for finding particle neighbors in periodic systems, andoffers a uniform API to a wide variety of methods implemented using thesetools. As such, freud users can access standard methods such as the radialdistribution function as well as newer, more specialized methods such as thepotential of mean force and torque and local crystal environment analysis withequal ease. While many comparable tools place a heavy emphasis on reading andoperating on trajectory file formats, freud instead accepts numerical arrays ofdata directly as inputs. By remaining agnostic to its data source, freud issuitable for analyzing any coarse-grained particle simulation, regardless ofthe original data representation or simulation method. When used for on-the-flyanalysis in conjunction with scriptable simulation software such as HOOMD-blue,freud enables smart simulations that adapt to the current state of the system,allowing users to study phenomena such as nucleation and growth.",
    "Article_Subject": "Computational Physics (physics.comp-ph); Materials Science (cond-mat.mtrl-sci); Computational Engineering, Finance, and Science (cs.CE)",
    "Article_Date": "2019/06/14",
    "Article_PDF": "https://arxiv.org/pdf/1906.06317"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.05676",
    "DOI": "arXiv:1906.05676v1",
    "Article_Title": "Sionnx: Automatic Unit Test Generator for ONNX Conformance",
    "Article_Abstract": "Open Neural Network Exchange (ONNX) is an open format to represent AI modelsand is supported by many machine learning frameworks. While ONNX definesunified and portable computation operators across various frameworks, theconformance tests for those operators are insufficient, which makes itdifficult to verify if an operator's behavior in an ONNX backend implementationcomplies with the ONNX standard. In this paper, we present the first automaticunit test generator named Sionnx for verifying the compliance of ONNXimplementation. First, we propose a compact yet complete set of rules todescribe the operator's attributes and the properties of its operands. Second,we design an Operator Specification Language (OSL) to provide a high-leveldescription for the operator's syntax. Finally, through this easy-to-usespecification language, we are able to build a full testing specification whichleverages LLVM TableGen to automatically generate unit tests for ONNX operatorswith much large coverage. Sionnx is lightweight and flexible to supportcross-framework verification. The Sionnx framework is open-sourced in thegithub repository (https://github.com/alibaba/Sionnx).",
    "Article_Subject": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/06/12",
    "Article_PDF": "https://arxiv.org/pdf/1906.05676"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.05603",
    "DOI": "arXiv:1906.05603v1",
    "Article_Title": "A review of available software for adaptive clinical trial design",
    "Article_Abstract": "Background/Aims: The increasing expense of the drug development process hasseen interest in the use of adaptive designs (ADs) grow substantially in recentyears. Accordingly, much research has been conducted to identify potentialbarriers to increasing the use of ADs in practice, and several articles haveargued that the availability of user-friendly software will be an importantstep in making ADs easier to implement. Therefore, in this paper we present areview of the current state of software availability for AD. Methods: We firstreview articles from 31 journals published in 2013-17 that relate tomethodology for adaptive trials, in order to assess how often code and softwarefor implementing novel ADs is made available at the time of publication. Wecontrast our findings against these journals' current policies on codedistribution. Secondly, we conduct additional searches of popular coderepositories, such as CRAN and GitHub, to identify further existinguser-contributed software for ADs. From this, we are able to direct interestedparties towards solutions for their problem of interest by classifyingavailable code by type of adaptation. Results: Only 29% of included articlesmade their code available in some form. In many instances, articles publishedin journals that had mandatory requirements on code provision still did notmake code available. There are several areas in which available software iscurrently limited or saturated. In particular, many packages are available toaddress group sequential design, but comparatively little code is present inthe public domain to determine biomarker-guided ADs. Conclusions: There is muchroom for improvement in the provision of software alongside AD publications.Additionally, whilst progress has been made, well-established software forvarious types of trial adaptation remains sparsely available.",
    "Article_Subject": "Computation (stat.CO)",
    "Article_Date": "2019/06/13",
    "Article_PDF": "https://arxiv.org/pdf/1906.05603"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.04554",
    "DOI": "arXiv:1906.04554v1",
    "Article_Title": "Principled Training of Neural Networks with Direct Feedback Alignment",
    "Article_Abstract": "The backpropagation algorithm has long been the canonical training method forneural networks. Modern paradigms are implicitly optimized for it, and numerousguidelines exist to ensure its proper use. Recently, synthetic gradientsmethods -where the error gradient is only roughly approximated - have garneredinterest. These methods not only better portray how biological brains arelearning, but also open new computational possibilities, such as updatinglayers asynchronously. Even so, they have failed to scale past simple taskslike MNIST or CIFAR-10. This is in part due to a lack of standards, leading toill-suited models and practices forbidding such methods from performing to thebest of their abilities. In this work, we focus on direct feedback alignmentand present a set of best practices justified by observations of the alignmentangles. We characterize a bottleneck effect that prevents alignment in narrowlayers, and hypothesize it may explain why feedback alignment methods have yetto scale to large convolutional networks.",
    "Article_Subject": "Machine Learning (stat.ML); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)",
    "Article_Date": "2019/06/11",
    "Article_PDF": "https://arxiv.org/pdf/1906.04554"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.04281",
    "DOI": "arXiv:1906.04281v1",
    "Article_Title": "Towards Amortized Ranking-Critical Training for Collaborative Filtering",
    "Article_Abstract": "Collaborative filtering is widely used in modern recommender systems. Recentresearch shows that variational autoencoders (VAEs) yield state-of-the-artperformance by integrating flexible representations from deep neural networksinto latent variable models, mitigating limitations of traditional linearfactor models. VAEs are typically trained by maximizing the likelihood (MLE) ofusers interacting with ground-truth items. While simple and often effective,MLE-based training does not directly maximize the recommendation-qualitymetrics one typically cares about, such as top-N ranking. In this paper weinvestigate new methods for training collaborative filtering models based onactor-critic reinforcement learning, to directly optimize thenon-differentiable quality metrics of interest. Specifically, we train a criticnetwork to approximate ranking-based metrics, and then update the actor network(represented here by a VAE) to directly optimize against the learned metrics.In contrast to traditional learning-to-rank methods that require to re-run theoptimization procedure for new lists, our critic-based method amortizes thescoring process with a neural network, and can directly provide the(approximate) ranking scores for new lists. Empirically, we show that theproposed methods outperform several state-of-the-art baselines, includingrecently-proposed deep learning approaches, on three large-scale real-worlddatasets. The code to reproduce the experimental results and figure plots is onGithub: https://github.com/samlobel/RaCT_CF",
    "Article_Subject": "Machine Learning (cs.LG); Information Retrieval (cs.IR); Machine Learning (stat.ML)",
    "Article_Date": "2019/06/10",
    "Article_PDF": "https://arxiv.org/pdf/1906.04281"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03951",
    "DOI": "arXiv:1906.03951v1",
    "Article_Title": "SCAN: A Scalable Neural Networks Framework Towards Compact and Efficient Models",
    "Article_Abstract": "Remarkable achievements have been attained by deep neural networks in variousapplications. However, the increasing depth and width of such models also leadto explosive growth in both storage and computation, which has restricted thedeployment of deep neural networks on resource-limited edge devices. To addressthis problem, we propose the so-called SCAN framework for networks training andinference, which is orthogonal and complementary to existing acceleration andcompression methods. The proposed SCAN firstly divides neural networks intomultiple sections according to their depth and constructs shallow classifiersupon the intermediate features of different sections. Moreover, attentionmodules and knowledge distillation are utilized to enhance the accuracy ofshallow classifiers. Based on this architecture, we further propose a thresholdcontrolled scalable inference mechanism to approach human-like sample-specificinference. Experimental results show that SCAN can be easily equipped onvarious neural networks without any adjustment on hyper-parameters or neuralnetworks architectures, yielding significant performance gain on CIFAR100 andImageNet. Codes will be released on github soon.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/27",
    "Article_PDF": "https://arxiv.org/pdf/1906.03951"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03773",
    "DOI": "arXiv:1906.03773v1",
    "Article_Title": "DataLearner: A Data Mining and Knowledge Discovery Tool for Android Smartphones and Tablets",
    "Article_Abstract": "Smartphones have become the ultimate 'personal' computer, yet despite this,general-purpose data-mining and knowledge discovery tools for mobile devicesare surprisingly rare. DataLearner is a new data-mining application designedspecifically for Android devices that imports the Weka data-mining engine andaugments it with algorithms developed by Charles Sturt University. Moreover,DataLearner can be expanded with additional algorithms. Combined, DataLearnerdelivers 40 classification, clustering and association rule mining algorithmsfor model training and evaluation without need for cloud computing resources ornetwork connectivity. It provides the same classification accuracy as PCs andlaptops, while doing so with acceptable processing speed and consumingnegligible battery life. With its ability to provide easy-to-use data-mining ona phone-size screen, DataLearner is a new portable, self-contained data-miningtool for remote, personalised and learning applications alike. DataLearnerfeatures four elements - this paper, the app available on Google Play, theGPL3-licensed source code on GitHub and a short video on YouTube.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/06/10",
    "Article_PDF": "https://arxiv.org/pdf/1906.03773"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03277",
    "DOI": "arXiv:1906.03277v1",
    "Article_Title": "xBIT: an easy to use scanning tool with machine learning abilities",
    "Article_Abstract": "xBIT is a tool for performing parameter scans in beyond the Standard Modeltheories. It's written in Python and fully open source. The main purpose ofxBIT is to provide an easy to use tool to help phenomenologists with theirdaily task: exploring the parameter space of new models. It was developed underthe impression of the SARAH/SPheno framework, but should be use-able with othertools as well that use the SLHA format to transfer data. It also supports bydefault MicrOmegas for dark matter calculations, HiggsBounds and HiggsSignalsfor checking the Higgs properties, and Vevacious for testing the vacuumstability. Classes for other tools can be added if necessary. In order toimprove the efficiency of the parameter scans, the recently proposed 'MachineLearning Scan' approach is included. For this purpose, xBIT uses pyTorch todeal with artificial neural networks.",
    "Article_Subject": "High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Experiment (hep-ex)",
    "Article_Date": "2019/06/07",
    "Article_PDF": "https://arxiv.org/pdf/1906.03277"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03049",
    "DOI": "arXiv:1906.03049v1",
    "Article_Title": "Computing Exact Guarantees for Differential Privacy",
    "Article_Abstract": "Quantification of the privacy loss associated with a randomised algorithm hasbecome an active area of research and $(\\varepsilon,\u03b4)$-differentialprivacy has arisen as the standard measure of it. We propose a numerical methodfor evaluating the parameters of differential privacy for algorithms withcontinuous one dimensional output. In this way the parameters $\\varepsilon$ and$\u03b4$ can be evaluated, for example, for the subsampled multidimensionalGaussian mechanism which is also the underlying mechanism of differentiallyprivate stochastic gradient descent. The proposed method is based on anumerical approximation of an integral formula which gives the exact$(\\varepsilon,\u03b4)$-values. The approximation is carried out by discretisingthe integral and by evaluating discrete convolutions using a fast Fouriertransform algorithm. We give theoretical error bounds which show theconvergence of the approximation and guarantee its accuracy to an arbitrarydegree. Experimental comparisons with state-of-the-art techniques illustratethe efficacy of the method. Python code for the proposed method can be found inGithub (https://github.com/DPBayes/PLD-Accountant/).",
    "Article_Subject": "Machine Learning (stat.ML); Cryptography and Security (cs.CR); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/07",
    "Article_PDF": "https://arxiv.org/pdf/1906.03049"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03008",
    "DOI": "arXiv:1906.03008v2",
    "Article_Title": "RankQA: Neural Question Answering with Answer Re-Ranking",
    "Article_Abstract": "The conventional paradigm in neural question answering (QA) for narrativecontent is limited to a two-stage process: first, relevant text passages areretrieved and, subsequently, a neural network for machine comprehensionextracts the likeliest answer. However, both stages are largely isolated in thestatus quo and, hence, information from the two phases is never properly fused.In contrast, this work proposes RankQA: RankQA extends the conventionaltwo-stage process in neural QA with a third stage that performs an additionalanswer re-ranking. The re-ranking leverages different features that aredirectly extracted from the QA pipeline, i.e., a combination of retrieval andcomprehension features. While our intentionally simple design allows for anefficient, data-sparse estimation, it nevertheless outperforms more complex QAsystems by a significant margin: in fact, RankQA achieves state-of-the-artperformance on 3 out of 4 benchmark datasets. Furthermore, its performance isespecially superior in settings where the size of the corpus is dynamic. Herethe answer re-ranking provides an effective remedy against the underlyingnoise-information trade-off due to a variable corpus size. As a consequence,RankQA represents a novel, powerful, and thus challenging baseline for futureresearch in content-based QA.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/06/07",
    "Article_PDF": "https://arxiv.org/pdf/1906.03008"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.02126",
    "DOI": "arXiv:1906.02126v1",
    "Article_Title": "Extractive Summarization via Weighted Dissimilarity and Importance Aligned Key Iterative Algorithm",
    "Article_Abstract": "We present importance aligned key iterative algorithm for extractivesummarization that is faster than conventional algorithms keeping its accuracy.The computational complexity of our algorithm is O($SNlogN$) to summarizeoriginal $N$ sentences into final $S$ sentences. Our algorithm maximizes theweighted dissimilarity defined by the product of importance and cosinedissimilarity so that the summary represents the document and at the same timethe sentences of the summary are not similar to each other. The weighteddissimilarity is heuristically maximized by iterative greedy search and binarysearch to the sentences ordered by importance. We finally show a benchmarkscore based on summarization of customer reviews of products, which highlightsthe quality of our algorithm comparable to human and existing algorithms. Weprovide the source code of our algorithm on githubhttps://github.com/qhapaq-49/imakita .",
    "Article_Subject": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/05/15",
    "Article_PDF": "https://arxiv.org/pdf/1906.02126"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.01388",
    "DOI": "arXiv:1906.01388v1",
    "Article_Title": "A Comprehensive Study on Deep Learning Bug Characteristics",
    "Article_Abstract": "Deep learning has gained substantial popularity in recent years. Developersmainly rely on libraries and tools to add deep learning capabilities to theirsoftware. What kinds of bugs are frequently found in such software? What arethe root causes of such bugs? What impacts do such bugs have? Which stages ofdeep learning pipeline are more bug prone? Are there any antipatterns?Understanding such characteristics of bugs in deep learning software has thepotential to foster the development of better deep learning platforms,debugging mechanisms, development practices, and encourage the development ofanalysis and verification frameworks. Therefore, we study 2716 high-qualityposts from Stack Overflow and 500 bug fix commits from Github about fivepopular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch tounderstand the types of bugs, root causes of bugs, impacts of bugs, bug-pronestage of deep learning pipeline as well as whether there are some commonantipatterns found in this buggy software. The key findings of our studyinclude: data bug and logic bug are the most severe bug types in deep learningsoftware appearing more than 48% of the times, major root causes of these bugsare Incorrect Model Parameter (IPS) and Structural Inefficiency (SI) showing upmore than 43% of the times. We have also found that the bugs in the usage ofdeep learning libraries have some common antipatterns that lead to a strongcorrelation of bug types among the libraries.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.01388"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.01211",
    "DOI": "arXiv:1906.01211v3",
    "Article_Title": "Raising the Performance of the Tinker-HP Molecular Modeling Package [Article v1.0]",
    "Article_Abstract": "This living paper reviews the present High Performance Computing (HPC)capabilities of the Tinker-HP molecular modeling package. We focus here on thereference, double precision, massively parallel molecular dynamics enginepresent in Tinker-HP and dedicated to perform large scale simulations. We showhow it can be adapted to recent Intel Central Processing Unit (CPU) petascalearchitectures. First, we discuss the new set of Intel Advanced VectorExtensions 512 (Intel AVX-512) instructions present in recent Intel processors(e.g., the Intel Xeon Scalable and Intel Xeon Phi 2nd generation processors)allowing for larger vectorization enhancements. These instructions constitutethe central source of potential computational gains when using the latestprocessors, justifying important vectorization efforts for developers. We thenbriefly review the organization of the Tinker-HP code and identify thecomputational hotspots which require Intel AVX-512 optimization and we proposea general and optimal strategy to vectorize those particular parts of the code.We intended to present our optimization strategy in a pedagogical way so itcould benefit to other researchers and students interested in gainingperformances in their own software. Finally we present the performanceenhancements obtained compared to the unoptimized code both sequentially and atthe scaling limit in parallel for classical non-polarizable (CHARMM) andpolarizable force fields (AMOEBA). This paper never ceases to be updated as weaccumulate new data on the associated Github repository between new versions ofthis living paper.",
    "Article_Subject": "Mathematical Software (cs.MS); Chemical Physics (physics.chem-ph); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/06/04",
    "Article_PDF": "https://arxiv.org/pdf/1906.01211"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.01032",
    "DOI": "arXiv:1906.01032v1",
    "Article_Title": "A Language-Agnostic Model for Semantic Source Code Labeling",
    "Article_Abstract": "Code search and comprehension have become more difficult in recent years dueto the rapid expansion of available source code. Current tools lack a way tolabel arbitrary code at scale while maintaining up-to-date representations ofnew programming languages, libraries, and functionalities. Comprehensivelabeling of source code enables users to search for documents of interest andobtain a high-level understanding of their contents. We use Stack Overflow codesnippets and their tags to train a language-agnostic, deep convolutional neuralnetwork to automatically predict semantic labels for source code documents. OnStack Overflow code snippets, we demonstrate a mean area under ROC of 0.957over a long-tailed list of 4,508 tags. We also manually validate the modeloutputs on a diverse set of unlabeled source code documents retrieved fromGithub, and we obtain a top-1 accuracy of 86.6%. This strongly indicates thatthe model successfully transfers its knowledge from Stack Overflow snippets toarbitrary source code documents.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Software Engineering (cs.SE); Machine Learning (stat.ML)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.01032"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.00966",
    "DOI": "arXiv:1906.00966v3",
    "Article_Title": "Wotan: Comprehensive time-series de-trending in Python",
    "Article_Abstract": "The detection of transiting exoplanets in time-series photometry requires theremoval or modeling of instrumental and stellar noise. While instrumentalsystematics can be reduced using methods such as pixel level decorrelation,removing stellar trends while preserving transit signals proves challenging.Due to vast archives of light curves from recent transit surveys, there is astrong need for accurate automatic detrending, without human intervention. Alarge variety of detrending algorithms are in active use, but their comparativeperformance for transit discovery is unexplored. We benchmark all commonly useddetrending methods against hundreds of Kepler, K2, and TESS planets, selectedto represent the most difficult cases for systems with small planet-to-starradius ratios. The full parameter range is explored for each method todetermine the best choices for planet discovery. We conclude that the idealmethod is a time-windowed slider with an iterative robust location estimatorbased on Tukey's biweight. This method recovers 99% and 94% of the shallowestKepler and K2 planets, respectively. We include an additional analysis foryoung stars with extreme variability and conclude they are best treated using aspline-based method with a robust Huber estimator. All stellar detrendingmethods explored are available for public use in wotan, an open-source Pythonpackage on GitHub (see https://github.com/hippke/wotan).",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.00966"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.00925",
    "DOI": "arXiv:1906.00925v2",
    "Article_Title": "3D Appearance Super-Resolution with Deep Learning",
    "Article_Abstract": "We tackle the problem of retrieving high-resolution (HR) texture maps ofobjects that are captured from multiple view points. In the multi-view case,model-based super-resolution (SR) methods have been recently proved to recoverhigh quality texture maps. On the other hand, the advent of deep learning-basedmethods has already a significant impact on the problem of video and image SR.Yet, a deep learning-based approach to super-resolve the appearance of 3Dobjects is still missing. The main limitation of exploiting the power of deeplearning techniques in the multi-view case is the lack of data. We introduce a3D appearance SR (3DASR) dataset based on the existing ETH3D [42], SyB3R [31],MiddleBury, and our Collection of 3D scenes from TUM [21], Fountain [51] andRelief [53]. We provide the high- and low-resolution texture maps, the 3Dgeometric model, images and projection matrices. We exploit the power of 2Dlearning-based SR methods and design networks suitable for the 3D multi-viewcase. We incorporate the geometric information by introducing normal maps andfurther improve the learning process. Experimental results demonstrate that ourproposed networks successfully incorporate the 3D geometric information andsuper-resolve the texture maps.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.00925"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.00657",
    "DOI": "arXiv:1906.00657v1",
    "Article_Title": "Kandinsky Patterns",
    "Article_Abstract": "Kandinsky Figures and Kandinsky Patterns are mathematically describable,simple self-contained hence controllable test data sets for the development,validation and training of explainability in artificial intelligence. WhilstKandinsky Patterns have these computationally manageable properties, they areat the same time easily distinguishable from human observers. Consequently,controlled patterns can be described by both humans and computers. We define aKandinsky Pattern as a set of Kandinsky Figures, where for each figure an\"infallible authority\" defines that the figure belongs to the KandinskyPattern. With this simple principle we build training and validation data setsfor automatic interpretability and context learning. In this paper we describethe basic idea and some underlying principles of Kandinsky Patterns and providea Github repository to invite the international machine learning researchcommunity to a challenge to experiment with our Kandinsky Patterns to expandand thus make progress in the field of explainable AI and to contribute to theupcoming field of explainability and causability.",
    "Article_Subject": "Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.00657"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.13658",
    "DOI": "arXiv:1905.13658v1",
    "Article_Title": "Ordinal Regression as Structured Classification",
    "Article_Abstract": "This paper extends the class of ordinal regression models with a structuredinterpretation of the problem by applying a novel treatment of encoded labels.The net effect of this is to transform the underlying problem from an ordinalregression task to a (structured) classification task which we solve withconditional random fields, thereby achieving a coherent and probabilistic modelin which all model parameters are jointly learnt. Importantly, we show thatalthough we have cast ordinal regression to classification, our method stillfall within the class of decomposition methods in the ordinal regressionontology. This is an important link since our experience is that manyapplications of machine learning to healthcare ignores completely the importantnature of the label ordering, and hence these approaches should considerednaive in this ontology. We also show that our model is flexible both in how itadapts to data manifolds and in terms of the operations that are available forpractitioner to execute. Our empirical evaluation demonstrates that theproposed approach overwhelmingly produces superior and often statisticallysignificant results over baseline approaches on forty popular ordinalregression models, and demonstrate that the proposed model significantlyout-performs baselines on synthetic and real datasets. Our implementation,together with scripts to reproduce the results of this work, will be availableon a public GitHub repository.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/31",
    "Article_PDF": "https://arxiv.org/pdf/1905.13658"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.13313",
    "DOI": "arXiv:1905.13313v5",
    "Article_Title": "Technical Report of the Video Event Reconstruction and Analysis (VERA) System -- Shooter Localization, Models, Interface, and Beyond",
    "Article_Abstract": "Every minute, hundreds of hours of video are uploaded to social media sitesand the Internet from around the world. This material creates a visual recordof the experiences of a significant percentage of humanity and can helpilluminate how we live in the present moment. When properly analyzed, thisvideo can also help analysts to reconstruct events of interest, including warcrimes, human rights violations, and terrorist acts. Machine learning andcomputer vision can play a crucial role in this process. In this technicalreport, we describe the Video Event Reconstruction and Analysis (VERA) system.This new tool brings together a variety of capabilities we have developed overthe past few years (including video synchronization and geolocation to orderunstructured videos lacking metadata over time and space, and sound recognitionalgorithms) to enable the reconstruction and analysis of events captured onvideo. Among other uses, VERA enables the localization of a shooter from just afew videos that include the sound of gunshots. To demonstrate the efficacy ofthis suite of tools, we present the results of estimating the shooter'slocation of the Las Vegas Shooting in 2017 and show that VERA accuratelypredicts the shooter's location using only the first few gunshots. We thenpoint out future directions that can help improve the system and further reduceunnecessary human labor in the process. All of the components of VERA runthrough a web interface that enables human-in-the-loop verification to ensureaccurate estimations. All relevant source code, including the web interface andmachine learning models, is freely available on Github. We hope thatresearchers and software developers will be inspired to improve and expand thissystem moving forward to better meet the needs of human rights and publicsafety.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multimedia (cs.MM)",
    "Article_Date": "2019/05/26",
    "Article_PDF": "https://arxiv.org/pdf/1905.13313"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.12768",
    "DOI": "arXiv:1905.12768v2",
    "Article_Title": "Using Propensity Scores to Develop and Evaluate Treatment Rules with Observational Data",
    "Article_Abstract": "In this paper, we outline a principled approach to estimate an individualizedtreatment rule that is appropriate for data from observational studies where,in addition to treatment assignment not being independent of individualcharacteristics, some characteristics may affect treatment assignment in thecurrent study but not be available in future clinical settings where theestimated rule would be applied. The estimation framework is quite flexible andaccommodates any prediction method that uses observation weights, where theobservation weights themselves are a ratio of two flexibly estimated propensityscores. We also discuss how to obtain a trustworthy estimate of the rule'spopulation benefit based on simple propensity-score-based estimators of averagetreatment effect. We implement our approach in the R package DevTreatRules andshare the code needed to reproduce our results on GitHub.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/05/29",
    "Article_PDF": "https://arxiv.org/pdf/1905.12768"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.12111",
    "DOI": "arXiv:1905.12111v1",
    "Article_Title": "Analyzing and Supporting Adaptation of Online Code Examples",
    "Article_Abstract": "Developers often resort to online Q&A forums such as Stack Overflow (SO) forfilling their programming needs. Although code examples on those forums aregood starting points, they are often incomplete and inadequate for developers'local program contexts; adaptation of those examples is necessary to integratethem to production code. As a consequence, the process of adapting online codeexamples is done over and over again, by multiple developers independently. Ourwork extensively studies these adaptations and variations, serving as the basisfor a tool that helps integrate these online code examples in a target contextin an interactive manner.  We perform a large-scale empirical study about the nature and extent ofadaptations and variations of SO snippets. We construct a comprehensive datasetlinking SO posts to GitHub counterparts based on clone detection, time stampanalysis, and explicit URL references. We then qualitatively inspect 400 SOexamples and their GitHub counterparts and develop a taxonomy of 24 adaptationtypes. Using this taxonomy, we build an automated adaptation analysis techniqueon top of GumTree to classify the entire dataset into these types. We build aChrome extension called ExampleStack that automatically lifts anadaptation-aware template from each SO example and its GitHub counterparts toidentify hot spots where most changes happen. A user study with sixteenprogrammers shows that seeing the commonalities and variations in similarGitHub counterparts increases their confidence about the given SO example, andhelps them grasp a more comprehensive view about how to reuse the exampledifferently and avoid common pitfalls.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/28",
    "Article_PDF": "https://arxiv.org/pdf/1905.12111"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.11830",
    "DOI": "arXiv:1905.11830v2",
    "Article_Title": "A Graph Theoretic Additive Approximation of Optimal Transport",
    "Article_Abstract": "Transportation cost is an attractive similarity measure between probabilitydistributions due to its many useful theoretical properties. However, solvingoptimal transport exactly can be prohibitively expensive. Therefore, there hasbeen significant effort towards the design of scalable approximationalgorithms. Previous combinatorial results [Sharathkumar, Agarwal STOC '12,Agarwal, Sharathkumar STOC '14] have focused primarily on the design ofstrongly polynomial multiplicative approximation algorithms. There has alsobeen an effort to design approximate solutions with additive errors [CuturiNIPS '13, Altschuler et. al NIPS '17, Dvurechensky et al., ICML '18, Quanrud,SOSA '19] within a time bound that is linear in the size of the cost matrix andpolynomial in $C/\u03b4$; here $C$ is the largest value in the cost matrix and$\u03b4$ is the additive error. We present an adaptation of the classical graphalgorithm of Gabow and Tarjan and provide a novel analysis of this algorithmthat bounds its execution time by $O(\\frac{n^2 C}\u03b4+\\frac{nC^2}{\u03b4^2})$. Our algorithm is extremely simple and executes, for anarbitrarily small constant $\\varepsilon$, only $\\lfloor\\frac{2C}{(1-\\varepsilon)\u03b4}\\rfloor + 1$ iterations, where each iterationconsists only of a Dijkstra search followed by a depth-first search. We alsoprovide empirical results that suggest our algorithm significantly outperformsexisting approaches in execution time.",
    "Article_Subject": "Machine Learning (cs.LG); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/28",
    "Article_PDF": "https://arxiv.org/pdf/1905.11830"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.11681",
    "DOI": "arXiv:1905.11681v2",
    "Article_Title": "Validating the Validation: Reanalyzing a large-scale comparison of Deep Learning and Machine Learning models for bioactivity prediction",
    "Article_Abstract": "Machine learning methods may have the potential to significantly acceleratedrug discovery. However, the increasing rate of new methodological approachesbeing published in the literature raises the fundamental question of how modelsshould be benchmarked and validated. We reanalyze the data generated by arecently published large-scale comparison of machine learning models forbioactivity prediction and arrive at a somewhat different conclusion. We showthat the performance of support vector machines is competitive with that ofdeep learning methods. Additionally, using a series of numerical experiments,we question the relevance of area under the receiver operating characteristiccurve as a metric in virtual screening, and instead suggest that area under theprecision-recall curve should be used in conjunction with the receiveroperating characteristic. Our numerical experiments also highlight challengesin estimating the uncertainty in model performance via scaffold-split nestedcross validation.",
    "Article_Subject": "Machine Learning (cs.LG); Chemical Physics (physics.chem-ph); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/28",
    "Article_PDF": "https://arxiv.org/pdf/1905.11681"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.11127",
    "DOI": "arXiv:1905.11127v1",
    "Article_Title": "DockerizeMe: Automatic Inference of Environment Dependencies for Python Code Snippets",
    "Article_Abstract": "Platforms like Stack Overflow and GitHub's gist system promote the sharing ofideas and programming techniques via the distribution of code snippets designedto illustrate particular tasks. Python, a popular and fast-growing programminglanguage, sees heavy use on both sites, with nearly one million questions askedon Stack Overflow and 400 thousand public gists on GitHub. Unfortunately,around 75% of the Python example code shared through these sites cannot bedirectly executed. When run in a clean environment, over 50% of public Pythongists fail due to an import error for a missing library.  We present DockerizeMe, a technique for inferring the dependencies needed toexecute a Python code snippet without import error. DockerizeMe starts withoffline knowledge acquisition of the resources and dependencies for popularPython packages from the Python Package Index (PyPI). It then builds Dockerspecifications using a graph-based inference procedure. Our inference procedureresolves import errors in 892 out of nearly 3,000 gists from the Gistabledataset for which Gistable's baseline approach could not find and install alldependencies.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/27",
    "Article_PDF": "https://arxiv.org/pdf/1905.11127"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.10536",
    "DOI": "arXiv:1905.10536v1",
    "Article_Title": "DeepRec: An Open-source Toolkit for Deep Learning based Recommendation",
    "Article_Abstract": "Deep learning based recommender systems have been extensively explored inrecent years. However, the large number of models proposed each year poses abig challenge for both researchers and practitioners in reproducing the resultsfor further comparisons. Although a portion of papers provides source code,they adopted different programming languages or different deep learningpackages, which also raises the bar in grasping the ideas. To alleviate thisproblem, we released the open source project: \\textbf{DeepRec}. In thistoolkit, we have implemented a number of deep learning based recommendationalgorithms using Python and the widely used deep learning package - Tensorflow.Three major recommendation scenarios: rating prediction, top-N recommendation(item ranking) and sequential recommendation, were considered. Meanwhile,DeepRec maintains good modularity and extensibility to easily incorporate newmodels into the framework. It is distributed under the terms of the GNU GeneralPublic License. The source code is available at github:\\url{https://github.com/cheungdaven/DeepRec}",
    "Article_Subject": "Information Retrieval (cs.IR); Machine Learning (cs.LG)",
    "Article_Date": "2019/05/25",
    "Article_PDF": "https://arxiv.org/pdf/1905.10536"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.09907",
    "DOI": "arXiv:1905.09907v1",
    "Article_Title": "Multi-level Texture Encoding and Representation (MuLTER) based on Deep Neural Networks",
    "Article_Abstract": "In this paper, we propose a multi-level texture encoding and representationnetwork (MuLTER) for texture-related applications. Based on a multi-levelpooling architecture, the MuLTER network simultaneously leverages low- andhigh-level features to maintain both texture details and spatial information.Such a pooling architecture involves few extra parameters and keeps featuredimensions fixed despite of the changes of image sizes. In comparison withstate-of-the-art texture descriptors, the MuLTER network yields higherrecognition accuracy on typical texture datasets such as MINC-2500 andGTOS-mobile with a discriminative and compact representation. In addition, weanalyze the impact of combining features from different levels, which supportsour claim that the fusion of multi-level features efficiently enhancesrecognition performance. Our source code will be published on GitHub(https://github.com/olivesgatech).",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/05/23",
    "Article_PDF": "https://arxiv.org/pdf/1905.09907"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.09717",
    "DOI": "arXiv:1905.09717v2",
    "Article_Title": "Network Pruning via Transformable Architecture Search",
    "Article_Abstract": "Network pruning reduces the computation costs of an over-parameterizednetwork without performance damage. Prevailing pruning algorithms pre-definethe width and depth of the pruned networks, and then transfer parameters fromthe unpruned network to pruned networks. To break the structure limitation ofthe pruned networks, we propose to apply neural architecture search to searchdirectly for a network with flexible channel and layer sizes. The number of thechannels/layers is learned by minimizing the loss of the pruned networks. Thefeature map of the pruned network is an aggregation of K feature map fragments(generated by K networks of different sizes), which are sampled based on theprobability distribution.The loss can be back-propagated not only to thenetwork weights, but also to the parameterized distribution to explicitly tunethe size of the channels/layers. Specifically, we apply channel-wiseinterpolation to keep the feature map with different channel sizes aligned inthe aggregation procedure. The maximum probability for the size in eachdistribution serves as the width and depth of the pruned network, whoseparameters are learned by knowledge transfer, e.g., knowledge distillation,from the original networks. Experiments on CIFAR-10, CIFAR-100 and ImageNetdemonstrate the effectiveness of our new perspective of network pruningcompared to traditional network pruning algorithms. Various searching andknowledge transfer approaches are conducted to show the effectiveness of thetwo components.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/05/23",
    "Article_PDF": "https://arxiv.org/pdf/1905.09717"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.09263",
    "DOI": "arXiv:1905.09263v4",
    "Article_Title": "FastSpeech: Fast, Robust and Controllable Text to Speech",
    "Article_Abstract": "Neural network based end-to-end text to speech (TTS) has significantlyimproved the quality of synthesized speech. Prominent methods (e.g., Tacotron2) usually first generate mel-spectrogram from text, and then synthesize speechfrom mel-spectrogram using vocoder such as WaveNet. Compared with traditionalconcatenative and statistical parametric approaches, neural network basedend-to-end models suffer from slow inference speed, and the synthesized speechis usually not robust (i.e., some words are skipped or repeated) and lack ofcontrollability (voice speed or prosody control). In this work, we propose anovel feed-forward network based on Transformer to generate mel-spectrogram inparallel for TTS. Specifically, we extract attention alignments from anencoder-decoder based teacher model for phoneme duration prediction, which isused by a length regulator to expand the source phoneme sequence to match thelength of target mel-spectrogram sequence for parallel mel-spectrogramgeneration. Experiments on the LJSpeech dataset show that our parallel modelmatches autoregressive models in terms of speech quality, nearly eliminates theproblem of word skipping and repeating in particularly hard cases, and canadjust voice speed smoothly. Most importantly, compared with autoregressiveTransformer TTS, our model speeds up the mel-spectrogram generation by 270x andthe end-to-end speech synthesis by 38x. Therefore, we call our modelFastSpeech. We will release the code on Github. Synthesized speech samples canbe found in https://speechresearch.github.io/fastspeech/.",
    "Article_Subject": "Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "Article_Date": "2019/05/22",
    "Article_PDF": "https://arxiv.org/pdf/1905.09263"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08880",
    "DOI": "arXiv:1905.08880v1",
    "Article_Title": "A Scalable Hybrid Research Paper Recommender System for Microsoft Academic",
    "Article_Abstract": "We present the design and methodology for the large scale hybrid paperrecommender system used by Microsoft Academic. The system providesrecommendations for approximately 160 million English research papers andpatents. Our approach handles incomplete citation information while alsoalleviating the cold-start problem that often affects other recommendersystems. We use the Microsoft Academic Graph (MAG), titles, and availableabstracts of research papers to build a recommendation list for all documents,thereby combining co-citation and content based approaches. Tuning systemparameters also allows for blending and prioritization of each approach which,in turn, allows us to balance paper novelty versus authority in recommendationresults. We evaluate the generated recommendations via a user study of 40participants, with over 2400 recommendation pairs graded and discuss thequality of the results using P@10 and nDCG scores. We see that there is astrong correlation between participant scores and the similarity rankingsproduced by our system but that additional focus needs to be put towardsimproving recommender precision, particularly for content basedrecommendations. The results of the user survey and associated analysis scriptsare made available via GitHub and the recommendations produced by our systemare available as part of the MAG on Azure to facilitate further research andlight up novel research paper recommendation applications.",
    "Article_Subject": "Digital Libraries (cs.DL); Information Retrieval (cs.IR); Machine Learning (cs.LG)",
    "Article_Date": "2019/05/21",
    "Article_PDF": "https://arxiv.org/pdf/1905.08880"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08667",
    "DOI": "arXiv:1905.08667v1",
    "Article_Title": "Legacy Archive for Microwave Background Data Analysis (LAMBDA): An Overview",
    "Article_Abstract": "This is an overview of the data products and other resources availablethrough NASA's LAMBDA site https://lambda.gsfc.nasa.gov/. An up-to-date versionof this document, along with code tools actively maintained and developed byLAMBDA staff, can be found on the LAMBDA GitHub page athttps://github.com/nasa-lambda/lambda_overview. New data products and otherupdates are announced on LAMBDA's twitter account athttps://twitter.com/NASA_LAMBDA. If you have questions or suggestions relatingto LAMBDA, or are interested in joining a LAMBDA advisory group, please contactus using the form here: https://lambda.gsfc.nasa.gov/contact/contact.cfm.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Article_Date": "2019/05/21",
    "Article_PDF": "https://arxiv.org/pdf/1905.08667"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08628",
    "DOI": "arXiv:1905.08628v1",
    "Article_Title": "Constraining the Parameters of High-Dimensional Models with Active Learning",
    "Article_Abstract": "Constraining the parameters of physical models with $>5-10$ parameters is awidespread problem in fields like particle physics and astronomy. In this paperwe show that this problem can be alleviated by the use of active learning. Weillustrate this with examples from high energy physics, a field wherecomputationally expensive simulations and large parameter spaces are common. Weshow that the active learning techniques query-by-committee andquery-by-dropout-committee allow for the identification of model points ininteresting regions of high-dimensional parameter spaces (e.g. around decisionboundaries). This makes it possible to constrain model parameters moreefficiently than is currently done with the most common sampling algorithms.Code implementing active learning can be found on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Instrumentation and Methods for Astrophysics (astro-ph.IM); High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Theory (hep-th)",
    "Article_Date": "2019/05/19",
    "Article_PDF": "https://arxiv.org/pdf/1905.08628"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08094",
    "DOI": "arXiv:1905.08094v1",
    "Article_Title": "Be Your Own Teacher: Improve the Performance of Convolutional Neural Networks via Self Distillation",
    "Article_Abstract": "Convolutional neural networks have been widely deployed in variousapplication scenarios. In order to extend the applications' boundaries to someaccuracy-crucial domains, researchers have been investigating approaches toboost accuracy through either deeper or wider network structures, which bringswith them the exponential increment of the computational and storage cost,delaying the responding time. In this paper, we propose a general trainingframework named self distillation, which notably enhances the performance(accuracy) of convolutional neural networks through shrinking the size of thenetwork rather than aggrandizing it. Different from traditional knowledgedistillation - a knowledge transformation methodology among networks, whichforces student neural networks to approximate the softmax layer outputs ofpre-trained teacher neural networks, the proposed self distillation frameworkdistills knowledge within network itself. The networks are firstly divided intoseveral sections. Then the knowledge in the deeper portion of the networks issqueezed into the shallow ones. Experiments further prove the generalization ofthe proposed self distillation framework: enhancement of accuracy at averagelevel is 2.65%, varying from 0.61% in ResNeXt as minimum to 4.07% in VGG19 asmaximum. In addition, it can also provide flexibility of depth-wise scalableinference on resource-limited edge devices.Our codes will be released on githubsoon.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/17",
    "Article_PDF": "https://arxiv.org/pdf/1905.08094"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.07650",
    "DOI": "arXiv:1905.07650v1",
    "Article_Title": "SAWNet: A Spatially Aware Deep Neural Network for 3D Point Cloud Processing",
    "Article_Abstract": "Deep neural networks have established themselves as the state-of-the-artmethodology in almost all computer vision tasks to date. But their applicationto processing data lying on non-Euclidean domains is still a very active areaof research. One such area is the analysis of point cloud data which poses achallenge due to its lack of order. Many recent techniques have been proposed,spearheaded by the PointNet architecture. These techniques use either global orlocal information from the point clouds to extract a latent representation forthe points, which is then used for the task at hand(classification/segmentation). In our work, we introduce a neural network layerthat combines both global and local information to produce better embeddings ofthese points. We enhance our architecture with residual connections, to passinformation between the layers, which also makes the network easier to train.We achieve state-of-the-art results on the ModelNet40 dataset with ourarchitecture, and our results are also highly competitive with thestate-of-the-art on the ShapeNet part segmentation dataset and the indoor scenesegmentation dataset. We plan to open source our pre-trained models on githubto encourage the research community to test our networks on their data, orsimply use them for benchmarking purposes.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/05/18",
    "Article_PDF": "https://arxiv.org/pdf/1905.07650"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.06280",
    "DOI": "arXiv:1905.06280v1",
    "Article_Title": "Trustee: Full Privacy Preserving Vickrey Auction on top of Ethereum",
    "Article_Abstract": "The wide deployment of tokens for digital assets on top of Ethereum impliesthe need for powerful trading platforms. Vickrey auctions have been known todetermine the real market price of items as bidders are motivated to submittheir own monetary valuations without leaking their information to thecompetitors. Recent constructions have utilized various cryptographic protocolssuch as ZKP and MPC, however, these approaches either are partiallyprivacy-preserving or require complex computations with several rounds. In thispaper, we overcome these limits by presenting Trustee as a Vickrey auction onEthereum which fully preserves bids' privacy at relatively much lower fees.Trustee consists of three components: a front-end smart contract deployed onEthereum, an Intel SGX enclave, and a relay to redirect messages between them.Initially, the enclave generates an Ethereum account and ECDH key-pair.Subsequently, the relay publishes the account's address and ECDH public key onthe smart contract. As a prerequisite, bidders are encouraged to verify theauthenticity and security of Trustee by using the SGX remote attestationservice. To participate in the auction, bidders utilize the ECDH public key toencrypt their bids and submit them to the smart contract. Once the biddinginterval is closed, the relay retrieves the encrypted bids and feeds them tothe enclave that autonomously generates a signed transaction indicating theauction winner. Finally, the relay submits the transaction to the smartcontract which verifies the transaction's authenticity and the parameters'consistency before accepting the claimed auction winner. As part of ourcontributions, we have made a prototype for Trustee available on Github for thecommunity to review and inspect it. Additionally, we analyze the securityfeatures of Trustee and report on the transactions' gas cost incurred onTrustee smart contract.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/05/15",
    "Article_PDF": "https://arxiv.org/pdf/1905.06280"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.04482",
    "DOI": "arXiv:1905.04482v1",
    "Article_Title": "GE852: A Dataset of 852 Game Engines",
    "Article_Abstract": "Game engines provide a platform for developers to build games with aninterface tailored to handle the complexity during game development. To reduceeffort and improve quality of game development, there is a strong need tounderstand and analyze the quality of game engines and their various aspectssuch as API usability, code quality, code reuse and so on. To the best ourknowledge, we are not aware of any dataset that caters to game engines in theliterature. To this end, we present GE852, a dataset of 852 game enginerepositories mined from GitHub in two languages, namely Java and C++. Thedataset contains metadata of all the mined repositories including commits, pullrequests, issues and so on. We believe that our dataset can lay foundation forempirical investigation in the area of game engines.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/11",
    "Article_PDF": "https://arxiv.org/pdf/1905.04482"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.04303",
    "DOI": "arXiv:1905.04303v1",
    "Article_Title": "Using Convolutional Neural Networks to identify Gravitational Lenses in Astronomical images",
    "Article_Abstract": "The Euclid telescope, due for launch in 2021, will perform an imaging andslitless spectroscopy survey over half the sky, to map baryon wiggles and weaklensing. During the survey Euclid is expected to resolve 100,000 stronggravitational lens systems. This is ideal to find rare lens configurations,provided they can be identified reliably and on a reasonable timescale. Forthis reason we have developed a Convolutional Neural Network (CNN) that can beused to identify images containing lensing systems. CNNs have already been usedfor image and digit classification as well as being used in astronomy forstar-galaxy classification. Here our CNN is trained and tested on Euclid-likeand KiDS-like simulations from the Euclid Strong Lensing Group, successfullyclassifying 77% of lenses, with an area under the ROC curve of up to 0.96. OurCNN also attempts to classify the lenses in COSMOS HST F814W-band images. Afterconvolution to the Euclid resolution, we find we can recover most systems thatare identifiable by eye. The Python code is available on Github.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Astrophysics of Galaxies (astro-ph.GA)",
    "Article_Date": "2019/05/10",
    "Article_PDF": "https://arxiv.org/pdf/1905.04303"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.04294",
    "DOI": "arXiv:1905.04294v1",
    "Article_Title": "Fruitbat: A Python Package for Estimating Redshifts of Fast Radio Bursts",
    "Article_Abstract": "Fruitbat is an open source Python 2/3 package for estimating redshifts,energies and the galactic dispersion measure contributions of fast radio bursts(FRBs). Fruitbat combines various dispersion measure (DM) and redshiftrelations with the YMW16 galactic dispersion measure model into a single easyto use API.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); High Energy Astrophysical Phenomena (astro-ph.HE)",
    "Article_Date": "2019/05/10",
    "Article_PDF": "https://arxiv.org/pdf/1905.04294"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.03593",
    "DOI": "arXiv:1905.03593v3",
    "Article_Title": "A Topological Analysis of Communication Channels for Knowledge Sharing in Contemporary GitHub Projects",
    "Article_Abstract": "With over 28 million developers, success of the GitHub collaborative platformis highlighted through an abundance of communication channels amongcontemporary software projects. Knowledge is broken into two forms and itssharing (through communication channels) can be described as externalization orcombination by the SECI model. Such platforms have revolutionized the waydevelopers work, introducing new channels to share knowledge in the form ofpull requests, issues and wikis. It is unclear how these channels capture andshare knowledge. In this research, our goal is to analyze these communicationchannels in GitHub. First, using the SECI model, we are able to map howknowledge is shared through the communication channels. Then in a large-scaletopology analysis of seven library package projects (i.e., involving over 70thousand projects), we extracted insights of the different communicationchannels within GitHub. Using two research questions, we explored the evolutionof the channels and adoption of channels by both popular and unpopular librarypackage projects. Results show that (i) contemporary GitHub Projects tend toadopt multiple communication channels, (ii) communication channels change overtime and (iii) communication channels are used to both capture new knowledge(i.e., externalization) and updating existing knowledge (i.e., combination).",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/09",
    "Article_PDF": "https://arxiv.org/pdf/1905.03593"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.02050",
    "DOI": "arXiv:1905.02050v1",
    "Article_Title": "Analyzing Code Comments to Boost Program Comprehension",
    "Article_Abstract": "We are trying to find source code comments that help programmers understand anontrivial part of source code. One of such examples would be explaining toassign a zero as a way to \"clear\" a buffer. Such comments are invaluable toprogrammers and identifying them correctly would be of great help. Toward thisgoal, we developed a method to discover explanatory code comments in a sourcecode. We first propose eleven distinct categories of code comments. We thendeveloped a decision-tree based classifier that can identify explanatorycomments with 60% precision and 80% recall. We analyzed 2,000 GitHub projectsthat are written in two languages: Java and Python. This task is novel in thatit focuses on a microscopic comment (\"local comment\") within a method orfunction, in contrast to the prior efforts that focused on API- or method-levelcomments. We also investigated how different category of comments is used indifferent projects. Our key finding is that there are two dominant types ofcomments: preconditional and postconditional. Our findings also suggest thatmany English code comments have a certain grammatical structure that areconsistent across different projects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/06",
    "Article_PDF": "https://arxiv.org/pdf/1905.02050"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.02005",
    "DOI": "arXiv:1905.02005v2",
    "Article_Title": "Deep Ordinal Reinforcement Learning",
    "Article_Abstract": "Reinforcement learning usually makes use of numerical rewards, which havenice properties but also come with drawbacks and difficulties. Using rewards onan ordinal scale (ordinal rewards) is an alternative to numerical rewards thathas received more attention in recent years. In this paper, a general approachto adapting reinforcement learning problems to the use of ordinal rewards ispresented and motivated. We show how to convert common reinforcement learningalgorithms to an ordinal variation by the example of Q-learning and introduceOrdinal Deep Q-Networks, which adapt deep reinforcement learning to ordinalrewards. Additionally, we run evaluations on problems provided by the OpenAIGym framework, showing that our ordinal variants exhibit a performance that iscomparable to the numerical variations for a number of problems. We also givefirst evidence that our ordinal variant is able to produce better results forproblems with less engineered and simpler-to-design reward signals.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/06",
    "Article_PDF": "https://arxiv.org/pdf/1905.02005"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.01833",
    "DOI": "arXiv:1905.01833v3",
    "Article_Title": "Characterizing and Detecting CUDA Program Bugs",
    "Article_Abstract": "While CUDA has become a major parallel computing platform and programmingmodel for general-purpose GPU computing, CUDA-induced bug patterns have not yetbeen well explored. In this paper, we conduct the first empirical study toreveal important categories of CUDA program bug patterns based on 319 bugsidentified within 5 popular CUDA projects in GitHub. Our findings demonstratethat CUDA-specific characteristics may cause program bugs such assynchronization bugs that are rather difficult to detect. To efficiently detectsuch synchronization bugs, we establish the first lightweight general CUDA bugdetection framework, namely Simulee, to simulate CUDA program execution byinterpreting the corresponding llvm bytecode and collecting the memory-accessinformation to automatically detect CUDA synchronization bugs. To evaluate theeffectiveness and efficiency of Simulee, we conduct a set of experiments andthe experimental results suggest that Simulee can detect 20 out of the 27studied synchronization bugs and successfully detects 26 previously unknownsynchronization bugs, 10 of which have been confirmed by the developers.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/06",
    "Article_PDF": "https://arxiv.org/pdf/1905.01833"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.00976",
    "DOI": "arXiv:1905.00976v2",
    "Article_Title": "Collaborative Evolutionary Reinforcement Learning",
    "Article_Abstract": "Deep reinforcement learning algorithms have been successfully applied to arange of challenging control tasks. However, these methods typically strugglewith achieving effective exploration and are extremely sensitive to the choiceof hyperparameters. One reason is that most approaches use a noisy version oftheir operating policy to explore - thereby limiting the range of exploration.In this paper, we introduce Collaborative Evolutionary Reinforcement Learning(CERL), a scalable framework that comprises a portfolio of policies thatsimultaneously explore and exploit diverse regions of the solution space. Acollection of learners - typically proven algorithms like TD3 - optimize overvarying time-horizons leading to this diverse portfolio. All learnerscontribute to and use a shared replay buffer to achieve greater sampleefficiency. Computational resources are dynamically distributed to favor thebest learners as a form of online algorithm selection. Neuroevolution bindsthis entire process to generate a single emergent learner that exceeds thecapabilities of any individual learner. Experiments in a range of continuouscontrol benchmarks demonstrate that the emergent learner significantlyoutperforms its composite learners while remaining overall moresample-efficient - notably solving the Mujoco Humanoid benchmark where all ofits composite learners (TD3) fail entirely in isolation.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/02",
    "Article_PDF": "https://arxiv.org/pdf/1905.00976"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.00221",
    "DOI": "arXiv:1905.00221v1",
    "Article_Title": "Concerns about the reliability of publicly available SNe Ia data",
    "Article_Abstract": "I highlight several concerns regarding the consistency of Type Ia supernovadata in the publicly available Pantheon and JLA compilations. The measuredheliocentric redshifts (zhel) of $\\sim$150 SNe Ia as reported in the Pantheoncatalogue are significantly discrepant from those in JLA - with 58 havingdifferences amounting to between 5 and 137 times the quoted measurementuncertainty. The discrepancy seems to have been introduced in the process ofrectifying a previously reported issue. The Pantheon catalogue until veryrecently had the redshifts of all SNe Ia up to z $\\sim$ 0.3 modified under theguise of 'peculiar velocity corrections' - although there is no information onpeculiar velocities at such high redshifts. While this has reportedly beenrectified on Github by removing peculiar velocity corrections for z > 0.08, theimpact of this on the published cosmological analysis of the Pantheon catalogueis not stated. In JLA, the effect of these 'corrections' is to significantlybias the inferred value of $\u03a9_\u039b$ towards higher values, while theequivalent effect on Pantheon cannot be ascertained due to the unavailabilityof the individual components of the covariance matrix in the public domain. Iprovide Jupyter notebooks and URLs in order to allow the reader to ascertainthe veracity of these assertions.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Article_Date": "2019/05/01",
    "Article_PDF": "https://arxiv.org/pdf/1905.00221"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.12903",
    "DOI": "arXiv:1904.12903v1",
    "Article_Title": "Modified Gravity Away from a $\\Lambda$CDM Background",
    "Article_Abstract": "Within the effective field theory approach to cosmic acceleration, thebackground expansion can be specified separately from the gravitationalmodifications. We explore the impact of modified gravity in a backgrounddifferent from a cosmological constant plus cold dark matter ($\u039b$CDM) onthe stability and cosmological observables, including covariance betweengravity and expansion parameters. In No Slip Gravity the more generalbackground allows more gravitational freedom, including both positive andnegative Planck mass running. We examine the effects on cosmic structuregrowth, as well as showing that a viable positive integrated Sachs-Wolfe effectcrosscorrelation easily arises from this modified gravity theory. Using currentdata we constrain parameters with a Monte Carlo analysis, finding a maximumrunning $|\u03b1_M|\\lesssim 0.03$. We provide the modified {\\tt hi\\_class} codepublicly on GitHub, now enabling computation and inclusion of the redshiftspace distortion observable $f\u03c3_8$ as well as the No Slip Gravitymodifications.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); General Relativity and Quantum Cosmology (gr-qc)",
    "Article_Date": "2019/04/29",
    "Article_PDF": "https://arxiv.org/pdf/1904.12903"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.11603",
    "DOI": "arXiv:1904.11603v1",
    "Article_Title": "Bayesian Factor Analysis for Inference on Interactions",
    "Article_Abstract": "This article is motivated by the problem of inference on interactions amongchemical exposures impacting human health outcomes. Chemicals often co-occur inthe environment or in synthetic mixtures and as a result exposure levels can behighly correlated. We propose a latent factor joint model, which includesshared factors in both the predictor and response components while assumingconditional independence. By including a quadratic regression in the latentvariables in the response component, we induce flexible dimension reduction incharacterizing main effects and interactions. We propose a Bayesian approach toinference under this Factor analysis for INteractions (FIN) framework. Throughappropriate modifications of the factor modeling structure, FIN can accommodatehigher order interactions and multivariate outcomes. We provide theory onposterior consistency and the impact of misspecifying the number of factors. Weevaluate the performance using a simulation study and data from the NationalHealth and Nutrition Examination Survey (NHANES). Code is available on GitHub.",
    "Article_Subject": "Methodology (stat.ME); Applications (stat.AP)",
    "Article_Date": "2019/04/25",
    "Article_PDF": "https://arxiv.org/pdf/1904.11603"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.11164",
    "DOI": "arXiv:1904.11164v1",
    "Article_Title": "PHANTOM: Curating GitHub for engineered software projects using time-series clustering",
    "Article_Abstract": "Context: Within the field of Mining Software Repositories, there are numerousmethods employed to filter datasets in order to avoid analysing low-qualityprojects. Unfortunately, the existing filtering methods have not kept up withthe growth of existing data sources, such as GitHub, and researchers often relyon quick and dirty techniques to curate datasets.  Objective: The objective of this study is to develop a method capable offiltering large quantities of software projects in a time-efficient way.  Method: This study follows the Design Science Research (DSR) methodology. Theproposed method, PHANTOM, extracts five measures from Git logs. Each measure istransformed into a time-series, which is represented as a feature vector forclustering using the k-means algorithm.  Results: Using the ground truth from a previous study, PHANTOM was shown tobe able to rediscover the ground truth with up to 0.87 Precision or 0.94Recall, and be able to identify \"well-engineered\" projects with up to 0.87Precision and 0.94 Recall on the validation dataset. PHANTOM downloaded andprocessed the metadata of 1,786,601 GitHub repositories in 21.5 days, which isover 33\\% faster than a similar study, which used a computer cluster of 200nodes.  Conclusions: It is possible to use an unsupervised approach to identifywell-engineering projects. PHANTOM was shown to be competitive compared to theexisting supervised approaches while reducing the hardware requirements by twoorders of magnitude.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/25",
    "Article_PDF": "https://arxiv.org/pdf/1904.11164"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10581",
    "DOI": "arXiv:1904.10581v2",
    "Article_Title": "Quantifying Correlated Truncation Errors in Effective Field Theory",
    "Article_Abstract": "Effective field theories (EFTs) organize the description of complex systemsinto an infinite sequence of decreasing importance. Predictions are made with afinite number of terms, which induces a truncation error that is often leftunquantified. We formalize the notion of EFT convergence and propose a Bayesiantruncation error model for predictions that are correlated across theindependent variables, e.g., energy or scattering angle. Central to ourapproach are Gaussian processes that encode both the naturalness andcorrelation structure of EFT coefficients. Our use of Gaussian processespermits efficient and accurate assessment of credible intervals, allows EFTfits to easily include correlated theory errors, and provides analyticposteriors for physical EFT-related quantities such as the expansion parameter.We demonstrate that model-checking diagnostics---applied to the case ofmultiple curves---are powerful tools for EFT validation. As an example, weassess a set of nucleon-nucleon scattering observables in chiral EFT. In aneffort to be self contained, appendices include thorough derivations of ourstatistical results. Our methods are packaged in Python code, called gsum, thatis available for download on GitHub.",
    "Article_Subject": "Nuclear Theory (nucl-th); High Energy Physics - Phenomenology (hep-ph); Nuclear Experiment (nucl-ex); Data Analysis, Statistics and Probability (physics.data-an)",
    "Article_Date": "2019/04/24",
    "Article_PDF": "https://arxiv.org/pdf/1904.10581"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10464",
    "DOI": "arXiv:1904.10464v1",
    "Article_Title": "$\\mathtt{bimEX}$: A Mathematica package for exact computations in 3$+$1 bimetric relativity",
    "Article_Abstract": "We present $\\mathtt{bimEX}$, a Mathematica package for exact computations in3$+$1 bimetric relativity. It is based on the $\\mathtt{xAct}$ bundle, which canhandle computations involving both abstract tensors and their components. Inthis communication, we refer to the latter case as concrete computations. Thepackage consists of two main parts. The first part involves the abstracttensors, and focuses on how to deal with multiple metrics in $\\mathtt{xAct}$.The second part takes an ansatz for the primary variables in a chart as theinput, and returns the covariant BSSN bimetric equations in components in thatchart. Several functions are implemented to make this process as fast anduser-friendly as possible. The package has been used and tested extensively inspherical symmetry and was the workhorse in obtaining the bimetric covariantBSSN equations and reproducing the bimetric 3$+$1 equations in the sphericalpolar chart.",
    "Article_Subject": "Symbolic Computation (cs.SC); Cosmology and Nongalactic Astrophysics (astro-ph.CO); Mathematical Software (cs.MS); General Relativity and Quantum Cosmology (gr-qc)",
    "Article_Date": "2019/04/23",
    "Article_PDF": "https://arxiv.org/pdf/1904.10464"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10255",
    "DOI": "arXiv:1904.10255v1",
    "Article_Title": "End-to-end Sleep Staging with Raw Single Channel EEG using Deep Residual ConvNets",
    "Article_Abstract": "Humans approximately spend a third of their life sleeping, which makesmonitoring sleep an integral part of well-being. In this paper, a 34-layer deepresidual ConvNet architecture for end-to-end sleep staging is proposed. Thenetwork takes raw single channel electroencephalogram (Fpz-Cz) signal as inputand yields hypnogram annotations for each 30s segments as output. Experimentsare carried out for two different scoring standards (5 and 6 stageclassification) on the expanded PhysioNet Sleep-EDF dataset, which containsmulti-source data from hospital and household polysomnography setups. Theperformance of the proposed network is compared with that of thestate-of-the-art algorithms in patient independent validation tasks. Theexperimental results demonstrate the superiority of the proposed networkcompared to the best existing method, providing a relative improvement inepoch-wise average accuracy of 6.8% and 6.3% on the household data andmulti-source data, respectively. Codes are made publicly available on Github.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/23",
    "Article_PDF": "https://arxiv.org/pdf/1904.10255"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10247",
    "DOI": "arXiv:1904.10247v3",
    "Article_Title": "Free-form Video Inpainting with 3D Gated Convolution and Temporal PatchGAN",
    "Article_Abstract": "Free-form video inpainting is a very challenging task that could be widelyused for video editing such as text removal. Existing patch-based methods couldnot handle non-repetitive structures such as faces, while directly applyingimage-based inpainting models to videos will result in temporal inconsistency(see http://bit.ly/2Fu1n6b ). In this paper, we introduce a deep learn-ingbased free-form video inpainting model, with proposed 3D gated convolutions totackle the uncertainty of free-form masks and a novel Temporal PatchGAN loss toenhance temporal consistency. In addition, we collect videos and design afree-form mask generation algorithm to build the free-form video inpainting(FVI) dataset for training and evaluation of video inpainting models. Wedemonstrate the benefits of these components and experiments on both theFaceForensics and our FVI dataset suggest that our method is superior toexisting ones. Related source code, full-resolution result videos and the FVIdataset could be found on Githubhttps://github.com/amjltc295/Free-Form-Video-Inpainting .",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/04/23",
    "Article_PDF": "https://arxiv.org/pdf/1904.10247"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.09954",
    "DOI": "arXiv:1904.09954v1",
    "Article_Title": "Why Software Projects need Heroes (Lessons Learned from 1100+ Projects)",
    "Article_Abstract": "A \"hero\" project is one where 80% or more of the contributions are made bythe 20% of the developers. In the literature, such projects are deprecatedsince they might cause bottlenecks in development and communication. However,there is little empirical evidence on this matter. Further, recent studies showthat such hero projects are very prevalent. Accordingly, this paper exploresthe effect of having heroes in project, from a code quality perspective. Weidentify the heroes developer communities in 1100+ open source GitHub projects.Based on the analysis, we find that (a) hero projects are majorly all projects;and (b) the commits from \"hero developers\" (who contribute most to the code)result in far fewer bugs than other developers. That is, contrary to theliterature, heroes are standard and very useful part of modern open sourceprojects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/22",
    "Article_PDF": "https://arxiv.org/pdf/1904.09954"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.09416",
    "DOI": "arXiv:1904.09416v2",
    "Article_Title": "An Analysis of 35+ Million Jobs of Travis CI",
    "Article_Abstract": "Travis CI handles automatically thousands of builds every day to, amongstother things, provide valuable feedback to thousands of open-source developers.In this paper, we investigate Travis CI to firstly understand who is using it,and when they start to use it. Secondly, we investigate how the developers useTravis CI and finally, how frequently the developers change the Travis CIconfigurations. We observed during our analysis that the main users of TravisCI are corporate users such as Microsoft. And the programming languages used inTravis CI by those users do not follow the same popularity trend than onGitHub, for example, Python is the most popular language on Travis CI, but itis only the third one on GitHub. We also observe that Travis CI is set up onaverage seven days after the creation of the repository and the jobs are stillmainly used (60%) to run tests. And finally, we observe that 7.34% of thecommits modify the Travis CI configuration. We share the biggest benchmark ofTravis CI jobs (to our knowledge): it contains 35,793,144 jobs from 272,917different GitHub projects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/20",
    "Article_PDF": "https://arxiv.org/pdf/1904.09416"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.09355",
    "DOI": "arXiv:1904.09355v2",
    "Article_Title": "Exoplanet Reflected Light Spectroscopy with PICASO",
    "Article_Abstract": "Here we present the first open-source radiative transfer model for computingthe reflected light of exoplanets at any phase geometry, called PICASO:Planetary Intensity Code for Atmospheric Scattering Observations. This code,written in Python, has heritage from a decades old, well-known Fortran modelused for several studies of planetary objects within the Solar System andbeyond. We have adopted it to include several methodologies for computing bothdirect and diffuse scattering phase functions, and have added several updatesincluding the ability to compute Raman scattering spectral features. Here webenchmark PICASO against two independent codes and discuss the degree to whichthe model is sensitive to a user's specification for various phase functions.Then, we conduct a full information content study of the model across a wideparameter space in temperature, cloud profile, SNR and resolving power.",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP)",
    "Article_Date": "2019/04/19",
    "Article_PDF": "https://arxiv.org/pdf/1904.09355"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.08315",
    "DOI": "arXiv:1904.08315v1",
    "Article_Title": "Multi-Level Mesa",
    "Article_Abstract": "Multi-level Mesa is an extension to support the Python based Agents BasedModel (ABM) library Mesa. Multi-level Mesa provides ABM infrastructure to allowfor the inclusion of complex networks, which have modules (groups) andhierarchies (layers) of agents. This approach allows for users to define andsimulate multi-layered adaptions of complex networks. This study reviews othermulti-level libraries currently in the field, describes the main functions andclasses of the Multi-level Mesa, and describes its implementation and impact innumerous varieties using the seminal ABM - Sugarscape. Multi-level Mesa andSugarscape examples are available on GitHub athttps://github.com/tpike3/multilevel_mesa andhttps://github.com/tpike3/SugarScape.",
    "Article_Subject": "Multiagent Systems (cs.MA)",
    "Article_Date": "2019/03/22",
    "Article_PDF": "https://arxiv.org/pdf/1904.08315"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07577",
    "DOI": "arXiv:1904.07577v1",
    "Article_Title": "ASD-DiagNet: A hybrid learning approach for detection of Autism Spectrum Disorder using fMRI data",
    "Article_Abstract": "Mental disorders such as Autism Spectrum Disorders (ASD) are heterogeneousdisorders that are notoriously difficult to diagnose, especially in children.The current psychiatric diagnostic process is based purely on the behaviouralobservation of symptomology (DSM-5/ICD-10) and may be prone to over-prescribingof drugs due to misdiagnosis. In order to move the field towards morequantitative fashion, we need advanced and scalable machine learninginfrastructure that will allow us to identify reliable biomarkers of mentalhealth disorders. In this paper, we propose a framework called ASD-DiagNet forclassifying subjects with ASD from healthy subjects by using only fMRI data. Wedesigned and implemented a joint learning procedure using an autoencoder and asingle layer perceptron which results in improved quality of extracted featuresand optimized parameters for the model. Further, we designed and implemented adata augmentation strategy, based on linear interpolation on available featurevectors, that allows us to produce synthetic datasets needed for training ofmachine learning models. The proposed approach is evaluated on a public datasetprovided by Autism Brain Imaging Data Exchange including 1035 subjects comingfrom 17 different brain imaging centers. Our machine learning model outperformsother state of the art methods from 13 imaging centers with increase inclassification accuracy up to 20% with maximum accuracy of 80%. The machinelearning technique presented in this paper, in addition to yielding betterquality, gives enormous advantages in terms of execution time (40 minutes vs. 6hours on other methods). The implemented code is available as GPL license onGitHub portal of our lab (https://github.com/pcdslab/ASD-DiagNet).",
    "Article_Subject": "Machine Learning (cs.LG); Image and Video Processing (eess.IV); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/16",
    "Article_PDF": "https://arxiv.org/pdf/1904.07577"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07387",
    "DOI": "arXiv:1904.07387v2",
    "Article_Title": "Predicting Fluid Intelligence of Children using T1-weighted MR Images and a StackNet",
    "Article_Abstract": "In this work, we utilize T1-weighted MR images and StackNet to predict fluidintelligence in adolescents. Our framework includes feature extraction, featurenormalization, feature denoising, feature selection, training a StackNet, andpredicting fluid intelligence. The extracted feature is the distribution ofdifferent brain tissues in different brain parcellation regions. The proposedStackNet consists of three layers and 11 models. Each layer uses thepredictions from all previous layers including the input layer. The proposedStackNet is tested on a public benchmark Adolescent Brain Cognitive DevelopmentNeurocognitive Prediction Challenge 2019 and achieves a mean squared error of82.42 on the combined training and validation set with 10-foldcross-validation. In addition, the proposed StackNet also achieves a meansquared error of 94.25 on the testing data. The source code is available onGitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/16",
    "Article_PDF": "https://arxiv.org/pdf/1904.07387"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07197",
    "DOI": "arXiv:1904.07197v1",
    "Article_Title": "Identification of Parameters for Large-scale Models in Systems Biology",
    "Article_Abstract": "Inverse problem for the identification of the parameters for large-scalesystems of nonlinear ordinary differential equations (ODEs) arising in systemsbiology is analyzed. In a recent paper in \\textit{Mathematical Biosciences,305(2018), 133-145}, the authors implemented the numerical method suggested byone of the authors in \\textit{J. Optim. Theory Appl., 85, 3(1995), 509-526} foridentification of parameters in moderate scale models of systems biology. Thismethod combines Pontryagin optimization or Bellman's quasilinearization withsensitivity analysis and Tikhonov regularization. We suggest modification ofthe method by embedding a method of staggered corrector for sensitivityanalysis and by enhancing multi-objective optimization which enablesapplication of the method to large-scale models with practicallynon-identifiable parameters based on multiple data sets, possibly with partialand noisy measurements. We apply the modified method to a benchmark model of athree-step pathway modeled by 8 nonlinear ODEs with 36 unknown parameters andtwo control input parameters. The numerical results demonstrate geometricconvergence with a minimum of five data sets and with minimum measurements perdata set. Software package \\textit{qlopt} is developed and posted in GitHub.MATLAB package AMIGO2 is used to demonstrate advantage of \\textit{qlopt} overmost popular methods/software such as \\textit{lsqnonlin}, \\textit{fmincon} and\\textit{nl2sol}.",
    "Article_Subject": "Quantitative Methods (q-bio.QM); Numerical Analysis (math.NA)",
    "Article_Date": "2019/04/15",
    "Article_PDF": "https://arxiv.org/pdf/1904.07197"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07088",
    "DOI": "arXiv:1904.07088v1",
    "Article_Title": "P4-MACsec: Dynamic Topology Monitoring and Data Layer Protection with MACsec in P4-SDN",
    "Article_Abstract": "We propose P4-MACsec to protect network links between P4 switches throughautomated deployment of MACsec, a widespread IEEE standard for securing Layer 2infrastructures. It is supported by switches and routers from majormanufacturers and has only little performance limitations compared to VPNtechnologies such as IPsec. P4-MACsec introduces a data plane implementation ofMACsec including AES-GCM encryption and decryption directly on P4 switches.P4-MACsec features a two-tier control plane structure where local controllersrunning on the P4 switches interact with a central controller. We propose anovel secure link discovery mechanism that leverages protected LLDP frames andthe two-tier control plane structure for secure and efficient management of aglobal link map. Automated deployment of MACsec creates secure channel,generates keying material, and configures the P4 switches for each detectedlink between two P4 switches. It detects link changes and performs rekeying toprovide a secure, configuration-free operation of MACsec. In this paper, wereview the technological background of P4-MACsec and explain its architecture.To demonstrate the feasibility of P4-MACsec, we implement it on the BMv2 P4software switch and validate the prototype through experiments. We evaluate itsperformance through experiments that focus on TCP throughput and round-triptime. We publish the prototype and experiment setups on Github.",
    "Article_Subject": "Networking and Internet Architecture (cs.NI)",
    "Article_Date": "2019/04/15",
    "Article_PDF": "https://arxiv.org/pdf/1904.07088"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.05257",
    "DOI": "arXiv:1904.05257v1",
    "Article_Title": "Instance Segmentation of Biological Images Using Harmonic Embeddings",
    "Article_Abstract": "We present a new instance segmentation approach tailored to biologicalimages, where instances may correspond to individual cells, organisms or plantparts. Unlike instance segmentation for user photographs or road scenes, inbiological data object instances may be particularly densely packed, theappearance variation may be particularly low, the processing power may berestricted, while, on the other hand, the variability of sizes of individualinstances may be limited. These peculiarities are successfully addressed andexploited by the proposed approach.  Our approach describes each object instance using an expectation of a limitednumber of sine waves with frequencies and phases adjusted to particular objectsizes and densities. At train time, a fully-convolutional network is learned topredict the object embeddings at each pixel using a simple pixelwise regressionloss, while at test time the instances are recovered using clustering in theembeddings space. In the experiments, we show that our approach outperformsprevious embedding-based instance segmentation approaches on a number ofbiological datasets, achieving state-of-the-art on a popular CVPPP benchmark.Notably, this excellent performance is combined with computational efficiencythat is needed for deployment to domain specialists.  The source code is publicly available at Github:https://github.com/kulikovv/harmonic",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/04/10",
    "Article_PDF": "https://arxiv.org/pdf/1904.05257"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.03801",
    "DOI": "arXiv:1904.03801v1",
    "Article_Title": "pdbmine: A Node.js API for the RCSB Protein Data Bank (PDB)",
    "Article_Abstract": "Summary: The advent of Web-based tools that assist in the analysis andvisualization of macromolecules require application programming interfaces(APIs) designed for modern web frameworks. To this end, we have developed aNode.js module pdbmine that allows any user to generate faster data-requestqueries to the RCSB Protein Data Bank (PDB). This JavaScript API acts as alayer over the XML-based RCSB PDB RESTful API. The relatively simple nature ofthe function calls within this module allows the user to easily implement andintegrate pdbmine into larger Node.js web applications.  Availability: This module can be installed via the Node Package Manager (NPM)at https://www.npmjs.com/package/pdbmine/, and is hosted on GitHub under theopen-source MIT license at https://github.com/nnj1/pdbmine/. Relevantdocumentation is detailed at https://nnj1.github.io/pdbmine/",
    "Article_Subject": "Genomics (q-bio.GN)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.03801"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.02724",
    "DOI": "arXiv:1904.02724v1",
    "Article_Title": "Bounties in Open Source Development on GitHub: A Case Study of Bountysource Bounties",
    "Article_Abstract": "Due to the voluntary nature of open source software, it can be hard to find adeveloper to work on a particular task. For example, some issue reports may betoo cumbersome and unexciting for someone to volunteer to do them, yet theseissue reports may be of high priority to the success of a project. To providean incentive for implementing such issue reports, one can propose a monetaryreward, i.e., a bounty, to the developer who completes that particular task. Inthis paper, we study bounties in open source projects on GitHub to betterunderstand how bounties can be leveraged to evolve such projects in terms ofaddressing issue reports. We investigated 5,445 bounties for GitHub projects.These bounties were proposed through the Bountysource platform with a totalbounty value of $406,425. We find that 1) in general, the timing of proposingbounties and the bounty-usage frequency are the most important factors thatimpact the likelihood of an issue being addressed. More specifically, issuereports are more likely to be addressed if they are for projects in whichbounties are used more frequently and if they are proposed earlier. 2) Thebounty value that an issue report has is the most important factor that impactsthe issue-addressing likelihood in the projects in which no bounties were usedbefore. Backers in such projects proposed higher bounty values to get issuesaddressed. 3) There is a risk of wasting money for backers who invest money onlong-standing issue reports.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/04",
    "Article_PDF": "https://arxiv.org/pdf/1904.02724"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.02414",
    "DOI": "arXiv:1904.02414v1",
    "Article_Title": "\"Won't We Fix this Issue?\" Qualitative Characterization and Automated Identification of Wontfix Issues on GitHub",
    "Article_Abstract": "Addressing users requests in the form of bug reports and Github issuesrepresents a crucial task of any successful software project. However,user-submitted issue reports tend to widely differ in their quality, anddevelopers spend a considerable amount of time handling these reports.Moreover, an inefficient prioritization of requested changes could have anegative impact on the developers' workloads. By collecting a dataset of around6,000 issues from the history of 323 GitHub projects, we observe thatdevelopers spend a long time (i.e., about five months, on average) beforelabeling an issue as a wontfix. For this reason, in this paper, we empiricallyinvestigate the nature of wontfix issues, by manually analyzing a sample of 800issues of this kind, extracted from heterogeneous projects. We explore thecommon reasons behind a \"wontfix decision\", the main characteristics of wontfixissues and the potential factors that could be connected with the time to closethem. Furthermore, we experiment approaches for just-in-time prediction ofwontfix issues using machine learning techniques to analyze the titles anddescriptions of reported issues. Our investigation shed some light on thewontfix issues' characteristics, as well as the potential factors that mayaffect the time required to make a \"wontfix decision\". Our results alsodemonstrate that it is possible to predict whether an issue will be closed as awontfix with average values of precision, recall, and F-measure close to 99%,confirming the practical usefulness of the proposed approach for improving theissue management practices on GitHub.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/04",
    "Article_PDF": "https://arxiv.org/pdf/1904.02414"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.01754",
    "DOI": "arXiv:1904.01754v1",
    "Article_Title": "Styler: Learning Formatting Conventions to Repair Checkstyle Errors",
    "Article_Abstract": "Formatting coding conventions play an important role on code readability. Inthis paper, we present Styler, an automatic repair tool dedicated to fixformatting-related errors raised by Checkstyle, a highly configurable formatchecker for Java. To fix formatting errors in a given project, Styler learnsfixes based on the Checkstyle ruleset defined in the project and predictsrepairs for the current errors using machine learning. In an empiricalevaluation, we found that Styler repaired 24% of 497 real Checkstyle errorsmined from five GitHub projects. Moreover, in a comparison of Styler with thestate-of-the-art machine learning code formatters Naturalize and CodeBuff, wefound that Styler is the tool that fixes more real Checkstyle errors and alsogenerates smaller repairs. Finally, we conclude that Styler is promising to beused in IDEs and in a Continuous Integration environment to repair Checkstyleerrors.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.01754"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.01740",
    "DOI": "arXiv:1904.01740v2",
    "Article_Title": "FaceQnet: Quality Assessment for Face Recognition based on Deep Learning",
    "Article_Abstract": "In this paper we develop a Quality Assessment approach for face recognitionbased on deep learning. The method consists of a Convolutional Neural Network,FaceQnet, that is used to predict the suitability of a specific input image forface recognition purposes. The training of FaceQnet is done using the VGGFace2database. We employ the BioLab-ICAO framework for labeling the VGGFace2 imageswith quality information related to their ICAO compliance level. Thegroundtruth quality labels are obtained using FaceNet to generate comparisonscores. We employ the groundtruth data to fine-tune a ResNet-based CNN, makingit capable of returning a numerical quality measure for each input image.Finally, we verify if the FaceQnet scores are suitable to predict the expectedperformance when employing a specific image for face recognition with a COTSface recognition system. Several conclusions can be drawn from this work, mostnotably: 1) we managed to employ an existing ICAO compliance framework and apretrained CNN to automatically label data with quality information, 2) wetrained FaceQnet for quality estimation by fine-tuning a pre-trained facerecognition network (ResNet-50), and 3) we have shown that the predictions fromFaceQnet are highly correlated with the face recognition accuracy of astate-of-the-art commercial system not used during development. FaceQnet ispublicly available in GitHub.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.01740"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.01738",
    "DOI": "arXiv:1904.01738v3",
    "Article_Title": "Adinkra Height Yielding Matrix Numbers: Eigenvalue Equivalence Classes for Minimal Four-Color Adinkras",
    "Article_Abstract": "An adinkra is a graph-theoretic representation of spacetime supersymmetry.Minimal four-color valise adinkras have been extensively studied due to theirrelations to minimal 4D, $\\cal N$ = 1 supermultiplets. Valise adinkras,although an important subclass, do not encode all the information present whena 4D supermultiplet is reduced to 1D. Eigenvalue equivalence classes for valiseadinkra matrices exist, known as $\u03c7_{\\rm o}$ equivalence classes, wherevalise adinkras within the same $\u03c7_{\\rm o}$ equivalence class are isomorphicin the sense that adinkras within a $\u03c7_{\\rm o}$-equivalence class can betransformed into each other via field redefinitions of the nodes. We extendthis to non-valise adinkras, via Python code, providing a complete eigenvalueclassification of \"node-lifting\" for all 36,864 valise adinkras associated withthe Coxeter group $BC{}_4$. We term the eigenvalues associated with thesenode-lifted adinkras Height Yielding Matrix Numbers (HYMNs) and introduce HYMNequivalence classes. These findings have been summarized in a $Mathematica$notebook that can found at the HEPTHools Data Repository(https://hepthools.github.io/Data/) on GitHub.",
    "Article_Subject": "High Energy Physics - Theory (hep-th); Representation Theory (math.RT)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.01738"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.00935",
    "DOI": "arXiv:1904.00935v1",
    "Article_Title": "STYLE-ANALYZER: fixing code style inconsistencies with interpretable unsupervised algorithms",
    "Article_Abstract": "Source code reviews are manual, time-consuming, and expensive. Humaninvolvement should be focused on analyzing the most relevant aspects of theprogram, such as logic and maintainability, rather than amending style, syntax,or formatting defects. Some tools with linting capabilities can format codeautomatically and report various stylistic violations for supported programminglanguages. They are based on rules written by domain experts, hence, theirconfiguration is often tedious, and it is impractical for the given set ofrules to cover all possible corner cases. Some machine learning-based solutionsexist, but they remain uninterpretable black boxes. This paper introducesSTYLE-ANALYZER, a new open source tool to automatically fix code formattingviolations using the decision tree forest model which adapts to each codebaseand is fully unsupervised. STYLE-ANALYZER is built on top of our novel assistedcode review framework, Lookout. It accurately mines the formatting style ofeach analyzed Git repository and expresses the found format patterns withcompact human-readable rules. STYLE-ANALYZER can then suggest styleinconsistency fixes in the form of code review comments. We evaluate the outputquality and practical relevance of STYLE-ANALYZER by demonstrating that it canreproduce the original style with high precision, measured on 19 popularJavaScript projects, and by showing that it yields promising results in fixingreal style mistakes. STYLE-ANALYZER includes a web application to visualize howthe rules are triggered. We release STYLE-ANALYZER as a reusable and extendableopen source software package on GitHub for the benefit of the community.",
    "Article_Subject": "Machine Learning (cs.LG); Software Engineering (cs.SE); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/01",
    "Article_PDF": "https://arxiv.org/pdf/1904.00935"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.00243",
    "DOI": "arXiv:1904.00243v3",
    "Article_Title": "Symmetry-Based Disentangled Representation Learning requires Interaction with Environments",
    "Article_Abstract": "Finding a generally accepted formal definition of a disentangledrepresentation in the context of an agent behaving in an environment is animportant challenge towards the construction of data-efficient autonomousagents. Higgins et al. recently proposed Symmetry-Based DisentangledRepresentation Learning, a definition based on a characterization of symmetriesin the environment using group theory. We build on their work and makeobservations, theoretical and empirical, that lead us to argue thatSymmetry-Based Disentangled Representation Learning cannot only be based onstatic observations: agents should interact with the environment to discoverits symmetries. Our experiments can be reproduced in Colab and the code isavailable on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/30",
    "Article_PDF": "https://arxiv.org/pdf/1904.00243"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.12180",
    "DOI": "arXiv:1903.12180v1",
    "Article_Title": "ACRONYM: Acronym CReatiON for You and Me",
    "Article_Abstract": "Each year, countless hours of productive research time is spent brainstormingcreative acronyms for surveys, simulations, codes, and conferences. We presentACRONYM, a command-line program developed specifically to assist astronomers inidentifying the best acronyms for ongoing projects. The code returns allapproximately-English-language words that appear within an input string oftext, regardless of whether the letters occur at the beginning of the componentwords (in true astronomer fashion).",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/03/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.12180"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.12112",
    "DOI": "arXiv:1903.12112v2",
    "Article_Title": "Merging Combinatorial Design and Optimization: the Oberwolfach Problem",
    "Article_Abstract": "The Oberwolfach Problem $OP(F)$, posed by Gerhard Ringel in 1967, is aparadigmatic Combinatorial Design problem asking whether the complete graph$K_v$ decomposes into edge-disjoint copies of a $2$-regular graph $F$ of order$v$. In Combinatorial Design Theory, so-called difference methods represent awell-known solution technique and construct solutions in infinitely many casesexploiting symmetric and balanced structures. This approach reduces the problemto finding a well-structured $2$-factor which allows us to build solutions thatwe call $1$- or $2$-rotational according to their symmetries. We tackle $OP$ bymodeling difference methods with Optimization tools, specifically ConstraintProgramming ($CP$) and Integer Programming ($IP$), and correspondingly solveinstances with up to $v=120$ within $60s$. In particular, we model the$2$-rotational method by solving in cascade two subproblems, namely the binaryand group labeling, respectively. A polynomial-time algorithm solves the binarylabeling, while $CP$ tackles the group labeling. Furthermore, we providenecessary conditions for the existence of some $1$-rotational solutions whichstem from computational results. This paper shows thereby that both theoreticaland empirical results may arise from the interaction between CombinatorialDesign Theory and Operation Research.",
    "Article_Subject": "Combinatorics (math.CO)",
    "Article_Date": "2019/03/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.12112"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.11914",
    "DOI": "arXiv:1903.11914v3",
    "Article_Title": "Improving convergence of volume penalized fluid-solid interactions",
    "Article_Abstract": "Boundary conditions on arbitrary geometries are a common issue in simulatingpartial differential equations. The conventional approach is to discretize on agrid conforming to the geometry. However grid construction is challenging, andthis difficulty is compounded for evolving domains. Several methods insteadaugment the equations themselves to implicitly enforce the boundary conditions.This paper examines the Volume Penalty Method, which approximates Dirichletboundary conditions in the Navier Stokes equations with rapid linear damping(non-dimensional time scale $\u03b7$) inside the object. This technique is provento converge to the true solution, and also leads to simple volume-integralforce and torque calculations. Unfortunately, previous analysis showedconvergence of only $\\mathcal{O}(\u03b7^{1/2})$. We analyze the source of thiserror using matched asymptotic expansions and show that it stems from adisplacement length, proportional to a Reynolds number Re dependent boundarylayer of size $\\mathcal{O}(\u03b7^{1/2}\\text{Re}^{-1/2})$. The relative size ofthe displacement length and damping time scale lead to the emergence ofmultiple asymptotic regimes. The key finding is that there is a simplecorrection that can be efficiently calculated to eliminate the displacementlength and promote the accuracy to $\\mathcal{O}(\u03b7)$. This improvement alsoextends to the force and torque calculations. We demonstrate these findings in1D planar Poiseuille flow, 2D steady flow past a viscous stagnation point, and2D unsteady flow past a rotating cylinder, and finally show that Richardsonextrapolation can be used with our correction to further improve convergence to$\\mathcal{O}(\u03b7^{2})$.",
    "Article_Subject": "Numerical Analysis (math.NA)",
    "Article_Date": "2019/03/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.11914"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.10729",
    "DOI": "arXiv:1903.10729v3",
    "Article_Title": "WGANSing: A Multi-Voice Singing Voice Synthesizer Based on the Wasserstein-GAN",
    "Article_Abstract": "We present a deep neural network based singing voice synthesizer, inspired bythe Deep Convolutions Generative Adversarial Networks (DCGAN) architecture andoptimized using the Wasserstein-GAN algorithm. We use vocoder parameters foracoustic modelling, to separate the influence of pitch and timbre. Thisfacilitates the modelling of the large variability of pitch in the singingvoice. Our network takes a block of consecutive frame-wise linguistic andfundamental frequency features, along with global singer identity as input andoutputs vocoder features, corresponding to the block of features. Thisblock-wise approach, along with the training methodology allows us to modeltemporal dependencies within the features of the input block. For inference,sequential blocks are concatenated using an overlap-add procedure. We show thatthe performance of our model is competitive with regards to thestate-of-the-art and the original sample using objective metrics and asubjective listening test. We also present examples of the synthesis on asupplementary website and the source code via GitHub.",
    "Article_Subject": "Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "Article_Date": "2019/03/26",
    "Article_PDF": "https://arxiv.org/pdf/1903.10729"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.10326",
    "DOI": "arXiv:1903.10326v1",
    "Article_Title": "topFiberM: Scalable and Efficient Boolean Matrix Factorization",
    "Article_Abstract": "Matrix Factorization has many applications such as clustering. When thematrix is Boolean it is favorable to have Boolean factors too. This will savethe efforts of quantizing the reconstructed data back, which usually is doneusing arbitrary thresholds. Here we introduce topFiberM a Boolean matrixfactorization algorithm. topFiberM chooses in a greedy way the fibers (rows orcolumns) to represent the entire matrix. Fibers are extended to rectanglesaccording to a threshold on precision. The search for these \"top fibers\" cancontinue beyond the required rank and according to an optional parameter thatdefines the limit for this search. A factor with a better gain replaces thefactor with minimum gain in \"top fibers\". We compared topFiberM to thestate-of-the-art methods, it achieved better quality for the set of datasetsusually used in literature. We also applied our algorithm to linked-data toshow its scalability. topFiberM was in average 128 times faster than the wellknown Asso method when applied to a set of matrices representing a realmultigraph although Asso is implemented in C and topFiberM is implemented in Rwhich is generally slower than C. topFiberM is publicly available from Github(https://github.com/dice-group/BMF).",
    "Article_Subject": "Data Structures and Algorithms (cs.DS)",
    "Article_Date": "2019/03/06",
    "Article_PDF": "https://arxiv.org/pdf/1903.10326"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08718",
    "DOI": "arXiv:1903.08718v1",
    "Article_Title": "CRAFT: A multifunction online platform for speech prosody visualisation",
    "Article_Abstract": "There are many research tools which are also used for teaching the acousticphonetics of speech rhythm and speech melody. But they were notpurpose-designed for teaching-learning situations, and some have a steeplearning curve. CRAFT (Creation and Recovery of Amplitude and Frequency Tracks)is custom-designed as a novel flexible online tool for visualisation andcritical comparison of functions and transforms, with implementations of theReaper, RAPT, PyRapt, YAAPT, YIN and PySWIPE F0 estimators, three Praatconfigurations, and two purpose-built estimators, PyAMDF, S0FT. Visualisationsof amplitude and frequency envelope spectra, spectral edge detection of rhythmzones, and a parametrised spectrogram are included. A selection of audio clipsfrom tone and intonation languages is provided for demonstration purposes. Themain advantages of online tools are consistency (users have the same versionand the same data selection), interoperability over different platforms, andease of maintenance. The code is available on GitHub.",
    "Article_Subject": "Sound (cs.SD); Computation and Language (cs.CL)",
    "Article_Date": "2019/03/18",
    "Article_PDF": "https://arxiv.org/pdf/1903.08718"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08621",
    "DOI": "arXiv:1903.08621v1",
    "Article_Title": "Column2Vec: Structural Understanding via Distributed Representations of Database Schemas",
    "Article_Abstract": "We present Column2Vec, a distributed representation of database columns basedon column metadata. Our distributed representation has several applications.Using known names for groups of columns (i.e., a table name), we train a modelto generate an appropriate name for columns in an unnamed table. We demonstratethe viability of our approach using schema information collected from opensource applications on GitHub.",
    "Article_Subject": "Databases (cs.DB); Machine Learning (cs.LG)",
    "Article_Date": "2019/03/20",
    "Article_PDF": "https://arxiv.org/pdf/1903.08621"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08215",
    "DOI": "arXiv:1903.08215v2",
    "Article_Title": "The Galaxy Cluster 'Pypeline' for X-ray Temperature Maps: ClusterPyXT",
    "Article_Abstract": "ClusterPyXT is a new software pipeline to generate spectral temperature,X-ray surface brightness, pressure, and density maps from X-ray observations ofgalaxy clusters. These data products help elucidate the physics of processesoccurring within clusters of galaxies, including turbulence, shock fronts,nonthermal phenomena, and the overall dynamics of cluster mergers. ClusterPyXTautomates the creation of these data products with minimal user interaction,and allows for rapid analyses of archival data with user defined parameters andthe ability to straightforwardly incorporate additional observations. In thispaper, we describe in detail the use of this code and release it as an opensource Python project on GitHub.",
    "Article_Subject": "High Energy Astrophysical Phenomena (astro-ph.HE); Cosmology and Nongalactic Astrophysics (astro-ph.CO); Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/03/19",
    "Article_PDF": "https://arxiv.org/pdf/1903.08215"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08186",
    "DOI": "arXiv:1903.08186v1",
    "Article_Title": "Spectroscopic Transit Search: a self-calibrating method for detecting planets around bright stars",
    "Article_Abstract": "We search for transiting exoplanets around the star $\u03b2$ Pictoris usinghigh resolution spectroscopy and Doppler imaging that removes the need forstandard star observations. These data were obtained on the VLT with UVESduring the course of an observing campaign throughout 2017 that monitored theHill sphere transit of the exoplanet $\u03b2$ Pictoris b. We utilize lineprofile tomography as a method for the discovery of transiting exoplanets. Bymeasuring the exoplanet distortion of the stellar line profile, we remove theneed for reference star measurements. We demonstrate the method with whitenoise simulations, and then look at the case of $\u03b2$ Pictoris, which is a$\u03b4$ Scuti pulsator. We describe a method to remove the stellar pulsationsand perform a search for any transiting exoplanets in the resultant data set.We inject fake planet transits with varying orbital periods and planet radiiinto the spectra and determine the recovery fraction. In the photon noiselimited case we can recover planets down to a Neptune radius with an $\\sim$80%success rate, using an 8 m telescope with a $R\\sim 100,000$ spectrograph and 20minutes of observations per night. The pulsations of $\u03b2$ Pictoris limit oursensitivity to Jupiter-sized planets, but a pulsation removal algorithmimproves this limit to Saturn-sized planets. We present two planet candidates,but argue that their signals are most likely caused by other phenomena. We havedemonstrated a method for searching for transiting exoplanets that (i) does notrequire ancillary calibration observations, (ii) can work on any star whoserotational broadening can be resolved with a high spectral dispersionspectrograph and (iii) provides the lowest limits so far on the radii oftransiting Jupiter-sized exoplanets around $\u03b2$ Pictoris with orbitalperiods from 15 days to 200 days with >50% coverage.",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/03/19",
    "Article_PDF": "https://arxiv.org/pdf/1903.08186"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08113",
    "DOI": "arXiv:1903.08113v1",
    "Article_Title": "Identifying Experts in Software Libraries and Frameworks among GitHub Users",
    "Article_Abstract": "Software development increasingly depends on libraries and frameworks toincrease productivity and reduce time-to-market. Despite this fact, we stilllack techniques to assess developers expertise in widely popular libraries andframeworks. In this paper, we evaluate the performance of unsupervised (basedon clustering) and supervised machine learning classifiers (Random Forest andSVM) to identify experts in three popular JavaScript libraries: facebook/react,mongodb/node-mongodb, and socketio/socket.io. First, we collect 13 featuresabout developers activity on GitHub projects, including commits on source codefiles that depend on these libraries. We also build a ground truth includingthe expertise of 575 developers on the studied libraries, as self-reported bythem in a survey. Based on our findings, we document the challenges of usingmachine learning classifiers to predict expertise in software libraries, usingfeatures extracted from GitHub. Then, we propose a method to identify libraryexperts based on clustering feature data from GitHub; by triangulating theresults of this method with information available on Linkedin profiles, we showthat it is able to recommend dozens of GitHub users with evidences of beingexperts in the studied JavaScript libraries. We also provide a public datasetwith the expertise of 575 developers on the studied libraries.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/03/19",
    "Article_PDF": "https://arxiv.org/pdf/1903.08113"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.07611",
    "DOI": "arXiv:1903.07611v1",
    "Article_Title": "Total Power Map to Visibilities (TP2VIS): Joint Deconvolution of ALMA 12m, 7m, and Total Power Array Data",
    "Article_Abstract": "We present a new package for joint deconvolution of ALMA 12m, 7m, and TotalPower (TP) data, dubbed ``Total Power Map to Visibilities (TP2VIS)\". Itconverts a TP (single-dish) map into visibilities on the CASA platform, whichcan be input into deconvolvers (e.g., CLEAN) along with 12m and 7mvisibilities. A manual is presented in the Github repository(https://github.com/tp2vis/distribute). Combining data from the different ALMAarrays is a driver for a number of science topics, namely those that probe sizescales of extended and compact structures simultaneously. We test TP2VIS usingmodel images, one with a single Gaussian and another that mimics the internalstructures of giant molecular clouds. The result shows that the better uvcoverage with TP2VIS visibilities helps the deconvolution process andreproduces the model image within errors of only 5% over two orders ofmagnitude in flux.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Earth and Planetary Astrophysics (astro-ph.EP); Astrophysics of Galaxies (astro-ph.GA); Solar and Stellar Astrophysics (astro-ph.SR)",
    "Article_Date": "2019/03/18",
    "Article_PDF": "https://arxiv.org/pdf/1903.07611"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.06768",
    "DOI": "arXiv:1903.06768v2",
    "Article_Title": "Joint Mean-Covariance Estimation via the Horseshoe with an Application in Genomic Data Analysis",
    "Article_Abstract": "Seemingly unrelated regression is a natural framework for regressing multiplecorrelated responses on multiple predictors. The model is very flexible, withmultiple linear regression and covariance selection models being special cases.However, its practical deployment in genomic data analysis under a Bayesianframework is limited due to both statistical and computational challenges. Thestatistical challenge is that one needs to infer both the mean vector and theinverse covariance matrix, a problem inherently more complex than separatelyestimating each. The computational challenge is due to the dimensionality ofthe parameter space that routinely exceeds the sample size. We propose the useof horseshoe priors on both the mean vector and the inverse covariance matrix.This prior has demonstrated excellent performance when estimating a mean vectoror inverse covariance matrix separately. The current work shows theseadvantages are also present when addressing both simultaneously. A fullBayesian treatment is proposed, with a sampling algorithm that is linear in thenumber of predictors. MATLAB code implementing the algorithm is freelyavailable from github at https://github.com/liyf1988/HS_GHS. Extensiveperformance comparisons are provided with both frequentist and Bayesianalternatives, and both estimation and prediction performances are verified on agenomic data set.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/03/15",
    "Article_PDF": "https://arxiv.org/pdf/1903.06768"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.06348",
    "DOI": "arXiv:1903.06348v1",
    "Article_Title": "Automatically Generating Documentation for Lambda Expressions in Java",
    "Article_Abstract": "When lambda expressions were introduced to the Java programming language aspart of the release of Java 8 in 2014, they were the language's first step intofunctional programming. Since lambda expressions are still relatively new, notall developers use or understand them. In this paper, we first present theresults of an empirical study to determine how frequently developers of GitHubrepositories make use of lambda expressions and how they are documented. Wefind that 11% of Java GitHub repositories use lambda expressions, and that only6% of the lambda expressions are accompanied by source code comments. We thenpresent a tool called LambdaDoc which can automatically detect lambdaexpressions in a Java repository and generate natural language documentationfor them. Our evaluation of LambdaDoc with 23 professional developers showsthat they perceive the generated documentation to be complete, concise, andexpressive, while the majority of the documentation produced by ourparticipants without tool support was inadequate. Our contribution builds animportant step towards automatically generating documentation for functionalprogramming constructs in an object-oriented language.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/03/15",
    "Article_PDF": "https://arxiv.org/pdf/1903.06348"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.05277",
    "DOI": "arXiv:1903.05277v1",
    "Article_Title": "Activity-Based Analysis of Open Source Software Contributors: Roles and Dynamics",
    "Article_Abstract": "Contributors to open source software (OSS) communities assume diverse rolesto take different responsibilities. One major limitation of the current OSStools and platforms is that they provide a uniform user interface regardless ofthe activities performed by the various types of contributors. This paperserves as a non-trivial first step towards resolving this challenge bydemonstrating a methodology and establishing knowledge to understand how thecontributors' roles and their dynamics, reflected in the activitiescontributors perform, are exhibited in OSS communities. Based on an analysis ofuser action data from 29 GitHub projects, we extracted six activities thatdistinguished four Active roles and five Supporting roles of OSS contributors,as well as patterns in role changes. Through the lens of the Activity Theory,these findings provided rich design guidelines for OSS tools to support diversecontributor roles.",
    "Article_Subject": "Software Engineering (cs.SE); Human-Computer Interaction (cs.HC)",
    "Article_Date": "2019/03/13",
    "Article_PDF": "https://arxiv.org/pdf/1903.05277"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.05084",
    "DOI": "arXiv:1903.05084v3",
    "Article_Title": "Decay Replay Mining to Predict Next Process Events",
    "Article_Abstract": "In complex processes, various events can happen in different sequences. Theprediction of the next event given an a-priori process state is of importancein such processes. Recent methods have proposed deep learning techniques suchas recurrent neural networks, developed on raw event logs, to predict the nextevent from a process state. However, such deep learning models by themselveslack a clear representation of the process states. At the same time, recentmethods have neglected the time feature of event instances. In this paper, wetake advantage of Petri nets as a powerful tool in modeling complex processbehaviors considering time as an elemental variable. We propose an approachwhich starts from a Petri net process model constructed by a process miningalgorithm. We enhance the Petri net model with time decay functions to createcontinuous process state samples. Finally, we use these samples in combinationwith discrete token movement counters and Petri net markings to train a deeplearning model that predicts the next event. We demonstrate significantperformance improvements and outperform the state-of-the-art methods on ninereal-world benchmark event logs.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/12",
    "Article_PDF": "https://arxiv.org/pdf/1903.05084"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.04042",
    "DOI": "arXiv:1903.04042v1",
    "Article_Title": "Algorithms for an Efficient Tensor Biclustering",
    "Article_Abstract": "Consider a data set collected by (individuals-features) pairs in differenttimes. It can be represented as a tensor of three dimensions (Individuals,features and times). The tensor biclustering problem computes a subset ofindividuals and a subset of features whose signal trajectories over time lie ina low-dimensional subspace, modeling similarity among the signal trajectorieswhile allowing different scalings across different individuals or differentfeatures. This approach are based on spectral decomposition in order to buildthe desired biclusters. We evaluate the quality of the results from eachalgorithms with both synthetic and real data set.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/10",
    "Article_PDF": "https://arxiv.org/pdf/1903.04042"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.03804",
    "DOI": "arXiv:1903.03804v1",
    "Article_Title": "Program Classification Using Gated Graph Attention Neural Network for Online Programming Service",
    "Article_Abstract": "The online programing services, such as Github,TopCoder, and EduCoder, havepromoted a lot of social interactions among the service users. However, theexisting social interactions is rather limited and inefficient due to the rapidincreasing of source-code repositories, which is difficult to explore manually.The emergence of source-code mining provides a promising way to analyze thosesource codes, so that those source codes can be relatively easy to understandand share among those service users. Among all the source-code miningattempts,program classification lays a foundation for various tasks related tosource-code understanding, because it is impossible for a machine to understanda computer program if it cannot classify the program correctly. Althoughnumerous machine learning models, such as the Natural Language Processing (NLP)based models and the Abstract Syntax Tree (AST) based models, have beenproposed to classify computer programs based on their corresponding sourcecodes, the existing works cannot fully characterize the source codes from theperspective of both the syntax and semantic information. To address thisproblem, we proposed a Graph Neural Network (GNN) based model, which integratesdata flow and function call information to the AST,and applies an improved GNNmodel to the integrated graph, so as to achieve the state-of-art programclassification accuracy. The experiment results have shown that the proposedwork can classify programs with accuracy over 97%.",
    "Article_Subject": "Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/03/09",
    "Article_PDF": "https://arxiv.org/pdf/1903.03804"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.03375",
    "DOI": "arXiv:1903.03375v1",
    "Article_Title": "Online division of labour: emergent structures in Open Source Software",
    "Article_Abstract": "The development Open Source Software fundamentally depends on theparticipation and commitment of volunteer developers to progress. Several workshave presented strategies to increase the on-boarding and engagement of newcontributors, but little is known on how these diverse groups of developersself-organise to work together. To understand this, one must consider that, onone hand, platforms like GitHub provide a virtually unlimited developmentframework: any number of actors can potentially join to contribute in adecentralised, distributed, remote, and asynchronous manner. On the other,however, it seems reasonable that some sort of hierarchy and division of labourmust be in place to meet human biological and cognitive limits, and also toachieve some level of efficiency. These latter features (hierarchy and divisionof labour) should translate into recognisable structural arrangements whenprojects are represented as developer-file bipartite networks. In this paper weanalyse a set of popular open source projects from GitHub, placing the accenton three key properties: nestedness, modularity and in-block nestedness -whichtypify the emergence of heterogeneities among contributors, the emergence ofsubgroups of developers working on specific subgroups of files, and a mixtureof the two previous, respectively. These analyses show that indeed projectsevolve into internally organised blocks. Furthermore, the distribution of sizesof such blocks is bounded, connecting our results to the celebrated Dunbarnumber both in off- and on-line environments. Our analyses create a linkbetween bio-cognitive constraints, group formation and online workingenvironments, opening up a rich scenario for future research on (online) workteam assembly.",
    "Article_Subject": "Physics and Society (physics.soc-ph); Computers and Society (cs.CY); Software Engineering (cs.SE)",
    "Article_Date": "2019/03/08",
    "Article_PDF": "https://arxiv.org/pdf/1903.03375"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.02904",
    "DOI": "arXiv:1903.02904v1",
    "Article_Title": "Halin graphs are 3-vertex-colorable except even wheels",
    "Article_Abstract": "A Halin graph is a graph obtained by embedding a tree having no nodes ofdegree two in the plane, and then adding a cycle to join the leaves of the treein such a way that the resulting graph is planar. According to the four colortheorem, Halin graphs are 4-vertex-colorable. On the other hand, they are not2-vertex-colorable because they have triangles. We show that all Halin graphsare 3-vertex-colorable except even wheels. We also show how to find the perfectelimination ordering of a chordal completion for a given Halin graph. Thealgorithms are implemented in Python using the graphtheory package. Generatorsof random Halin graphs (general or cubic) are included. The source code isavailable from the public GitHub repository.",
    "Article_Subject": "Data Structures and Algorithms (cs.DS)",
    "Article_Date": "2019/03/07",
    "Article_PDF": "https://arxiv.org/pdf/1903.02904"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.02779",
    "DOI": "arXiv:1903.02779v4",
    "Article_Title": "Deep neural networks for classifying complex features in diffraction images",
    "Article_Abstract": "Intense short-wavelength pulses from free-electron lasers andhigh-harmonic-generation sources enable diffractive imaging of individualnano-sized objects with a single x-ray laser shot. The enormous data sets withup to several million diffraction patterns represent a severe problem for dataanalysis, due to the high dimensionality of imaging data. Feature recognitionand selection is a crucial step to reduce the dimensionality. Usually,custom-made algorithms are developed at a considerable effort to approximatethe particular features connected to an individual specimen, but facingdifferent experimental conditions, these approaches do not generalize well. Onthe other hand, deep neural networks are the principal instrument for today'srevolution in automated image recognition, a development that has not beenadapted to its full potential for data analysis in science. We recentlypublished in Langbehn et al. (Phys. Rev. Lett. 121, 255301 (2018)) the firstapplication of a deep neural network as a feature extractor for wide-anglediffraction images of helium nanodroplets. Here we present the setup, ourmodifications and the training process of the deep neural network fordiffraction image classification and its systematic benchmarking. We find thatdeep neural networks significantly outperform previous attempts for sorting andclassifying complex diffraction patterns and are a significant improvement forthe much-needed assistance during post-processing of large amounts ofexperimental coherent diffraction imaging data.",
    "Article_Subject": "Data Analysis, Statistics and Probability (physics.data-an); Atomic and Molecular Clusters (physics.atm-clus)",
    "Article_Date": "2019/03/07",
    "Article_PDF": "https://arxiv.org/pdf/1903.02779"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.02557",
    "DOI": "arXiv:1903.02557v3",
    "Article_Title": "DASH: Deep Learning for the Automated Spectral Classification of Supernovae and their Hosts",
    "Article_Abstract": "We present DASH (Deep Automated Supernova and Host classifier), a novelsoftware package that automates the classification of the type, age, redshift,and host galaxy of supernova spectra. DASH makes use of a new approach thatdoes not rely on iterative template matching techniques like all previoussoftware, but instead classifies based on the learned features of eachsupernova's type and age. It has achieved this by employing a deepconvolutional neural network to train a matching algorithm. This approach hasenabled DASH to be orders of magnitude faster than previous tools, being ableto accurately classify hundreds or thousands of objects within seconds. We havetested its performance on four years of data from the Australian Dark EnergySurvey (OzDES). The deep learning models were developed using TensorFlow, andwere trained using over 4000 supernova spectra taken from the CfA SupernovaProgram and the Berkeley SN Ia Program as used in SNID (SupernovaIdentification software, Blondin & Tonry 2007). Unlike template matchingmethods, the trained models are independent of the number of spectra in thetraining data, which allows for DASH's unprecedented speed. We have developedboth a graphical interface for easy visual classification and analysis ofsupernovae, and a Python library for the autonomous and quick classification ofseveral supernova spectra. The speed, accuracy, user-friendliness, andversatility of DASH presents an advancement to existing spectral classificationtools. We have made the code publicly available on GitHub and PyPI (pip installastrodash) to allow for further contributions and development. The packagedocumentation is available at https://astrodash.readthedocs.io.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Article_Date": "2019/03/06",
    "Article_PDF": "https://arxiv.org/pdf/1903.02557"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01742",
    "DOI": "arXiv:1903.01742v2",
    "Article_Title": "SZZ Unleashed: An Open Implementation of the SZZ Algorithm -- Featuring Example Usage in a Study of Just-in-Time Bug Prediction for the Jenkins Project",
    "Article_Abstract": "Numerous empirical software engineering studies rely on detailed informationabout bugs. While issue trackers often contain information about when bugs werefixed, details about when they were introduced to the system are often absent.As a remedy, researchers often rely on the SZZ algorithm as a heuristicapproach to identify bug-introducing software changes. Unfortunately, asreported in a recent systematic literature review, few researchers have madetheir SZZ implementations publicly available. Consequently, there is a riskthat research effort is wasted as new projects based on SZZ output need toinitially reimplement the approach. Furthermore, there is a risk that newlydeveloped (closed source) SZZ implementations have not been properly tested,thus conducting research based on their output might introduce threats tovalidity. We present SZZ Unleashed, an open implementation of the SZZ algorithmfor git repositories. This paper describes our implementation along with ausage example for the Jenkins project, and conclude with an illustrative studyon just-in-time bug prediction. We hope to continue evolving SZZ Unleashed onGitHub, and warmly invite the community to contribute.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/03/05",
    "Article_PDF": "https://arxiv.org/pdf/1903.01742"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01698",
    "DOI": "arXiv:1903.01698v3",
    "Article_Title": "Improving Cross-Domain Chinese Word Segmentation with Word Embeddings",
    "Article_Abstract": "Cross-domain Chinese Word Segmentation (CWS) remains a challenge despiterecent progress in neural-based CWS. The limited amount of annotated data inthe target domain has been the key obstacle to a satisfactory performance. Inthis paper, we propose a semi-supervised word-based approach to improvingcross-domain CWS given a baseline segmenter. Particularly, our model onlydeploys word embeddings trained on raw text in the target domain, discardingcomplex hand-crafted features and domain-specific dictionaries. Innovativesubsampling and negative sampling methods are proposed to derive wordembeddings optimized for CWS. We conduct experiments on five datasets inspecial domains, covering domains in novels, medicine, and patent. Results showthat our model can obviously improve cross-domain CWS, especially in thesegmentation of domain-specific noun entities. The word F-measure increases byover 3.0% on four datasets, outperforming state-of-the-art semi-supervised andunsupervised cross-domain CWS approaches with a large margin. We make our codeand data available on Github.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/03/05",
    "Article_PDF": "https://arxiv.org/pdf/1903.01698"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01555",
    "DOI": "arXiv:1903.01555v1",
    "Article_Title": "An Explorative Study of GitHub Repositories of AI Papers",
    "Article_Abstract": "With the rapid development of AI technologies, thousands of AI papers arebeing published each year. Many of these papers have released sample code tofacilitate follow-up researchers. This paper presents an explorative study ofover 1700 code repositories of AI papers hosted on GitHub. We find that theserepositories are often poorly written, lack of documents, lack of maintenance,and hard to configure the underlying runtime environment. Thus, many coderepositories become inactive and abandoned. Such a situation makes follow-upresearchers hard to reproduce the results or do further research. In addition,these hard-to-reuse code makes a gap between academia and industry. Based onthe findings, we give some recommendations on how to improve the quality ofcode repositories of AI papers.",
    "Article_Subject": "Digital Libraries (cs.DL)",
    "Article_Date": "2019/02/16",
    "Article_PDF": "https://arxiv.org/pdf/1903.01555"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01284",
    "DOI": "arXiv:1903.01284v1",
    "Article_Title": "Relation Extraction Datasets in the Digital Humanities Domain and their Evaluation with Word Embeddings",
    "Article_Abstract": "In this research, we manually create high-quality datasets in the digitalhumanities domain for the evaluation of language models, specifically wordembedding models. The first step comprises the creation of unigram and n-gramdatasets for two fantasy novel book series for two task types each, analogy anddoesn't-match. This is followed by the training of models on the two bookseries with various popular word embedding model types such as word2vec, GloVe,fastText, or LexVec. Finally, we evaluate the suitability of word embeddingmodels for such specific relation extraction tasks in a situation of comparablysmall corpus sizes. In the evaluations, we also investigate and analyzeparticular aspects such as the impact of corpus term frequencies and taskdifficulty on accuracy. The datasets, and the underlying system and wordembedding models are available on github and can be easily extended with newdatasets and tasks, be used to reproduce the presented results, or betransferred to other domains.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/03/04",
    "Article_PDF": "https://arxiv.org/pdf/1903.01284"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.00904",
    "DOI": "arXiv:1903.00904v1",
    "Article_Title": "Self-adversarial Variational Autoencoder with Gaussian Anomaly Prior Distribution for Anomaly Detection",
    "Article_Abstract": "Recently, deep generative models have become increasingly popular inunsupervised anomaly detection. However, deep generative models aim atrecovering the data distribution rather than detecting anomalies. Besides, deepgenerative models have the risk of overfitting training samples, which hasdisastrous effects on anomaly detection performance. To solve the above twoproblems, we propose a Self-adversarial Variational Autoencoder with a Gaussiananomaly prior assumption. We assume that both the anomalous and the normalprior distribution are Gaussian and have overlaps in the latent space.Therefore, a Gaussian transformer net T is trained to synthesize anomalous butnear-normal latent variables. Keeping the original training objective ofVariational Autoencoder, besides, the generator G tries to distinguish betweenthe normal latent variables and the anomalous ones synthesized by T, and theencoder E is trained to discriminate whether the output of G is real. These newobjectives we added not only give both G and E the ability to discriminate butalso introduce additional regularization to prevent overfitting. Compared withthe SOTA baselines, the proposed model achieves significant improvements inextensive experiments. Datasets and our model are available at a Githubrepository.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/03",
    "Article_PDF": "https://arxiv.org/pdf/1903.00904"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.00037",
    "DOI": "arXiv:1903.00037v1",
    "Article_Title": "Distance-Based Independence Screening for Canonical Analysis",
    "Article_Abstract": "This paper introduces a new method named Distance-based IndependenceScreening for Canonical Analysis (DISCA) to reduce dimensions of two randomvectors with arbitrary dimensions. The objective of our method is to identifythe low dimensional linear projections of two random vectors, such that anydimension reduction based on linear projection with lower dimensions willsurely affect some dependent structure -- the removed components are notindependent. The essence of DISCA is to use the distance correlation toeliminate the \"redundant\" dimensions until infeasible. Unlike the existingcanonical analysis methods, DISCA does not require the dimensions of thereduced subspaces of the two random vectors to be equal, nor does it requirecertain distributional assumption on the random vectors. We show that undermild conditions, our approach does undercover the lowest possible lineardependency structures between two random vectors, and our conditions are weakerthan some sufficient linear subspace-based methods. Numerically, DISCA is tosolve a non-convex optimization problem. We formulate it as adifference-of-convex (DC) optimization problem, and then further adopt thealternating direction method of multipliers (ADMM) on the convex step of the DCalgorithms to parallelize/accelerate the computation. Some sufficient linearsubspace-based methods use potentially numerically-intensive bootstrap methodto determine the dimensions of the reduced subspaces in advance; our methodavoids this complexity. In simulations, we present cases that DISCA can solveeffectively, while other methods cannot. In both the simulation studies andreal data cases, when the other state-of-the-art dimension reduction methodsare applicable, we observe that DISCA performs either comparably or better thanmost of them. Codes and an R package can be found in GitHubhttps://github.com/ChuanpingYu/DISCA.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/02/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.00037"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.11108",
    "DOI": "arXiv:1902.11108v2",
    "Article_Title": "Artist Style Transfer Via Quadratic Potential",
    "Article_Abstract": "In this paper we address the problem of artist style transfer where thepainting style of a given artist is applied on a real world photograph. Wetrain our neural networks in adversarial setting via recently introducedquadratic potential divergence for stable learning process. To further improvethe quality of generated artist stylized images we also integrate some of therecently introduced deep learning techniques in our method. To our bestknowledge this is the first attempt towards artist style transfer via quadraticpotential divergence. We provide some stylized image samples in thesupplementary material. The source code for experimentation was written inPyTorch and is available online in my GitHub repository.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/02/14",
    "Article_PDF": "https://arxiv.org/pdf/1902.11108"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.10149",
    "DOI": "arXiv:1902.10149v2",
    "Article_Title": "Primordial power spectrum and cosmology from black-box galaxy surveys",
    "Article_Abstract": "We propose a new, likelihood-free approach to inferring the primordial matterpower spectrum and cosmological parameters from arbitrarily complex forwardmodels of galaxy surveys where all relevant statistics can be determined fromnumerical simulations, i.e. black-boxes. Our approach, which we call simulatorexpansion for likelihood-free inference (SELFI), builds upon approximateBayesian computation using a novel effective likelihood, and upon thelinearisation of black-box models around an expansion point. Consequently, weobtain simple \"filter equations\" for an effective posterior of the primordialpower spectrum, and a straightforward scheme for cosmological parameterinference. We demonstrate that the workload is computationally tractable, fixeda priori, and perfectly parallel. As a proof of concept, we apply our frameworkto a realistic synthetic galaxy survey, with a data model accounting forphysical structure formation and incomplete and noisy galaxy observations. Indoing so, we show that the use of non-linear numerical models allows the galaxypower spectrum to be safely fitted up to at least $k_\\mathrm{max} = 0.5$$h$/Mpc, outperforming state-of-the-art backward-modelling techniques by afactor of $\\sim 5$ in the number of modes used. The result is an unbiasedinference of the primordial matter power spectrum across the entire range ofscales considered, including a high-fidelity reconstruction of baryon acousticoscillations. It translates into an unbiased and robust inference ofcosmological parameters. Our results pave the path towards easy applications oflikelihood-free simulation-based inference in cosmology. We have made our codepySELFI and our data products publicly available athttp://pyselfi.florent-leclercq.eu.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/02/26",
    "Article_PDF": "https://arxiv.org/pdf/1902.10149"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.09386",
    "DOI": "arXiv:1902.09386v1",
    "Article_Title": "SMARTp: A SMART design for non-surgical treatments of chronic periodontitis with spatially-referenced and non-randomly missing skewed outcomes",
    "Article_Abstract": "This paper proposes dynamic treatment regimes for choosing individualizedeffective treatment strategies of chronic periodontal disease. R codes forimplementing the proposed sample size formula are available in GitHub.",
    "Article_Subject": "Applications (stat.AP)",
    "Article_Date": "2019/02/25",
    "Article_PDF": "https://arxiv.org/pdf/1902.09386"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.08702",
    "DOI": "arXiv:1902.08702v1",
    "Article_Title": "pyro: a framework for hydrodynamics explorations and prototyping",
    "Article_Abstract": "pyro is a Python-based simulation framework designed for ease ofimplementation and exploration of hydrodynamics methods. It is built in aobject-oriented fashion, allowing for the reuse of the core components and fastprototyping of new methods.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/02/22",
    "Article_PDF": "https://arxiv.org/pdf/1902.08702"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.08182",
    "DOI": "arXiv:1902.08182v1",
    "Article_Title": "Finding the Needle in a Haystack: Detrending Photometric Timeseries Data of Strictly Periodic Astrophysical Objects",
    "Article_Abstract": "Light curves of astrophysical objects frequently contain strictly periodicsignals. In those cases we can use that property to aid the detrendingalgorithm to fully disentangle an unknown periodic signal and an unknownbaseline signal with no power at that period. The periodic signal is modeled asa discrete probability distribution function (pdf), while the baseline signalis modeled as a residual timeseries. Those two components are disentangled byminimizing the length of the residual timeseries w.r.t. the per-bin pdf fluxes.We demonstrate the use of the algorithm on a synthetic case, on the eclipsingbinary KIC 3953981 and on the eccentric ellipsoidal variable KIC 3547874. Wefurther discuss the parameters and the limitations of the algorithm andspeculate on the two most common use cases: detrending the periodic signal ofinterest and measuring the dependence of instrumental response on controlledinstrumental variables. A more sophisticated version of the algorithm isreleased as open source on github and available via pip.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Solar and Stellar Astrophysics (astro-ph.SR)",
    "Article_Date": "2019/02/21",
    "Article_PDF": "https://arxiv.org/pdf/1902.08182"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.07740",
    "DOI": "arXiv:1902.07740v1",
    "Article_Title": "Nitrogen Oxide Concentrations in Natural Waters on Early Earth",
    "Article_Abstract": "A key challenge in origins-of-life studies is estimating the abundances ofspecies relevant to the chemical pathways proposed to have contributed to theemergence of life on early Earth. Dissolved nitrogen oxide anions(NO$_{X}^{-}$), in particular nitrate (NO$_{3}^{-}$) and nitrite(NO$_{2}^{-}$), have been invoked in diverse origins-of-life chemistry, fromthe oligomerization of RNA to the emergence of protometabolism. Recent work hascalculated the supply of NO$_{X}^{-}$ from the prebiotic atmosphere to theocean, and reported steady-state [NO$_{X}^{-}$] to be high across all plausibleparameter space. These findings rest on the assumption that NO$_{X}^{-}$ isstable in natural waters unless processed at a hydrothermal vent. Here, we showthat NO$_{X}^{-}$ is unstable in the reducing environment of early Earth. Sinksdue to UV photolysis and reactions with reduced iron (Fe$^{2+}$) suppress[NO$_{X}^{-}$] by several orders of magnitude relative to past predictions. ForpH$=6.5-8$ and $T=0-50^\\circ$C, we find that it is most probable thatNO$_{X}^{-}$]$<1~\u03bc$M in the prebiotic ocean. On the other hand, prebioticponds with favorable drainage characteristics may have sustained[NO$_{X}^{-}$]$\\geq 1~\u03bc$M. As on modern Earth, most NO$_{X}^{-}$ on prebioticEarth should have been present as NO$_{3}^{-}$, due to its much greaterstability. These findings inform the kind of prebiotic chemistries that wouldhave been possible on early Earth. We discuss the implications for proposedprebiotic chemistries, and highlight the need for further studies ofNO$_{X}^{-}$ kinetics to reduce the considerable uncertainties in predicting[NO$_{X}^{-}$] on early Earth.",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP)",
    "Article_Date": "2019/02/20",
    "Article_PDF": "https://arxiv.org/pdf/1902.07740"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.07704",
    "DOI": "arXiv:1902.07704v1",
    "Article_Title": "How Do the Open Source Communities Address Usability and UX Issues? An Exploratory Study",
    "Article_Abstract": "Usability and user experience (UX) issues are often not well emphasized andaddressed in open source software (OSS) development. There is an imperativeneed for supporting OSS communities to collaboratively identify, understand,and fix UX design issues in a distributed environment. In this paper, weprovide an initial step towards this effort and report on an exploratory studythat investigated how the OSS communities currently reported, discussed,negotiated, and eventually addressed usability and UX issues. We conductedin-depth qualitative analysis of selected issue tracking threads from three OSSprojects hosted on GitHub. Our findings indicated that discussions aboutusability and UX issues in OSS communities were largely influenced by thepersonal opinions and experiences of the participants. Moreover, thecharacteristics of the community may have greatly affected the focus of suchdiscussion.",
    "Article_Subject": "Human-Computer Interaction (cs.HC); Software Engineering (cs.SE)",
    "Article_Date": "2019/02/20",
    "Article_PDF": "https://arxiv.org/pdf/1902.07704"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.03867",
    "DOI": "arXiv:1910.03867v1",
    "Article_Title": "Loss Surface Sightseeing by Multi-Point Optimization",
    "Article_Abstract": "We present multi-point optimization: an optimization technique that allows totrain several models simultaneously without the need to keep the parameters ofeach one individually. The proposed method is used for a thorough empiricalanalysis of the loss landscape of neural networks. By extensive experiments onFashionMNIST and CIFAR10 datasets we demonstrate two things: 1) loss surface issurprisingly diverse and intricate in terms of landscape patterns it contains,and 2) adding batch normalization makes it more smooth. Source code toreproduce all the reported results is available on GitHub:https://github.com/universome/loss-patterns.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/10/09",
    "Article_PDF": "https://arxiv.org/pdf/1910.03867"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.02513",
    "DOI": "arXiv:1910.02513v1",
    "Article_Title": "Automated Isolation for White-box Test Generation",
    "Article_Abstract": "Context. White-box test generation is a technique used for automaticallyselecting test inputs using only the source or binary code. However, suchtechniques encounter challenges when applying them to complex programs. One ofthe main challenges is handling the dependencies of the unit under test.  Objective. Without proper actions, generated tests cannot cover all parts ofthe source code, or calling the dependencies may cause unexpected side effects(e.g., file system or network access). These issues should be tackled whilemaintaining the advantages of white-box test generation.  Method. In this paper, we present an automated source code transformationapproach tackling the dependency issue for white-box test generation. Thistechnique isolates the test execution by creating a parameterized sandboxwrapped around the transformed unit. We implemented the approach in aready-to-use tool using Microsoft Pex as a test generator, and evaluated it on10 open-source projects from GitHub having more than 38.000 lines of code intotal.  Results. The results from the evaluation indicate that if the lack ofisolation hinders white-box test generation, then our approach is able to help:it increases the code coverage reached by the automatically generated test,while it reduces unwanted side effects. Also, our results act as a uniquebaseline for the test generation performance of Microsoft Pex on open-sourceprojects.  Conclusion. Based on the results, our source code transformations might servewell for alleviating the isolation problem in white-box test generation as itincreases the coverage reached in such situations, while maintaining thepractical applicability of the tests generated on the isolated code.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/10/06",
    "Article_PDF": "https://arxiv.org/pdf/1910.02513"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01750",
    "DOI": "arXiv:1910.01750v2",
    "Article_Title": "PEXO: a global modeling framework for nanosecond timing, microsecond astrometry, and {\\mu}m/s radial velocities",
    "Article_Abstract": "The ability to make independent detections of the signatures of exoplanetswith complementary telescopes and instruments brings a new potential for robustidentification of exoplanets and precision characterization. We introduce PEXO,a package for Precise EXOplanetology to facilitate the efficient modeling oftiming, astrometry, and radial velocity data, which will benefit not onlyexoplanet science but also various astrophysical studies in general. PEXO isgeneral enough to account for binary motion and stellar reflex motions inducedby planetary companions and is precise enough to treat various relativisticeffects both in the solar system and in the target system. We also model thepost-Newtonian barycentric motion for future tests of general relativity inextrasolar systems. We benchmark PEXO with the pulsar timing package TEMPO2 andfind that PEXO produces numerically similar results with timing precision ofabout 1 ns, space-based astrometry to a precision of 1\u03bcas, and radialvelocity of 1 \u03bcm/s and improves on TEMPO2 for decade-long timing data ofnearby targets, due to its consideration of third-order terms of Roemer delay.PEXO is able to avoid the bias introduced by decoupling the target system andthe solar system and to account for the atmospheric effects which set apractical limit for ground-based radial velocities close to 1 cm/s. Consideringthe various caveats in barycentric correction and ancillary data required torealize cm/s modeling, we recommend the preservation of original observationaldata. The PEXO modeling package is available at GitHub(https://github.com/phillippro/pexo).",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM); Solar and Stellar Astrophysics (astro-ph.SR)",
    "Article_Date": "2019/10/03",
    "Article_PDF": "https://arxiv.org/pdf/1910.01750"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01321",
    "DOI": "arXiv:1910.01321v1",
    "Article_Title": "An Empirical Study of C++ Vulnerabilities in Crowd-Sourced Code Examples",
    "Article_Abstract": "Software developers share programming solutions in Q&A sites like StackOverflow. The reuse of crowd-sourced code snippets can facilitate rapidprototyping. However, recent research shows that the shared code snippets maybe of low quality and can even contain vulnerabilities. This paper aims tounderstand the nature and the prevalence of security vulnerabilities incrowd-sourced code examples. To achieve this goal, we investigate securityvulnerabilities in the C++ code snippets shared on Stack Overflow over a periodof 10 years. In collaborative sessions involving multiple human coders, wemanually assessed each code snippet for security vulnerabilities following CWE(Common Weakness Enumeration) guidelines. From the 72,483 reviewed codesnippets used in at least one project hosted on GitHub, we found a total of 69vulnerable code snippets categorized into 29 types. Many of the investigatedcode snippets are still not corrected on Stack Overflow. The 69 vulnerable codesnippets found in Stack Overflow were reused in a total of 2859 GitHubprojects. To help improve the quality of code snippets shared on StackOverflow, we developed a browser extension that allow Stack Overflow users tocheck for vulnerabilities in code snippets when they upload them on theplatform.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/10/03",
    "Article_PDF": "https://arxiv.org/pdf/1910.01321"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01212",
    "DOI": "arXiv:1910.01212v1",
    "Article_Title": "Social Influence and Radicalization: A Social Data Analytics Study",
    "Article_Abstract": "The confluence of technological and societal advances is changing the natureof global terrorism. For example, engagement with Web, social media, and smartdevices has the potential to affect the mental behavior of the individuals andinfluence extremist and criminal behaviors such as Radicalization. In thiscontext, social data analytics (i.e., the discovery, interpretation, andcommunication of meaningful patterns in social data) and influence maximization(i.e., the problem of finding a small subset of nodes in a social network whichcan maximize the propagation of influence) has the potential to become a vitalasset to explore the factors involved in influencing people to participate inextremist activities.  To address this challenge, we study and analyze the recent work done ininfluence maximization and social data analytics from effectiveness, efficiencyand scalability viewpoints. We introduce a social data analytics pipeline,namely iRadical, to enable analysts engage with social data to explore thepotential for online radicalization. In iRadical, we present algorithms toanalyse the social data as well as the user activity patterns to learn howinfluence flows in social networks. We implement iRadical as an extensiblearchitecture that is publicly available on GitHub and present the evaluationresults.",
    "Article_Subject": "Computers and Society (cs.CY); Machine Learning (cs.LG)",
    "Article_Date": "2019/09/04",
    "Article_PDF": "https://arxiv.org/pdf/1910.01212"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.01078",
    "DOI": "arXiv:1910.01078v1",
    "Article_Title": "ROS Rescue : Fault Tolerance System for Robot Operating System",
    "Article_Abstract": "In this chapter we discuss the problem of master failure in ROS1.0 and itsimpact on robotic deployments in the real world. We address this issue in thistutorial chapter where we outline, design and demonstrate a fault tolerantmechanism associated with ROS master failure. Unlike previous solutions whichuse primary backup replication and external checkpointing libraries which areprocess heavy, our mechanism adds a lightweight functionality to the ROS masterto enable it to recover from failure.  We present a modified version of ROS master which is equipped with a loggingmechanism to record the meta information and network state of ROS nodes as wellas a recovery mechanism to go back to the previous state without having toabort or restart all the nodes. We also implement an additional master monitornode responsible for failure detection on the master by polling it for itsavailability. Our code is implemented in python and preliminary tests wereconducted successfully on a variety of land, aerial and underwater robots and atele-operating computer running ROS Kinetic on Ubuntu 16.04. The code ispublicly available under a creative commons license on github athttps://github.com/PushyamiKaveti/fault-tolerant-ros-master",
    "Article_Subject": "Robotics (cs.RO)",
    "Article_Date": "2019/10/02",
    "Article_PDF": "https://arxiv.org/pdf/1910.01078"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00725",
    "DOI": "arXiv:1910.00725v1",
    "Article_Title": "Cosmic Microwave Background Anisotropy numerical solution (CMBAns) I: An introduction to $C_l$ calculation",
    "Article_Abstract": "Cosmological Boltzmann codes are often used by researchers for calculatingthe CMB angular power spectra from different theoretical models, forcosmological parameter estimation, etc. Therefore, the accuracy of a Boltzmanncode is of utmost importance. Different Markov Chain Monte Carlo basedparameter estimation algorithms typically require 10^3 - 10^4 iterations ofBoltzmann code. This makes the time complexity of such codes another criticalfactor. In the last two decades, several Boltzmann packages, such as CMBFAST,CAMB, CMBEasy, CLASS etc., have been developed. In this paper, we present a newcosmological Boltzmann code, CMBAns, that can be used for accurate calculationof the CMB power spectrum. At present, CMBAns is developed for a flatbackground matrix. It is mostly written in the C language. However, we borrowedthe concept of class from C++. This gives researchers the flexibility todevelop their own independent package based on CMBAns, without an in-depthunderstanding of the source code. We also develop multiple stand-alonefacilities which can be directly compiled and run on a given parameter set. Inthis paper, we discuss all the mathematical formulation, approximation schemes,integration methods etc., that are used in CMBAns. The package will be madeavailable through github for public use in the near future.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); Instrumentation and Methods for Astrophysics (astro-ph.IM); General Relativity and Quantum Cosmology (gr-qc)",
    "Article_Date": "2019/10/02",
    "Article_PDF": "https://arxiv.org/pdf/1910.00725"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00536",
    "DOI": "arXiv:1910.00536v1",
    "Article_Title": "Scalable String Reconciliation by Recursive Content-Dependent Shingling",
    "Article_Abstract": "We consider the problem of reconciling similar, but remote, strings withminimum communication complexity. This \"string reconciliation\" problem is afundamental building block for a variety of networking applications, includingthose that maintain large-scale distributed networks and perform remote filesynchronization. We present the novel Recursive Content-Dependent Shingling(RCDS) protocol that is computationally practical for large strings and scaleslinearly with the edit distance between the remote strings. We providecomparisons to the performance of Rsync, one of the most popular filesynchronization tools in active use. Our experiments show that, with minimalengineering, RCDS outperforms the heavily optimized Rsync in reconcilingrelease revisions for about 51% of the 5000 top starred git repositories onGitHub. The improvement is particularly evident for repositories that seefrequent, but small, updates.",
    "Article_Subject": "Information Theory (cs.IT)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00536"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00286",
    "DOI": "arXiv:1910.00286v1",
    "Article_Title": "Ransomware Analysis using Feature Engineering and Deep Neural Networks",
    "Article_Abstract": "Detection and Analysis of a potential malware specifically, used for ransomis a challenging task. Recently, intruders are utilizing advance cryptographictechniques to get hold of digital assets and then demand ransom. It is believedthat generally, the files comprise of some attributes, states, and patternsthat can be recognized by a machine learning technique. This work thus focuseson detection of Ransomware by performing feature engineering, which helps inanalyzing vital attributes and behaviors of the malware. The main contributionof this work is the identification of important and distinct characteristics ofRansomware that can help in detecting them. Finally, based on the selectedfeatures, both conventional machine learning techniques and Transfer Learningbased Deep Convolutional Neural Networks have been used to detect Ransomware.In order to perform feature engineering and analysis, two separate datasets(static and dynamic) were generated. The static dataset has 3646 samples (1700Ransomware and 1946 Goodware). On the other hand, the dynamic dataset comprisedof 3444 samples (1455 Ransomware and 1989 Goodware). Through variousexperiments, it is observed that the Registry changes, API calls, and DLLs arethe most important features for Ransomware detection. Additionally, importantsequences are found with the help of N Gram technique. It is also observed thatin case of Registry Delete operation, if a malicious file tries to deleteregistries, it follows a specific and repeated sequence. However for the benignfile, it doesnt follow any specific sequence or repetition. Similarly, aninteresting observation made through this study is that there is no commonRegistry deleted sequence between malicious and benign file. And thus thisdiscernible fact can be readily exploited for Ransomware detection. Therelevant Python code and dataset are available at github.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00286"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00199",
    "DOI": "arXiv:1910.00199v1",
    "Article_Title": "Underwhelming Generalization Improvements From Controlling Feature Attribution",
    "Article_Abstract": "Overfitting is a common issue in machine learning, which can arise when themodel learns to predict class membership using convenient butspuriously-correlated image features instead of the true image features thatdenote a class. These are typically visualized using saliency maps. In someobject classification tasks such as for medical images, one may have someimages with masks, indicating a region of interest, i.e., which part of theimage contains the most relevant information for the classification. Wedescribe a simple method for taking advantage of such auxiliary labels, bytraining networks to ignore the distracting features which may be extractedoutside of the region of interest, on the training images for which such masksare available. This mask information is only used during training and has animpact on generalization accuracy in a dataset-dependent way. We observe anunderwhelming relationship between controlling saliency maps and improvinggeneralization performance.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00199"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00188",
    "DOI": "arXiv:1910.00188v1",
    "Article_Title": "Beyond Textual Issues: Understanding the Usage and Impact of GitHub Reactions",
    "Article_Abstract": "Recently, GitHub introduced a new social feature, named reactions, which are\"pictorial characters\" similar to emoji symbols widely used nowadays intext-based communications. Particularly, GitHub users can use a pre-defined setof such symbols to react to issues and pull requests. However, little is knownabout the real usage and impact of GitHub reactions. In this paper, we analyzethe reactions provided by developers to more than 2.5 million issues and 9.7million issue comments, in order to answer an extensive list of nine researchquestions about the usage and adoption of reactions. We show that reactions arebeing increasingly used by open source developers. Moreover, we also found thatissues with reactions usually take more time to be handled and have longerdiscussions.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/10/01",
    "Article_PDF": "https://arxiv.org/pdf/1910.00188"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1910.00024",
    "DOI": "arXiv:1910.00024v1",
    "Article_Title": "Neural Canonical Transformation with Symplectic Flows",
    "Article_Abstract": "Canonical transformation plays a fundamental role in simplifying and solvingclassical Hamiltonian systems. We construct flexible and powerful canonicaltransformations as generative models using symplectic neural networks. Themodel transforms physical variables towards a latent representation with anindependent harmonic oscillator Hamiltonian. Correspondingly, the phase spacedensity of the physical system flows towards a factorized Gaussian distributionin the latent space. Since the canonical transformation preserves theHamiltonian evolution, the model captures nonlinear collective modes in thelearned latent representation. We present an efficient implementation ofsymplectic neural coordinate transformations and two ways to train the model.The variational free energy calculation is based on the analytical form ofphysical Hamiltonian. While the phase space density estimation only requiressamples in the coordinate space for separable Hamiltonians. We demonstrateappealing features of neural canonical transformation using toy problemsincluding two-dimensional ring potential and harmonic chain. Finally, we applythe approach to real-world problems such as identifying slow collective modesin alanine dipeptide and conceptual compression of the MNIST dataset.",
    "Article_Subject": "Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG); Computational Physics (physics.comp-ph); Machine Learning (stat.ML)",
    "Article_Date": "2019/09/30",
    "Article_PDF": "https://arxiv.org/pdf/1910.00024"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.13589",
    "DOI": "arXiv:1909.13589v1",
    "Article_Title": "Domain Adaptation for Semantic Segmentation with Maximum Squares Loss",
    "Article_Abstract": "Deep neural networks for semantic segmentation always require a large numberof samples with pixel-level labels, which becomes the major difficulty in theirreal-world applications. To reduce the labeling cost, unsupervised domainadaptation (UDA) approaches are proposed to transfer knowledge from labeledsynthesized datasets to unlabeled real-world datasets. Recently, somesemi-supervised learning methods have been applied to UDA and achievedstate-of-the-art performance. One of the most popular approaches insemi-supervised learning is the entropy minimization method. However, whenapplying the entropy minimization to UDA for semantic segmentation, thegradient of the entropy is biased towards samples that are easy to transfer. Tobalance the gradient of well-classified target samples, we propose the maximumsquares loss. Our maximum squares loss prevents the training process beingdominated by easy-to-transfer samples in the target domain. Besides, weintroduce the image-wise weighting ratio to alleviate the class imbalance inthe unlabeled target domain. Both synthetic-to-real and cross-city adaptationexperiments demonstrate the effectiveness of our proposed approach. The code isreleased at https://github. com/ZJULearning/MaxSquareLoss.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/30",
    "Article_PDF": "https://arxiv.org/pdf/1909.13589"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.13092",
    "DOI": "arXiv:1909.13092v1",
    "Article_Title": "GLA-Net: An Attention Network with Guided Loss for Mismatch Removal",
    "Article_Abstract": "Mismatch removal is a critical prerequisite in many feature-based tasks.Recent attempts cast the mismatch removal task as a binary classificationproblem and solve it through deep learning based methods. In these methods, theimbalance between positive and negative classes is important, which affectsnetwork performance, i.e., Fn-score. To establish the link between Fn-score andloss, we propose to guide the loss with the Fn-score directly. We theoreticallydemonstrate the direct link between our Guided Loss and Fn-score duringtraining. Moreover, we discover that outliers often impair global context inmismatch removal networks. To address this issue, we introduce the attentionmechanism to mismatch removal task and propose a novel Inlier Attention Block(IA Block). To evaluate the effectiveness of our loss and IA Block, we designan end-to-end network for mismatch removal, called GLA-Net \\footnote{Our codewill be available in Github later.}. Experiments have shown that our networkachieves the state-of-the-art performance on benchmark datasets.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/28",
    "Article_PDF": "https://arxiv.org/pdf/1909.13092"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.11977",
    "DOI": "arXiv:1909.11977v1",
    "Article_Title": "Stochastic Weight Matrix-based Regularization Methods for Deep Neural Networks",
    "Article_Abstract": "The aim of this paper is to introduce two widely applicable regularizationmethods based on the direct modification of weight matrices. The first method,Weight Reinitialization, utilizes a simplified Bayesian assumption withpartially resetting a sparse subset of the parameters. The second one, WeightShuffling, introduces an entropy- and weight distribution-invariant non-whitenoise to the parameters. The latter can also be interpreted as an ensembleapproach. The proposed methods are evaluated on benchmark datasets, such asMNIST, CIFAR-10 or the JSB Chorales database, and also on time series modelingtasks. We report gains both regarding performance and entropy of the analyzednetworks. We also made our code available as a GitHub repository(https://github.com/rpatrik96/lod-wmm-2019).",
    "Article_Subject": "Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)",
    "Article_Date": "2019/09/26",
    "Article_PDF": "https://arxiv.org/pdf/1909.11977"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.11811",
    "DOI": "arXiv:1909.11811v1",
    "Article_Title": "A fast, complete, point cloud based loop closure for LiDAR odometry and mapping",
    "Article_Abstract": "This paper presents a loop closure method to correct the long-term drift inLiDAR odometry and mapping (LOAM). Our proposed method computes the 2Dhistogram of keyframes, a local map patch, and uses the normalizedcross-correlation of the 2D histograms as the similarity metric between thecurrent keyframe and those in the map. We show that this method is fast,invariant to rotation, and produces reliable and accurate loop detection. Theproposed method is implemented with careful engineering and integrated into theLOAM algorithm, forming a complete and practical system ready to use. Tobenefit the community by serving a benchmark for loop closure, the entiresystem is made open source on Github",
    "Article_Subject": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/25",
    "Article_PDF": "https://arxiv.org/pdf/1909.11811"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.11544",
    "DOI": "arXiv:1909.11544v1",
    "Article_Title": "PyDEns: a Python Framework for Solving Differential Equations with Neural Networks",
    "Article_Abstract": "Recently, a lot of papers proposed to use neural networks to approximatelysolve partial differential equations (PDEs). Yet, there has been a lack offlexible framework for convenient experimentation. In an attempt to fill thegap, we introduce a PyDEns-module open-sourced on GitHub. Coupled withcapabilities of BatchFlow, open-source framework for convenient andreproducible deep learning, PyDEns-module allows to 1) solve partialdifferential equations from a large family, including heat equation and waveequation 2) easily search for the best neural-network architecture among thezoo, that includes ResNet and DenseNet 3) fully control the process ofmodel-training by testing different point-sampling schemes. With that in mind,our main contribution goes as follows: implementation of a ready-to-use andopen-source numerical solver of PDEs of a novel format, based on neuralnetworks.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/09/25",
    "Article_PDF": "https://arxiv.org/pdf/1909.11544"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.10051",
    "DOI": "arXiv:1909.10051v1",
    "Article_Title": "PyIT2FLS: A New Python Toolkit for Interval Type 2 Fuzzy Logic Systems",
    "Article_Abstract": "Fuzzy logic is an accepted and well-developed approach for constructingverbal models. Fuzzy based methods are getting more popular, while theengineers deal with more daily life tasks. This paper presents a new Pythontoolkit for Interval Type 2 Fuzzy Logic Systems (IT2FLS). Developing softwaretools is an important issue for facilitating the practical use of theoreticalresults. There are limited tools for implementing IT2FLSs in Python. Thedeveloped PyIT2FLS is providing a set of tools for fast and easy modeling offuzzy systems. This paper includes a brief description of how developed toolkitcan be used. Also, three examples are given showing the usage of the developedtoolkit for simulating IT2FLSs. First, a simple rule-based system is developedand it's codes are presented in the paper. The second example is the predictionof the Mackey-Glass chaotic time series using IT2FLS. In this example, theParticle Swarm Optimization (PSO) algorithm is used for determining systemparameters while minimizing the mean square error. In the last example, anIT2FPID is used in a linear time-delay system. The code for the examples areavailable on toolkit's GitHub page: https://github.com/Haghrah/PyIT2FLS. Thesimulations and their results confirm the ability of the developed toolkit tobe used in a wide range of the applications.",
    "Article_Subject": "Systems and Control (eess.SY); Mathematical Software (cs.MS)",
    "Article_Date": "2019/09/22",
    "Article_PDF": "https://arxiv.org/pdf/1909.10051"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.09029",
    "DOI": "arXiv:1909.09029v2",
    "Article_Title": "DIRE: A Neural Approach to Decompiled Identifier Naming",
    "Article_Abstract": "The decompiler is one of the most common tools for examining binaries withoutcorresponding source code. It transforms binaries into high-level code,reversing the compilation process. Decompilers can reconstruct much of theinformation that is lost during the compilation process (e.g., structure andtype information). Unfortunately, they do not reconstruct semanticallymeaningful variable names, which are known to increase code understandability.We propose the Decompiled Identifier Renaming Engine (DIRE), a novelprobabilistic technique for variable name recovery that uses both lexical andstructural information recovered by the decompiler. We also present a techniquefor generating corpora suitable for training and evaluating models ofdecompiled code renaming, which we use to create a corpus of 164,632 uniquex86-64 binaries generated from C projects mined from GitHub. Our results showthat on this corpus DIRE can predict variable names identical to the names inthe original source code up to 74.3% of the time.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/09/19",
    "Article_PDF": "https://arxiv.org/pdf/1909.09029"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.08766",
    "DOI": "arXiv:1909.08766v1",
    "Article_Title": "A High-Fidelity Open Embodied Avatar with Lip Syncing and Expression Capabilities",
    "Article_Abstract": "Embodied avatars as virtual agents have many applications and providebenefits over disembodied agents, allowing non-verbal social and interactionalcues to be leveraged, in a similar manner to how humans interact with eachother. We present an open embodied avatar built upon the Unreal Engine that canbe controlled via a simple python programming interface. The avatar has lipsyncing (phoneme control), head gesture and facial expression (using eitherfacial action units or cardinal emotion categories) capabilities. We releasecode and models to illustrate how the avatar can be controlled like a puppet orused to create a simple conversational agent using public applicationprogramming interfaces (APIs). GITHUB link:https://github.com/danmcduff/AvatarSim",
    "Article_Subject": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)",
    "Article_Date": "2019/09/19",
    "Article_PDF": "https://arxiv.org/pdf/1909.08766"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.06700",
    "DOI": "arXiv:1909.06700v1",
    "Article_Title": "Loam_livox: A fast, robust, high-precision LiDAR odometry and mapping package for LiDARs of small FoV",
    "Article_Abstract": "LiDAR odometry and mapping (LOAM) has been playing an important role inautonomous vehicles, due to its ability to simultaneously localize the robot'spose and build high-precision, high-resolution maps of the surroundingenvironment. This enables autonomous navigation and safe path planning ofautonomous vehicles. In this paper, we present a robust, real-time LOAMalgorithm for LiDARs with small FoV and irregular samplings. By taking efforton both front-end and back-end, we address several fundamental challengesarising from such LiDARs, and achieve better performance in both precision andefficiency compared to existing baselines. To share our findings and to makecontributions to the community, we open source our codes on Github",
    "Article_Subject": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/09/15",
    "Article_PDF": "https://arxiv.org/pdf/1909.06700"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.05983",
    "DOI": "arXiv:1909.05983v1",
    "Article_Title": "Content-Aware Unsupervised Deep Homography Estimation",
    "Article_Abstract": "Robust homography estimation between two images is a fundamental task whichhas been widely applied to various vision applications. Traditional featurebased methods often detect image features and fit a homography according tomatched features with RANSAC outlier removal. However, the quality ofhomography heavily relies on the quality of image features, which are prone toerrors with respect to low light and low texture images. On the other hand,previous deep homography approaches either synthesize images for supervisedlearning or adopt aerial images for unsupervised learning, both ignoring theimportance of depth disparities in homography estimation. Moreover, they treatthe image content equally, including regions of dynamic objects and near-rangeforegrounds, which further decreases the quality of estimation. In this work,to overcome such problems, we propose an unsupervised deep homography methodwith a new architecture design. We learn a mask during the estimation to rejectoutlier regions. In addition, we calculate loss with respect to our learneddeep features instead of directly comparing the image contents as didpreviously. Moreover, a comprehensive dataset is presented, covering bothregular and challenging cases, such as poor textures and non-planarinterferences. The effectiveness of our method is validated through comparisonswith both feature-based and previous deep-based methods. Code will be soonavailable at Github.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/09/12",
    "Article_PDF": "https://arxiv.org/pdf/1909.05983"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.05090",
    "DOI": "arXiv:1909.05090v1",
    "Article_Title": "DNANet: De-Normalized Attention Based Multi-Resolution Network for Human Pose Estimation",
    "Article_Abstract": "Recently, multi-resolution networks (such as Hourglass, CPN, HRNet, etc.)have achieved significant performance on the task of human pose estimation bycombining features from various resolutions. In this paper, we propose a noveltype of attention module, namely De-Normalized Attention (DNA) to deal with thefeature attenuations of conventional attention modules. Our method extends theoriginal HRNet with spatial, channel-wise and resolution-wise DNAs, which aimsat evaluating the importance of features from different locations, channels andresolutions to enhance the network capability for feature representation. Wealso propose to add fine-to-coarse connections across high-to-low resolutionsin-side each layer of HRNet to increase the maximum depth of network topology.In addition, we propose to modify the keypoint regressor at the end of HRNetfor accurate keypoint heatmap prediction. The effectiveness of our proposednetwork is demonstrated on COCO keypoint detection dataset, achievingstate-of-the-art performance at 76.9 AP score on COCO val2017 dataset withoutusing extra keypoint training data. Our paper will be accompanied with publiclyavailable codes at GitHub.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/09/11",
    "Article_PDF": "https://arxiv.org/pdf/1909.05090"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.04556",
    "DOI": "arXiv:1909.04556v1",
    "Article_Title": "Human Languages in Source Code: Auto-Translation for Localized Instruction",
    "Article_Abstract": "Computer science education has promised open access around the world, butaccess is largely determined by what human language you speak. As youngerstudents learn computer science it is less appropriate to assume that theyshould learn English beforehand. To that end we present CodeInternational, thefirst tool to translate code between human languages. To develop a theory ofnon-English code, and inform our translation decisions, we conduct a study ofpublic code repositories on GitHub. The study is to the best of our knowledgethe first on human-language in code and covers 2.9 million Java repositories.To demonstrate CodeInternational's educational utility, we build an interactiveversion of the popular English-language Karel reader and translate it into 100spoken languages. Our translations have already been used in classrooms aroundthe world, and represent a first step in an important open CS-educationproblem.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/09/10",
    "Article_PDF": "https://arxiv.org/pdf/1909.04556"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.04301",
    "DOI": "arXiv:1909.04301v1",
    "Article_Title": "Frequency domain variant of Velvet noise and its application to acoustic measurements",
    "Article_Abstract": "We propose a new family of test signals for acoustic measurements such asimpulse response, nonlinearity, and the effects of background noise. Theproposed family complements difficulties in existing families, the Swept-Sine(SS), pseudo-random noise such as the maximum length sequence (MLS). Theproposed family uses the frequency domain variant of the Velvet noise (FVN) asits building block. An FVN is an impulse response of an all-pass filter andyields the unit impulse when convolved with the time-reversed version ofitself. In this respect, FVN is a member of the time-stretched pulse (TSP) inthe broadest sense. The high degree of freedom in designing an FVN opens a vastrange of applications in acoustic measurement. We introduce the followingapplications and their specific procedures, among other possibilities. They areas follows. a) Spectrum shaping adaptive to background noise. b) Simultaneousmeasurement of impulse responses of multiple acoustic paths. d) Simultaneousmeasurement of linear and nonlinear components of an acoustic path. e)Automatic procedure for time axis alignment of the source and the receiver whenthey are using independent clocks in acoustic impulse response measurement. Weimplemented a reference measurement tool equipped with all these procedures.The MATLAB source code and related materials are open-sourced and placed in aGitHub repository.",
    "Article_Subject": "Audio and Speech Processing (eess.AS); Sound (cs.SD); Signal Processing (eess.SP)",
    "Article_Date": "2019/09/10",
    "Article_PDF": "https://arxiv.org/pdf/1909.04301"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.03650",
    "DOI": "arXiv:1909.03650v1",
    "Article_Title": "Real-time and interactive tools for vocal training based on an analytic signal with a cosine series envelope",
    "Article_Abstract": "We introduce real-time and interactive tools for assisting vocal training. Inthis presentation, we demonstrate mainly a tool based on real-time visualizerof fundamental frequency candidates to provide information-rich feedback tolearners. The visualizer uses an efficient algorithm using analytic signals forderiving phase-based attributes. We start using these tools in vocal trainingfor assisting learners to acquire the awareness of appropriate vocalization.The first author made the MATLAB implementation of the tools open-source. Thecode and associated video materials are accessible in the first author's GitHubrepository.",
    "Article_Subject": "Sound (cs.SD); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)",
    "Article_Date": "2019/09/09",
    "Article_PDF": "https://arxiv.org/pdf/1909.03650"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.03181",
    "DOI": "arXiv:1909.03181v2",
    "Article_Title": "Receding Horizon Control for Drinking Water Networks: The Case for Geometric Programming",
    "Article_Abstract": "Optimal, network-driven control of Water Distribution Network (WDN) is verydifficult: valve and pump models form non-trivial, combinatorial logic,hydraulic models are nonconvex, water demand patterns are uncertain, and WDNsare naturally large-scale. Prior research on control of WDNs addressed majorresearch challenges, yet mostly adopted simplified hydraulic models, WDNtopologies, and rudimentary valve/pump modeling.  The objective of this paper is to develop tractable computational algorithmsto manage WDN operation, while considering arbitrary topology, flow direction,an abundance of valve types, control objectives, hydraulic models, andoperational constraints. Specifically, we propose new Geometric Programming(GP)-based Model Predictive Control (MPC) algorithms, designed to solve thewater flow equations and obtain WDN controls---pump/valve schedules alongsideheads and flows. The proposed approach amounts to solving a series of convexoptimization problems that graciously scale to large networks. Under demanduncertainty, the proposed approach is tested using a 126-node network with manyvalves and pumps. The developed GP-based MPC algorithms, as well as thenumerical test results are all included on Github.",
    "Article_Subject": "Systems and Control (eess.SY); Optimization and Control (math.OC)",
    "Article_Date": "2019/09/07",
    "Article_PDF": "https://arxiv.org/pdf/1909.03181"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.03147",
    "DOI": "arXiv:1909.03147v1",
    "Article_Title": "Self Learning from Large Scale Code Corpus to Infer Structure of Method Invocations",
    "Article_Abstract": "Automatically generating code from a textual description of method invocationconfronts challenges. There were two current research directions for thisproblem. One direction focuses on considering a textual description of methodinvocations as a separate Natural Language query and do not consider thesurrounding context of the code. Another direction takes advantage of apractical large scale code corpus for providing a Machine Translation model togenerate code. However, this direction got very low accuracy. In this work, wetried to improve these drawbacks by proposing MethodInfoToCode, an approachthat embeds context information and optimizes the ability of learning oforiginal Phrase-based Statistical Machine Translation (PBMT) in NLP to inferimplementation of method invocation given method name and other contextinformation. We conduct an expression prediction models learned from 2.86million method invocations from the practical data of high qualities corpus onGithub that used 6 popular libraries: JDK, Android, GWT, Joda-Time, Hibernate,and Xstream. By the evaluation, we show that if the developers only write themethod name of a method invocation in a body of a method, MethodInfoToCode canpredict the generated expression correctly at 73% in F1 score.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/09/06",
    "Article_PDF": "https://arxiv.org/pdf/1909.03147"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.02548",
    "DOI": "arXiv:1909.02548v1",
    "Article_Title": "Explanation based Handwriting Verification",
    "Article_Abstract": "Deep learning system have drawback that their output is not accompanied withex-planation. In a domain such as forensic handwriting verification it isessential to provideexplanation to jurors. The goal of handwriting verificationis to find a measure of confi-dence whether the given handwritten samples arewritten by the same or different writer.We propose a method to generateexplanations for the confidence provided by convolu-tional neural network (CNN)which maps the input image to 15 annotations (features)provided by experts. Oursystem comprises of: (1) Feature learning network (FLN),a differentiablesystem, (2) Inference module for providing explanations. Furthermore,inferencemodule provides two types of explanations: (a) Based on cosinesimilaritybetween categorical probabilities of each feature, (b) Based onLog-Likelihood Ratio(LLR) using directed probabilistic graphical model. Weperform experiments using acombination of feature learning network (FLN) andeach inference module. We evaluateour system using XAI-AND dataset, containing13700 handwritten samples and 15 cor-responding expert examined features foreach sample. The dataset is released for publicuse and the methods can beextended to provide explanations on other verification taskslike faceverification and bio-medical comparison. This dataset can serve as the basisand benchmark for future research in explanation based handwritingverification. The code is available on github.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
    "Article_Date": "2019/08/14",
    "Article_PDF": "https://arxiv.org/pdf/1909.02548"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.02218",
    "DOI": "arXiv:1909.02218v1",
    "Article_Title": "A Better Way to Attend: Attention with Trees for Video Question Answering",
    "Article_Abstract": "We propose a new attention model for video question answering. The main ideaof the attention models is to locate on the most informative parts of thevisual data. The attention mechanisms are quite popular these days. However,most existing visual attention mechanisms regard the question as a whole. Theyignore the word-level semantics where each word can have different attentionsand some words need no attention. Neither do they consider the semanticstructure of the sentences. Although the Extended Soft Attention (E-SA) modelfor video question answering leverages the word-level attention, it performspoorly on long question sentences. In this paper, we propose the heterogeneoustree-structured memory network (HTreeMN) for video question answering. Ourproposed approach is based upon the syntax parse trees of the questionsentences. The HTreeMN treats the words differently where the \\textit{visual}words are processed with an attention module and the \\textit{verbal} ones not.It also utilizes the semantic structure of the sentences by combining theneighbors based on the recursive structure of the parse trees. Theunderstandings of the words and the videos are propagated and merged fromleaves to the root. Furthermore, we build a hierarchical attention mechanism todistill the attended features. We evaluate our approach on two datasets. Theexperimental results show the superiority of our HTreeMN model over the otherattention models especially on complex questions. Our code is available ongithub.  Our code is available at https://github.com/ZJULearning/TreeAttention",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Machine Learning (cs.LG)",
    "Article_Date": "2019/09/05",
    "Article_PDF": "https://arxiv.org/pdf/1909.02218"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.02203",
    "DOI": "arXiv:1909.02203v2",
    "Article_Title": "Elastic_HH: Tailored Elastic for Finding Heavy Hitters",
    "Article_Abstract": "Finding heavy hitters has been of vital importance in network measurement.Among all the recent works in finding heavy hitters, the Elastic sketchachieves the highest accuracy and fastest speed. However, we find that there isstill room for improvement of the Elastic sketch in finding heavy hitters. Inthis paper, we propose a tailored Elastic to enhance the sketch only forfinding heavy hitters at the cost of losing the generality of Elastic. Totailor Elastic, we abandon the light part, and improve the eviction strategy.Our experimental results show that compared with the standard Elastic, ourtailored Elastic reduces the error rate to 5.7~8.1 times and increases thespeed to 2.5 times. All the related source codes and datasets are available atGithub.",
    "Article_Subject": "Networking and Internet Architecture (cs.NI)",
    "Article_Date": "2019/09/05",
    "Article_PDF": "https://arxiv.org/pdf/1909.02203"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.01441",
    "DOI": "arXiv:1909.01441v1",
    "Article_Title": "CrossWeigh: Training Named Entity Tagger from Imperfect Annotations",
    "Article_Abstract": "Everyone makes mistakes. So do human annotators when curating labels fornamed entity recognition (NER). Such label mistakes might hurt model trainingand interfere model comparison. In this study, we dive deep into one of thewidely-adopted NER benchmark datasets, CoNLL03 NER. We are able to identifylabel mistakes in about 5.38% test sentences, which is a significant ratioconsidering that the state-of-the-art test F1 score is already around 93%.Therefore, we manually correct these label mistakes and form a cleaner testset. Our re-evaluation of popular models on this corrected test set leads tomore accurate assessments, compared to those on the original test set. Moreimportantly, we propose a simple yet effective framework, CrossWeigh, to handlelabel mistakes during NER model training. Specifically, it partitions thetraining data into several folds and train independent NER models to identifypotential mistakes in each fold. Then it adjusts the weights of training dataaccordingly to train the final NER model. Extensive experiments demonstratesignificant improvements of plugging various NER models into our proposedframework on three datasets. All implementations and corrected test set areavailable at our Github repo: https://github.com/ZihanWangKi/CrossWeigh.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/09/03",
    "Article_PDF": "https://arxiv.org/pdf/1909.01441"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1909.01377",
    "DOI": "arXiv:1909.01377v1",
    "Article_Title": "Deep Equilibrium Models",
    "Article_Abstract": "We present a new approach to modeling sequential data: the deep equilibriummodel (DEQ). Motivated by an observation that the hidden layers of manyexisting deep sequence models converge towards some fixed point, we propose theDEQ approach that directly finds these equilibrium points via root-finding.Such a method is equivalent to running an infinite depth (weight-tied)feedforward network, but has the notable advantage that we can analyticallybackpropagate through the equilibrium point using implicit differentiation.Using this approach, training and prediction in these networks require onlyconstant memory, regardless of the effective \"depth\" of the network. Wedemonstrate how DEQs can be applied to two state-of-the-art deep sequencemodels: self-attention transformers and trellis networks. On large-scalelanguage modeling tasks, such as the WikiText-103 benchmark, we show that DEQs1) often improve performance over these state-of-the-art models (for similarparameter counts); 2) have similar computational requirements as existingmodels; and 3) vastly reduce memory consumption (often the bottleneck fortraining large sequence models), demonstrating an up-to 88% memory reduction inour experiments. The code is available at https://github. com/locuslab/deq .",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/09/03",
    "Article_PDF": "https://arxiv.org/pdf/1909.01377"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.11527",
    "DOI": "arXiv:1908.11527v2",
    "Article_Title": "Implicit Deep Latent Variable Models for Text Generation",
    "Article_Abstract": "Deep latent variable models (LVM) such as variational auto-encoder (VAE) haverecently played an important role in text generation. One key factor is theexploitation of smooth latent structures to guide the generation. However, therepresentation power of VAEs is limited due to two reasons: (1) the Gaussianassumption is often made on the variational posteriors; and meanwhile (2) anotorious \"posterior collapse\" issue occurs. In this paper, we advocatesample-based representations of variational distributions for natural language,leading to implicit latent features, which can provide flexible representationpower compared with Gaussian-based posteriors. We further develop an LVM todirectly match the aggregated posterior to the prior. It can be viewed as anatural extension of VAEs with a regularization of maximizing mutualinformation, mitigating the \"posterior collapse\" issue. We demonstrate theeffectiveness and versatility of our models in various text generationscenarios, including language modeling, unaligned style transfer, and dialogresponse generation. The source code to reproduce our experimental results isavailable on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/30",
    "Article_PDF": "https://arxiv.org/pdf/1908.11527"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.10267",
    "DOI": "arXiv:1908.10267v2",
    "Article_Title": "DRD-Net: Detail-recovery Image Deraining via Context Aggregation Networks",
    "Article_Abstract": "Image deraining is a fundamental, yet not well-solved problem in computervision and graphics. The traditional image deraining approaches commonly behaveineffectively in medium and heavy rain removal, while the learning-based oneslead to image degradations such as the loss of image details, halo artifactsand/or color distortion. Unlike existing image deraining approaches that lackthe detail-recovery mechanism, we propose an end-to-end detail-recovery imagederaining network (termed a DRD-Net) for single images. We for the first timeintroduce two sub-networks with a comprehensive loss function which synergizeto derain and recover the lost details caused by deraining. We have three keycontributions. First, we present a rain residual network to remove rain streaksfrom the rainy images, which combines the squeeze-and-excitation (SE) operationwith residual blocks to make full advantage of spatial contextual information.Second, we design a new connection style block, named structure detail contextaggregation block (SDCAB), which aggregates context feature information and hasa large reception field. Third, benefiting from the SDCAB, we construct adetail repair network to encourage the lost details to return for eliminatingimage degradations. We have validated our approach on four recognized datasets(three synthetic and one real-world). Both quantitative and qualitativecomparisons show that our approach outperforms the state-of-the-art derainingmethods in terms of the deraining robustness and detail accuracy. The sourcecode has been available for public evaluation and use on GitHub.",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/27",
    "Article_PDF": "https://arxiv.org/pdf/1908.10267"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.09195",
    "DOI": "arXiv:1908.09195v1",
    "Article_Title": "Scalable Modeling of Spatiotemporal Data using the Variational Autoencoder: an Application in Glaucoma",
    "Article_Abstract": "As big spatial data becomes increasingly prevalent, classical spatiotemporal(ST) methods often do not scale well. While methods have been developed toaccount for high-dimensional spatial objects, the setting where there areexceedingly large samples of spatial observations has had less attention. Thevariational autoencoder (VAE), an unsupervised generative model based on deeplearning and approximate Bayesian inference, fills this void using a latentvariable specification that is inferred jointly across the large number ofsamples. In this manuscript, we compare the performance of the VAE with a moreclassical ST method when analyzing longitudinal visual fields from a largecohort of patients in a prospective glaucoma study. Through simulation and acase study, we demonstrate that the VAE is a scalable method for analyzing STdata, when the goal is to obtain accurate predictions. R code to implement theVAE can be found on GitHub: https://github.com/berchuck/vaeST.",
    "Article_Subject": "Applications (stat.AP); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/24",
    "Article_PDF": "https://arxiv.org/pdf/1908.09195"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08856",
    "DOI": "arXiv:1908.08856v1",
    "Article_Title": "Assessing Knee OA Severity with CNN attention-based end-to-end architectures",
    "Article_Abstract": "This work proposes a novel end-to-end convolutional neural network (CNN)architecture to automatically quantify the severity of knee osteoarthritis (OA)using X-Ray images, which incorporates trainable attention modules acting asunsupervised fine-grained detectors of the region of interest (ROI). Theproposed attention modules can be applied at different levels and scales acrossany CNN pipeline helping the network to learn relevant attention patterns overthe most informative parts of the image at different resolutions. We test theproposed attention mechanism on existing state-of-the-art CNN architectures asour base models, achieving promising results on the benchmark knee OA datasetsfrom the osteoarthritis initiative (OAI) and multicenter osteoarthritis study(MOST). All code from our experiments will be publicly available on the githubrepository: https://github.com/marc-gorriz/KneeOA-CNNAttention",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
    "Article_Date": "2019/08/23",
    "Article_PDF": "https://arxiv.org/pdf/1908.08856"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08584",
    "DOI": "arXiv:1908.08584v1",
    "Article_Title": "Feedbackward Decoding for Semantic Segmentation",
    "Article_Abstract": "We propose a novel approach for semantic segmentation that uses an encoder inthe reverse direction to decode. Many semantic segmentation networks adopt afeedforward encoder-decoder architecture. Typically, an input is firstdownsampled by the encoder to extract high-level semantic features andcontinues to be fed forward through the decoder module to recover low-levelspatial clues. Our method works in an alternative direction that letsinformation flow backward from the last layer of the encoder towards the first.The encoder performs encoding in the forward pass and the same network performsdecoding in the backward pass. Therefore, the encoder itself is also thedecoder. Compared to conventional encoder-decoder architectures, ours doesn'trequire additional layers for decoding and further reuses the encoder weightsthereby reducing the total number of parameters required for processing. Weshow by using only the 13 convolutional layers from VGG-16 plus one tinyclassification layer, our model significantly outperforms other frequentlycited models that are also adapted from VGG-16. On the Cityscapes semanticsegmentation benchmark, our model uses 50.0% less parameters than SegNet andachieves an 18.1% higher \"IoU class\" score; it uses 28.3% less parameters thanDeepLab LargeFOV and the achieved \"IoU class\" score is 3.9% higher; it uses89.1% fewer parameters than FCN-8s and the achieved \"IoU class\" score is 3.1%higher. Our code will be publicly available on Github later.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Image and Video Processing (eess.IV); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/22",
    "Article_PDF": "https://arxiv.org/pdf/1908.08584"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08196",
    "DOI": "arXiv:1908.08196v1",
    "Article_Title": "Unveiling Elite Developers' Activities in Open Source Projects",
    "Article_Abstract": "Open-source developers, particularly the elite developers, maintain a diverseportfolio of contributing activities. They do not only commit source code butalso spend a significant amount of effort on other communicative,organizational, and supportive activities. However, almost all prior researchfocuses on a limited number of specific activities and fails to analyze elitedevelopers' activities in a comprehensive way. To bridge this gap, we conductan empirical study with fine-grained event data from 20 large open-sourceprojects hosted on GitHub. Thus, we investigate elite developers' contributingactivities and their impacts on project outcomes. Our analyses reveal three keyfindings: (1) they participate in a variety of activities while technicalcontributions (e.g., coding) accounting for a small proportion only; (2) theytend to put more effort into supportive and communicative activities and lesseffort into coding as the project grows; (3) their participation innon-technical activities is negatively associated with the project's outcomesin term of productivity and software quality. These results provide a panoramicview of elite developers' activities and can inform an individual's decisionmaking about effort allocation, thus leading to finer project outcomes. Theresults also provide implications for supporting these elite developers.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/22",
    "Article_PDF": "https://arxiv.org/pdf/1908.08196"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.08123",
    "DOI": "arXiv:1908.08123v3",
    "Article_Title": "Computing System Congestion Management Using Exponential Smoothing Forecasting",
    "Article_Abstract": "An overloaded computer must finish what it starts and not start what willfail or hang. A congestion management algorithm the author developed, andSiemens Corporation patented for telecom products, effectively manages trafficoverload with its unique formulation of Exponential Smoothing forecasting.Siemens filed for exclusive rights to this technique in 2003 and obtained USpatent US7301903B2 in 2007 with this author, an employee at the time of thefiling, the sole inventor. A computer program, written in C language, whichexercises the methodology is listed at the end of this document and availableon GitHub.",
    "Article_Subject": "Performance (cs.PF)",
    "Article_Date": "2019/08/21",
    "Article_PDF": "https://arxiv.org/pdf/1908.08123"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.07984",
    "DOI": "arXiv:1908.07984v1",
    "Article_Title": "Minimal residual multistep methods for large stiff non-autonomous linear problems",
    "Article_Abstract": "The purpose of this work is to introduce a new idea of how to avoid thefactorization of large matrices during the solution of stiff systems of ODEs.Starting from the general form of an explicit linear multistep method wesuggest to adaptively choose its coefficients on each integration step in orderto minimize the norm of the residual of an implicit BDF formula. Thereby wereduce the number of unknowns on each step from $n$ to $O(1)$, where $n$ is thedimension of the ODE system. We call this type of methods Minimal ResidualMultistep (MRMS) methods. In the case of linear non-autonomous problem, besidesthe evaluations of the right-hand side of ODE, the resulting numerical schemeadditionally requires one solution of a linear least-squares problem with athin matrix per step. We show that the order of the method and itszero-stability properties coincide with those of the used underlying BDFformula. For the simplest analog of the implicit Euler method the properties oflinear stability are investigated. Though the classical absolute stabilityanalysis is not fully relevant to the MRMS methods, it is shown that thisone-step method is applicable in stiff case. In the numerical experimentsection we consider the fixed-step integration of a two-dimensionalnon-autonomous heat equation using the MRMS methods and their classical BDFcounterparts. The starting values are taken from a preset slowly-varying exactsolution. The comparison showed that both methods give similar numericalsolutions, but in the case of large systems the MRMS methods are faster, andtheir advantage considerably increases with the growth of dimension. Pythoncode with the experimantal code can be downloaded from the GitHub repositoryhttps://github.com/bfaleichik/mrms.",
    "Article_Subject": "Numerical Analysis (math.NA)",
    "Article_Date": "2019/08/21",
    "Article_PDF": "https://arxiv.org/pdf/1908.07984"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.07883",
    "DOI": "arXiv:1908.07883v3",
    "Article_Title": "Scala Implicits are Everywhere: A large-scale study of the use of Implicits in the wild",
    "Article_Abstract": "The Scala programming language offers two distinctive language featuresimplicit parameters and implicit conversions, often referred together asimplicits. Announced without fanfare in 2004, implicits have quickly grown tobecome a widely and pervasively used feature of the language. They provide away to reduce the boilerplate code in Scala programs. They are also used toimplement certain language features without having to modify the compiler. Wereport on a large-scale study of the use of implicits in the wild. For this, weanalyzed 7,280 Scala projects hosted on GitHub, spanning over 8.1M call sitesinvolving implicits and 370.7K implicit declarations across 18.7M lines ofScala code.",
    "Article_Subject": "Programming Languages (cs.PL); Software Engineering (cs.SE)",
    "Article_Date": "2019/08/21",
    "Article_PDF": "https://arxiv.org/pdf/1908.07883"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.06473",
    "DOI": "arXiv:1908.06473v1",
    "Article_Title": "From Open Set to Closed Set: Counting Objects by Spatial Divide-and-Conquer",
    "Article_Abstract": "Visual counting, a task that predicts the number of objects from animage/video, is an open-set problem by nature, i.e., the number of populationcan vary in $[0,+\\infty)$ in theory. However, the collected images and labeledcount values are limited in reality, which means only a small closed set isobserved. Existing methods typically model this task in a regression manner,while they are likely to suffer from an unseen scene with counts out of thescope of the closed set. In fact, counting is decomposable. A dense region canalways be divided until sub-region counts are within the previously observedclosed set. Inspired by this idea, we propose a simple but effective approach,Spatial Divide-and- Conquer Network (S-DCNet). S-DCNet only learns from aclosed set but can generalize well to open-set scenarios via S-DC. S-DCNet isalso efficient. To avoid repeatedly computing sub-region convolutionalfeatures, S-DC is executed on the feature map instead of on the input image.S-DCNet achieves the state-of-the-art performance on three crowd countingdatasets (ShanghaiTech, UCF_CC_50 and UCF-QNRF), a vehicle counting dataset(TRANCOS) and a plant counting dataset (MTC). Compared to the previous bestmethods, S-DCNet brings a 20.2% relative improvement on the ShanghaiTech PartB, 20.9% on the UCF-QNRF, 22.5% on the TRANCOS and 15.1% on the MTC. Code hasbeen made available at: https://github. com/xhp-hust-2018-2011/S-DCNet.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/15",
    "Article_PDF": "https://arxiv.org/pdf/1908.06473"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.06412",
    "DOI": "arXiv:1908.06412v1",
    "Article_Title": "Characterizing the transition to Kotlin of Android apps: a study on F-Droid, Play Store and GitHub",
    "Article_Abstract": "Kotlin is a novel language that represents an alternative to Java, and hasbeen recently adopted as a first-class programming language for Androidapplications. Kotlin is achieving a significant diffusion among developers, andseveral studies have highlighted various advantages of the language whencompared to Java.  The objective of this paper is to analyze a set of open-source Android apps,to evaluate their transition to the Kotlin programming language throughouttheir lifespan and understand whether the adoption of Kotlin has impacts on thesuccess of Android apps.  We mined all the projects from the F-Droid repository of Android open-sourceapplications, and we found the corresponding projects on the official GooglePlay Store and on the GitHub platform. We defined a set of eight metrics toquantify the relevance of Kotlin code in the latest update and through allreleases of an application. Then, we statistically analyzed the correlationbetween the presence of Kotlin code in a project and popularity metrics minedfrom the platforms where the apps were released.  Of a set of 1232 projects that were updated after October 2017, near 20%adopted Kotlin and about 12% had more Kotlin code than Java; most of theprojects that adopted Kotlin quickly transitioned from Java to the newlanguage. The projects featuring Kotlin had on average higher popularitymetrics; a statistically significant correlation has been found between thepresence of Kotlin and the number of stars on the GitHub repository.  The Kotlin language seems able to guarantee a seamless migration from Javafor Android developers. With an inspection on a large set of open-sourceAndroid apps, we observed that the adoption of the Kotlin language is rapid(when compared to the average lifespan of an Android project) and seems to comeat no cost in terms of popularity among the users and other developers.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/18",
    "Article_PDF": "https://arxiv.org/pdf/1908.06412"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.06309",
    "DOI": "arXiv:1908.06309v1",
    "Article_Title": "ED2: Two-stage Active Learning for Error Detection -- Technical Report",
    "Article_Abstract": "Traditional error detection approaches require user-defined parameters andrules. Thus, the user has to know both the error detection system and the data.However, we can also formulate error detection as a semi-supervisedclassification problem that only requires domain expertise. The challenges forsuch an approach are twofold: (1) to represent the data in a way that enables aclassification model to identify various kinds of data errors, and (2) to pickthe most promising data values for learning. In this paper, we address thesechallenges with ED2, our new example-driven error detection method. First, wepresent a new two-dimensional multi-classifier sampling strategy for activelearning. Second, we propose novel multi-column features. The combinedapplication of these techniques provides fast convergence of the classificationtask with high detection accuracy. On several real-world datasets, ED2requires, on average, less than 1% labels to outperform existing errordetection approaches. This report extends the peer-reviewed paper \"ED2: A Casefor Active Learning in Error Detection\". All source code related to thisproject is available on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Databases (cs.DB); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/17",
    "Article_PDF": "https://arxiv.org/pdf/1908.06309"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05541",
    "DOI": "arXiv:1908.05541v1",
    "Article_Title": "Hamming Sentence Embeddings for Information Retrieval",
    "Article_Abstract": "In retrieval applications, binary hashes are known to offer significantimprovements in terms of both memory and speed. We investigate the compressionof sentence embeddings using a neural encoder-decoder architecture, which istrained by minimizing reconstruction error. Instead of employing the originalreal-valued embeddings, we use latent representations in Hamming space producedby the encoder for similarity calculations.  In quantitative experiments on several benchmarks for semantic similaritytasks, we show that our compressed hamming embeddings yield a comparableperformance to uncompressed embeddings (Sent2Vec, InferSent, Glove-BoW), atcompression ratios of up to 256:1. We further demonstrate that our modelstrongly decorrelates input features, and that the compressor generalizes wellwhen pre-trained on Wikipedia sentences. We publish the source code on Githuband all experimental results.",
    "Article_Subject": "Information Retrieval (cs.IR); Computation and Language (cs.CL); Machine Learning (cs.LG)",
    "Article_Date": "2019/08/15",
    "Article_PDF": "https://arxiv.org/pdf/1908.05541"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05437",
    "DOI": "arXiv:1908.05437v1",
    "Article_Title": "Massive Multi-Agent Data-Driven Simulations of the GitHub Ecosystem",
    "Article_Abstract": "Simulating and predicting planetary-scale techno-social systems poses heavycomputational and modeling challenges. The DARPA SocialSim program set thechallenge to model the evolution of GitHub, a large collaborativesoftware-development ecosystem, using massive multi-agent simulations. Wedescribe our best performing models and our agent-based simulation framework,which we are currently extending to allow simulating other planetary-scaletechno-social systems. The challenge problem measured participant's ability,given 30 months of meta-data on user activity on GitHub, to predict the nextmonths' activity as measured by a broad range of metrics applied to groundtruth, using agent-based simulation. The challenge required scaling to asimulation of roughly 3 million agents producing a combined 30 million actions,acting on 6 million repositories with commodity hardware. It was also importantto use the data optimally to predict the agent's next moves. We describe theagent framework and the data analysis employed by one of the winning teams inthe challenge. Six different agent models were tested based on a variety ofmachine learning and statistical methods. While no single method proved themost accurate on every metric, the broadly most successful sampled from astationary probability distribution of actions and repositories for each agent.Two reasons for the success of these agents were their use of a distinctcharacterization of each agent, and that GitHub users change their behaviorrelatively slowly.",
    "Article_Subject": "Multiagent Systems (cs.MA); Social and Information Networks (cs.SI)",
    "Article_Date": "2019/08/15",
    "Article_PDF": "https://arxiv.org/pdf/1908.05437"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05354",
    "DOI": "arXiv:1908.05354v2",
    "Article_Title": "Large-Scale-Exploit of GitHub Repository Metadata and Preventive Measures",
    "Article_Abstract": "When working with Git, a popular version-control system, email addresses arepart of the metadata for each individual commit. When those commits are pushedto remote hosting services like GitHub, those email addresses become visiblenot only to fellow developers, but also to malicious actors aiming to exploitthem.  As a part of our research we created a tool that leverages the publiclyavailable GitHub API to collect user data. Analysis of this data not only givesaccess to millions of email addresses in very little time, but is also powerfuland dense enough to create targeted phishing attacks posing a great threat toall GitHub users and their private, potentially sensitive data. Even worse,existing countermeasures fail to effectively protect against such exploits.  As a consequence and main conclusion of this paper, we suggest multiplepreventive measures that should be implemented as soon as possible. We alsoconsider it the duty of both companies like GitHub and well informed softwareengineers to inform fellow developers about the risk of exposing private emailaddresses in Git commits published publicly.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/08/14",
    "Article_PDF": "https://arxiv.org/pdf/1908.05354"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.05097",
    "DOI": "arXiv:1908.05097v1",
    "Article_Title": "Causal discovery in heavy-tailed models",
    "Article_Abstract": "Causal questions are omnipresent in many scientific problems. While muchprogress has been made in the analysis of causal relationships between randomvariables, these methods are not well suited if the causal mechanisms manifestthemselves only in extremes. This work aims to connect the two fields of causalinference and extreme value theory. We define the causal tail coefficient thatcaptures asymmetries in the extremal dependence of two random variables. In thepopulation case, the causal tail coefficient is shown to reveal the causalstructure if the distribution follows a linear structural causal model. Thisholds even in the presence of latent common causes that have the same tailindex as the observed variables. Based on a consistent estimator of the causaltail coefficient, we propose a computationally highly efficient algorithm thatinfers causal structure from finitely many data. We prove that our methodconsistently estimates the causal order and compare it to otherwell-established and non-extremal approaches in causal discovery on syntheticdata. The code is available as an open-access R package on Github.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/08/14",
    "Article_PDF": "https://arxiv.org/pdf/1908.05097"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.04710",
    "DOI": "arXiv:1908.04710v1",
    "Article_Title": "metric-learn: Metric Learning Algorithms in Python",
    "Article_Abstract": "metric-learn is an open source Python package implementing supervised andweakly-supervised distance metric learning algorithms. As part ofscikit-learn-contrib, it provides a unified interface compatible withscikit-learn which allows to easily perform cross-validation, model selection,and pipelining with other machine learning estimators. metric-learn isthoroughly tested and available on PyPi under the MIT licence.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/13",
    "Article_PDF": "https://arxiv.org/pdf/1908.04710"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.04219",
    "DOI": "arXiv:1908.04219v1",
    "Article_Title": "How do Developers Promote Open Source Projects?",
    "Article_Abstract": "Open source projects have an increasing importance on modern softwaredevelopment. For this reason, these projects, as usual with commercial softwareprojects, should make use of promotion channels to communicate and establishcontact with users and contributors. In this article, we study the channelsused to promote a set of 100 popular GitHub projects. First, we reveal thatTwitter, user meetings, and blogs are the most common promotion channels usedby the studied projects. Second, we report a major difference between thestudied projects and a random sample of projects, regarding the use of theinvestigated promotion channels. Third, we show the importance of a popularnews aggregation site (Hacker News) on the promotion of open source. Weconclude by presenting a set of practical recommendation to open source projectmanagers and leaders, regarding the promotion of their projects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/12",
    "Article_PDF": "https://arxiv.org/pdf/1908.04219"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.03952",
    "DOI": "arXiv:1908.03952v2",
    "Article_Title": "Constraining new physics from Higgs measurements with Lilith: update to LHC Run 2 results",
    "Article_Abstract": "Lilith is a public Python library for constraining new physics from Higgssignal strength measurements. We here present version 2.0 of Lilith togetherwith an updated XML database which includes the current ATLAS and CMS Run 2Higgs results for 36/fb. Both the code and the database were extended from theordinary Gaussian approximation employed in Lilith-1.1 to using variableGaussian and Poisson likelihoods. Moreover, Lilith can now make use ofcorrelation matrices of arbitrary dimension. We provide detailed validations ofthe implemented experimental results as well as a status of global fits forreduced Higgs couplings, Two-Higgs-doublet models of Type I and Type II, andinvisible Higgs decays. Lilith-2.0 is available on GitHub and ready to be usedto constrain a wide class of new physics scenarios.",
    "Article_Subject": "High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Experiment (hep-ex)",
    "Article_Date": "2019/08/11",
    "Article_PDF": "https://arxiv.org/pdf/1908.03952"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.02320",
    "DOI": "arXiv:1908.02320v1",
    "Article_Title": "Do as I Do, Not as I Say: Do Contribution Guidelines Match the GitHub Contribution Process?",
    "Article_Abstract": "Developer contribution guidelines are used in social coding sites like GitHubto explain and shape the process a project expects contributors to follow. Theyset standards for all participants and \"save time and hassle caused byimproperly created pull requests or issues that have to be rejected andresubmitted\" (GitHub). Yet, we lack a systematic understanding of the contentof a typical contribution guideline, as well as the extent to which theseguidelines are followed in practice. Additionally, understanding how guidelinesmay impact projects that use Continuous Integration as part of the contributionprocess is of particular interest. To address this knowledge gap, we conducteda mixed-methods study of 53 GitHub projects with explicit contributionguidelines and coded the guidelines to extract key themes. We then created aprocess model using GitHub activity data (e.g., commit, new issue, new pullrequest) to compare the actual activity with the prescribed contributionguidelines. We show that approximately 68% of these projects divergesignificantly from the expected process.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/06",
    "Article_PDF": "https://arxiv.org/pdf/1908.02320"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.02116",
    "DOI": "arXiv:1908.02116v3",
    "Article_Title": "Teacher Supervises Students How to Learn From Partially Labeled Images for Facial Landmark Detection",
    "Article_Abstract": "Facial landmark detection aims to localize the anatomically defined points ofhuman faces. In this paper, we study facial landmark detection from partiallylabeled facial images. A typical approach is to (1) train a detector on thelabeled images; (2) generate new training samples using this detector'sprediction as pseudo labels of unlabeled images; (3) retrain the detector onthe labeled samples and partial pseudo labeled samples. In this way, thedetector can learn from both labeled and unlabeled data to become robust. Inthis paper, we propose an interaction mechanism between a teacher and twostudents to generate more reliable pseudo labels for unlabeled data, which arebeneficial to semi-supervised facial landmark detection. Specifically, the twostudents are instantiated as dual detectors. The teacher learns to judge thequality of the pseudo labels generated by the students and filter outunqualified samples before the retraining stage. In this way, the studentdetectors get feedback from their teacher and are retrained by premium datagenerated by itself. Since the two students are trained by different samples, acombination of their predictions will be more robust as the final predictioncompared to either prediction. Extensive experiments on 300-W and AFLWbenchmarks show that the interactions between teacher and students contributeto better utilization of the unlabeled data and achieves state-of-the-artperformance.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/06",
    "Article_PDF": "https://arxiv.org/pdf/1908.02116"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01711",
    "DOI": "arXiv:1908.01711v1",
    "Article_Title": "fgivenx: A Python package for functional posterior plotting",
    "Article_Abstract": "fgivenx is a Python package for functional posterior plotting, currently usedin astronomy, but will be of use to scientists performing any Bayesian analysiswhich has predictive posteriors that are functions. The source code for fgivenxis available on GitHub at https://github.com/williamjameshandley/fgivenx",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.01711"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01373",
    "DOI": "arXiv:1908.01373v2",
    "Article_Title": "Unsupervised Microvascular Image Segmentation Using an Active Contours Mimicking Neural Network",
    "Article_Abstract": "The task of blood vessel segmentation in microscopy images is crucial formany diagnostic and research applications. However, vessels can look vastlydifferent, depending on the transient imaging conditions, and collecting datafor supervised training is laborious. We present a novel deep learning methodfor unsupervised segmentation of blood vessels. The method is inspired by thefield of active contours and we introduce a new loss term, which is based onthe morphological Active Contours Without Edges (ACWE) optimization method. Therole of the morphological operators is played by novel pooling layers that areincorporated to the network's architecture. We demonstrate the challenges thatare faced by previous supervised learning solutions, when the imagingconditions shift. Our unsupervised method is able to outperform such previousmethods in both the labeled dataset, and when applied to similar but differentdatasets. Our code, as well as efficient PyTorch reimplementations of thebaseline methods VesselNN and DeepVess is available on GitHub -https://github.com/shirgur/UMIS.",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/04",
    "Article_PDF": "https://arxiv.org/pdf/1908.01373"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01242",
    "DOI": "arXiv:1908.01242v1",
    "Article_Title": "Kannada-MNIST: A new handwritten digits dataset for the Kannada language",
    "Article_Abstract": "In this paper, we disseminate a new handwritten digits-dataset, termedKannada-MNIST, for the Kannada script, that can potentially serve as a directdrop-in replacement for the original MNIST dataset. In addition to thisdataset, we disseminate an additional real world handwritten dataset (with$10k$ images), which we term as the Dig-MNIST dataset that can serve as anout-of-domain test dataset. We also duly open source all the code as well asthe raw scanned images along with the scanner settings so that researchers whowant to try out different signal processing pipelines can perform end-to-endcomparisons. We provide high level morphological comparisons with the MNISTdataset and provide baselines accuracies for the dataset disseminated. Theinitial baselines obtained using an oft-used CNN architecture ($96.8\\%$ for themain test-set and $76.1\\%$ for the Dig-MNIST test-set) indicate that thesedatasets do provide a sterner challenge with regards to generalizability thanMNIST or the KMNIST datasets. We also hope this dissemination will spur thecreation of similar datasets for all the languages that use different symbolsfor the numeral digits.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/03",
    "Article_PDF": "https://arxiv.org/pdf/1908.01242"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.01031",
    "DOI": "arXiv:1908.01031v1",
    "Article_Title": "RuleKit: A Comprehensive Suite for Rule-Based Learning",
    "Article_Abstract": "Rule-based models are often used for data analysis as they combineinterpretability with predictive power. We present RuleKit, a versatile toolfor rule learning. Based on a sequential covering induction algorithm, it issuitable for classification, regression, and survival problems. The presence ofa user-guided induction facilitates verifying hypotheses concerning datadependencies which are expected or of interest. The powerful and flexibleexperimental environment allows straightforward investigation of differentinduction schemes. The analysis can be performed in batch mode, throughRapidMiner plug-in, or R package. A documented Java API is also provided forconvenience. The software is publicly available at GitHub under GNU AGPL-3.0license.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (stat.ML)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.01031"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.00867",
    "DOI": "arXiv:1908.00867v1",
    "Article_Title": "An Evaluation of Action Recognition Models on EPIC-Kitchens",
    "Article_Abstract": "We benchmark contemporary action recognition models (TSN, TRN, and TSM) onthe recently introduced EPIC-Kitchens dataset and release pretrained models onGitHub (https://github.com/epic-kitchens/action-models) for others to buildupon. In contrast to popular action recognition datasets like Kinetics,Something-Something, UCF101, and HMDB51, EPIC-Kitchens is shot from anegocentric perspective and captures daily actions in-situ. In this report, weaim to understand how well these models can tackle the challenges present inthis dataset, such as its long tail class distribution, unseen environment testset, and multiple tasks (verb, noun and, action classification). We discuss themodels' shortcomings and avenues for future research.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.00867"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.00717",
    "DOI": "arXiv:1908.00717v1",
    "Article_Title": "Lagrange2D: A Mathematica package for Lagrangian analysis of two-dimensional fluid flows",
    "Article_Abstract": "We introduce Lagrange2D, a Mathematica package for analysis andcharacterization of complex fluid flows using Lagrangian transport metrics.Lagrange2D includes built-in functions for integrating ensembles oftrajectories subject to time-varying two-dimensional flows, as well asutilities for calculating various quantities of interest, such as finite-timeLyapunov exponents, stretching vector fields, the fractal dimension, andflushing times. The package also includes tools for visualizing transport andpathlines, as well as for generating videos. This package aims to ease rapidcharacterization of arbitrary flows, by allowing identification of Lagrangiancoherent structures and other quantities of interest. The open-source code forthe package is available on GitHub at:\\url{https://github.com/williamgilpin/lagrange2d}",
    "Article_Subject": "Fluid Dynamics (physics.flu-dyn); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/08/02",
    "Article_PDF": "https://arxiv.org/pdf/1908.00717"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1908.00614",
    "DOI": "arXiv:1908.00614v2",
    "Article_Title": "Learning to Identify Security-Related Issues Using Convolutional Neural Networks",
    "Article_Abstract": "Software security is becoming a high priority for both large companies andstart-ups alike due to the increasing potential for harm that vulnerabilitiesand breaches carry with them. However, attaining robust security assurancewhile delivering features requires a precarious balancing act in the context ofagile development practices. One path forward to help aid development teams insecuring their software products is through the design and development ofsecurity-focused automation. Ergo, we present a novel approach, calledSecureReqNet, for automatically identifying whether issues in software issuetracking systems describe security-related content. Our approach consists of atwo-phase neural net architecture that operates purely on the natural languagedescriptions of issues. The first phase of our approach learns high dimensionalword embeddings from hundreds of thousands of vulnerability descriptions listedin the CVE database and issue descriptions extracted from open source projects.The second phase then utilizes the semantic ontology represented by theseembeddings to train a convolutional neural network capable of predictingwhether a given issue is security-related. We evaluated SecureReqNet byapplying it to identify security-related issues from a dataset of thousands ofissues mined from popular projects on GitLab and GitHub. In addition, we alsoapplied our approach to identify security-related requirements from acommercial software project developed by a major telecommunication company. Ourpreliminary results are encouraging, with SecureReqNet achieving an accuracy of96% on open source issues and 71.6% on industrial requirements.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/08/01",
    "Article_PDF": "https://arxiv.org/pdf/1908.00614"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.13012",
    "DOI": "arXiv:1907.13012v1",
    "Article_Title": "An Empirical Study of GraphQL Schemas",
    "Article_Abstract": "GraphQL is a query language for APIs and a runtime to execute queries. UsingGraphQL queries, clients define precisely what data they wish to retrieve ormutate on a server, leading to fewer round trips and reduced response sizes.Although interest in GraphQL is on the rise, with increasing adoption at majororganizations, little is known about what GraphQL interfaces look like inpractice. This lack of knowledge makes it hard for providers to understand whatpractices promote idiomatic, easy-to-use APIs, and what pitfalls to avoid. Toaddress this gap, we study the design of GraphQL interfaces in practice byanalyzing their schemas - the descriptions of their exposed data types and thepossible operations on the underlying data. We base our study on two novelcorpuses of GraphQL schemas, one of 16 commercial GraphQL schemas and the otherof 8,399 GraphQL schemas mined from GitHub projects. We make both corpusesavailable to other researchers. Using these corpuses, we characterize the sizeof schemas and their use of GraphQL features and assess the use of bothprescribed and organic naming conventions. We also report that a majority ofAPIs are susceptible to denial of service through complex queries, posing realsecurity risks previously discussed only in theory. We also assess ways inwhich GraphQL APIs attempt to address these concerns.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/07/30",
    "Article_PDF": "https://arxiv.org/pdf/1907.13012"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.11017",
    "DOI": "arXiv:1907.11017v2",
    "Article_Title": "Particle Methods for Stochastic Differential Equation Mixed Effects Models",
    "Article_Abstract": "Parameter inference for stochastic differential equation mixed effects models(SDEMEMs) is a challenging problem. Analytical solutions for these models arerarely available, which means that the likelihood is also intractable. In thiscase, exact inference is possible using the pseudo-marginal method, where theintractable likelihood is replaced by its nonnegative unbiased estimate. Auseful application of this idea is particle MCMC, which uses a particle filterestimate of the likelihood. While the exact posterior is targeted by thesemethods, a naive implementation for SDEMEMs can be highly inefficient. Wedevelop three extensions to the naive approach which exploits specific aspectsof SDEMEMs and other advances such as correlated pseudo-marginal methods. Wecompare these methods on real and simulated data from a tumour xenography studyon mice.",
    "Article_Subject": "Computation (stat.CO); Methodology (stat.ME)",
    "Article_Date": "2019/07/25",
    "Article_PDF": "https://arxiv.org/pdf/1907.11017"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.10121",
    "DOI": "arXiv:1907.10121v1",
    "Article_Title": "SciPy 1.0--Fundamental Algorithms for Scientific Computing in Python",
    "Article_Abstract": "SciPy is an open source scientific computing library for the Pythonprogramming language. SciPy 1.0 was released in late 2017, about 16 years afterthe original version 0.1 release. SciPy has become a de facto standard forleveraging scientific algorithms in the Python programming language, with morethan 600 unique code contributors, thousands of dependent packages, over100,000 dependent repositories, and millions of downloads per year. Thisincludes usage of SciPy in almost half of all machine learning projects onGitHub, and usage by high profile projects including LIGO gravitational waveanalysis and creation of the first-ever image of a black hole (M87). Thelibrary includes functionality spanning clustering, Fourier transforms,integration, interpolation, file I/O, linear algebra, image processing,orthogonal distance regression, minimization algorithms, signal processing,sparse matrix handling, computational geometry, and statistics. In this work,we provide an overview of the capabilities and development practices of theSciPy library and highlight some recent technical developments.",
    "Article_Subject": "Mathematical Software (cs.MS); Data Structures and Algorithms (cs.DS); Software Engineering (cs.SE); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/07/23",
    "Article_PDF": "https://arxiv.org/pdf/1907.10121"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.09600",
    "DOI": "arXiv:1907.09600v2",
    "Article_Title": "Evaluation of Embeddings of Laboratory Test Codes for Patients at a Cancer Center",
    "Article_Abstract": "Laboratory test results are an important and generally high dimensionalcomponent of a patient's Electronic Health Record (EHR). We train embeddingrepresentations (via Word2Vec and GloVe) for LOINC codes of laboratory testsfrom the EHRs of about 80,000 patients at a cancer center. To includeinformation about lab test outcomes, we also train embeddings on theconcatenation of a LOINC code with a symbol indicating normality or abnormalityof the result. We observe several clinically meaningful similarities amongLOINC embeddings trained over our data. For the embeddings of the concatenationof LOINCs with abnormality codes, we evaluate the performance for mortalityprediction tasks and the ability to preserve ordinality properties: i.e. a labtest with normal outcome should be more similar to an abnormal one than to thea very abnormal one.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/22",
    "Article_PDF": "https://arxiv.org/pdf/1907.09600"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.08395",
    "DOI": "arXiv:1907.08395v2",
    "Article_Title": "Refractive Interstellar Scintillation of Extra-galactic Radio Sources I: Expectations",
    "Article_Abstract": "Surveys for transient and variable phenomena can be confounded by thepresence of extrinsic variability such as refractive interstellar scintillation(RISS). We have developed an all-sky model for RISS which can predictvariability on a variety of timescales, survey locations, and observingfrequencies. The model makes use of Halpha intensity maps to probe the emissionmeasure along the line of sight, convert this to a scattering measure, andfinally a scintillation strength. The model uses previously developed and longunderstood physics along with (indirect) measurements of the electron contentand distribution within the Milky Way. We develop a set of expectations thatare useful in the planning of future surveys for transient and radiovariability, and demonstrate that the 1-GHz sky is a poor predictor of thevariable nature of the $100$-MHz sky. Interestingly, the correlation betweenthe incidence of variability and Galactic latitude which has been seen at 1GHz,is reversed at 100MHz. We compare the predictions of our model to alow-frequency radio survey that was conducted with the Murchison WidefieldArray, and find good qualitative agreement. We discuss the implications,current limitations, and future development of the model. The model has beenimplemented in a Python code and is available on GitHub/Zenodo.",
    "Article_Subject": "Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/07/19",
    "Article_PDF": "https://arxiv.org/pdf/1907.08395"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.07951",
    "DOI": "arXiv:1907.07951v1",
    "Article_Title": "Automatic vocal tract landmark localization from midsagittal MRI data",
    "Article_Abstract": "The various speech sounds of a language are obtained by varying the shape andposition of the articulators surrounding the vocal tract. Analyzing theirvariability is crucial for understanding speech production, diagnosing speechand swallowing disorders and building intuitive applications forrehabilitation. Magnetic Resonance Imaging (MRI) is currently the most harmlesspowerful imaging modality used for this purpose. Identifying key anatomicallandmarks on it is a pre-requisite for further analyses. This is a challengingtask considering the high inter- and intra-speaker variability and the mutualinteraction between the articulators. This study intends to solve this issueautomatically for the first time. For this purpose, midsagittal anatomical MRIfor 9 speakers sustaining 62 articulations and annotated with the location of21 key anatomical landmarks are considered. Four state-of-the-art methods,including deep learning methods, are adapted from the literature for faciallandmark localization and human pose estimation and evaluated. Furthermore, anapproach based on the description of each landmark location as a heat-map imagestored in a channel of a single multi-channel image embedding all landmarks isproposed. The generation of such a multi-channel image from an input MRI imageis tested through two deep learning networks, one taken from the literature andone designed on purpose in this study, the flat-net. Results show that theflat-net approach outperforms the other methods, leading to an overall RootMean Square Error of 3.4~pixels/0.34~cm obtained in a leave-one-out procedureover the speakers. All of the codes are publicly available on GitHub.",
    "Article_Subject": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "Article_Date": "2019/07/18",
    "Article_PDF": "https://arxiv.org/pdf/1907.07951"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.06274",
    "DOI": "arXiv:1907.06274v1",
    "Article_Title": "Predicting Merge Conflicts in Collaborative Software Development",
    "Article_Abstract": "Background. During collaborative software development, developers often usebranches to add features or fix bugs. When merging changes from two branches,conflicts may occur if the changes are inconsistent. Developers need to resolvethese conflicts before completing the merge, which is an error-prone andtime-consuming process. Early detection of merge conflicts, which warnsdevelopers about resolving conflicts before they become large and complicated,is among the ways of dealing with this problem. Existing techniques do this bycontinuously pulling and merging all combinations of branches in the backgroundto notify developers as soon as a conflict occurs, which is a computationallyexpensive process. One potential way for reducing this cost is to use amachine-learning based conflict predictor that filters out the merge scenariosthat are not likely to have conflicts, ie safe merge scenarios. Aims. In thispaper, we assess if conflict prediction is feasible. Method. We design aclassifier for predicting merge conflicts, based on 9 light-weight Git featuresets. To evaluate our predictor, we perform a large-scale study on 267, 657merge scenarios from 744 GitHub repositories in seven programming languages.Results. Our results show that we achieve high f1-scores, varying from 0.95 to0.97 for different programming languages, when predicting safe merge scenarios.The f1-score is between 0.57 and 0.68 for the conflicting merge scenarios.Conclusions. Predicting merge conflicts is feasible in practice, especially inthe context of predicting safe merge scenarios as a pre-filtering step forspeculative merging.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/07/14",
    "Article_PDF": "https://arxiv.org/pdf/1907.06274"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.06146",
    "DOI": "arXiv:1907.06146v1",
    "Article_Title": "Satellite System Graph: Towards the Efficiency Up-Boundary of Graph-Based Approximate Nearest Neighbor Search",
    "Article_Abstract": "Approximate Nearest Neighbor Search (ANNS) in high dimensional space isessential in database and information retrieval. Recently, there has been asurge of interests in exploring efficient graph-based indices for the ANNSproblem. Among them, the NSG has resurrected the theory of Monotonic SearchNetworks (MSNET) and achieved the state-of-the-art performance. However, theperformance of the NSG deviates from a potentially optimal position due to thehigh sparsity of the graph. Specifically, though the average degree of thegraph is small, their search algorithm travels a longer way to reach the query.Integrating both factors, the total search complexity (i.e., the number ofdistance calculations) is not minimized as their wish. In addition, NSG suffersfrom a high indexing time complexity, which limits the efficiency and thescalability of their method. In this paper, we aim to further mine thepotential of the MSNETs. Inspired by the message transfer mechanism of thecommunication satellite system, we find a new family of MSNETs, namely theSatellite System Graphs (SSG). In particular, while inheriting the superiorANNS properties from the MSNET, we try to ensure the angles between the edgesto be no smaller than a given value. Consequently, each node in the graphbuilds effective connections to its neighborhood omnidirectionally, whichensures an efficient search-routing on the graph like the message transferamong the satellites. We also propose an approximation of the SSG, NavigatingSSG, to increase the efficiency of indexing. Both theoretical and extensiveexperimental analysis are provided to demonstrate the strengths of the proposedapproach over the existing state-of-the-art algorithms. Our code has beenreleased on GitHub.",
    "Article_Subject": "Information Retrieval (cs.IR); Databases (cs.DB)",
    "Article_Date": "2019/07/13",
    "Article_PDF": "https://arxiv.org/pdf/1907.06146"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.05062",
    "DOI": "arXiv:1907.05062v1",
    "Article_Title": "FIRE: Unsupervised bi-directional inter-modality registration using deep networks",
    "Article_Abstract": "Inter-modality image registration is an critical preprocessing step for manyapplications within the routine clinical pathway. This paper presents anunsupervised deep inter-modality registration network that can learn theoptimal affine and non-rigid transformations simultaneously.Inverse-consistency is an important property commonly ignored in recent deeplearning based inter-modality registration algorithms. We address this issuethrough the proposed multi-task architecture and the new comprehensivetransformation network. Specifically, the proposed model learns amodality-independent latent representation to perform cycle-consistentcross-modality synthesis, and use an inverse-consistent loss to learn a pair oftransformations to align the synthesized image with the target. We name thisproposed framework as FIRE due to the shape of its structure. Our method showscomparable and better performances with the popular baseline method inexperiments on multi-sequence brain MR data and intra-modality 4D cardiacCine-MR data.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/07/11",
    "Article_PDF": "https://arxiv.org/pdf/1907.05062"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04908",
    "DOI": "arXiv:1907.04908v1",
    "Article_Title": "Executability of Python Snippets in Stack Overflow",
    "Article_Abstract": "Online resources today contain an abundant amount of code snippets fordocumentation, collaboration, learning, and problem-solving purposes. Theirexecutability in a \"plug and play\" manner enables us to confirm their qualityand use them directly in projects. But, in practice that is often not the casedue to several requirements violations or incompleteness. However, it is adifficult task to investigate the executability on a large scale due todifferent possible errors during the execution. We have developed a scalableframework to investigate this for SOTorrent Python snippets. We found that withminor adjustments, 27.92% of snippets are executable. The executability has notchanged significantly over time. The code snippets referenced in GitHub aremore likely to be directly executable. But executability does not affect thechances of the answer to be selected as the accepted answer significantly.These properties help us understand and improve the interaction of users withonline resources that include code snippets.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/07/10",
    "Article_PDF": "https://arxiv.org/pdf/1907.04908"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04527",
    "DOI": "arXiv:1907.04527v1",
    "Article_Title": "Dynamics of Team Library Adoptions: An Exploration of GitHub Commit Logs",
    "Article_Abstract": "When a group of people strives to understand new information, struggle ensuesas various ideas compete for attention. Steep learning curves are surmounted asteams learn together. To understand how these team dynamics play out insoftware development, we explore Git logs, which provide a complete changehistory of software repositories. In these repositories, we observe codeadditions, which represent successfully implemented ideas, and code deletions,which represent ideas that have failed or been superseded. By examining thepatterns between these commit types, we can begin to understand how teams adoptnew information. We specifically study what happens after a software library isadopted by a project, i.e., when a library is used for the first time in theproject. We find that a variety of factors, including team size, librarypopularity, and prevalence on Stack Overflow are associated with how quicklyteams learn and successfully adopt new software libraries.",
    "Article_Subject": "Social and Information Networks (cs.SI); Software Engineering (cs.SE)",
    "Article_Date": "2019/07/10",
    "Article_PDF": "https://arxiv.org/pdf/1907.04527"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04433",
    "DOI": "arXiv:1907.04433v1",
    "Article_Title": "GluonCV and GluonNLP: Deep Learning in Computer Vision and Natural Language Processing",
    "Article_Abstract": "We present GluonCV and GluonNLP, the deep learning toolkits for computervision and natural language processing based on Apache MXNet (incubating).These toolkits provide state-of-the-art pre-trained models, training scripts,and training logs, to facilitate rapid prototyping and promote reproducibleresearch. We also provide modular APIs with flexible building blocks to enableefficient customization. Leveraging the MXNet ecosystem, the deep learningmodels in GluonCV and GluonNLP can be deployed onto a variety of platforms withdifferent programming languages. Benefiting from open source under the Apache2.0 license, GluonCV and GluonNLP have attracted 100 contributors worldwide onGitHub. Models of GluonCV and GluonNLP have been downloaded for more than 1.6million times in fewer than 10 months.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/09",
    "Article_PDF": "https://arxiv.org/pdf/1907.04433"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.04002",
    "DOI": "arXiv:1907.04002v1",
    "Article_Title": "Characterizing Bitcoin donations to open source software on GitHub",
    "Article_Abstract": "Web-based hosting services for version control, such as GitHub, have made iteasier for people to develop, share, and donate money to software repositories.In this paper, we study the use of Bitcoin to make donations to open sourcerepositories on GitHub. In particular, we analyze the amount and volume ofdonations over time, in addition to its relationship to the age and popularityof a repository.  We scanned over three million repositories looking for donation addresses. Wethen extracted and analyzed their transactions from Bitcoin's publicblockchain. Overall, we found a limited adoption of Bitcoin as a payment methodfor receiving donations, with nearly 44 thousand deposits adding up to only 8.3million dollars in the last 10 years. We also found weak positive correlationbetween the amount of donations in dollars and the popularity of a repository,with highest correlation (r=0.013) associated with number of forks.",
    "Article_Subject": "Computers and Society (cs.CY); Cryptography and Security (cs.CR)",
    "Article_Date": "2019/07/09",
    "Article_PDF": "https://arxiv.org/pdf/1907.04002"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03892",
    "DOI": "arXiv:1907.03892v5",
    "Article_Title": "Fast Visual Object Tracking with Rotated Bounding Boxes",
    "Article_Abstract": "In this paper, we demonstrate a novel algorithm that uses ellipse fitting toestimate the bounding box rotation angle and size with the segmentation(mask)on the target for online and real-time visual object tracking. Our method,SiamMask_E, improves the bounding box fitting procedure of the state-of-the-artobject tracking algorithm SiamMask and still retains a fast-tracking frame rate(80 fps) on a system equipped with GPU (GeForce GTX 1080 Ti or higher). Wetested our approach on the visual object tracking datasets (VOT2016, VOT2018,and VOT2019) that were labeled with rotated bounding boxes. By comparing withthe original SiamMask, we achieved an improved Accuracy of 0.652 and 0.309 EAOon VOT2019, which is 0.056 and 0.026 higher than the original SiamMask. Theimplementation is available on GitHub:https://github.com/baoxinchen/siammask_e.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/07/08",
    "Article_PDF": "https://arxiv.org/pdf/1907.03892"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03660",
    "DOI": "arXiv:1907.03660v2",
    "Article_Title": "Can Dark Matter be Geometry? A Case Study with Mimetic Dark Matter",
    "Article_Abstract": "We investigate the possibility of dark matter being a pure geometricaleffect, rather than a particle or a compact object, by exploring a specificmodified gravity model: mimetic dark matter. We present an alternativeformulation of the theory, closer to the standard cosmological perturbationtheory framework. We make manifest the presence of arbitrary parameters andextra functions, both at background level and at first order in perturbationtheory. We present the full set of independent equations of motion for thismodel, and we discuss the amount of tuning needed to match predictions of thetheory to actual data. By using the matter power spectrum and cosmic microwavebackground angular power spectra as benchmark observables, we explicitly showthat since there is no natural mechanism to generate adiabatic initialconditions in this specific model, extra fine-tuning is required. We modify thepublicly available Boltzmann code \\texttt{CLASS} to make accurate predictionsfor the observables in mimetic dark matter. Our modified version of\\texttt{CLASS} is available on GitHub. We have used mimetic dark matter as anillustration of how much one is allowed to change the initial conditions beforecontradicting observations when modifying the laws of gravity as described byGeneral Relativity but we point out that modifying gravity without providing anatural mechanism to generate adiabatic initial conditions will always lead tohighly fine-tuned models.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); General Relativity and Quantum Cosmology (gr-qc); High Energy Physics - Theory (hep-th)",
    "Article_Date": "2019/07/08",
    "Article_PDF": "https://arxiv.org/pdf/1907.03660"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03407",
    "DOI": "arXiv:1907.03407v1",
    "Article_Title": "On The Lag of Library Vulnerability Updates: An Investigation into the Repackage and Delivery of Security Fixes Within The npm JavaScript Ecosystem",
    "Article_Abstract": "Vulnerabilities in third-party libraries is a growing concern for thesoftware developer, as it poses risks not only to the software client itselfbut to the entire software ecosystem. To mitigate these risks, developers arestrongly recommended to update their dependencies. Recent studies show thataffected developers are not likely to respond to the vulnerability threat.However, another reason for the lag of vulnerability updates is due to slowrepackaging (i.e., package the vulnerability fix into a new version) anddelivery (i.e., affected client adopt the new version) of the fix. Tounderstand these lags of updates, we use both qualitative and quantitativeapproaches to conduct an empirical study on how 188 fixes were repackaged anddelivered across over eight hundred thousand releases of npm software clientshosted on GitHub. We report two lags: (1) lags in repackaging occur asvulnerability fixes are more likely to be bundled with other non-relatedupdates (i.e., about 83.33\\% of commits are not related to the fix) and (2)lags in the delivery are caused by clients that are more likely to adopt theminor fix than adopt the patch fix. Furthermore, other factors such asdownstream dependencies and severity do have an impact. We also find thatfreshness of packages does not impact the amount of lags. The identification ofthese two lags opens up different avenues on how to facilitate faster fixdelivery throughout a library ecosystem.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/07/08",
    "Article_PDF": "https://arxiv.org/pdf/1907.03407"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.03187",
    "DOI": "arXiv:1907.03187v1",
    "Article_Title": "Applying a Pre-trained Language Model to Spanish Twitter Humor Prediction",
    "Article_Abstract": "Our entry into the HAHA 2019 Challenge placed $3^{rd}$ in the classificationtask and $2^{nd}$ in the regression task. We describe our system andinnovations, as well as comparing our results to a Naive Bayes baseline. Alarge Twitter based corpus allowed us to train a language model from scratchfocused on Spanish and transfer that knowledge to our competition model. Toovercome the inherent errors in some labels we reduce our class confidence withlabel smoothing in the loss function. All the code for our project is includedin a GitHub repository for easy reference and to enable replication by others.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/07/06",
    "Article_PDF": "https://arxiv.org/pdf/1907.03187"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.02862",
    "DOI": "arXiv:1907.02862v1",
    "Article_Title": "Essential Motor Cortex Signal Processing: an ERP and functional connectivity MATLAB toolbox -- User Guide",
    "Article_Abstract": "The purpose of this document is to help individuals use the \"Essential MotorCortex Signal Processing MATLAB Toolbox\". The toolbox implements variousmethods for three major aspects of investigating human motor cortex fromNeuroscience view point: (1) ERP estimation and quantification, (2) CorticalFunctional Connectivity analysis and (3) EMG quantification. The toolbox --which is distributed under the terms of the GNU GENERAL PUBLIC LICENSE as a setof MATLAB R routines -- can be downloaded directly at the address:http://oset.ir/category.php?dir=Tools or from the public repository on GitHub,at address below: https://github.com/EsiSeraj/ERP Connectivity EMG Analysis  The purpose of this toolbox is threefold: 1. Extract theevent-related-potential (ERP) from preprocessed cerebral signals (i.e. EEG,MEG, etc.), identify and then quantify the event-relatedsynchronization/desynchronization (ERS/ERD) events. Both time-course dynamicsand time-frequency (TF) analyzes are included. 2. Measure, quantify anddemonstrate the cortical functional connectivity (CFC) across scalp electrodes.These set of functions can also be applied to various types of cerebral signals(i.e. electric and magnetic). 3. Quantify electromyogram (EMG) recorded fromactive muscles during performing motor tasks.",
    "Article_Subject": "Signal Processing (eess.SP); Computational Engineering, Finance, and Science (cs.CE); Image and Video Processing (eess.IV); Neurons and Cognition (q-bio.NC); Quantitative Methods (q-bio.QM)",
    "Article_Date": "2019/06/15",
    "Article_PDF": "https://arxiv.org/pdf/1907.02862"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.02202",
    "DOI": "arXiv:1907.02202v1",
    "Article_Title": "SEntiMoji: An Emoji-Powered Learning Approach for Sentiment Analysis in Software Engineering",
    "Article_Abstract": "Sentiment analysis has various application scenarios in software engineering(SE), such as detecting developers' emotions in commit messages and identifyingtheir opinions on Q&A forums. However, commonly used out-of-the-box sentimentanalysis tools cannot obtain reliable results on SE tasks and themisunderstanding of technical jargon is demonstrated to be the main reason.Then, researchers have to utilize labeled SE-related texts to customizesentiment analysis for SE tasks via a variety of algorithms. However, thescarce labeled data can cover only very limited expressions and thus cannotguarantee the analysis quality. To address such a problem, we turn to theeasily available emoji usage data for help. More specifically, we employemotional emojis as noisy labels of sentiments and propose a representationlearning approach that uses both Tweets and GitHub posts containing emojis tolearn sentiment-aware representations for SE-related texts. These emoji-labeledposts can not only supply the technical jargon, but also incorporate moregeneral sentiment patterns shared across domains. They as well as labeled dataare used to learn the final sentiment classifier. Compared to the existingsentiment analysis methods used in SE, the proposed approach can achievesignificant improvement on representative benchmark datasets. By furthercontrast experiments, we find that the Tweets make a key contribution to thepower of our approach. This finding informs future research not to unilaterallypursue the domain-specific resource, but try to transform knowledge from theopen domain through ubiquitous signals such as emojis.",
    "Article_Subject": "Software Engineering (cs.SE); Computation and Language (cs.CL)",
    "Article_Date": "2019/07/04",
    "Article_PDF": "https://arxiv.org/pdf/1907.02202"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00903",
    "DOI": "arXiv:1907.00903v1",
    "Article_Title": "Resolving the Multiple Withdrawal Attack on ERC20 Tokens",
    "Article_Abstract": "Custom tokens are an integral component of decentralized applications (dapps)deployed on Ethereum and other blockchain platforms. For Ethereum, the ERC20standard is a widely used token interface and is interoperable with manyexisting dapps, user interface platforms, and popular web applications (e.g.,exchange services). An ERC20 security issue, known as the \"multiple withdrawalattack\", was raised on GitHub and has been open since November 2016. The issueconcerns ERC20's defined method approve() which was envisioned as a way fortoken holders to give permission for other users and dapps to withdraw a cappednumber of tokens. The security issue arises when a token holder wants to adjustthe amount of approved tokens from N to M (this could be an increase ordecrease). If malicious, a user or dapp who is approved for N tokens canfront-run the adjustment transaction to first withdraw N tokens, then allow theapproval to be confirmed, and withdraw an additional M tokens. In this paper,we evaluate 10 proposed mitigations for this issues and find that no solutionis fully satisfactory. We then propose 2 new solutions that mitigate theattack, one of which fully fulfills constraints of the standard, and the secondone shows a general limitation in addressing this issue from ERC20's approvemethod.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00903"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00863",
    "DOI": "arXiv:1907.00863v1",
    "Article_Title": "Understanding GCC Builtins to Develop Better Tools",
    "Article_Abstract": "C programs can use compiler builtins to provide functionality that the Clanguage lacks. On Linux, GCC provides several thousands of builtins that arealso supported by other mature compilers, such as Clang and ICC. Maintainers ofother tools lack guidance on whether and which builtins should be implementedto support popular projects. To assist tool developers who want to support GCCbuiltins, we analyzed builtin use in 4,913 C projects from GitHub. We foundthat 37% of these projects relied on at least one builtin. Supporting anincreasing proportion of projects requires support of an exponentiallyincreasing number of builtins; however, implementing only 10 builtins alreadycovers over 30% of the projects. Since we found that many builtins in ourcorpus remained unused, the effort needed to support 90% of the projects ismoderate, requiring about 110 builtins to be implemented. For each project, weanalyzed the evolution of builtin use over time and found that the majority ofprojects mostly added builtins. This suggests that builtins are not a legacyfeature and must be supported in future tools. Systematic testing of builtinsupport in existing tools revealed that many lacked support for builtins eitherpartially or completely; we also discovered incorrect implementations invarious tools, including the formally verified CompCert compiler.",
    "Article_Subject": "Programming Languages (cs.PL); Software Engineering (cs.SE)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00863"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00652",
    "DOI": "arXiv:1907.00652v1",
    "Article_Title": "Avoiding Implementation Pitfalls of \"Matrix Capsules with EM Routing\" by Hinton et al",
    "Article_Abstract": "The recent progress on capsule networks by Hinton et al. has generatedconsiderable excitement in the machine learning community. The idea behind acapsule is inspired by a cortical minicolumn in the brain, whereby a verticallyorganised group of around 100 neurons receive common inputs, have commonoutputs, are interconnected, and may well constitute a fundamental computationunit of the cerebral cortex. However, Hinton's paper on \"Matrix Capsule with EMRouting'\" was unfortunately not accompanied by a release of source code, whichleft interested researchers attempting to implement the architecture andreproduce the benchmarks on their own. This has certainly slowed the progressof research building on this work. While writing our own implementation, wenoticed several common mistakes in other open source implementations that wecame across. In this paper we share some of these learnings, specificallyfocusing on three implementation pitfalls and how to avoid them: (1) parentcapsules with only one child; (2) normalising the amount of data assigned toparent capsules; (3) parent capsules at different positions compete for childcapsules. While our implementation is a considerable improvement over currentlyavailable implementations, it still falls slightly short of the performancereported by Hinton et al. (2018). The source code for this implementation isavailable on GitHub at the following URL:https://github.com/IBM/matrix-capsules-with-em-routing.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00652"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1907.00558",
    "DOI": "arXiv:1907.00558v1",
    "Article_Title": "Improved Forecasting of Cryptocurrency Price using Social Signals",
    "Article_Abstract": "Social media signals have been successfully used to develop large-scalepredictive and anticipatory analytics. For example, forecasting stock marketprices and influenza outbreaks. Recently, social data has been explored toforecast price fluctuations of cryptocurrencies, which are a novel disruptivetechnology with significant political and economic implications. In this paperwe leverage and contrast the predictive power of social signals, specificallyuser behavior and communication patterns, from multiple social platforms GitHuband Reddit to forecast prices for three cyptocurrencies with high developer andcommunity interest - Bitcoin, Ethereum, and Monero. We evaluate the performanceof neural network models that rely on long short-term memory units (LSTMs)trained on historical price data and social data against price only LSTMs andbaseline autoregressive integrated moving average (ARIMA) models, commonly usedto predict stock prices. Our results not only demonstrate that social signalsreduce error when forecasting daily coin price, but also show that the languageused in comments within the official communities on Reddit (r/Bitcoin,r/Ethereum, and r/Monero) are the best predictors overall. We observe thatmodels are more accurate in forecasting price one day ahead for Bitcoin (4%root mean squared percent error) compared to Ethereum (7%) and Monero (8%).",
    "Article_Subject": "Statistical Finance (q-fin.ST); Machine Learning (cs.LG); Social and Information Networks (cs.SI); Machine Learning (stat.ML)",
    "Article_Date": "2019/07/01",
    "Article_PDF": "https://arxiv.org/pdf/1907.00558"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.11976",
    "DOI": "arXiv:1906.11976v1",
    "Article_Title": "Multivariate Big Data Analysis for Intrusion Detection: 5 steps from the haystack to the needle",
    "Article_Abstract": "The research literature on cybersecurity incident detection & response isvery rich in automatic detection methodologies, in particular those based onthe anomaly detection paradigm. However, very little attention has been devotedto the diagnosis ability of the methods, aimed to provide useful information onthe causes of a given detected anomaly. This information is of utmostimportance for the security team to reduce the time from detection to response.In this paper, we present Multivariate Big Data Analysis (MBDA), a completeintrusion detection approach based on 5 steps to effectively handle massiveamounts of disparate data sources. The approach has been designed to deal withthe main characteristics of Big Data, that is, the high volume, velocity andvariety. The core of the approach is the Multivariate Statistical NetworkMonitoring (MSNM) technique proposed in a recent paper. Unlike in state of theart machine learning methodologies applied to the intrusion detection problem,when an anomaly is identified in MBDA the output of the system includes thedetail of the logs of raw information associated to this anomaly, so that thesecurity team can use this information to elucidate its root causes. MBDA isbased in two open software packages available in Github: the MEDA Toolbox andthe FCParser. We illustrate our approach with two case studies. The first onedemonstrates the application of MBDA to semistructured sources of information,using the data from the VAST 2012 mini challenge 2. This complete case study issupplied in a virtual machine available for download. In the second case studywe show the Big Data capabilities of the approach in data collected from a realnetwork with labeled attacks.",
    "Article_Subject": "Networking and Internet Architecture (cs.NI); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Other Statistics (stat.OT)",
    "Article_Date": "2019/06/27",
    "Article_PDF": "https://arxiv.org/pdf/1906.11976"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.11565",
    "DOI": "arXiv:1906.11565v2",
    "Article_Title": "EmotionX-KU: BERT-Max based Contextual Emotion Classifier",
    "Article_Abstract": "We propose a contextual emotion classifier based on a transferable languagemodel and dynamic max pooling, which predicts the emotion of each utterance ina dialogue. A representative emotion analysis task, EmotionX, requires toconsider contextual information from colloquial dialogues and to deal with aclass imbalance problem. To alleviate these problems, our model leverages theself-attention based transferable language model and the weighted cross entropyloss. Furthermore, we apply post-training and fine-tuning mechanisms to enhancethe domain adaptability of our model and utilize several machine learningtechniques to improve its performance. We conduct experiments on twoemotion-labeled datasets named Friends and EmotionPush. As a result, our modeloutperforms the previous state-of-the-art model and also shows competitiveperformance in the EmotionX 2019 challenge. The code will be available in theGithub page.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/06/27",
    "Article_PDF": "https://arxiv.org/pdf/1906.11565"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.11017",
    "DOI": "arXiv:1906.11017v1",
    "Article_Title": "A project-based course on software development for (engineering) research",
    "Article_Abstract": "This paper describes the motivation and design of a 10-week graduate coursethat teaches practices for developing research software; although offered by anengineering program, the content applies broadly to any field of scientificresearch where software may be developed. Topics taught in the course includelocal and remote version control, licensing and copyright, structuring Pythonmodules, testing and test coverage, continuous integration, packaging anddistribution, open science, software citation, and reproducibility basics,among others. Lectures are supplemented by in-class activities and discussions,and all course material is shared openly via GitHub. Coursework is heavilybased on a single, term-long project where students individually develop asoftware package targeted at their own research topic; all contributions mustbe submitted as pull requests and reviewed/merged by other students. The coursewas initially offered in Spring 2018 with 17 students enrolled, and will betaught again in Spring 2019.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/06/13",
    "Article_PDF": "https://arxiv.org/pdf/1906.11017"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.10506",
    "DOI": "arXiv:1906.10506v1",
    "Article_Title": "GaussPy+: A fully automated Gaussian decomposition package for emission line spectra",
    "Article_Abstract": "Our understanding of the dynamics of the interstellar medium is informed bythe study of the detailed velocity structure of emission line observations. Oneapproach to study the velocity structure is to decompose the spectra intoindividual velocity components; this leads to a description of the dataset thatis significantly reduced in complexity. However, this decomposition requiresfull automation lest it becomes prohibitive for large datasets, such asGalactic plane surveys. We developed GaussPy+, a fully automated Gaussiandecomposition package that can be applied to emission line datasets, especiallylarge surveys of HI and isotopologues of CO. We built our package upon theexisting GaussPy algorithm and significantly improved its performance for noisydata. New functionalities of GaussPy+ include: i) automated preparatory steps,such as an accurate noise estimation, which can also be used as standaloneapplications; ii) an improved fitting routine; iii) an automated spatialrefitting routine that can add spatial coherence to the decomposition resultsby refitting spectra based on neighbouring fit solutions. We thoroughly testedthe performance of GaussPy+ on synthetic spectra and a test field from theGalactic Ring Survey. We found that GaussPy+ can deal with cases of complexemission and even low to moderate signal-to-noise values.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Astrophysics of Galaxies (astro-ph.GA)",
    "Article_Date": "2019/06/25",
    "Article_PDF": "https://arxiv.org/pdf/1906.10506"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.10362",
    "DOI": "arXiv:1906.10362v1",
    "Article_Title": "EVulHunter: Detecting Fake Transfer Vulnerabilities for EOSIO's Smart Contracts at Webassembly-level",
    "Article_Abstract": "As one of the representative Delegated Proof-of-Stake (DPoS) blockchainplatforms, EOSIO's ecosystem grows rapidly in recent years. A number ofvulnerabilities and corresponding attacks of EOSIO's smart contracts have beendiscovered and observed in the wild, which caused a large amount of financialdamages. However, the majority of EOSIO's smart contracts are not open-sourced.As a result, the WebAssembly code may become the only available object to beanalyzed in most cases. Unfortunately, current tools are web-applicationoriented and cannot be applied to EOSIO WebAssembly code directly, which makesit more difficult to detect vulnerabilities from those smart contracts. In thispaper, we propose \\toolname, a static analysis tool that can be used to detectvulnerabilities from EOSIO WASM code automatically. We focus on one particulartype of vulnerabilities named \\textit{fake-transfer}, and the exploitation ofsuch vulnerabilities has led to millions of dollars in damages. To the best ofour knowledge, it is the first attempt to build an automatic tool to detectvulnerabilities of EOSIO's smart contracts. The experimental resultsdemonstrate that our tool is able to detect fake transfer vulnerabilitiesquickly and precisely. EVulHunter is available on GitHub\\footnote{Tool andbenchmarks: https://github.com/EVulHunter/EVulHunter} and YouTube\\footnote{Demovideo: https://youtu.be/5SJ0ZJKVZvw}.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/06/25",
    "Article_PDF": "https://arxiv.org/pdf/1906.10362"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.09808",
    "DOI": "arXiv:1906.09808v1",
    "Article_Title": "Recurrent Adversarial Service Times",
    "Article_Abstract": "Service system dynamics occur at the interplay between customer behaviour anda service provider's response. This kind of dynamics can effectively be modeledwithin the framework of queuing theory where customers' arrivals are describedby point process models. However, these approaches are limited by parametricassumptions as to, for example, inter-event time distributions. In this paper,we address these limitations and propose a novel, deep neural network solutionto the queuing problem. Our solution combines a recurrent neural network thatmodels the arrival process with a recurrent generative adversarial networkwhich models the service time distribution. We evaluate our methodology onvarious empirical datasets ranging from internet services (Blockchain, GitHub,Stackoverflow) to mobility service systems (New York taxi cab).",
    "Article_Subject": "Machine Learning (stat.ML); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/24",
    "Article_PDF": "https://arxiv.org/pdf/1906.09808"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08351",
    "DOI": "arXiv:1906.08351v1",
    "Article_Title": "Towards Lakosian Multilingual Software Design Principles",
    "Article_Abstract": "Large software systems often comprise programs written in differentprogramming languages. In the case when cross-language interoperability isaccomplished with a Foreign Function Interface (FFI), for example pybind11,Boost.Python, Emscripten, PyV8, or JNI, among many others, common softwareengineering tools, such as call-graph analysis, are obstructed by the opacityof the FFI. This complicates debugging and fosters potential inefficiency andsecurity problems. One contributing issue is that there is little rigoroussoftware design advice for multilingual software. In this paper, we present ourprogress towards a more rigorous design approach to multilingual software. Theapproach is based on the existing approach to the design of large-scale C++systems developed by Lakos. The Lakosian approach is one of the few designmethodologies to address physical design rather than just logical design. Usingthe MLSA toolkit developed in prior work for analysis of multilingual software,we focus in on one FFI -- the pybind11 FFI. An extension to the Lakosian C++design rules is proposed to address multilingual software that uses pybind11.Using a sample of 50 public GitHub repositories that use pybind11, we measurehow many repositories would currently satisfy these rules. We conclude with aproposed generalization of the pybind11-based rules for any multilingualsoftware using an FFI interface.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08351"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08101",
    "DOI": "arXiv:1906.08101v1",
    "Article_Title": "Pre-Training with Whole Word Masking for Chinese BERT",
    "Article_Abstract": "Bidirectional Encoder Representations from Transformers (BERT) has shownmarvelous improvements across various NLP tasks. Recently, an upgraded versionof BERT has been released with Whole Word Masking (WWM), which mitigate thedrawbacks of masking partial WordPiece tokens in pre-training BERT. In thistechnical report, we adapt whole word masking in Chinese text, that masking thewhole word instead of masking Chinese characters, which could bring anotherchallenge in Masked Language Model (MLM) pre-training task. The model wastrained on the latest Chinese Wikipedia dump. We aim to provide easyextensibility and better performance for Chinese BERT without changing anyneural architecture or even hyper-parameters. The model is verified on variousNLP tasks, across sentence-level to document-level, including sentimentclassification (ChnSentiCorp, Sina Weibo), named entity recognition (PeopleDaily, MSRA-NER), natural language inference (XNLI), sentence pair matching(LCQMC, BQ Corpus), and machine reading comprehension (CMRC 2018, DRCD, CAILRC). Experimental results on these datasets show that the whole word maskingcould bring another significant gain. Moreover, we also examine theeffectiveness of Chinese pre-trained models: BERT, ERNIE, BERT-wwm. We releasethe pre-trained model (both TensorFlow and PyTorch) on GitHub:https://github.com/ymcui/Chinese-BERT-wwm",
    "Article_Subject": "Computation and Language (cs.CL); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08101"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08085",
    "DOI": "arXiv:1906.08085v1",
    "Article_Title": "PLANE: An Extensible Open Source Framework for modeling the Internet of Drones",
    "Article_Abstract": "Python Library for simulating unManNed vehiclEs(PLANE) is an open sourcesoftware module, written in Python, that focuses on Unmanned Aerial Vehicles(UAVs), on their movements and on the mechanics of flight, thus devotingparticular attention to the equations that describe drones' movement. In thecontext of the Internet of Drones (IoD), the module can be widely used for thestudy of the mutual control of position/coordination in scenarios in whichdrones may find obstacles, as it happens in densely populated urban scenarios.Emphasis is put on ease of use, performance evaluation, documentation, andApplication Programming Interface (API) consistency. The software tool hasminimal dependencies and is distributed under MIT License. Source code,binaries, and documentation can be downloaded from GitHub.",
    "Article_Subject": "Robotics (cs.RO); Software Engineering (cs.SE)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08085"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.08058",
    "DOI": "arXiv:1906.08058v1",
    "Article_Title": "On the abandonment and survival of open source projects: An empirical investigation",
    "Article_Abstract": "Background: Evolution of open source projects frequently depends on a smallnumber of core developers. The loss of such core developers might bedetrimental for projects and even threaten their entire continuation. However,it is possible that new core developers assume the project maintenance andallow the project to survive. Aims: The objective of this paper is to provideempirical evidence on: 1) the frequency of project abandonment and survival, 2)the differences between abandoned and surviving projects, and 3) the motivationand difficulties faced when assuming an abandoned project. Method: We adopt amixed-methods approach to investigate project abandonment and survival. Wecarefully select 1,932 popular GitHub projects and recover the abandoned andsurviving projects, and conduct a survey with developers that have beeninstrumental in the survival of the projects. Results: We found that 315projects (16%) were abandoned and 128 of these projects (41%) survived becauseof new core developers who assumed the project development. The surveyindicates that (i) in most cases the new maintainers were aware of the projectabandonment risks when they started to contribute; (ii) their own usage of thesystems is the main motivation to contribute to such projects; (iii) human andsocial factors played a key role when making these contributions; and (iv) lackof time and the difficulty to obtain push access to the repositories are themain barriers faced by them. Conclusions: Project abandonment is a reality evenin large open source projects and our work enables a better understanding ofsuch risks, as well as highlights ways in avoiding them.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/06/19",
    "Article_PDF": "https://arxiv.org/pdf/1906.08058"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.07771",
    "DOI": "arXiv:1906.07771v1",
    "Article_Title": "Crop Lodging Prediction from UAV-Acquired Images of Wheat and Canola using a DCNN Augmented with Handcrafted Texture Features",
    "Article_Abstract": "Lodging, the permanent bending over of food crops, leads to poor plant growthand development. Consequently, lodging results in reduced crop quality, lowerscrop yield, and makes harvesting difficult. Plant breeders routinely evaluateseveral thousand breeding lines, and therefore, automatic lodging detection andprediction is of great value aid in selection. In this paper, we propose a deepconvolutional neural network (DCNN) architecture for lodging classificationusing five spectral channel orthomosaic images from canola and wheat breedingtrials. Also, using transfer learning, we trained 10 lodging detection modelsusing well-established deep convolutional neural network architectures. Ourproposed model outperforms the state-of-the-art lodging detection methods inthe literature that use only handcrafted features. In comparison to 10 DCNNlodging detection models, our proposed model achieves comparable results whilehaving a substantially lower number of parameters. This makes the proposedmodel suitable for applications such as real-time classification usinginexpensive hardware for high-throughput phenotyping pipelines. The GitHubrepository at https://github.com/FarhadMaleki/LodgedNet contains code andmodels.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/06/18",
    "Article_PDF": "https://arxiv.org/pdf/1906.07771"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.07637",
    "DOI": "arXiv:1906.07637v2",
    "Article_Title": "Periphery Plots for Contextualizing Heterogeneous Time-Based Charts",
    "Article_Abstract": "Patterns in temporal data can often be found across different scales, such asdays, weeks, and months, making effective visualization of time-based datachallenging. Here we propose a new approach for providing focus and context intime-based charts to enable interpretation of patterns across time scales. Ourapproach employs a focus zone with a time and a second axis, that can eitherrepresent quantities or categories, as well as a set of adjacent peripheryplots that can aggregate data along the time, value, or both dimensions. Wepresent a framework for periphery plots and describe two use cases thatdemonstrate the utility of our approach.",
    "Article_Subject": "Human-Computer Interaction (cs.HC)",
    "Article_Date": "2019/06/18",
    "Article_PDF": "https://arxiv.org/pdf/1906.07637"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.07505",
    "DOI": "arXiv:1906.07505v1",
    "Article_Title": "A Model-Based General Alternative to the Standardised Precipitation Index",
    "Article_Abstract": "In this paper, we introduce two new model-based versions of the widely-usedstandardized precipitation index (SPI) for detecting and quantifying themagnitude of extreme hydro-climatic events. Our analytical approach is based ongeneralized additive models for location, scale and shape (GAMLSS), which helpsas to overcome some limitations of the SPI. We compare our model-basedstandardised indices (MBSIs) with the SPI using precipitation data collectedbetween January 2004 - December 2013 (522 weeks) in Caapiranga, a road-lessmunicipality of Amazonas State. As a result, it is shown that the MBSI-1 is anindex with similar properties to the SPI, but with improved methodology. Incomparison to the SPI, our MBSI-1 index allows for the use of differentzero-augmented distributions, it works with more flexible time-scales, can beapplied to shorter records of data and also takes into account temporaldependencies in known seasonal behaviours. Our approach is implemented in an Rpackage, mbsi, available from Github.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/06/18",
    "Article_PDF": "https://arxiv.org/pdf/1906.07505"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.06905",
    "DOI": "arXiv:1906.06905v2",
    "Article_Title": "Manipulating the Difficulty of C-Tests",
    "Article_Abstract": "We propose two novel manipulation strategies for increasing and decreasingthe difficulty of C-tests automatically. This is a crucial step towardsgenerating learner-adaptive exercises for self-directed language learning andpreparing language assessment tests. To reach the desired difficulty level, wemanipulate the size and the distribution of gaps based on absolute and relativegap difficulty predictions. We evaluate our approach in corpus-basedexperiments and in a user study with 60 participants. We find that bothstrategies are able to generate C-tests with the desired difficulty level.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/06/17",
    "Article_PDF": "https://arxiv.org/pdf/1906.06905"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.06583",
    "DOI": "arXiv:1906.06583v2",
    "Article_Title": "Linear regression with stationary errors : the R package slm",
    "Article_Abstract": "This paper introduces the R package slm which stands for Stationary LinearModels. The package contains a set of statistical procedures for linearregression in the general context where the error process is strictlystationary with short memory. We work in the setting of Hannan (1973), whoproved the asymptotic normality of the (normalized) least squares estimators(LSE) under very mild conditions on the error process. We propose differentways to estimate the asymptotic covariance matrix of the LSE, and then tocorrect the type I error rates of the usual tests on the parameters (as well asconfidence intervals). The procedures are evaluated through different sets ofsimulations, and two examples of real datasets are studied.",
    "Article_Subject": "Applications (stat.AP); Computation (stat.CO); Methodology (stat.ME)",
    "Article_Date": "2019/06/15",
    "Article_PDF": "https://arxiv.org/pdf/1906.06583"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.06317",
    "DOI": "arXiv:1906.06317v1",
    "Article_Title": "freud: A Software Suite for High Throughput Analysis of Particle Simulation Data",
    "Article_Abstract": "The freud Python package is a powerful library for analyzing simulation data.Written with modern simulation and data analysis workflows in mind, freudprovides a Python interface to fast, parallelized C++ routines that runefficiently on laptops, workstations, and supercomputing clusters. The packageprovides the core tools for finding particle neighbors in periodic systems, andoffers a uniform API to a wide variety of methods implemented using thesetools. As such, freud users can access standard methods such as the radialdistribution function as well as newer, more specialized methods such as thepotential of mean force and torque and local crystal environment analysis withequal ease. While many comparable tools place a heavy emphasis on reading andoperating on trajectory file formats, freud instead accepts numerical arrays ofdata directly as inputs. By remaining agnostic to its data source, freud issuitable for analyzing any coarse-grained particle simulation, regardless ofthe original data representation or simulation method. When used for on-the-flyanalysis in conjunction with scriptable simulation software such as HOOMD-blue,freud enables smart simulations that adapt to the current state of the system,allowing users to study phenomena such as nucleation and growth.",
    "Article_Subject": "Computational Physics (physics.comp-ph); Materials Science (cond-mat.mtrl-sci); Computational Engineering, Finance, and Science (cs.CE)",
    "Article_Date": "2019/06/14",
    "Article_PDF": "https://arxiv.org/pdf/1906.06317"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.05676",
    "DOI": "arXiv:1906.05676v1",
    "Article_Title": "Sionnx: Automatic Unit Test Generator for ONNX Conformance",
    "Article_Abstract": "Open Neural Network Exchange (ONNX) is an open format to represent AI modelsand is supported by many machine learning frameworks. While ONNX definesunified and portable computation operators across various frameworks, theconformance tests for those operators are insufficient, which makes itdifficult to verify if an operator's behavior in an ONNX backend implementationcomplies with the ONNX standard. In this paper, we present the first automaticunit test generator named Sionnx for verifying the compliance of ONNXimplementation. First, we propose a compact yet complete set of rules todescribe the operator's attributes and the properties of its operands. Second,we design an Operator Specification Language (OSL) to provide a high-leveldescription for the operator's syntax. Finally, through this easy-to-usespecification language, we are able to build a full testing specification whichleverages LLVM TableGen to automatically generate unit tests for ONNX operatorswith much large coverage. Sionnx is lightweight and flexible to supportcross-framework verification. The Sionnx framework is open-sourced in thegithub repository (https://github.com/alibaba/Sionnx).",
    "Article_Subject": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/06/12",
    "Article_PDF": "https://arxiv.org/pdf/1906.05676"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.05603",
    "DOI": "arXiv:1906.05603v1",
    "Article_Title": "A review of available software for adaptive clinical trial design",
    "Article_Abstract": "Background/Aims: The increasing expense of the drug development process hasseen interest in the use of adaptive designs (ADs) grow substantially in recentyears. Accordingly, much research has been conducted to identify potentialbarriers to increasing the use of ADs in practice, and several articles haveargued that the availability of user-friendly software will be an importantstep in making ADs easier to implement. Therefore, in this paper we present areview of the current state of software availability for AD. Methods: We firstreview articles from 31 journals published in 2013-17 that relate tomethodology for adaptive trials, in order to assess how often code and softwarefor implementing novel ADs is made available at the time of publication. Wecontrast our findings against these journals' current policies on codedistribution. Secondly, we conduct additional searches of popular coderepositories, such as CRAN and GitHub, to identify further existinguser-contributed software for ADs. From this, we are able to direct interestedparties towards solutions for their problem of interest by classifyingavailable code by type of adaptation. Results: Only 29% of included articlesmade their code available in some form. In many instances, articles publishedin journals that had mandatory requirements on code provision still did notmake code available. There are several areas in which available software iscurrently limited or saturated. In particular, many packages are available toaddress group sequential design, but comparatively little code is present inthe public domain to determine biomarker-guided ADs. Conclusions: There is muchroom for improvement in the provision of software alongside AD publications.Additionally, whilst progress has been made, well-established software forvarious types of trial adaptation remains sparsely available.",
    "Article_Subject": "Computation (stat.CO)",
    "Article_Date": "2019/06/13",
    "Article_PDF": "https://arxiv.org/pdf/1906.05603"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.04554",
    "DOI": "arXiv:1906.04554v1",
    "Article_Title": "Principled Training of Neural Networks with Direct Feedback Alignment",
    "Article_Abstract": "The backpropagation algorithm has long been the canonical training method forneural networks. Modern paradigms are implicitly optimized for it, and numerousguidelines exist to ensure its proper use. Recently, synthetic gradientsmethods -where the error gradient is only roughly approximated - have garneredinterest. These methods not only better portray how biological brains arelearning, but also open new computational possibilities, such as updatinglayers asynchronously. Even so, they have failed to scale past simple taskslike MNIST or CIFAR-10. This is in part due to a lack of standards, leading toill-suited models and practices forbidding such methods from performing to thebest of their abilities. In this work, we focus on direct feedback alignmentand present a set of best practices justified by observations of the alignmentangles. We characterize a bottleneck effect that prevents alignment in narrowlayers, and hypothesize it may explain why feedback alignment methods have yetto scale to large convolutional networks.",
    "Article_Subject": "Machine Learning (stat.ML); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)",
    "Article_Date": "2019/06/11",
    "Article_PDF": "https://arxiv.org/pdf/1906.04554"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.04281",
    "DOI": "arXiv:1906.04281v1",
    "Article_Title": "Towards Amortized Ranking-Critical Training for Collaborative Filtering",
    "Article_Abstract": "Collaborative filtering is widely used in modern recommender systems. Recentresearch shows that variational autoencoders (VAEs) yield state-of-the-artperformance by integrating flexible representations from deep neural networksinto latent variable models, mitigating limitations of traditional linearfactor models. VAEs are typically trained by maximizing the likelihood (MLE) ofusers interacting with ground-truth items. While simple and often effective,MLE-based training does not directly maximize the recommendation-qualitymetrics one typically cares about, such as top-N ranking. In this paper weinvestigate new methods for training collaborative filtering models based onactor-critic reinforcement learning, to directly optimize thenon-differentiable quality metrics of interest. Specifically, we train a criticnetwork to approximate ranking-based metrics, and then update the actor network(represented here by a VAE) to directly optimize against the learned metrics.In contrast to traditional learning-to-rank methods that require to re-run theoptimization procedure for new lists, our critic-based method amortizes thescoring process with a neural network, and can directly provide the(approximate) ranking scores for new lists. Empirically, we show that theproposed methods outperform several state-of-the-art baselines, includingrecently-proposed deep learning approaches, on three large-scale real-worlddatasets. The code to reproduce the experimental results and figure plots is onGithub: https://github.com/samlobel/RaCT_CF",
    "Article_Subject": "Machine Learning (cs.LG); Information Retrieval (cs.IR); Machine Learning (stat.ML)",
    "Article_Date": "2019/06/10",
    "Article_PDF": "https://arxiv.org/pdf/1906.04281"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03951",
    "DOI": "arXiv:1906.03951v1",
    "Article_Title": "SCAN: A Scalable Neural Networks Framework Towards Compact and Efficient Models",
    "Article_Abstract": "Remarkable achievements have been attained by deep neural networks in variousapplications. However, the increasing depth and width of such models also leadto explosive growth in both storage and computation, which has restricted thedeployment of deep neural networks on resource-limited edge devices. To addressthis problem, we propose the so-called SCAN framework for networks training andinference, which is orthogonal and complementary to existing acceleration andcompression methods. The proposed SCAN firstly divides neural networks intomultiple sections according to their depth and constructs shallow classifiersupon the intermediate features of different sections. Moreover, attentionmodules and knowledge distillation are utilized to enhance the accuracy ofshallow classifiers. Based on this architecture, we further propose a thresholdcontrolled scalable inference mechanism to approach human-like sample-specificinference. Experimental results show that SCAN can be easily equipped onvarious neural networks without any adjustment on hyper-parameters or neuralnetworks architectures, yielding significant performance gain on CIFAR100 andImageNet. Codes will be released on github soon.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/27",
    "Article_PDF": "https://arxiv.org/pdf/1906.03951"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03773",
    "DOI": "arXiv:1906.03773v1",
    "Article_Title": "DataLearner: A Data Mining and Knowledge Discovery Tool for Android Smartphones and Tablets",
    "Article_Abstract": "Smartphones have become the ultimate 'personal' computer, yet despite this,general-purpose data-mining and knowledge discovery tools for mobile devicesare surprisingly rare. DataLearner is a new data-mining application designedspecifically for Android devices that imports the Weka data-mining engine andaugments it with algorithms developed by Charles Sturt University. Moreover,DataLearner can be expanded with additional algorithms. Combined, DataLearnerdelivers 40 classification, clustering and association rule mining algorithmsfor model training and evaluation without need for cloud computing resources ornetwork connectivity. It provides the same classification accuracy as PCs andlaptops, while doing so with acceptable processing speed and consumingnegligible battery life. With its ability to provide easy-to-use data-mining ona phone-size screen, DataLearner is a new portable, self-contained data-miningtool for remote, personalised and learning applications alike. DataLearnerfeatures four elements - this paper, the app available on Google Play, theGPL3-licensed source code on GitHub and a short video on YouTube.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/06/10",
    "Article_PDF": "https://arxiv.org/pdf/1906.03773"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03277",
    "DOI": "arXiv:1906.03277v1",
    "Article_Title": "xBIT: an easy to use scanning tool with machine learning abilities",
    "Article_Abstract": "xBIT is a tool for performing parameter scans in beyond the Standard Modeltheories. It's written in Python and fully open source. The main purpose ofxBIT is to provide an easy to use tool to help phenomenologists with theirdaily task: exploring the parameter space of new models. It was developed underthe impression of the SARAH/SPheno framework, but should be use-able with othertools as well that use the SLHA format to transfer data. It also supports bydefault MicrOmegas for dark matter calculations, HiggsBounds and HiggsSignalsfor checking the Higgs properties, and Vevacious for testing the vacuumstability. Classes for other tools can be added if necessary. In order toimprove the efficiency of the parameter scans, the recently proposed 'MachineLearning Scan' approach is included. For this purpose, xBIT uses pyTorch todeal with artificial neural networks.",
    "Article_Subject": "High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Experiment (hep-ex)",
    "Article_Date": "2019/06/07",
    "Article_PDF": "https://arxiv.org/pdf/1906.03277"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03049",
    "DOI": "arXiv:1906.03049v1",
    "Article_Title": "Computing Exact Guarantees for Differential Privacy",
    "Article_Abstract": "Quantification of the privacy loss associated with a randomised algorithm hasbecome an active area of research and $(\\varepsilon,\u03b4)$-differentialprivacy has arisen as the standard measure of it. We propose a numerical methodfor evaluating the parameters of differential privacy for algorithms withcontinuous one dimensional output. In this way the parameters $\\varepsilon$ and$\u03b4$ can be evaluated, for example, for the subsampled multidimensionalGaussian mechanism which is also the underlying mechanism of differentiallyprivate stochastic gradient descent. The proposed method is based on anumerical approximation of an integral formula which gives the exact$(\\varepsilon,\u03b4)$-values. The approximation is carried out by discretisingthe integral and by evaluating discrete convolutions using a fast Fouriertransform algorithm. We give theoretical error bounds which show theconvergence of the approximation and guarantee its accuracy to an arbitrarydegree. Experimental comparisons with state-of-the-art techniques illustratethe efficacy of the method. Python code for the proposed method can be found inGithub (https://github.com/DPBayes/PLD-Accountant/).",
    "Article_Subject": "Machine Learning (stat.ML); Cryptography and Security (cs.CR); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/07",
    "Article_PDF": "https://arxiv.org/pdf/1906.03049"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.03008",
    "DOI": "arXiv:1906.03008v2",
    "Article_Title": "RankQA: Neural Question Answering with Answer Re-Ranking",
    "Article_Abstract": "The conventional paradigm in neural question answering (QA) for narrativecontent is limited to a two-stage process: first, relevant text passages areretrieved and, subsequently, a neural network for machine comprehensionextracts the likeliest answer. However, both stages are largely isolated in thestatus quo and, hence, information from the two phases is never properly fused.In contrast, this work proposes RankQA: RankQA extends the conventionaltwo-stage process in neural QA with a third stage that performs an additionalanswer re-ranking. The re-ranking leverages different features that aredirectly extracted from the QA pipeline, i.e., a combination of retrieval andcomprehension features. While our intentionally simple design allows for anefficient, data-sparse estimation, it nevertheless outperforms more complex QAsystems by a significant margin: in fact, RankQA achieves state-of-the-artperformance on 3 out of 4 benchmark datasets. Furthermore, its performance isespecially superior in settings where the size of the corpus is dynamic. Herethe answer re-ranking provides an effective remedy against the underlyingnoise-information trade-off due to a variable corpus size. As a consequence,RankQA represents a novel, powerful, and thus challenging baseline for futureresearch in content-based QA.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/06/07",
    "Article_PDF": "https://arxiv.org/pdf/1906.03008"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.02126",
    "DOI": "arXiv:1906.02126v1",
    "Article_Title": "Extractive Summarization via Weighted Dissimilarity and Importance Aligned Key Iterative Algorithm",
    "Article_Abstract": "We present importance aligned key iterative algorithm for extractivesummarization that is faster than conventional algorithms keeping its accuracy.The computational complexity of our algorithm is O($SNlogN$) to summarizeoriginal $N$ sentences into final $S$ sentences. Our algorithm maximizes theweighted dissimilarity defined by the product of importance and cosinedissimilarity so that the summary represents the document and at the same timethe sentences of the summary are not similar to each other. The weighteddissimilarity is heuristically maximized by iterative greedy search and binarysearch to the sentences ordered by importance. We finally show a benchmarkscore based on summarization of customer reviews of products, which highlightsthe quality of our algorithm comparable to human and existing algorithms. Weprovide the source code of our algorithm on githubhttps://github.com/qhapaq-49/imakita .",
    "Article_Subject": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/05/15",
    "Article_PDF": "https://arxiv.org/pdf/1906.02126"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.01388",
    "DOI": "arXiv:1906.01388v1",
    "Article_Title": "A Comprehensive Study on Deep Learning Bug Characteristics",
    "Article_Abstract": "Deep learning has gained substantial popularity in recent years. Developersmainly rely on libraries and tools to add deep learning capabilities to theirsoftware. What kinds of bugs are frequently found in such software? What arethe root causes of such bugs? What impacts do such bugs have? Which stages ofdeep learning pipeline are more bug prone? Are there any antipatterns?Understanding such characteristics of bugs in deep learning software has thepotential to foster the development of better deep learning platforms,debugging mechanisms, development practices, and encourage the development ofanalysis and verification frameworks. Therefore, we study 2716 high-qualityposts from Stack Overflow and 500 bug fix commits from Github about fivepopular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch tounderstand the types of bugs, root causes of bugs, impacts of bugs, bug-pronestage of deep learning pipeline as well as whether there are some commonantipatterns found in this buggy software. The key findings of our studyinclude: data bug and logic bug are the most severe bug types in deep learningsoftware appearing more than 48% of the times, major root causes of these bugsare Incorrect Model Parameter (IPS) and Structural Inefficiency (SI) showing upmore than 43% of the times. We have also found that the bugs in the usage ofdeep learning libraries have some common antipatterns that lead to a strongcorrelation of bug types among the libraries.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.01388"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.01211",
    "DOI": "arXiv:1906.01211v3",
    "Article_Title": "Raising the Performance of the Tinker-HP Molecular Modeling Package [Article v1.0]",
    "Article_Abstract": "This living paper reviews the present High Performance Computing (HPC)capabilities of the Tinker-HP molecular modeling package. We focus here on thereference, double precision, massively parallel molecular dynamics enginepresent in Tinker-HP and dedicated to perform large scale simulations. We showhow it can be adapted to recent Intel Central Processing Unit (CPU) petascalearchitectures. First, we discuss the new set of Intel Advanced VectorExtensions 512 (Intel AVX-512) instructions present in recent Intel processors(e.g., the Intel Xeon Scalable and Intel Xeon Phi 2nd generation processors)allowing for larger vectorization enhancements. These instructions constitutethe central source of potential computational gains when using the latestprocessors, justifying important vectorization efforts for developers. We thenbriefly review the organization of the Tinker-HP code and identify thecomputational hotspots which require Intel AVX-512 optimization and we proposea general and optimal strategy to vectorize those particular parts of the code.We intended to present our optimization strategy in a pedagogical way so itcould benefit to other researchers and students interested in gainingperformances in their own software. Finally we present the performanceenhancements obtained compared to the unoptimized code both sequentially and atthe scaling limit in parallel for classical non-polarizable (CHARMM) andpolarizable force fields (AMOEBA). This paper never ceases to be updated as weaccumulate new data on the associated Github repository between new versions ofthis living paper.",
    "Article_Subject": "Mathematical Software (cs.MS); Chemical Physics (physics.chem-ph); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/06/04",
    "Article_PDF": "https://arxiv.org/pdf/1906.01211"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.01032",
    "DOI": "arXiv:1906.01032v1",
    "Article_Title": "A Language-Agnostic Model for Semantic Source Code Labeling",
    "Article_Abstract": "Code search and comprehension have become more difficult in recent years dueto the rapid expansion of available source code. Current tools lack a way tolabel arbitrary code at scale while maintaining up-to-date representations ofnew programming languages, libraries, and functionalities. Comprehensivelabeling of source code enables users to search for documents of interest andobtain a high-level understanding of their contents. We use Stack Overflow codesnippets and their tags to train a language-agnostic, deep convolutional neuralnetwork to automatically predict semantic labels for source code documents. OnStack Overflow code snippets, we demonstrate a mean area under ROC of 0.957over a long-tailed list of 4,508 tags. We also manually validate the modeloutputs on a diverse set of unlabeled source code documents retrieved fromGithub, and we obtain a top-1 accuracy of 86.6%. This strongly indicates thatthe model successfully transfers its knowledge from Stack Overflow snippets toarbitrary source code documents.",
    "Article_Subject": "Machine Learning (cs.LG); Computation and Language (cs.CL); Software Engineering (cs.SE); Machine Learning (stat.ML)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.01032"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.00966",
    "DOI": "arXiv:1906.00966v3",
    "Article_Title": "Wotan: Comprehensive time-series de-trending in Python",
    "Article_Abstract": "The detection of transiting exoplanets in time-series photometry requires theremoval or modeling of instrumental and stellar noise. While instrumentalsystematics can be reduced using methods such as pixel level decorrelation,removing stellar trends while preserving transit signals proves challenging.Due to vast archives of light curves from recent transit surveys, there is astrong need for accurate automatic detrending, without human intervention. Alarge variety of detrending algorithms are in active use, but their comparativeperformance for transit discovery is unexplored. We benchmark all commonly useddetrending methods against hundreds of Kepler, K2, and TESS planets, selectedto represent the most difficult cases for systems with small planet-to-starradius ratios. The full parameter range is explored for each method todetermine the best choices for planet discovery. We conclude that the idealmethod is a time-windowed slider with an iterative robust location estimatorbased on Tukey's biweight. This method recovers 99% and 94% of the shallowestKepler and K2 planets, respectively. We include an additional analysis foryoung stars with extreme variability and conclude they are best treated using aspline-based method with a robust Huber estimator. All stellar detrendingmethods explored are available for public use in wotan, an open-source Pythonpackage on GitHub (see https://github.com/hippke/wotan).",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.00966"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.00925",
    "DOI": "arXiv:1906.00925v2",
    "Article_Title": "3D Appearance Super-Resolution with Deep Learning",
    "Article_Abstract": "We tackle the problem of retrieving high-resolution (HR) texture maps ofobjects that are captured from multiple view points. In the multi-view case,model-based super-resolution (SR) methods have been recently proved to recoverhigh quality texture maps. On the other hand, the advent of deep learning-basedmethods has already a significant impact on the problem of video and image SR.Yet, a deep learning-based approach to super-resolve the appearance of 3Dobjects is still missing. The main limitation of exploiting the power of deeplearning techniques in the multi-view case is the lack of data. We introduce a3D appearance SR (3DASR) dataset based on the existing ETH3D [42], SyB3R [31],MiddleBury, and our Collection of 3D scenes from TUM [21], Fountain [51] andRelief [53]. We provide the high- and low-resolution texture maps, the 3Dgeometric model, images and projection matrices. We exploit the power of 2Dlearning-based SR methods and design networks suitable for the 3D multi-viewcase. We incorporate the geometric information by introducing normal maps andfurther improve the learning process. Experimental results demonstrate that ourproposed networks successfully incorporate the 3D geometric information andsuper-resolve the texture maps.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.00925"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1906.00657",
    "DOI": "arXiv:1906.00657v1",
    "Article_Title": "Kandinsky Patterns",
    "Article_Abstract": "Kandinsky Figures and Kandinsky Patterns are mathematically describable,simple self-contained hence controllable test data sets for the development,validation and training of explainability in artificial intelligence. WhilstKandinsky Patterns have these computationally manageable properties, they areat the same time easily distinguishable from human observers. Consequently,controlled patterns can be described by both humans and computers. We define aKandinsky Pattern as a set of Kandinsky Figures, where for each figure an\"infallible authority\" defines that the figure belongs to the KandinskyPattern. With this simple principle we build training and validation data setsfor automatic interpretability and context learning. In this paper we describethe basic idea and some underlying principles of Kandinsky Patterns and providea Github repository to invite the international machine learning researchcommunity to a challenge to experiment with our Kandinsky Patterns to expandand thus make progress in the field of explainable AI and to contribute to theupcoming field of explainability and causability.",
    "Article_Subject": "Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/06/03",
    "Article_PDF": "https://arxiv.org/pdf/1906.00657"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.13658",
    "DOI": "arXiv:1905.13658v1",
    "Article_Title": "Ordinal Regression as Structured Classification",
    "Article_Abstract": "This paper extends the class of ordinal regression models with a structuredinterpretation of the problem by applying a novel treatment of encoded labels.The net effect of this is to transform the underlying problem from an ordinalregression task to a (structured) classification task which we solve withconditional random fields, thereby achieving a coherent and probabilistic modelin which all model parameters are jointly learnt. Importantly, we show thatalthough we have cast ordinal regression to classification, our method stillfall within the class of decomposition methods in the ordinal regressionontology. This is an important link since our experience is that manyapplications of machine learning to healthcare ignores completely the importantnature of the label ordering, and hence these approaches should considerednaive in this ontology. We also show that our model is flexible both in how itadapts to data manifolds and in terms of the operations that are available forpractitioner to execute. Our empirical evaluation demonstrates that theproposed approach overwhelmingly produces superior and often statisticallysignificant results over baseline approaches on forty popular ordinalregression models, and demonstrate that the proposed model significantlyout-performs baselines on synthetic and real datasets. Our implementation,together with scripts to reproduce the results of this work, will be availableon a public GitHub repository.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/31",
    "Article_PDF": "https://arxiv.org/pdf/1905.13658"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.13313",
    "DOI": "arXiv:1905.13313v5",
    "Article_Title": "Technical Report of the Video Event Reconstruction and Analysis (VERA) System -- Shooter Localization, Models, Interface, and Beyond",
    "Article_Abstract": "Every minute, hundreds of hours of video are uploaded to social media sitesand the Internet from around the world. This material creates a visual recordof the experiences of a significant percentage of humanity and can helpilluminate how we live in the present moment. When properly analyzed, thisvideo can also help analysts to reconstruct events of interest, including warcrimes, human rights violations, and terrorist acts. Machine learning andcomputer vision can play a crucial role in this process. In this technicalreport, we describe the Video Event Reconstruction and Analysis (VERA) system.This new tool brings together a variety of capabilities we have developed overthe past few years (including video synchronization and geolocation to orderunstructured videos lacking metadata over time and space, and sound recognitionalgorithms) to enable the reconstruction and analysis of events captured onvideo. Among other uses, VERA enables the localization of a shooter from just afew videos that include the sound of gunshots. To demonstrate the efficacy ofthis suite of tools, we present the results of estimating the shooter'slocation of the Las Vegas Shooting in 2017 and show that VERA accuratelypredicts the shooter's location using only the first few gunshots. We thenpoint out future directions that can help improve the system and further reduceunnecessary human labor in the process. All of the components of VERA runthrough a web interface that enables human-in-the-loop verification to ensureaccurate estimations. All relevant source code, including the web interface andmachine learning models, is freely available on Github. We hope thatresearchers and software developers will be inspired to improve and expand thissystem moving forward to better meet the needs of human rights and publicsafety.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multimedia (cs.MM)",
    "Article_Date": "2019/05/26",
    "Article_PDF": "https://arxiv.org/pdf/1905.13313"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.12768",
    "DOI": "arXiv:1905.12768v2",
    "Article_Title": "Using Propensity Scores to Develop and Evaluate Treatment Rules with Observational Data",
    "Article_Abstract": "In this paper, we outline a principled approach to estimate an individualizedtreatment rule that is appropriate for data from observational studies where,in addition to treatment assignment not being independent of individualcharacteristics, some characteristics may affect treatment assignment in thecurrent study but not be available in future clinical settings where theestimated rule would be applied. The estimation framework is quite flexible andaccommodates any prediction method that uses observation weights, where theobservation weights themselves are a ratio of two flexibly estimated propensityscores. We also discuss how to obtain a trustworthy estimate of the rule'spopulation benefit based on simple propensity-score-based estimators of averagetreatment effect. We implement our approach in the R package DevTreatRules andshare the code needed to reproduce our results on GitHub.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/05/29",
    "Article_PDF": "https://arxiv.org/pdf/1905.12768"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.12111",
    "DOI": "arXiv:1905.12111v1",
    "Article_Title": "Analyzing and Supporting Adaptation of Online Code Examples",
    "Article_Abstract": "Developers often resort to online Q&A forums such as Stack Overflow (SO) forfilling their programming needs. Although code examples on those forums aregood starting points, they are often incomplete and inadequate for developers'local program contexts; adaptation of those examples is necessary to integratethem to production code. As a consequence, the process of adapting online codeexamples is done over and over again, by multiple developers independently. Ourwork extensively studies these adaptations and variations, serving as the basisfor a tool that helps integrate these online code examples in a target contextin an interactive manner.  We perform a large-scale empirical study about the nature and extent ofadaptations and variations of SO snippets. We construct a comprehensive datasetlinking SO posts to GitHub counterparts based on clone detection, time stampanalysis, and explicit URL references. We then qualitatively inspect 400 SOexamples and their GitHub counterparts and develop a taxonomy of 24 adaptationtypes. Using this taxonomy, we build an automated adaptation analysis techniqueon top of GumTree to classify the entire dataset into these types. We build aChrome extension called ExampleStack that automatically lifts anadaptation-aware template from each SO example and its GitHub counterparts toidentify hot spots where most changes happen. A user study with sixteenprogrammers shows that seeing the commonalities and variations in similarGitHub counterparts increases their confidence about the given SO example, andhelps them grasp a more comprehensive view about how to reuse the exampledifferently and avoid common pitfalls.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/28",
    "Article_PDF": "https://arxiv.org/pdf/1905.12111"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.11830",
    "DOI": "arXiv:1905.11830v2",
    "Article_Title": "A Graph Theoretic Additive Approximation of Optimal Transport",
    "Article_Abstract": "Transportation cost is an attractive similarity measure between probabilitydistributions due to its many useful theoretical properties. However, solvingoptimal transport exactly can be prohibitively expensive. Therefore, there hasbeen significant effort towards the design of scalable approximationalgorithms. Previous combinatorial results [Sharathkumar, Agarwal STOC '12,Agarwal, Sharathkumar STOC '14] have focused primarily on the design ofstrongly polynomial multiplicative approximation algorithms. There has alsobeen an effort to design approximate solutions with additive errors [CuturiNIPS '13, Altschuler et. al NIPS '17, Dvurechensky et al., ICML '18, Quanrud,SOSA '19] within a time bound that is linear in the size of the cost matrix andpolynomial in $C/\u03b4$; here $C$ is the largest value in the cost matrix and$\u03b4$ is the additive error. We present an adaptation of the classical graphalgorithm of Gabow and Tarjan and provide a novel analysis of this algorithmthat bounds its execution time by $O(\\frac{n^2 C}\u03b4+\\frac{nC^2}{\u03b4^2})$. Our algorithm is extremely simple and executes, for anarbitrarily small constant $\\varepsilon$, only $\\lfloor\\frac{2C}{(1-\\varepsilon)\u03b4}\\rfloor + 1$ iterations, where each iterationconsists only of a Dijkstra search followed by a depth-first search. We alsoprovide empirical results that suggest our algorithm significantly outperformsexisting approaches in execution time.",
    "Article_Subject": "Machine Learning (cs.LG); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/28",
    "Article_PDF": "https://arxiv.org/pdf/1905.11830"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.11681",
    "DOI": "arXiv:1905.11681v2",
    "Article_Title": "Validating the Validation: Reanalyzing a large-scale comparison of Deep Learning and Machine Learning models for bioactivity prediction",
    "Article_Abstract": "Machine learning methods may have the potential to significantly acceleratedrug discovery. However, the increasing rate of new methodological approachesbeing published in the literature raises the fundamental question of how modelsshould be benchmarked and validated. We reanalyze the data generated by arecently published large-scale comparison of machine learning models forbioactivity prediction and arrive at a somewhat different conclusion. We showthat the performance of support vector machines is competitive with that ofdeep learning methods. Additionally, using a series of numerical experiments,we question the relevance of area under the receiver operating characteristiccurve as a metric in virtual screening, and instead suggest that area under theprecision-recall curve should be used in conjunction with the receiveroperating characteristic. Our numerical experiments also highlight challengesin estimating the uncertainty in model performance via scaffold-split nestedcross validation.",
    "Article_Subject": "Machine Learning (cs.LG); Chemical Physics (physics.chem-ph); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/28",
    "Article_PDF": "https://arxiv.org/pdf/1905.11681"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.11127",
    "DOI": "arXiv:1905.11127v1",
    "Article_Title": "DockerizeMe: Automatic Inference of Environment Dependencies for Python Code Snippets",
    "Article_Abstract": "Platforms like Stack Overflow and GitHub's gist system promote the sharing ofideas and programming techniques via the distribution of code snippets designedto illustrate particular tasks. Python, a popular and fast-growing programminglanguage, sees heavy use on both sites, with nearly one million questions askedon Stack Overflow and 400 thousand public gists on GitHub. Unfortunately,around 75% of the Python example code shared through these sites cannot bedirectly executed. When run in a clean environment, over 50% of public Pythongists fail due to an import error for a missing library.  We present DockerizeMe, a technique for inferring the dependencies needed toexecute a Python code snippet without import error. DockerizeMe starts withoffline knowledge acquisition of the resources and dependencies for popularPython packages from the Python Package Index (PyPI). It then builds Dockerspecifications using a graph-based inference procedure. Our inference procedureresolves import errors in 892 out of nearly 3,000 gists from the Gistabledataset for which Gistable's baseline approach could not find and install alldependencies.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/27",
    "Article_PDF": "https://arxiv.org/pdf/1905.11127"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.10536",
    "DOI": "arXiv:1905.10536v1",
    "Article_Title": "DeepRec: An Open-source Toolkit for Deep Learning based Recommendation",
    "Article_Abstract": "Deep learning based recommender systems have been extensively explored inrecent years. However, the large number of models proposed each year poses abig challenge for both researchers and practitioners in reproducing the resultsfor further comparisons. Although a portion of papers provides source code,they adopted different programming languages or different deep learningpackages, which also raises the bar in grasping the ideas. To alleviate thisproblem, we released the open source project: \\textbf{DeepRec}. In thistoolkit, we have implemented a number of deep learning based recommendationalgorithms using Python and the widely used deep learning package - Tensorflow.Three major recommendation scenarios: rating prediction, top-N recommendation(item ranking) and sequential recommendation, were considered. Meanwhile,DeepRec maintains good modularity and extensibility to easily incorporate newmodels into the framework. It is distributed under the terms of the GNU GeneralPublic License. The source code is available at github:\\url{https://github.com/cheungdaven/DeepRec}",
    "Article_Subject": "Information Retrieval (cs.IR); Machine Learning (cs.LG)",
    "Article_Date": "2019/05/25",
    "Article_PDF": "https://arxiv.org/pdf/1905.10536"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.09907",
    "DOI": "arXiv:1905.09907v1",
    "Article_Title": "Multi-level Texture Encoding and Representation (MuLTER) based on Deep Neural Networks",
    "Article_Abstract": "In this paper, we propose a multi-level texture encoding and representationnetwork (MuLTER) for texture-related applications. Based on a multi-levelpooling architecture, the MuLTER network simultaneously leverages low- andhigh-level features to maintain both texture details and spatial information.Such a pooling architecture involves few extra parameters and keeps featuredimensions fixed despite of the changes of image sizes. In comparison withstate-of-the-art texture descriptors, the MuLTER network yields higherrecognition accuracy on typical texture datasets such as MINC-2500 andGTOS-mobile with a discriminative and compact representation. In addition, weanalyze the impact of combining features from different levels, which supportsour claim that the fusion of multi-level features efficiently enhancesrecognition performance. Our source code will be published on GitHub(https://github.com/olivesgatech).",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/05/23",
    "Article_PDF": "https://arxiv.org/pdf/1905.09907"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.09717",
    "DOI": "arXiv:1905.09717v2",
    "Article_Title": "Network Pruning via Transformable Architecture Search",
    "Article_Abstract": "Network pruning reduces the computation costs of an over-parameterizednetwork without performance damage. Prevailing pruning algorithms pre-definethe width and depth of the pruned networks, and then transfer parameters fromthe unpruned network to pruned networks. To break the structure limitation ofthe pruned networks, we propose to apply neural architecture search to searchdirectly for a network with flexible channel and layer sizes. The number of thechannels/layers is learned by minimizing the loss of the pruned networks. Thefeature map of the pruned network is an aggregation of K feature map fragments(generated by K networks of different sizes), which are sampled based on theprobability distribution.The loss can be back-propagated not only to thenetwork weights, but also to the parameterized distribution to explicitly tunethe size of the channels/layers. Specifically, we apply channel-wiseinterpolation to keep the feature map with different channel sizes aligned inthe aggregation procedure. The maximum probability for the size in eachdistribution serves as the width and depth of the pruned network, whoseparameters are learned by knowledge transfer, e.g., knowledge distillation,from the original networks. Experiments on CIFAR-10, CIFAR-100 and ImageNetdemonstrate the effectiveness of our new perspective of network pruningcompared to traditional network pruning algorithms. Various searching andknowledge transfer approaches are conducted to show the effectiveness of thetwo components.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/05/23",
    "Article_PDF": "https://arxiv.org/pdf/1905.09717"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.09263",
    "DOI": "arXiv:1905.09263v4",
    "Article_Title": "FastSpeech: Fast, Robust and Controllable Text to Speech",
    "Article_Abstract": "Neural network based end-to-end text to speech (TTS) has significantlyimproved the quality of synthesized speech. Prominent methods (e.g., Tacotron2) usually first generate mel-spectrogram from text, and then synthesize speechfrom mel-spectrogram using vocoder such as WaveNet. Compared with traditionalconcatenative and statistical parametric approaches, neural network basedend-to-end models suffer from slow inference speed, and the synthesized speechis usually not robust (i.e., some words are skipped or repeated) and lack ofcontrollability (voice speed or prosody control). In this work, we propose anovel feed-forward network based on Transformer to generate mel-spectrogram inparallel for TTS. Specifically, we extract attention alignments from anencoder-decoder based teacher model for phoneme duration prediction, which isused by a length regulator to expand the source phoneme sequence to match thelength of target mel-spectrogram sequence for parallel mel-spectrogramgeneration. Experiments on the LJSpeech dataset show that our parallel modelmatches autoregressive models in terms of speech quality, nearly eliminates theproblem of word skipping and repeating in particularly hard cases, and canadjust voice speed smoothly. Most importantly, compared with autoregressiveTransformer TTS, our model speeds up the mel-spectrogram generation by 270x andthe end-to-end speech synthesis by 38x. Therefore, we call our modelFastSpeech. We will release the code on Github. Synthesized speech samples canbe found in https://speechresearch.github.io/fastspeech/.",
    "Article_Subject": "Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "Article_Date": "2019/05/22",
    "Article_PDF": "https://arxiv.org/pdf/1905.09263"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08880",
    "DOI": "arXiv:1905.08880v1",
    "Article_Title": "A Scalable Hybrid Research Paper Recommender System for Microsoft Academic",
    "Article_Abstract": "We present the design and methodology for the large scale hybrid paperrecommender system used by Microsoft Academic. The system providesrecommendations for approximately 160 million English research papers andpatents. Our approach handles incomplete citation information while alsoalleviating the cold-start problem that often affects other recommendersystems. We use the Microsoft Academic Graph (MAG), titles, and availableabstracts of research papers to build a recommendation list for all documents,thereby combining co-citation and content based approaches. Tuning systemparameters also allows for blending and prioritization of each approach which,in turn, allows us to balance paper novelty versus authority in recommendationresults. We evaluate the generated recommendations via a user study of 40participants, with over 2400 recommendation pairs graded and discuss thequality of the results using P@10 and nDCG scores. We see that there is astrong correlation between participant scores and the similarity rankingsproduced by our system but that additional focus needs to be put towardsimproving recommender precision, particularly for content basedrecommendations. The results of the user survey and associated analysis scriptsare made available via GitHub and the recommendations produced by our systemare available as part of the MAG on Azure to facilitate further research andlight up novel research paper recommendation applications.",
    "Article_Subject": "Digital Libraries (cs.DL); Information Retrieval (cs.IR); Machine Learning (cs.LG)",
    "Article_Date": "2019/05/21",
    "Article_PDF": "https://arxiv.org/pdf/1905.08880"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08667",
    "DOI": "arXiv:1905.08667v1",
    "Article_Title": "Legacy Archive for Microwave Background Data Analysis (LAMBDA): An Overview",
    "Article_Abstract": "This is an overview of the data products and other resources availablethrough NASA's LAMBDA site https://lambda.gsfc.nasa.gov/. An up-to-date versionof this document, along with code tools actively maintained and developed byLAMBDA staff, can be found on the LAMBDA GitHub page athttps://github.com/nasa-lambda/lambda_overview. New data products and otherupdates are announced on LAMBDA's twitter account athttps://twitter.com/NASA_LAMBDA. If you have questions or suggestions relatingto LAMBDA, or are interested in joining a LAMBDA advisory group, please contactus using the form here: https://lambda.gsfc.nasa.gov/contact/contact.cfm.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Article_Date": "2019/05/21",
    "Article_PDF": "https://arxiv.org/pdf/1905.08667"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08628",
    "DOI": "arXiv:1905.08628v1",
    "Article_Title": "Constraining the Parameters of High-Dimensional Models with Active Learning",
    "Article_Abstract": "Constraining the parameters of physical models with $>5-10$ parameters is awidespread problem in fields like particle physics and astronomy. In this paperwe show that this problem can be alleviated by the use of active learning. Weillustrate this with examples from high energy physics, a field wherecomputationally expensive simulations and large parameter spaces are common. Weshow that the active learning techniques query-by-committee andquery-by-dropout-committee allow for the identification of model points ininteresting regions of high-dimensional parameter spaces (e.g. around decisionboundaries). This makes it possible to constrain model parameters moreefficiently than is currently done with the most common sampling algorithms.Code implementing active learning can be found on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Instrumentation and Methods for Astrophysics (astro-ph.IM); High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Theory (hep-th)",
    "Article_Date": "2019/05/19",
    "Article_PDF": "https://arxiv.org/pdf/1905.08628"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.08094",
    "DOI": "arXiv:1905.08094v1",
    "Article_Title": "Be Your Own Teacher: Improve the Performance of Convolutional Neural Networks via Self Distillation",
    "Article_Abstract": "Convolutional neural networks have been widely deployed in variousapplication scenarios. In order to extend the applications' boundaries to someaccuracy-crucial domains, researchers have been investigating approaches toboost accuracy through either deeper or wider network structures, which bringswith them the exponential increment of the computational and storage cost,delaying the responding time. In this paper, we propose a general trainingframework named self distillation, which notably enhances the performance(accuracy) of convolutional neural networks through shrinking the size of thenetwork rather than aggrandizing it. Different from traditional knowledgedistillation - a knowledge transformation methodology among networks, whichforces student neural networks to approximate the softmax layer outputs ofpre-trained teacher neural networks, the proposed self distillation frameworkdistills knowledge within network itself. The networks are firstly divided intoseveral sections. Then the knowledge in the deeper portion of the networks issqueezed into the shallow ones. Experiments further prove the generalization ofthe proposed self distillation framework: enhancement of accuracy at averagelevel is 2.65%, varying from 0.61% in ResNeXt as minimum to 4.07% in VGG19 asmaximum. In addition, it can also provide flexibility of depth-wise scalableinference on resource-limited edge devices.Our codes will be released on githubsoon.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/17",
    "Article_PDF": "https://arxiv.org/pdf/1905.08094"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.07650",
    "DOI": "arXiv:1905.07650v1",
    "Article_Title": "SAWNet: A Spatially Aware Deep Neural Network for 3D Point Cloud Processing",
    "Article_Abstract": "Deep neural networks have established themselves as the state-of-the-artmethodology in almost all computer vision tasks to date. But their applicationto processing data lying on non-Euclidean domains is still a very active areaof research. One such area is the analysis of point cloud data which poses achallenge due to its lack of order. Many recent techniques have been proposed,spearheaded by the PointNet architecture. These techniques use either global orlocal information from the point clouds to extract a latent representation forthe points, which is then used for the task at hand(classification/segmentation). In our work, we introduce a neural network layerthat combines both global and local information to produce better embeddings ofthese points. We enhance our architecture with residual connections, to passinformation between the layers, which also makes the network easier to train.We achieve state-of-the-art results on the ModelNet40 dataset with ourarchitecture, and our results are also highly competitive with thestate-of-the-art on the ShapeNet part segmentation dataset and the indoor scenesegmentation dataset. We plan to open source our pre-trained models on githubto encourage the research community to test our networks on their data, orsimply use them for benchmarking purposes.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/05/18",
    "Article_PDF": "https://arxiv.org/pdf/1905.07650"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.06280",
    "DOI": "arXiv:1905.06280v1",
    "Article_Title": "Trustee: Full Privacy Preserving Vickrey Auction on top of Ethereum",
    "Article_Abstract": "The wide deployment of tokens for digital assets on top of Ethereum impliesthe need for powerful trading platforms. Vickrey auctions have been known todetermine the real market price of items as bidders are motivated to submittheir own monetary valuations without leaking their information to thecompetitors. Recent constructions have utilized various cryptographic protocolssuch as ZKP and MPC, however, these approaches either are partiallyprivacy-preserving or require complex computations with several rounds. In thispaper, we overcome these limits by presenting Trustee as a Vickrey auction onEthereum which fully preserves bids' privacy at relatively much lower fees.Trustee consists of three components: a front-end smart contract deployed onEthereum, an Intel SGX enclave, and a relay to redirect messages between them.Initially, the enclave generates an Ethereum account and ECDH key-pair.Subsequently, the relay publishes the account's address and ECDH public key onthe smart contract. As a prerequisite, bidders are encouraged to verify theauthenticity and security of Trustee by using the SGX remote attestationservice. To participate in the auction, bidders utilize the ECDH public key toencrypt their bids and submit them to the smart contract. Once the biddinginterval is closed, the relay retrieves the encrypted bids and feeds them tothe enclave that autonomously generates a signed transaction indicating theauction winner. Finally, the relay submits the transaction to the smartcontract which verifies the transaction's authenticity and the parameters'consistency before accepting the claimed auction winner. As part of ourcontributions, we have made a prototype for Trustee available on Github for thecommunity to review and inspect it. Additionally, we analyze the securityfeatures of Trustee and report on the transactions' gas cost incurred onTrustee smart contract.",
    "Article_Subject": "Cryptography and Security (cs.CR)",
    "Article_Date": "2019/05/15",
    "Article_PDF": "https://arxiv.org/pdf/1905.06280"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.04482",
    "DOI": "arXiv:1905.04482v1",
    "Article_Title": "GE852: A Dataset of 852 Game Engines",
    "Article_Abstract": "Game engines provide a platform for developers to build games with aninterface tailored to handle the complexity during game development. To reduceeffort and improve quality of game development, there is a strong need tounderstand and analyze the quality of game engines and their various aspectssuch as API usability, code quality, code reuse and so on. To the best ourknowledge, we are not aware of any dataset that caters to game engines in theliterature. To this end, we present GE852, a dataset of 852 game enginerepositories mined from GitHub in two languages, namely Java and C++. Thedataset contains metadata of all the mined repositories including commits, pullrequests, issues and so on. We believe that our dataset can lay foundation forempirical investigation in the area of game engines.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/11",
    "Article_PDF": "https://arxiv.org/pdf/1905.04482"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.04303",
    "DOI": "arXiv:1905.04303v1",
    "Article_Title": "Using Convolutional Neural Networks to identify Gravitational Lenses in Astronomical images",
    "Article_Abstract": "The Euclid telescope, due for launch in 2021, will perform an imaging andslitless spectroscopy survey over half the sky, to map baryon wiggles and weaklensing. During the survey Euclid is expected to resolve 100,000 stronggravitational lens systems. This is ideal to find rare lens configurations,provided they can be identified reliably and on a reasonable timescale. Forthis reason we have developed a Convolutional Neural Network (CNN) that can beused to identify images containing lensing systems. CNNs have already been usedfor image and digit classification as well as being used in astronomy forstar-galaxy classification. Here our CNN is trained and tested on Euclid-likeand KiDS-like simulations from the Euclid Strong Lensing Group, successfullyclassifying 77% of lenses, with an area under the ROC curve of up to 0.96. OurCNN also attempts to classify the lenses in COSMOS HST F814W-band images. Afterconvolution to the Euclid resolution, we find we can recover most systems thatare identifiable by eye. The Python code is available on Github.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Astrophysics of Galaxies (astro-ph.GA)",
    "Article_Date": "2019/05/10",
    "Article_PDF": "https://arxiv.org/pdf/1905.04303"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.04294",
    "DOI": "arXiv:1905.04294v1",
    "Article_Title": "Fruitbat: A Python Package for Estimating Redshifts of Fast Radio Bursts",
    "Article_Abstract": "Fruitbat is an open source Python 2/3 package for estimating redshifts,energies and the galactic dispersion measure contributions of fast radio bursts(FRBs). Fruitbat combines various dispersion measure (DM) and redshiftrelations with the YMW16 galactic dispersion measure model into a single easyto use API.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); High Energy Astrophysical Phenomena (astro-ph.HE)",
    "Article_Date": "2019/05/10",
    "Article_PDF": "https://arxiv.org/pdf/1905.04294"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.03593",
    "DOI": "arXiv:1905.03593v3",
    "Article_Title": "A Topological Analysis of Communication Channels for Knowledge Sharing in Contemporary GitHub Projects",
    "Article_Abstract": "With over 28 million developers, success of the GitHub collaborative platformis highlighted through an abundance of communication channels amongcontemporary software projects. Knowledge is broken into two forms and itssharing (through communication channels) can be described as externalization orcombination by the SECI model. Such platforms have revolutionized the waydevelopers work, introducing new channels to share knowledge in the form ofpull requests, issues and wikis. It is unclear how these channels capture andshare knowledge. In this research, our goal is to analyze these communicationchannels in GitHub. First, using the SECI model, we are able to map howknowledge is shared through the communication channels. Then in a large-scaletopology analysis of seven library package projects (i.e., involving over 70thousand projects), we extracted insights of the different communicationchannels within GitHub. Using two research questions, we explored the evolutionof the channels and adoption of channels by both popular and unpopular librarypackage projects. Results show that (i) contemporary GitHub Projects tend toadopt multiple communication channels, (ii) communication channels change overtime and (iii) communication channels are used to both capture new knowledge(i.e., externalization) and updating existing knowledge (i.e., combination).",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/09",
    "Article_PDF": "https://arxiv.org/pdf/1905.03593"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.02050",
    "DOI": "arXiv:1905.02050v1",
    "Article_Title": "Analyzing Code Comments to Boost Program Comprehension",
    "Article_Abstract": "We are trying to find source code comments that help programmers understand anontrivial part of source code. One of such examples would be explaining toassign a zero as a way to \"clear\" a buffer. Such comments are invaluable toprogrammers and identifying them correctly would be of great help. Toward thisgoal, we developed a method to discover explanatory code comments in a sourcecode. We first propose eleven distinct categories of code comments. We thendeveloped a decision-tree based classifier that can identify explanatorycomments with 60% precision and 80% recall. We analyzed 2,000 GitHub projectsthat are written in two languages: Java and Python. This task is novel in thatit focuses on a microscopic comment (\"local comment\") within a method orfunction, in contrast to the prior efforts that focused on API- or method-levelcomments. We also investigated how different category of comments is used indifferent projects. Our key finding is that there are two dominant types ofcomments: preconditional and postconditional. Our findings also suggest thatmany English code comments have a certain grammatical structure that areconsistent across different projects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/06",
    "Article_PDF": "https://arxiv.org/pdf/1905.02050"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.02005",
    "DOI": "arXiv:1905.02005v2",
    "Article_Title": "Deep Ordinal Reinforcement Learning",
    "Article_Abstract": "Reinforcement learning usually makes use of numerical rewards, which havenice properties but also come with drawbacks and difficulties. Using rewards onan ordinal scale (ordinal rewards) is an alternative to numerical rewards thathas received more attention in recent years. In this paper, a general approachto adapting reinforcement learning problems to the use of ordinal rewards ispresented and motivated. We show how to convert common reinforcement learningalgorithms to an ordinal variation by the example of Q-learning and introduceOrdinal Deep Q-Networks, which adapt deep reinforcement learning to ordinalrewards. Additionally, we run evaluations on problems provided by the OpenAIGym framework, showing that our ordinal variants exhibit a performance that iscomparable to the numerical variations for a number of problems. We also givefirst evidence that our ordinal variant is able to produce better results forproblems with less engineered and simpler-to-design reward signals.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/06",
    "Article_PDF": "https://arxiv.org/pdf/1905.02005"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.01833",
    "DOI": "arXiv:1905.01833v3",
    "Article_Title": "Characterizing and Detecting CUDA Program Bugs",
    "Article_Abstract": "While CUDA has become a major parallel computing platform and programmingmodel for general-purpose GPU computing, CUDA-induced bug patterns have not yetbeen well explored. In this paper, we conduct the first empirical study toreveal important categories of CUDA program bug patterns based on 319 bugsidentified within 5 popular CUDA projects in GitHub. Our findings demonstratethat CUDA-specific characteristics may cause program bugs such assynchronization bugs that are rather difficult to detect. To efficiently detectsuch synchronization bugs, we establish the first lightweight general CUDA bugdetection framework, namely Simulee, to simulate CUDA program execution byinterpreting the corresponding llvm bytecode and collecting the memory-accessinformation to automatically detect CUDA synchronization bugs. To evaluate theeffectiveness and efficiency of Simulee, we conduct a set of experiments andthe experimental results suggest that Simulee can detect 20 out of the 27studied synchronization bugs and successfully detects 26 previously unknownsynchronization bugs, 10 of which have been confirmed by the developers.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/05/06",
    "Article_PDF": "https://arxiv.org/pdf/1905.01833"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.00976",
    "DOI": "arXiv:1905.00976v2",
    "Article_Title": "Collaborative Evolutionary Reinforcement Learning",
    "Article_Abstract": "Deep reinforcement learning algorithms have been successfully applied to arange of challenging control tasks. However, these methods typically strugglewith achieving effective exploration and are extremely sensitive to the choiceof hyperparameters. One reason is that most approaches use a noisy version oftheir operating policy to explore - thereby limiting the range of exploration.In this paper, we introduce Collaborative Evolutionary Reinforcement Learning(CERL), a scalable framework that comprises a portfolio of policies thatsimultaneously explore and exploit diverse regions of the solution space. Acollection of learners - typically proven algorithms like TD3 - optimize overvarying time-horizons leading to this diverse portfolio. All learnerscontribute to and use a shared replay buffer to achieve greater sampleefficiency. Computational resources are dynamically distributed to favor thebest learners as a form of online algorithm selection. Neuroevolution bindsthis entire process to generate a single emergent learner that exceeds thecapabilities of any individual learner. Experiments in a range of continuouscontrol benchmarks demonstrate that the emergent learner significantlyoutperforms its composite learners while remaining overall moresample-efficient - notably solving the Mujoco Humanoid benchmark where all ofits composite learners (TD3) fail entirely in isolation.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/05/02",
    "Article_PDF": "https://arxiv.org/pdf/1905.00976"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1905.00221",
    "DOI": "arXiv:1905.00221v1",
    "Article_Title": "Concerns about the reliability of publicly available SNe Ia data",
    "Article_Abstract": "I highlight several concerns regarding the consistency of Type Ia supernovadata in the publicly available Pantheon and JLA compilations. The measuredheliocentric redshifts (zhel) of $\\sim$150 SNe Ia as reported in the Pantheoncatalogue are significantly discrepant from those in JLA - with 58 havingdifferences amounting to between 5 and 137 times the quoted measurementuncertainty. The discrepancy seems to have been introduced in the process ofrectifying a previously reported issue. The Pantheon catalogue until veryrecently had the redshifts of all SNe Ia up to z $\\sim$ 0.3 modified under theguise of 'peculiar velocity corrections' - although there is no information onpeculiar velocities at such high redshifts. While this has reportedly beenrectified on Github by removing peculiar velocity corrections for z > 0.08, theimpact of this on the published cosmological analysis of the Pantheon catalogueis not stated. In JLA, the effect of these 'corrections' is to significantlybias the inferred value of $\u03a9_\u039b$ towards higher values, while theequivalent effect on Pantheon cannot be ascertained due to the unavailabilityof the individual components of the covariance matrix in the public domain. Iprovide Jupyter notebooks and URLs in order to allow the reader to ascertainthe veracity of these assertions.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Article_Date": "2019/05/01",
    "Article_PDF": "https://arxiv.org/pdf/1905.00221"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.12903",
    "DOI": "arXiv:1904.12903v1",
    "Article_Title": "Modified Gravity Away from a $\\Lambda$CDM Background",
    "Article_Abstract": "Within the effective field theory approach to cosmic acceleration, thebackground expansion can be specified separately from the gravitationalmodifications. We explore the impact of modified gravity in a backgrounddifferent from a cosmological constant plus cold dark matter ($\u039b$CDM) onthe stability and cosmological observables, including covariance betweengravity and expansion parameters. In No Slip Gravity the more generalbackground allows more gravitational freedom, including both positive andnegative Planck mass running. We examine the effects on cosmic structuregrowth, as well as showing that a viable positive integrated Sachs-Wolfe effectcrosscorrelation easily arises from this modified gravity theory. Using currentdata we constrain parameters with a Monte Carlo analysis, finding a maximumrunning $|\u03b1_M|\\lesssim 0.03$. We provide the modified {\\tt hi\\_class} codepublicly on GitHub, now enabling computation and inclusion of the redshiftspace distortion observable $f\u03c3_8$ as well as the No Slip Gravitymodifications.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); General Relativity and Quantum Cosmology (gr-qc)",
    "Article_Date": "2019/04/29",
    "Article_PDF": "https://arxiv.org/pdf/1904.12903"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.11603",
    "DOI": "arXiv:1904.11603v1",
    "Article_Title": "Bayesian Factor Analysis for Inference on Interactions",
    "Article_Abstract": "This article is motivated by the problem of inference on interactions amongchemical exposures impacting human health outcomes. Chemicals often co-occur inthe environment or in synthetic mixtures and as a result exposure levels can behighly correlated. We propose a latent factor joint model, which includesshared factors in both the predictor and response components while assumingconditional independence. By including a quadratic regression in the latentvariables in the response component, we induce flexible dimension reduction incharacterizing main effects and interactions. We propose a Bayesian approach toinference under this Factor analysis for INteractions (FIN) framework. Throughappropriate modifications of the factor modeling structure, FIN can accommodatehigher order interactions and multivariate outcomes. We provide theory onposterior consistency and the impact of misspecifying the number of factors. Weevaluate the performance using a simulation study and data from the NationalHealth and Nutrition Examination Survey (NHANES). Code is available on GitHub.",
    "Article_Subject": "Methodology (stat.ME); Applications (stat.AP)",
    "Article_Date": "2019/04/25",
    "Article_PDF": "https://arxiv.org/pdf/1904.11603"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.11164",
    "DOI": "arXiv:1904.11164v1",
    "Article_Title": "PHANTOM: Curating GitHub for engineered software projects using time-series clustering",
    "Article_Abstract": "Context: Within the field of Mining Software Repositories, there are numerousmethods employed to filter datasets in order to avoid analysing low-qualityprojects. Unfortunately, the existing filtering methods have not kept up withthe growth of existing data sources, such as GitHub, and researchers often relyon quick and dirty techniques to curate datasets.  Objective: The objective of this study is to develop a method capable offiltering large quantities of software projects in a time-efficient way.  Method: This study follows the Design Science Research (DSR) methodology. Theproposed method, PHANTOM, extracts five measures from Git logs. Each measure istransformed into a time-series, which is represented as a feature vector forclustering using the k-means algorithm.  Results: Using the ground truth from a previous study, PHANTOM was shown tobe able to rediscover the ground truth with up to 0.87 Precision or 0.94Recall, and be able to identify \"well-engineered\" projects with up to 0.87Precision and 0.94 Recall on the validation dataset. PHANTOM downloaded andprocessed the metadata of 1,786,601 GitHub repositories in 21.5 days, which isover 33\\% faster than a similar study, which used a computer cluster of 200nodes.  Conclusions: It is possible to use an unsupervised approach to identifywell-engineering projects. PHANTOM was shown to be competitive compared to theexisting supervised approaches while reducing the hardware requirements by twoorders of magnitude.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/25",
    "Article_PDF": "https://arxiv.org/pdf/1904.11164"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10581",
    "DOI": "arXiv:1904.10581v2",
    "Article_Title": "Quantifying Correlated Truncation Errors in Effective Field Theory",
    "Article_Abstract": "Effective field theories (EFTs) organize the description of complex systemsinto an infinite sequence of decreasing importance. Predictions are made with afinite number of terms, which induces a truncation error that is often leftunquantified. We formalize the notion of EFT convergence and propose a Bayesiantruncation error model for predictions that are correlated across theindependent variables, e.g., energy or scattering angle. Central to ourapproach are Gaussian processes that encode both the naturalness andcorrelation structure of EFT coefficients. Our use of Gaussian processespermits efficient and accurate assessment of credible intervals, allows EFTfits to easily include correlated theory errors, and provides analyticposteriors for physical EFT-related quantities such as the expansion parameter.We demonstrate that model-checking diagnostics---applied to the case ofmultiple curves---are powerful tools for EFT validation. As an example, weassess a set of nucleon-nucleon scattering observables in chiral EFT. In aneffort to be self contained, appendices include thorough derivations of ourstatistical results. Our methods are packaged in Python code, called gsum, thatis available for download on GitHub.",
    "Article_Subject": "Nuclear Theory (nucl-th); High Energy Physics - Phenomenology (hep-ph); Nuclear Experiment (nucl-ex); Data Analysis, Statistics and Probability (physics.data-an)",
    "Article_Date": "2019/04/24",
    "Article_PDF": "https://arxiv.org/pdf/1904.10581"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10464",
    "DOI": "arXiv:1904.10464v1",
    "Article_Title": "$\\mathtt{bimEX}$: A Mathematica package for exact computations in 3$+$1 bimetric relativity",
    "Article_Abstract": "We present $\\mathtt{bimEX}$, a Mathematica package for exact computations in3$+$1 bimetric relativity. It is based on the $\\mathtt{xAct}$ bundle, which canhandle computations involving both abstract tensors and their components. Inthis communication, we refer to the latter case as concrete computations. Thepackage consists of two main parts. The first part involves the abstracttensors, and focuses on how to deal with multiple metrics in $\\mathtt{xAct}$.The second part takes an ansatz for the primary variables in a chart as theinput, and returns the covariant BSSN bimetric equations in components in thatchart. Several functions are implemented to make this process as fast anduser-friendly as possible. The package has been used and tested extensively inspherical symmetry and was the workhorse in obtaining the bimetric covariantBSSN equations and reproducing the bimetric 3$+$1 equations in the sphericalpolar chart.",
    "Article_Subject": "Symbolic Computation (cs.SC); Cosmology and Nongalactic Astrophysics (astro-ph.CO); Mathematical Software (cs.MS); General Relativity and Quantum Cosmology (gr-qc)",
    "Article_Date": "2019/04/23",
    "Article_PDF": "https://arxiv.org/pdf/1904.10464"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10255",
    "DOI": "arXiv:1904.10255v1",
    "Article_Title": "End-to-end Sleep Staging with Raw Single Channel EEG using Deep Residual ConvNets",
    "Article_Abstract": "Humans approximately spend a third of their life sleeping, which makesmonitoring sleep an integral part of well-being. In this paper, a 34-layer deepresidual ConvNet architecture for end-to-end sleep staging is proposed. Thenetwork takes raw single channel electroencephalogram (Fpz-Cz) signal as inputand yields hypnogram annotations for each 30s segments as output. Experimentsare carried out for two different scoring standards (5 and 6 stageclassification) on the expanded PhysioNet Sleep-EDF dataset, which containsmulti-source data from hospital and household polysomnography setups. Theperformance of the proposed network is compared with that of thestate-of-the-art algorithms in patient independent validation tasks. Theexperimental results demonstrate the superiority of the proposed networkcompared to the best existing method, providing a relative improvement inepoch-wise average accuracy of 6.8% and 6.3% on the household data andmulti-source data, respectively. Codes are made publicly available on Github.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/23",
    "Article_PDF": "https://arxiv.org/pdf/1904.10255"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.10247",
    "DOI": "arXiv:1904.10247v3",
    "Article_Title": "Free-form Video Inpainting with 3D Gated Convolution and Temporal PatchGAN",
    "Article_Abstract": "Free-form video inpainting is a very challenging task that could be widelyused for video editing such as text removal. Existing patch-based methods couldnot handle non-repetitive structures such as faces, while directly applyingimage-based inpainting models to videos will result in temporal inconsistency(see http://bit.ly/2Fu1n6b ). In this paper, we introduce a deep learn-ingbased free-form video inpainting model, with proposed 3D gated convolutions totackle the uncertainty of free-form masks and a novel Temporal PatchGAN loss toenhance temporal consistency. In addition, we collect videos and design afree-form mask generation algorithm to build the free-form video inpainting(FVI) dataset for training and evaluation of video inpainting models. Wedemonstrate the benefits of these components and experiments on both theFaceForensics and our FVI dataset suggest that our method is superior toexisting ones. Related source code, full-resolution result videos and the FVIdataset could be found on Githubhttps://github.com/amjltc295/Free-Form-Video-Inpainting .",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/04/23",
    "Article_PDF": "https://arxiv.org/pdf/1904.10247"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.09954",
    "DOI": "arXiv:1904.09954v1",
    "Article_Title": "Why Software Projects need Heroes (Lessons Learned from 1100+ Projects)",
    "Article_Abstract": "A \"hero\" project is one where 80% or more of the contributions are made bythe 20% of the developers. In the literature, such projects are deprecatedsince they might cause bottlenecks in development and communication. However,there is little empirical evidence on this matter. Further, recent studies showthat such hero projects are very prevalent. Accordingly, this paper exploresthe effect of having heroes in project, from a code quality perspective. Weidentify the heroes developer communities in 1100+ open source GitHub projects.Based on the analysis, we find that (a) hero projects are majorly all projects;and (b) the commits from \"hero developers\" (who contribute most to the code)result in far fewer bugs than other developers. That is, contrary to theliterature, heroes are standard and very useful part of modern open sourceprojects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/22",
    "Article_PDF": "https://arxiv.org/pdf/1904.09954"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.09416",
    "DOI": "arXiv:1904.09416v2",
    "Article_Title": "An Analysis of 35+ Million Jobs of Travis CI",
    "Article_Abstract": "Travis CI handles automatically thousands of builds every day to, amongstother things, provide valuable feedback to thousands of open-source developers.In this paper, we investigate Travis CI to firstly understand who is using it,and when they start to use it. Secondly, we investigate how the developers useTravis CI and finally, how frequently the developers change the Travis CIconfigurations. We observed during our analysis that the main users of TravisCI are corporate users such as Microsoft. And the programming languages used inTravis CI by those users do not follow the same popularity trend than onGitHub, for example, Python is the most popular language on Travis CI, but itis only the third one on GitHub. We also observe that Travis CI is set up onaverage seven days after the creation of the repository and the jobs are stillmainly used (60%) to run tests. And finally, we observe that 7.34% of thecommits modify the Travis CI configuration. We share the biggest benchmark ofTravis CI jobs (to our knowledge): it contains 35,793,144 jobs from 272,917different GitHub projects.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/20",
    "Article_PDF": "https://arxiv.org/pdf/1904.09416"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.09355",
    "DOI": "arXiv:1904.09355v2",
    "Article_Title": "Exoplanet Reflected Light Spectroscopy with PICASO",
    "Article_Abstract": "Here we present the first open-source radiative transfer model for computingthe reflected light of exoplanets at any phase geometry, called PICASO:Planetary Intensity Code for Atmospheric Scattering Observations. This code,written in Python, has heritage from a decades old, well-known Fortran modelused for several studies of planetary objects within the Solar System andbeyond. We have adopted it to include several methodologies for computing bothdirect and diffuse scattering phase functions, and have added several updatesincluding the ability to compute Raman scattering spectral features. Here webenchmark PICASO against two independent codes and discuss the degree to whichthe model is sensitive to a user's specification for various phase functions.Then, we conduct a full information content study of the model across a wideparameter space in temperature, cloud profile, SNR and resolving power.",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP)",
    "Article_Date": "2019/04/19",
    "Article_PDF": "https://arxiv.org/pdf/1904.09355"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.08315",
    "DOI": "arXiv:1904.08315v1",
    "Article_Title": "Multi-Level Mesa",
    "Article_Abstract": "Multi-level Mesa is an extension to support the Python based Agents BasedModel (ABM) library Mesa. Multi-level Mesa provides ABM infrastructure to allowfor the inclusion of complex networks, which have modules (groups) andhierarchies (layers) of agents. This approach allows for users to define andsimulate multi-layered adaptions of complex networks. This study reviews othermulti-level libraries currently in the field, describes the main functions andclasses of the Multi-level Mesa, and describes its implementation and impact innumerous varieties using the seminal ABM - Sugarscape. Multi-level Mesa andSugarscape examples are available on GitHub athttps://github.com/tpike3/multilevel_mesa andhttps://github.com/tpike3/SugarScape.",
    "Article_Subject": "Multiagent Systems (cs.MA)",
    "Article_Date": "2019/03/22",
    "Article_PDF": "https://arxiv.org/pdf/1904.08315"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07577",
    "DOI": "arXiv:1904.07577v1",
    "Article_Title": "ASD-DiagNet: A hybrid learning approach for detection of Autism Spectrum Disorder using fMRI data",
    "Article_Abstract": "Mental disorders such as Autism Spectrum Disorders (ASD) are heterogeneousdisorders that are notoriously difficult to diagnose, especially in children.The current psychiatric diagnostic process is based purely on the behaviouralobservation of symptomology (DSM-5/ICD-10) and may be prone to over-prescribingof drugs due to misdiagnosis. In order to move the field towards morequantitative fashion, we need advanced and scalable machine learninginfrastructure that will allow us to identify reliable biomarkers of mentalhealth disorders. In this paper, we propose a framework called ASD-DiagNet forclassifying subjects with ASD from healthy subjects by using only fMRI data. Wedesigned and implemented a joint learning procedure using an autoencoder and asingle layer perceptron which results in improved quality of extracted featuresand optimized parameters for the model. Further, we designed and implemented adata augmentation strategy, based on linear interpolation on available featurevectors, that allows us to produce synthetic datasets needed for training ofmachine learning models. The proposed approach is evaluated on a public datasetprovided by Autism Brain Imaging Data Exchange including 1035 subjects comingfrom 17 different brain imaging centers. Our machine learning model outperformsother state of the art methods from 13 imaging centers with increase inclassification accuracy up to 20% with maximum accuracy of 80%. The machinelearning technique presented in this paper, in addition to yielding betterquality, gives enormous advantages in terms of execution time (40 minutes vs. 6hours on other methods). The implemented code is available as GPL license onGitHub portal of our lab (https://github.com/pcdslab/ASD-DiagNet).",
    "Article_Subject": "Machine Learning (cs.LG); Image and Video Processing (eess.IV); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/16",
    "Article_PDF": "https://arxiv.org/pdf/1904.07577"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07387",
    "DOI": "arXiv:1904.07387v2",
    "Article_Title": "Predicting Fluid Intelligence of Children using T1-weighted MR Images and a StackNet",
    "Article_Abstract": "In this work, we utilize T1-weighted MR images and StackNet to predict fluidintelligence in adolescents. Our framework includes feature extraction, featurenormalization, feature denoising, feature selection, training a StackNet, andpredicting fluid intelligence. The extracted feature is the distribution ofdifferent brain tissues in different brain parcellation regions. The proposedStackNet consists of three layers and 11 models. Each layer uses thepredictions from all previous layers including the input layer. The proposedStackNet is tested on a public benchmark Adolescent Brain Cognitive DevelopmentNeurocognitive Prediction Challenge 2019 and achieves a mean squared error of82.42 on the combined training and validation set with 10-foldcross-validation. In addition, the proposed StackNet also achieves a meansquared error of 94.25 on the testing data. The source code is available onGitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/16",
    "Article_PDF": "https://arxiv.org/pdf/1904.07387"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07197",
    "DOI": "arXiv:1904.07197v1",
    "Article_Title": "Identification of Parameters for Large-scale Models in Systems Biology",
    "Article_Abstract": "Inverse problem for the identification of the parameters for large-scalesystems of nonlinear ordinary differential equations (ODEs) arising in systemsbiology is analyzed. In a recent paper in \\textit{Mathematical Biosciences,305(2018), 133-145}, the authors implemented the numerical method suggested byone of the authors in \\textit{J. Optim. Theory Appl., 85, 3(1995), 509-526} foridentification of parameters in moderate scale models of systems biology. Thismethod combines Pontryagin optimization or Bellman's quasilinearization withsensitivity analysis and Tikhonov regularization. We suggest modification ofthe method by embedding a method of staggered corrector for sensitivityanalysis and by enhancing multi-objective optimization which enablesapplication of the method to large-scale models with practicallynon-identifiable parameters based on multiple data sets, possibly with partialand noisy measurements. We apply the modified method to a benchmark model of athree-step pathway modeled by 8 nonlinear ODEs with 36 unknown parameters andtwo control input parameters. The numerical results demonstrate geometricconvergence with a minimum of five data sets and with minimum measurements perdata set. Software package \\textit{qlopt} is developed and posted in GitHub.MATLAB package AMIGO2 is used to demonstrate advantage of \\textit{qlopt} overmost popular methods/software such as \\textit{lsqnonlin}, \\textit{fmincon} and\\textit{nl2sol}.",
    "Article_Subject": "Quantitative Methods (q-bio.QM); Numerical Analysis (math.NA)",
    "Article_Date": "2019/04/15",
    "Article_PDF": "https://arxiv.org/pdf/1904.07197"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.07088",
    "DOI": "arXiv:1904.07088v1",
    "Article_Title": "P4-MACsec: Dynamic Topology Monitoring and Data Layer Protection with MACsec in P4-SDN",
    "Article_Abstract": "We propose P4-MACsec to protect network links between P4 switches throughautomated deployment of MACsec, a widespread IEEE standard for securing Layer 2infrastructures. It is supported by switches and routers from majormanufacturers and has only little performance limitations compared to VPNtechnologies such as IPsec. P4-MACsec introduces a data plane implementation ofMACsec including AES-GCM encryption and decryption directly on P4 switches.P4-MACsec features a two-tier control plane structure where local controllersrunning on the P4 switches interact with a central controller. We propose anovel secure link discovery mechanism that leverages protected LLDP frames andthe two-tier control plane structure for secure and efficient management of aglobal link map. Automated deployment of MACsec creates secure channel,generates keying material, and configures the P4 switches for each detectedlink between two P4 switches. It detects link changes and performs rekeying toprovide a secure, configuration-free operation of MACsec. In this paper, wereview the technological background of P4-MACsec and explain its architecture.To demonstrate the feasibility of P4-MACsec, we implement it on the BMv2 P4software switch and validate the prototype through experiments. We evaluate itsperformance through experiments that focus on TCP throughput and round-triptime. We publish the prototype and experiment setups on Github.",
    "Article_Subject": "Networking and Internet Architecture (cs.NI)",
    "Article_Date": "2019/04/15",
    "Article_PDF": "https://arxiv.org/pdf/1904.07088"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.05257",
    "DOI": "arXiv:1904.05257v1",
    "Article_Title": "Instance Segmentation of Biological Images Using Harmonic Embeddings",
    "Article_Abstract": "We present a new instance segmentation approach tailored to biologicalimages, where instances may correspond to individual cells, organisms or plantparts. Unlike instance segmentation for user photographs or road scenes, inbiological data object instances may be particularly densely packed, theappearance variation may be particularly low, the processing power may berestricted, while, on the other hand, the variability of sizes of individualinstances may be limited. These peculiarities are successfully addressed andexploited by the proposed approach.  Our approach describes each object instance using an expectation of a limitednumber of sine waves with frequencies and phases adjusted to particular objectsizes and densities. At train time, a fully-convolutional network is learned topredict the object embeddings at each pixel using a simple pixelwise regressionloss, while at test time the instances are recovered using clustering in theembeddings space. In the experiments, we show that our approach outperformsprevious embedding-based instance segmentation approaches on a number ofbiological datasets, achieving state-of-the-art on a popular CVPPP benchmark.Notably, this excellent performance is combined with computational efficiencythat is needed for deployment to domain specialists.  The source code is publicly available at Github:https://github.com/kulikovv/harmonic",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV)",
    "Article_Date": "2019/04/10",
    "Article_PDF": "https://arxiv.org/pdf/1904.05257"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.03801",
    "DOI": "arXiv:1904.03801v1",
    "Article_Title": "pdbmine: A Node.js API for the RCSB Protein Data Bank (PDB)",
    "Article_Abstract": "Summary: The advent of Web-based tools that assist in the analysis andvisualization of macromolecules require application programming interfaces(APIs) designed for modern web frameworks. To this end, we have developed aNode.js module pdbmine that allows any user to generate faster data-requestqueries to the RCSB Protein Data Bank (PDB). This JavaScript API acts as alayer over the XML-based RCSB PDB RESTful API. The relatively simple nature ofthe function calls within this module allows the user to easily implement andintegrate pdbmine into larger Node.js web applications.  Availability: This module can be installed via the Node Package Manager (NPM)at https://www.npmjs.com/package/pdbmine/, and is hosted on GitHub under theopen-source MIT license at https://github.com/nnj1/pdbmine/. Relevantdocumentation is detailed at https://nnj1.github.io/pdbmine/",
    "Article_Subject": "Genomics (q-bio.GN)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.03801"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.02724",
    "DOI": "arXiv:1904.02724v1",
    "Article_Title": "Bounties in Open Source Development on GitHub: A Case Study of Bountysource Bounties",
    "Article_Abstract": "Due to the voluntary nature of open source software, it can be hard to find adeveloper to work on a particular task. For example, some issue reports may betoo cumbersome and unexciting for someone to volunteer to do them, yet theseissue reports may be of high priority to the success of a project. To providean incentive for implementing such issue reports, one can propose a monetaryreward, i.e., a bounty, to the developer who completes that particular task. Inthis paper, we study bounties in open source projects on GitHub to betterunderstand how bounties can be leveraged to evolve such projects in terms ofaddressing issue reports. We investigated 5,445 bounties for GitHub projects.These bounties were proposed through the Bountysource platform with a totalbounty value of $406,425. We find that 1) in general, the timing of proposingbounties and the bounty-usage frequency are the most important factors thatimpact the likelihood of an issue being addressed. More specifically, issuereports are more likely to be addressed if they are for projects in whichbounties are used more frequently and if they are proposed earlier. 2) Thebounty value that an issue report has is the most important factor that impactsthe issue-addressing likelihood in the projects in which no bounties were usedbefore. Backers in such projects proposed higher bounty values to get issuesaddressed. 3) There is a risk of wasting money for backers who invest money onlong-standing issue reports.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/04",
    "Article_PDF": "https://arxiv.org/pdf/1904.02724"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.02414",
    "DOI": "arXiv:1904.02414v1",
    "Article_Title": "\"Won't We Fix this Issue?\" Qualitative Characterization and Automated Identification of Wontfix Issues on GitHub",
    "Article_Abstract": "Addressing users requests in the form of bug reports and Github issuesrepresents a crucial task of any successful software project. However,user-submitted issue reports tend to widely differ in their quality, anddevelopers spend a considerable amount of time handling these reports.Moreover, an inefficient prioritization of requested changes could have anegative impact on the developers' workloads. By collecting a dataset of around6,000 issues from the history of 323 GitHub projects, we observe thatdevelopers spend a long time (i.e., about five months, on average) beforelabeling an issue as a wontfix. For this reason, in this paper, we empiricallyinvestigate the nature of wontfix issues, by manually analyzing a sample of 800issues of this kind, extracted from heterogeneous projects. We explore thecommon reasons behind a \"wontfix decision\", the main characteristics of wontfixissues and the potential factors that could be connected with the time to closethem. Furthermore, we experiment approaches for just-in-time prediction ofwontfix issues using machine learning techniques to analyze the titles anddescriptions of reported issues. Our investigation shed some light on thewontfix issues' characteristics, as well as the potential factors that mayaffect the time required to make a \"wontfix decision\". Our results alsodemonstrate that it is possible to predict whether an issue will be closed as awontfix with average values of precision, recall, and F-measure close to 99%,confirming the practical usefulness of the proposed approach for improving theissue management practices on GitHub.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/04",
    "Article_PDF": "https://arxiv.org/pdf/1904.02414"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.01754",
    "DOI": "arXiv:1904.01754v1",
    "Article_Title": "Styler: Learning Formatting Conventions to Repair Checkstyle Errors",
    "Article_Abstract": "Formatting coding conventions play an important role on code readability. Inthis paper, we present Styler, an automatic repair tool dedicated to fixformatting-related errors raised by Checkstyle, a highly configurable formatchecker for Java. To fix formatting errors in a given project, Styler learnsfixes based on the Checkstyle ruleset defined in the project and predictsrepairs for the current errors using machine learning. In an empiricalevaluation, we found that Styler repaired 24% of 497 real Checkstyle errorsmined from five GitHub projects. Moreover, in a comparison of Styler with thestate-of-the-art machine learning code formatters Naturalize and CodeBuff, wefound that Styler is the tool that fixes more real Checkstyle errors and alsogenerates smaller repairs. Finally, we conclude that Styler is promising to beused in IDEs and in a Continuous Integration environment to repair Checkstyleerrors.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.01754"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.01740",
    "DOI": "arXiv:1904.01740v2",
    "Article_Title": "FaceQnet: Quality Assessment for Face Recognition based on Deep Learning",
    "Article_Abstract": "In this paper we develop a Quality Assessment approach for face recognitionbased on deep learning. The method consists of a Convolutional Neural Network,FaceQnet, that is used to predict the suitability of a specific input image forface recognition purposes. The training of FaceQnet is done using the VGGFace2database. We employ the BioLab-ICAO framework for labeling the VGGFace2 imageswith quality information related to their ICAO compliance level. Thegroundtruth quality labels are obtained using FaceNet to generate comparisonscores. We employ the groundtruth data to fine-tune a ResNet-based CNN, makingit capable of returning a numerical quality measure for each input image.Finally, we verify if the FaceQnet scores are suitable to predict the expectedperformance when employing a specific image for face recognition with a COTSface recognition system. Several conclusions can be drawn from this work, mostnotably: 1) we managed to employ an existing ICAO compliance framework and apretrained CNN to automatically label data with quality information, 2) wetrained FaceQnet for quality estimation by fine-tuning a pre-trained facerecognition network (ResNet-50), and 3) we have shown that the predictions fromFaceQnet are highly correlated with the face recognition accuracy of astate-of-the-art commercial system not used during development. FaceQnet ispublicly available in GitHub.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.01740"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.01738",
    "DOI": "arXiv:1904.01738v3",
    "Article_Title": "Adinkra Height Yielding Matrix Numbers: Eigenvalue Equivalence Classes for Minimal Four-Color Adinkras",
    "Article_Abstract": "An adinkra is a graph-theoretic representation of spacetime supersymmetry.Minimal four-color valise adinkras have been extensively studied due to theirrelations to minimal 4D, $\\cal N$ = 1 supermultiplets. Valise adinkras,although an important subclass, do not encode all the information present whena 4D supermultiplet is reduced to 1D. Eigenvalue equivalence classes for valiseadinkra matrices exist, known as $\u03c7_{\\rm o}$ equivalence classes, wherevalise adinkras within the same $\u03c7_{\\rm o}$ equivalence class are isomorphicin the sense that adinkras within a $\u03c7_{\\rm o}$-equivalence class can betransformed into each other via field redefinitions of the nodes. We extendthis to non-valise adinkras, via Python code, providing a complete eigenvalueclassification of \"node-lifting\" for all 36,864 valise adinkras associated withthe Coxeter group $BC{}_4$. We term the eigenvalues associated with thesenode-lifted adinkras Height Yielding Matrix Numbers (HYMNs) and introduce HYMNequivalence classes. These findings have been summarized in a $Mathematica$notebook that can found at the HEPTHools Data Repository(https://hepthools.github.io/Data/) on GitHub.",
    "Article_Subject": "High Energy Physics - Theory (hep-th); Representation Theory (math.RT)",
    "Article_Date": "2019/04/03",
    "Article_PDF": "https://arxiv.org/pdf/1904.01738"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.00935",
    "DOI": "arXiv:1904.00935v1",
    "Article_Title": "STYLE-ANALYZER: fixing code style inconsistencies with interpretable unsupervised algorithms",
    "Article_Abstract": "Source code reviews are manual, time-consuming, and expensive. Humaninvolvement should be focused on analyzing the most relevant aspects of theprogram, such as logic and maintainability, rather than amending style, syntax,or formatting defects. Some tools with linting capabilities can format codeautomatically and report various stylistic violations for supported programminglanguages. They are based on rules written by domain experts, hence, theirconfiguration is often tedious, and it is impractical for the given set ofrules to cover all possible corner cases. Some machine learning-based solutionsexist, but they remain uninterpretable black boxes. This paper introducesSTYLE-ANALYZER, a new open source tool to automatically fix code formattingviolations using the decision tree forest model which adapts to each codebaseand is fully unsupervised. STYLE-ANALYZER is built on top of our novel assistedcode review framework, Lookout. It accurately mines the formatting style ofeach analyzed Git repository and expresses the found format patterns withcompact human-readable rules. STYLE-ANALYZER can then suggest styleinconsistency fixes in the form of code review comments. We evaluate the outputquality and practical relevance of STYLE-ANALYZER by demonstrating that it canreproduce the original style with high precision, measured on 19 popularJavaScript projects, and by showing that it yields promising results in fixingreal style mistakes. STYLE-ANALYZER includes a web application to visualize howthe rules are triggered. We release STYLE-ANALYZER as a reusable and extendableopen source software package on GitHub for the benefit of the community.",
    "Article_Subject": "Machine Learning (cs.LG); Software Engineering (cs.SE); Machine Learning (stat.ML)",
    "Article_Date": "2019/04/01",
    "Article_PDF": "https://arxiv.org/pdf/1904.00935"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1904.00243",
    "DOI": "arXiv:1904.00243v3",
    "Article_Title": "Symmetry-Based Disentangled Representation Learning requires Interaction with Environments",
    "Article_Abstract": "Finding a generally accepted formal definition of a disentangledrepresentation in the context of an agent behaving in an environment is animportant challenge towards the construction of data-efficient autonomousagents. Higgins et al. recently proposed Symmetry-Based DisentangledRepresentation Learning, a definition based on a characterization of symmetriesin the environment using group theory. We build on their work and makeobservations, theoretical and empirical, that lead us to argue thatSymmetry-Based Disentangled Representation Learning cannot only be based onstatic observations: agents should interact with the environment to discoverits symmetries. Our experiments can be reproduced in Colab and the code isavailable on GitHub.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/30",
    "Article_PDF": "https://arxiv.org/pdf/1904.00243"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.12180",
    "DOI": "arXiv:1903.12180v1",
    "Article_Title": "ACRONYM: Acronym CReatiON for You and Me",
    "Article_Abstract": "Each year, countless hours of productive research time is spent brainstormingcreative acronyms for surveys, simulations, codes, and conferences. We presentACRONYM, a command-line program developed specifically to assist astronomers inidentifying the best acronyms for ongoing projects. The code returns allapproximately-English-language words that appear within an input string oftext, regardless of whether the letters occur at the beginning of the componentwords (in true astronomer fashion).",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/03/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.12180"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.12112",
    "DOI": "arXiv:1903.12112v2",
    "Article_Title": "Merging Combinatorial Design and Optimization: the Oberwolfach Problem",
    "Article_Abstract": "The Oberwolfach Problem $OP(F)$, posed by Gerhard Ringel in 1967, is aparadigmatic Combinatorial Design problem asking whether the complete graph$K_v$ decomposes into edge-disjoint copies of a $2$-regular graph $F$ of order$v$. In Combinatorial Design Theory, so-called difference methods represent awell-known solution technique and construct solutions in infinitely many casesexploiting symmetric and balanced structures. This approach reduces the problemto finding a well-structured $2$-factor which allows us to build solutions thatwe call $1$- or $2$-rotational according to their symmetries. We tackle $OP$ bymodeling difference methods with Optimization tools, specifically ConstraintProgramming ($CP$) and Integer Programming ($IP$), and correspondingly solveinstances with up to $v=120$ within $60s$. In particular, we model the$2$-rotational method by solving in cascade two subproblems, namely the binaryand group labeling, respectively. A polynomial-time algorithm solves the binarylabeling, while $CP$ tackles the group labeling. Furthermore, we providenecessary conditions for the existence of some $1$-rotational solutions whichstem from computational results. This paper shows thereby that both theoreticaland empirical results may arise from the interaction between CombinatorialDesign Theory and Operation Research.",
    "Article_Subject": "Combinatorics (math.CO)",
    "Article_Date": "2019/03/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.12112"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.11914",
    "DOI": "arXiv:1903.11914v3",
    "Article_Title": "Improving convergence of volume penalized fluid-solid interactions",
    "Article_Abstract": "Boundary conditions on arbitrary geometries are a common issue in simulatingpartial differential equations. The conventional approach is to discretize on agrid conforming to the geometry. However grid construction is challenging, andthis difficulty is compounded for evolving domains. Several methods insteadaugment the equations themselves to implicitly enforce the boundary conditions.This paper examines the Volume Penalty Method, which approximates Dirichletboundary conditions in the Navier Stokes equations with rapid linear damping(non-dimensional time scale $\u03b7$) inside the object. This technique is provento converge to the true solution, and also leads to simple volume-integralforce and torque calculations. Unfortunately, previous analysis showedconvergence of only $\\mathcal{O}(\u03b7^{1/2})$. We analyze the source of thiserror using matched asymptotic expansions and show that it stems from adisplacement length, proportional to a Reynolds number Re dependent boundarylayer of size $\\mathcal{O}(\u03b7^{1/2}\\text{Re}^{-1/2})$. The relative size ofthe displacement length and damping time scale lead to the emergence ofmultiple asymptotic regimes. The key finding is that there is a simplecorrection that can be efficiently calculated to eliminate the displacementlength and promote the accuracy to $\\mathcal{O}(\u03b7)$. This improvement alsoextends to the force and torque calculations. We demonstrate these findings in1D planar Poiseuille flow, 2D steady flow past a viscous stagnation point, and2D unsteady flow past a rotating cylinder, and finally show that Richardsonextrapolation can be used with our correction to further improve convergence to$\\mathcal{O}(\u03b7^{2})$.",
    "Article_Subject": "Numerical Analysis (math.NA)",
    "Article_Date": "2019/03/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.11914"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.10729",
    "DOI": "arXiv:1903.10729v3",
    "Article_Title": "WGANSing: A Multi-Voice Singing Voice Synthesizer Based on the Wasserstein-GAN",
    "Article_Abstract": "We present a deep neural network based singing voice synthesizer, inspired bythe Deep Convolutions Generative Adversarial Networks (DCGAN) architecture andoptimized using the Wasserstein-GAN algorithm. We use vocoder parameters foracoustic modelling, to separate the influence of pitch and timbre. Thisfacilitates the modelling of the large variability of pitch in the singingvoice. Our network takes a block of consecutive frame-wise linguistic andfundamental frequency features, along with global singer identity as input andoutputs vocoder features, corresponding to the block of features. Thisblock-wise approach, along with the training methodology allows us to modeltemporal dependencies within the features of the input block. For inference,sequential blocks are concatenated using an overlap-add procedure. We show thatthe performance of our model is competitive with regards to thestate-of-the-art and the original sample using objective metrics and asubjective listening test. We also present examples of the synthesis on asupplementary website and the source code via GitHub.",
    "Article_Subject": "Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "Article_Date": "2019/03/26",
    "Article_PDF": "https://arxiv.org/pdf/1903.10729"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.10326",
    "DOI": "arXiv:1903.10326v1",
    "Article_Title": "topFiberM: Scalable and Efficient Boolean Matrix Factorization",
    "Article_Abstract": "Matrix Factorization has many applications such as clustering. When thematrix is Boolean it is favorable to have Boolean factors too. This will savethe efforts of quantizing the reconstructed data back, which usually is doneusing arbitrary thresholds. Here we introduce topFiberM a Boolean matrixfactorization algorithm. topFiberM chooses in a greedy way the fibers (rows orcolumns) to represent the entire matrix. Fibers are extended to rectanglesaccording to a threshold on precision. The search for these \"top fibers\" cancontinue beyond the required rank and according to an optional parameter thatdefines the limit for this search. A factor with a better gain replaces thefactor with minimum gain in \"top fibers\". We compared topFiberM to thestate-of-the-art methods, it achieved better quality for the set of datasetsusually used in literature. We also applied our algorithm to linked-data toshow its scalability. topFiberM was in average 128 times faster than the wellknown Asso method when applied to a set of matrices representing a realmultigraph although Asso is implemented in C and topFiberM is implemented in Rwhich is generally slower than C. topFiberM is publicly available from Github(https://github.com/dice-group/BMF).",
    "Article_Subject": "Data Structures and Algorithms (cs.DS)",
    "Article_Date": "2019/03/06",
    "Article_PDF": "https://arxiv.org/pdf/1903.10326"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08718",
    "DOI": "arXiv:1903.08718v1",
    "Article_Title": "CRAFT: A multifunction online platform for speech prosody visualisation",
    "Article_Abstract": "There are many research tools which are also used for teaching the acousticphonetics of speech rhythm and speech melody. But they were notpurpose-designed for teaching-learning situations, and some have a steeplearning curve. CRAFT (Creation and Recovery of Amplitude and Frequency Tracks)is custom-designed as a novel flexible online tool for visualisation andcritical comparison of functions and transforms, with implementations of theReaper, RAPT, PyRapt, YAAPT, YIN and PySWIPE F0 estimators, three Praatconfigurations, and two purpose-built estimators, PyAMDF, S0FT. Visualisationsof amplitude and frequency envelope spectra, spectral edge detection of rhythmzones, and a parametrised spectrogram are included. A selection of audio clipsfrom tone and intonation languages is provided for demonstration purposes. Themain advantages of online tools are consistency (users have the same versionand the same data selection), interoperability over different platforms, andease of maintenance. The code is available on GitHub.",
    "Article_Subject": "Sound (cs.SD); Computation and Language (cs.CL)",
    "Article_Date": "2019/03/18",
    "Article_PDF": "https://arxiv.org/pdf/1903.08718"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08621",
    "DOI": "arXiv:1903.08621v1",
    "Article_Title": "Column2Vec: Structural Understanding via Distributed Representations of Database Schemas",
    "Article_Abstract": "We present Column2Vec, a distributed representation of database columns basedon column metadata. Our distributed representation has several applications.Using known names for groups of columns (i.e., a table name), we train a modelto generate an appropriate name for columns in an unnamed table. We demonstratethe viability of our approach using schema information collected from opensource applications on GitHub.",
    "Article_Subject": "Databases (cs.DB); Machine Learning (cs.LG)",
    "Article_Date": "2019/03/20",
    "Article_PDF": "https://arxiv.org/pdf/1903.08621"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08215",
    "DOI": "arXiv:1903.08215v2",
    "Article_Title": "The Galaxy Cluster 'Pypeline' for X-ray Temperature Maps: ClusterPyXT",
    "Article_Abstract": "ClusterPyXT is a new software pipeline to generate spectral temperature,X-ray surface brightness, pressure, and density maps from X-ray observations ofgalaxy clusters. These data products help elucidate the physics of processesoccurring within clusters of galaxies, including turbulence, shock fronts,nonthermal phenomena, and the overall dynamics of cluster mergers. ClusterPyXTautomates the creation of these data products with minimal user interaction,and allows for rapid analyses of archival data with user defined parameters andthe ability to straightforwardly incorporate additional observations. In thispaper, we describe in detail the use of this code and release it as an opensource Python project on GitHub.",
    "Article_Subject": "High Energy Astrophysical Phenomena (astro-ph.HE); Cosmology and Nongalactic Astrophysics (astro-ph.CO); Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/03/19",
    "Article_PDF": "https://arxiv.org/pdf/1903.08215"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08186",
    "DOI": "arXiv:1903.08186v1",
    "Article_Title": "Spectroscopic Transit Search: a self-calibrating method for detecting planets around bright stars",
    "Article_Abstract": "We search for transiting exoplanets around the star $\u03b2$ Pictoris usinghigh resolution spectroscopy and Doppler imaging that removes the need forstandard star observations. These data were obtained on the VLT with UVESduring the course of an observing campaign throughout 2017 that monitored theHill sphere transit of the exoplanet $\u03b2$ Pictoris b. We utilize lineprofile tomography as a method for the discovery of transiting exoplanets. Bymeasuring the exoplanet distortion of the stellar line profile, we remove theneed for reference star measurements. We demonstrate the method with whitenoise simulations, and then look at the case of $\u03b2$ Pictoris, which is a$\u03b4$ Scuti pulsator. We describe a method to remove the stellar pulsationsand perform a search for any transiting exoplanets in the resultant data set.We inject fake planet transits with varying orbital periods and planet radiiinto the spectra and determine the recovery fraction. In the photon noiselimited case we can recover planets down to a Neptune radius with an $\\sim$80%success rate, using an 8 m telescope with a $R\\sim 100,000$ spectrograph and 20minutes of observations per night. The pulsations of $\u03b2$ Pictoris limit oursensitivity to Jupiter-sized planets, but a pulsation removal algorithmimproves this limit to Saturn-sized planets. We present two planet candidates,but argue that their signals are most likely caused by other phenomena. We havedemonstrated a method for searching for transiting exoplanets that (i) does notrequire ancillary calibration observations, (ii) can work on any star whoserotational broadening can be resolved with a high spectral dispersionspectrograph and (iii) provides the lowest limits so far on the radii oftransiting Jupiter-sized exoplanets around $\u03b2$ Pictoris with orbitalperiods from 15 days to 200 days with >50% coverage.",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/03/19",
    "Article_PDF": "https://arxiv.org/pdf/1903.08186"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.08113",
    "DOI": "arXiv:1903.08113v1",
    "Article_Title": "Identifying Experts in Software Libraries and Frameworks among GitHub Users",
    "Article_Abstract": "Software development increasingly depends on libraries and frameworks toincrease productivity and reduce time-to-market. Despite this fact, we stilllack techniques to assess developers expertise in widely popular libraries andframeworks. In this paper, we evaluate the performance of unsupervised (basedon clustering) and supervised machine learning classifiers (Random Forest andSVM) to identify experts in three popular JavaScript libraries: facebook/react,mongodb/node-mongodb, and socketio/socket.io. First, we collect 13 featuresabout developers activity on GitHub projects, including commits on source codefiles that depend on these libraries. We also build a ground truth includingthe expertise of 575 developers on the studied libraries, as self-reported bythem in a survey. Based on our findings, we document the challenges of usingmachine learning classifiers to predict expertise in software libraries, usingfeatures extracted from GitHub. Then, we propose a method to identify libraryexperts based on clustering feature data from GitHub; by triangulating theresults of this method with information available on Linkedin profiles, we showthat it is able to recommend dozens of GitHub users with evidences of beingexperts in the studied JavaScript libraries. We also provide a public datasetwith the expertise of 575 developers on the studied libraries.",
    "Article_Subject": "Software Engineering (cs.SE); Machine Learning (cs.LG)",
    "Article_Date": "2019/03/19",
    "Article_PDF": "https://arxiv.org/pdf/1903.08113"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.07611",
    "DOI": "arXiv:1903.07611v1",
    "Article_Title": "Total Power Map to Visibilities (TP2VIS): Joint Deconvolution of ALMA 12m, 7m, and Total Power Array Data",
    "Article_Abstract": "We present a new package for joint deconvolution of ALMA 12m, 7m, and TotalPower (TP) data, dubbed ``Total Power Map to Visibilities (TP2VIS)\". Itconverts a TP (single-dish) map into visibilities on the CASA platform, whichcan be input into deconvolvers (e.g., CLEAN) along with 12m and 7mvisibilities. A manual is presented in the Github repository(https://github.com/tp2vis/distribute). Combining data from the different ALMAarrays is a driver for a number of science topics, namely those that probe sizescales of extended and compact structures simultaneously. We test TP2VIS usingmodel images, one with a single Gaussian and another that mimics the internalstructures of giant molecular clouds. The result shows that the better uvcoverage with TP2VIS visibilities helps the deconvolution process andreproduces the model image within errors of only 5% over two orders ofmagnitude in flux.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Earth and Planetary Astrophysics (astro-ph.EP); Astrophysics of Galaxies (astro-ph.GA); Solar and Stellar Astrophysics (astro-ph.SR)",
    "Article_Date": "2019/03/18",
    "Article_PDF": "https://arxiv.org/pdf/1903.07611"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.06768",
    "DOI": "arXiv:1903.06768v2",
    "Article_Title": "Joint Mean-Covariance Estimation via the Horseshoe with an Application in Genomic Data Analysis",
    "Article_Abstract": "Seemingly unrelated regression is a natural framework for regressing multiplecorrelated responses on multiple predictors. The model is very flexible, withmultiple linear regression and covariance selection models being special cases.However, its practical deployment in genomic data analysis under a Bayesianframework is limited due to both statistical and computational challenges. Thestatistical challenge is that one needs to infer both the mean vector and theinverse covariance matrix, a problem inherently more complex than separatelyestimating each. The computational challenge is due to the dimensionality ofthe parameter space that routinely exceeds the sample size. We propose the useof horseshoe priors on both the mean vector and the inverse covariance matrix.This prior has demonstrated excellent performance when estimating a mean vectoror inverse covariance matrix separately. The current work shows theseadvantages are also present when addressing both simultaneously. A fullBayesian treatment is proposed, with a sampling algorithm that is linear in thenumber of predictors. MATLAB code implementing the algorithm is freelyavailable from github at https://github.com/liyf1988/HS_GHS. Extensiveperformance comparisons are provided with both frequentist and Bayesianalternatives, and both estimation and prediction performances are verified on agenomic data set.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/03/15",
    "Article_PDF": "https://arxiv.org/pdf/1903.06768"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.06348",
    "DOI": "arXiv:1903.06348v1",
    "Article_Title": "Automatically Generating Documentation for Lambda Expressions in Java",
    "Article_Abstract": "When lambda expressions were introduced to the Java programming language aspart of the release of Java 8 in 2014, they were the language's first step intofunctional programming. Since lambda expressions are still relatively new, notall developers use or understand them. In this paper, we first present theresults of an empirical study to determine how frequently developers of GitHubrepositories make use of lambda expressions and how they are documented. Wefind that 11% of Java GitHub repositories use lambda expressions, and that only6% of the lambda expressions are accompanied by source code comments. We thenpresent a tool called LambdaDoc which can automatically detect lambdaexpressions in a Java repository and generate natural language documentationfor them. Our evaluation of LambdaDoc with 23 professional developers showsthat they perceive the generated documentation to be complete, concise, andexpressive, while the majority of the documentation produced by ourparticipants without tool support was inadequate. Our contribution builds animportant step towards automatically generating documentation for functionalprogramming constructs in an object-oriented language.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/03/15",
    "Article_PDF": "https://arxiv.org/pdf/1903.06348"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.05277",
    "DOI": "arXiv:1903.05277v1",
    "Article_Title": "Activity-Based Analysis of Open Source Software Contributors: Roles and Dynamics",
    "Article_Abstract": "Contributors to open source software (OSS) communities assume diverse rolesto take different responsibilities. One major limitation of the current OSStools and platforms is that they provide a uniform user interface regardless ofthe activities performed by the various types of contributors. This paperserves as a non-trivial first step towards resolving this challenge bydemonstrating a methodology and establishing knowledge to understand how thecontributors' roles and their dynamics, reflected in the activitiescontributors perform, are exhibited in OSS communities. Based on an analysis ofuser action data from 29 GitHub projects, we extracted six activities thatdistinguished four Active roles and five Supporting roles of OSS contributors,as well as patterns in role changes. Through the lens of the Activity Theory,these findings provided rich design guidelines for OSS tools to support diversecontributor roles.",
    "Article_Subject": "Software Engineering (cs.SE); Human-Computer Interaction (cs.HC)",
    "Article_Date": "2019/03/13",
    "Article_PDF": "https://arxiv.org/pdf/1903.05277"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.05084",
    "DOI": "arXiv:1903.05084v3",
    "Article_Title": "Decay Replay Mining to Predict Next Process Events",
    "Article_Abstract": "In complex processes, various events can happen in different sequences. Theprediction of the next event given an a-priori process state is of importancein such processes. Recent methods have proposed deep learning techniques suchas recurrent neural networks, developed on raw event logs, to predict the nextevent from a process state. However, such deep learning models by themselveslack a clear representation of the process states. At the same time, recentmethods have neglected the time feature of event instances. In this paper, wetake advantage of Petri nets as a powerful tool in modeling complex processbehaviors considering time as an elemental variable. We propose an approachwhich starts from a Petri net process model constructed by a process miningalgorithm. We enhance the Petri net model with time decay functions to createcontinuous process state samples. Finally, we use these samples in combinationwith discrete token movement counters and Petri net markings to train a deeplearning model that predicts the next event. We demonstrate significantperformance improvements and outperform the state-of-the-art methods on ninereal-world benchmark event logs.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/12",
    "Article_PDF": "https://arxiv.org/pdf/1903.05084"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.04042",
    "DOI": "arXiv:1903.04042v1",
    "Article_Title": "Algorithms for an Efficient Tensor Biclustering",
    "Article_Abstract": "Consider a data set collected by (individuals-features) pairs in differenttimes. It can be represented as a tensor of three dimensions (Individuals,features and times). The tensor biclustering problem computes a subset ofindividuals and a subset of features whose signal trajectories over time lie ina low-dimensional subspace, modeling similarity among the signal trajectorieswhile allowing different scalings across different individuals or differentfeatures. This approach are based on spectral decomposition in order to buildthe desired biclusters. We evaluate the quality of the results from eachalgorithms with both synthetic and real data set.",
    "Article_Subject": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/10",
    "Article_PDF": "https://arxiv.org/pdf/1903.04042"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.03804",
    "DOI": "arXiv:1903.03804v1",
    "Article_Title": "Program Classification Using Gated Graph Attention Neural Network for Online Programming Service",
    "Article_Abstract": "The online programing services, such as Github,TopCoder, and EduCoder, havepromoted a lot of social interactions among the service users. However, theexisting social interactions is rather limited and inefficient due to the rapidincreasing of source-code repositories, which is difficult to explore manually.The emergence of source-code mining provides a promising way to analyze thosesource codes, so that those source codes can be relatively easy to understandand share among those service users. Among all the source-code miningattempts,program classification lays a foundation for various tasks related tosource-code understanding, because it is impossible for a machine to understanda computer program if it cannot classify the program correctly. Althoughnumerous machine learning models, such as the Natural Language Processing (NLP)based models and the Abstract Syntax Tree (AST) based models, have beenproposed to classify computer programs based on their corresponding sourcecodes, the existing works cannot fully characterize the source codes from theperspective of both the syntax and semantic information. To address thisproblem, we proposed a Graph Neural Network (GNN) based model, which integratesdata flow and function call information to the AST,and applies an improved GNNmodel to the integrated graph, so as to achieve the state-of-art programclassification accuracy. The experiment results have shown that the proposedwork can classify programs with accuracy over 97%.",
    "Article_Subject": "Artificial Intelligence (cs.AI)",
    "Article_Date": "2019/03/09",
    "Article_PDF": "https://arxiv.org/pdf/1903.03804"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.03375",
    "DOI": "arXiv:1903.03375v1",
    "Article_Title": "Online division of labour: emergent structures in Open Source Software",
    "Article_Abstract": "The development Open Source Software fundamentally depends on theparticipation and commitment of volunteer developers to progress. Several workshave presented strategies to increase the on-boarding and engagement of newcontributors, but little is known on how these diverse groups of developersself-organise to work together. To understand this, one must consider that, onone hand, platforms like GitHub provide a virtually unlimited developmentframework: any number of actors can potentially join to contribute in adecentralised, distributed, remote, and asynchronous manner. On the other,however, it seems reasonable that some sort of hierarchy and division of labourmust be in place to meet human biological and cognitive limits, and also toachieve some level of efficiency. These latter features (hierarchy and divisionof labour) should translate into recognisable structural arrangements whenprojects are represented as developer-file bipartite networks. In this paper weanalyse a set of popular open source projects from GitHub, placing the accenton three key properties: nestedness, modularity and in-block nestedness -whichtypify the emergence of heterogeneities among contributors, the emergence ofsubgroups of developers working on specific subgroups of files, and a mixtureof the two previous, respectively. These analyses show that indeed projectsevolve into internally organised blocks. Furthermore, the distribution of sizesof such blocks is bounded, connecting our results to the celebrated Dunbarnumber both in off- and on-line environments. Our analyses create a linkbetween bio-cognitive constraints, group formation and online workingenvironments, opening up a rich scenario for future research on (online) workteam assembly.",
    "Article_Subject": "Physics and Society (physics.soc-ph); Computers and Society (cs.CY); Software Engineering (cs.SE)",
    "Article_Date": "2019/03/08",
    "Article_PDF": "https://arxiv.org/pdf/1903.03375"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.02904",
    "DOI": "arXiv:1903.02904v1",
    "Article_Title": "Halin graphs are 3-vertex-colorable except even wheels",
    "Article_Abstract": "A Halin graph is a graph obtained by embedding a tree having no nodes ofdegree two in the plane, and then adding a cycle to join the leaves of the treein such a way that the resulting graph is planar. According to the four colortheorem, Halin graphs are 4-vertex-colorable. On the other hand, they are not2-vertex-colorable because they have triangles. We show that all Halin graphsare 3-vertex-colorable except even wheels. We also show how to find the perfectelimination ordering of a chordal completion for a given Halin graph. Thealgorithms are implemented in Python using the graphtheory package. Generatorsof random Halin graphs (general or cubic) are included. The source code isavailable from the public GitHub repository.",
    "Article_Subject": "Data Structures and Algorithms (cs.DS)",
    "Article_Date": "2019/03/07",
    "Article_PDF": "https://arxiv.org/pdf/1903.02904"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.02779",
    "DOI": "arXiv:1903.02779v4",
    "Article_Title": "Deep neural networks for classifying complex features in diffraction images",
    "Article_Abstract": "Intense short-wavelength pulses from free-electron lasers andhigh-harmonic-generation sources enable diffractive imaging of individualnano-sized objects with a single x-ray laser shot. The enormous data sets withup to several million diffraction patterns represent a severe problem for dataanalysis, due to the high dimensionality of imaging data. Feature recognitionand selection is a crucial step to reduce the dimensionality. Usually,custom-made algorithms are developed at a considerable effort to approximatethe particular features connected to an individual specimen, but facingdifferent experimental conditions, these approaches do not generalize well. Onthe other hand, deep neural networks are the principal instrument for today'srevolution in automated image recognition, a development that has not beenadapted to its full potential for data analysis in science. We recentlypublished in Langbehn et al. (Phys. Rev. Lett. 121, 255301 (2018)) the firstapplication of a deep neural network as a feature extractor for wide-anglediffraction images of helium nanodroplets. Here we present the setup, ourmodifications and the training process of the deep neural network fordiffraction image classification and its systematic benchmarking. We find thatdeep neural networks significantly outperform previous attempts for sorting andclassifying complex diffraction patterns and are a significant improvement forthe much-needed assistance during post-processing of large amounts ofexperimental coherent diffraction imaging data.",
    "Article_Subject": "Data Analysis, Statistics and Probability (physics.data-an); Atomic and Molecular Clusters (physics.atm-clus)",
    "Article_Date": "2019/03/07",
    "Article_PDF": "https://arxiv.org/pdf/1903.02779"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.02557",
    "DOI": "arXiv:1903.02557v3",
    "Article_Title": "DASH: Deep Learning for the Automated Spectral Classification of Supernovae and their Hosts",
    "Article_Abstract": "We present DASH (Deep Automated Supernova and Host classifier), a novelsoftware package that automates the classification of the type, age, redshift,and host galaxy of supernova spectra. DASH makes use of a new approach thatdoes not rely on iterative template matching techniques like all previoussoftware, but instead classifies based on the learned features of eachsupernova's type and age. It has achieved this by employing a deepconvolutional neural network to train a matching algorithm. This approach hasenabled DASH to be orders of magnitude faster than previous tools, being ableto accurately classify hundreds or thousands of objects within seconds. We havetested its performance on four years of data from the Australian Dark EnergySurvey (OzDES). The deep learning models were developed using TensorFlow, andwere trained using over 4000 supernova spectra taken from the CfA SupernovaProgram and the Berkeley SN Ia Program as used in SNID (SupernovaIdentification software, Blondin & Tonry 2007). Unlike template matchingmethods, the trained models are independent of the number of spectra in thetraining data, which allows for DASH's unprecedented speed. We have developedboth a graphical interface for easy visual classification and analysis ofsupernovae, and a Python library for the autonomous and quick classification ofseveral supernova spectra. The speed, accuracy, user-friendliness, andversatility of DASH presents an advancement to existing spectral classificationtools. We have made the code publicly available on GitHub and PyPI (pip installastrodash) to allow for further contributions and development. The packagedocumentation is available at https://astrodash.readthedocs.io.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Article_Date": "2019/03/06",
    "Article_PDF": "https://arxiv.org/pdf/1903.02557"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01742",
    "DOI": "arXiv:1903.01742v2",
    "Article_Title": "SZZ Unleashed: An Open Implementation of the SZZ Algorithm -- Featuring Example Usage in a Study of Just-in-Time Bug Prediction for the Jenkins Project",
    "Article_Abstract": "Numerous empirical software engineering studies rely on detailed informationabout bugs. While issue trackers often contain information about when bugs werefixed, details about when they were introduced to the system are often absent.As a remedy, researchers often rely on the SZZ algorithm as a heuristicapproach to identify bug-introducing software changes. Unfortunately, asreported in a recent systematic literature review, few researchers have madetheir SZZ implementations publicly available. Consequently, there is a riskthat research effort is wasted as new projects based on SZZ output need toinitially reimplement the approach. Furthermore, there is a risk that newlydeveloped (closed source) SZZ implementations have not been properly tested,thus conducting research based on their output might introduce threats tovalidity. We present SZZ Unleashed, an open implementation of the SZZ algorithmfor git repositories. This paper describes our implementation along with ausage example for the Jenkins project, and conclude with an illustrative studyon just-in-time bug prediction. We hope to continue evolving SZZ Unleashed onGitHub, and warmly invite the community to contribute.",
    "Article_Subject": "Software Engineering (cs.SE)",
    "Article_Date": "2019/03/05",
    "Article_PDF": "https://arxiv.org/pdf/1903.01742"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01698",
    "DOI": "arXiv:1903.01698v3",
    "Article_Title": "Improving Cross-Domain Chinese Word Segmentation with Word Embeddings",
    "Article_Abstract": "Cross-domain Chinese Word Segmentation (CWS) remains a challenge despiterecent progress in neural-based CWS. The limited amount of annotated data inthe target domain has been the key obstacle to a satisfactory performance. Inthis paper, we propose a semi-supervised word-based approach to improvingcross-domain CWS given a baseline segmenter. Particularly, our model onlydeploys word embeddings trained on raw text in the target domain, discardingcomplex hand-crafted features and domain-specific dictionaries. Innovativesubsampling and negative sampling methods are proposed to derive wordembeddings optimized for CWS. We conduct experiments on five datasets inspecial domains, covering domains in novels, medicine, and patent. Results showthat our model can obviously improve cross-domain CWS, especially in thesegmentation of domain-specific noun entities. The word F-measure increases byover 3.0% on four datasets, outperforming state-of-the-art semi-supervised andunsupervised cross-domain CWS approaches with a large margin. We make our codeand data available on Github.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/03/05",
    "Article_PDF": "https://arxiv.org/pdf/1903.01698"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01555",
    "DOI": "arXiv:1903.01555v1",
    "Article_Title": "An Explorative Study of GitHub Repositories of AI Papers",
    "Article_Abstract": "With the rapid development of AI technologies, thousands of AI papers arebeing published each year. Many of these papers have released sample code tofacilitate follow-up researchers. This paper presents an explorative study ofover 1700 code repositories of AI papers hosted on GitHub. We find that theserepositories are often poorly written, lack of documents, lack of maintenance,and hard to configure the underlying runtime environment. Thus, many coderepositories become inactive and abandoned. Such a situation makes follow-upresearchers hard to reproduce the results or do further research. In addition,these hard-to-reuse code makes a gap between academia and industry. Based onthe findings, we give some recommendations on how to improve the quality ofcode repositories of AI papers.",
    "Article_Subject": "Digital Libraries (cs.DL)",
    "Article_Date": "2019/02/16",
    "Article_PDF": "https://arxiv.org/pdf/1903.01555"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.01284",
    "DOI": "arXiv:1903.01284v1",
    "Article_Title": "Relation Extraction Datasets in the Digital Humanities Domain and their Evaluation with Word Embeddings",
    "Article_Abstract": "In this research, we manually create high-quality datasets in the digitalhumanities domain for the evaluation of language models, specifically wordembedding models. The first step comprises the creation of unigram and n-gramdatasets for two fantasy novel book series for two task types each, analogy anddoesn't-match. This is followed by the training of models on the two bookseries with various popular word embedding model types such as word2vec, GloVe,fastText, or LexVec. Finally, we evaluate the suitability of word embeddingmodels for such specific relation extraction tasks in a situation of comparablysmall corpus sizes. In the evaluations, we also investigate and analyzeparticular aspects such as the impact of corpus term frequencies and taskdifficulty on accuracy. The datasets, and the underlying system and wordembedding models are available on github and can be easily extended with newdatasets and tasks, be used to reproduce the presented results, or betransferred to other domains.",
    "Article_Subject": "Computation and Language (cs.CL)",
    "Article_Date": "2019/03/04",
    "Article_PDF": "https://arxiv.org/pdf/1903.01284"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.00904",
    "DOI": "arXiv:1903.00904v1",
    "Article_Title": "Self-adversarial Variational Autoencoder with Gaussian Anomaly Prior Distribution for Anomaly Detection",
    "Article_Abstract": "Recently, deep generative models have become increasingly popular inunsupervised anomaly detection. However, deep generative models aim atrecovering the data distribution rather than detecting anomalies. Besides, deepgenerative models have the risk of overfitting training samples, which hasdisastrous effects on anomaly detection performance. To solve the above twoproblems, we propose a Self-adversarial Variational Autoencoder with a Gaussiananomaly prior assumption. We assume that both the anomalous and the normalprior distribution are Gaussian and have overlaps in the latent space.Therefore, a Gaussian transformer net T is trained to synthesize anomalous butnear-normal latent variables. Keeping the original training objective ofVariational Autoencoder, besides, the generator G tries to distinguish betweenthe normal latent variables and the anomalous ones synthesized by T, and theencoder E is trained to discriminate whether the output of G is real. These newobjectives we added not only give both G and E the ability to discriminate butalso introduce additional regularization to prevent overfitting. Compared withthe SOTA baselines, the proposed model achieves significant improvements inextensive experiments. Datasets and our model are available at a Githubrepository.",
    "Article_Subject": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
    "Article_Date": "2019/03/03",
    "Article_PDF": "https://arxiv.org/pdf/1903.00904"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1903.00037",
    "DOI": "arXiv:1903.00037v1",
    "Article_Title": "Distance-Based Independence Screening for Canonical Analysis",
    "Article_Abstract": "This paper introduces a new method named Distance-based IndependenceScreening for Canonical Analysis (DISCA) to reduce dimensions of two randomvectors with arbitrary dimensions. The objective of our method is to identifythe low dimensional linear projections of two random vectors, such that anydimension reduction based on linear projection with lower dimensions willsurely affect some dependent structure -- the removed components are notindependent. The essence of DISCA is to use the distance correlation toeliminate the \"redundant\" dimensions until infeasible. Unlike the existingcanonical analysis methods, DISCA does not require the dimensions of thereduced subspaces of the two random vectors to be equal, nor does it requirecertain distributional assumption on the random vectors. We show that undermild conditions, our approach does undercover the lowest possible lineardependency structures between two random vectors, and our conditions are weakerthan some sufficient linear subspace-based methods. Numerically, DISCA is tosolve a non-convex optimization problem. We formulate it as adifference-of-convex (DC) optimization problem, and then further adopt thealternating direction method of multipliers (ADMM) on the convex step of the DCalgorithms to parallelize/accelerate the computation. Some sufficient linearsubspace-based methods use potentially numerically-intensive bootstrap methodto determine the dimensions of the reduced subspaces in advance; our methodavoids this complexity. In simulations, we present cases that DISCA can solveeffectively, while other methods cannot. In both the simulation studies andreal data cases, when the other state-of-the-art dimension reduction methodsare applicable, we observe that DISCA performs either comparably or better thanmost of them. Codes and an R package can be found in GitHubhttps://github.com/ChuanpingYu/DISCA.",
    "Article_Subject": "Methodology (stat.ME)",
    "Article_Date": "2019/02/28",
    "Article_PDF": "https://arxiv.org/pdf/1903.00037"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.11108",
    "DOI": "arXiv:1902.11108v2",
    "Article_Title": "Artist Style Transfer Via Quadratic Potential",
    "Article_Abstract": "In this paper we address the problem of artist style transfer where thepainting style of a given artist is applied on a real world photograph. Wetrain our neural networks in adversarial setting via recently introducedquadratic potential divergence for stable learning process. To further improvethe quality of generated artist stylized images we also integrate some of therecently introduced deep learning techniques in our method. To our bestknowledge this is the first attempt towards artist style transfer via quadraticpotential divergence. We provide some stylized image samples in thesupplementary material. The source code for experimentation was written inPyTorch and is available online in my GitHub repository.",
    "Article_Subject": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "Article_Date": "2019/02/14",
    "Article_PDF": "https://arxiv.org/pdf/1902.11108"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.10149",
    "DOI": "arXiv:1902.10149v2",
    "Article_Title": "Primordial power spectrum and cosmology from black-box galaxy surveys",
    "Article_Abstract": "We propose a new, likelihood-free approach to inferring the primordial matterpower spectrum and cosmological parameters from arbitrarily complex forwardmodels of galaxy surveys where all relevant statistics can be determined fromnumerical simulations, i.e. black-boxes. Our approach, which we call simulatorexpansion for likelihood-free inference (SELFI), builds upon approximateBayesian computation using a novel effective likelihood, and upon thelinearisation of black-box models around an expansion point. Consequently, weobtain simple \"filter equations\" for an effective posterior of the primordialpower spectrum, and a straightforward scheme for cosmological parameterinference. We demonstrate that the workload is computationally tractable, fixeda priori, and perfectly parallel. As a proof of concept, we apply our frameworkto a realistic synthetic galaxy survey, with a data model accounting forphysical structure formation and incomplete and noisy galaxy observations. Indoing so, we show that the use of non-linear numerical models allows the galaxypower spectrum to be safely fitted up to at least $k_\\mathrm{max} = 0.5$$h$/Mpc, outperforming state-of-the-art backward-modelling techniques by afactor of $\\sim 5$ in the number of modes used. The result is an unbiasedinference of the primordial matter power spectrum across the entire range ofscales considered, including a high-fidelity reconstruction of baryon acousticoscillations. It translates into an unbiased and robust inference ofcosmological parameters. Our results pave the path towards easy applications oflikelihood-free simulation-based inference in cosmology. We have made our codepySELFI and our data products publicly available athttp://pyselfi.florent-leclercq.eu.",
    "Article_Subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO); Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Article_Date": "2019/02/26",
    "Article_PDF": "https://arxiv.org/pdf/1902.10149"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.09386",
    "DOI": "arXiv:1902.09386v1",
    "Article_Title": "SMARTp: A SMART design for non-surgical treatments of chronic periodontitis with spatially-referenced and non-randomly missing skewed outcomes",
    "Article_Abstract": "This paper proposes dynamic treatment regimes for choosing individualizedeffective treatment strategies of chronic periodontal disease. R codes forimplementing the proposed sample size formula are available in GitHub.",
    "Article_Subject": "Applications (stat.AP)",
    "Article_Date": "2019/02/25",
    "Article_PDF": "https://arxiv.org/pdf/1902.09386"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.08702",
    "DOI": "arXiv:1902.08702v1",
    "Article_Title": "pyro: a framework for hydrodynamics explorations and prototyping",
    "Article_Abstract": "pyro is a Python-based simulation framework designed for ease ofimplementation and exploration of hydrodynamics methods. It is built in aobject-oriented fashion, allowing for the reuse of the core components and fastprototyping of new methods.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Computational Physics (physics.comp-ph)",
    "Article_Date": "2019/02/22",
    "Article_PDF": "https://arxiv.org/pdf/1902.08702"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.08182",
    "DOI": "arXiv:1902.08182v1",
    "Article_Title": "Finding the Needle in a Haystack: Detrending Photometric Timeseries Data of Strictly Periodic Astrophysical Objects",
    "Article_Abstract": "Light curves of astrophysical objects frequently contain strictly periodicsignals. In those cases we can use that property to aid the detrendingalgorithm to fully disentangle an unknown periodic signal and an unknownbaseline signal with no power at that period. The periodic signal is modeled asa discrete probability distribution function (pdf), while the baseline signalis modeled as a residual timeseries. Those two components are disentangled byminimizing the length of the residual timeseries w.r.t. the per-bin pdf fluxes.We demonstrate the use of the algorithm on a synthetic case, on the eclipsingbinary KIC 3953981 and on the eccentric ellipsoidal variable KIC 3547874. Wefurther discuss the parameters and the limitations of the algorithm andspeculate on the two most common use cases: detrending the periodic signal ofinterest and measuring the dependence of instrumental response on controlledinstrumental variables. A more sophisticated version of the algorithm isreleased as open source on github and available via pip.",
    "Article_Subject": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Solar and Stellar Astrophysics (astro-ph.SR)",
    "Article_Date": "2019/02/21",
    "Article_PDF": "https://arxiv.org/pdf/1902.08182"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.07740",
    "DOI": "arXiv:1902.07740v1",
    "Article_Title": "Nitrogen Oxide Concentrations in Natural Waters on Early Earth",
    "Article_Abstract": "A key challenge in origins-of-life studies is estimating the abundances ofspecies relevant to the chemical pathways proposed to have contributed to theemergence of life on early Earth. Dissolved nitrogen oxide anions(NO$_{X}^{-}$), in particular nitrate (NO$_{3}^{-}$) and nitrite(NO$_{2}^{-}$), have been invoked in diverse origins-of-life chemistry, fromthe oligomerization of RNA to the emergence of protometabolism. Recent work hascalculated the supply of NO$_{X}^{-}$ from the prebiotic atmosphere to theocean, and reported steady-state [NO$_{X}^{-}$] to be high across all plausibleparameter space. These findings rest on the assumption that NO$_{X}^{-}$ isstable in natural waters unless processed at a hydrothermal vent. Here, we showthat NO$_{X}^{-}$ is unstable in the reducing environment of early Earth. Sinksdue to UV photolysis and reactions with reduced iron (Fe$^{2+}$) suppress[NO$_{X}^{-}$] by several orders of magnitude relative to past predictions. ForpH$=6.5-8$ and $T=0-50^\\circ$C, we find that it is most probable thatNO$_{X}^{-}$]$<1~\u03bc$M in the prebiotic ocean. On the other hand, prebioticponds with favorable drainage characteristics may have sustained[NO$_{X}^{-}$]$\\geq 1~\u03bc$M. As on modern Earth, most NO$_{X}^{-}$ on prebioticEarth should have been present as NO$_{3}^{-}$, due to its much greaterstability. These findings inform the kind of prebiotic chemistries that wouldhave been possible on early Earth. We discuss the implications for proposedprebiotic chemistries, and highlight the need for further studies ofNO$_{X}^{-}$ kinetics to reduce the considerable uncertainties in predicting[NO$_{X}^{-}$] on early Earth.",
    "Article_Subject": "Earth and Planetary Astrophysics (astro-ph.EP)",
    "Article_Date": "2019/02/20",
    "Article_PDF": "https://arxiv.org/pdf/1902.07740"
  },
  {
    "Article_Url": "https://arxiv.org/abs/1902.07704",
    "DOI": "arXiv:1902.07704v1",
    "Article_Title": "How Do the Open Source Communities Address Usability and UX Issues? An Exploratory Study",
    "Article_Abstract": "Usability and user experience (UX) issues are often not well emphasized andaddressed in open source software (OSS) development. There is an imperativeneed for supporting OSS communities to collaboratively identify, understand,and fix UX design issues in a distributed environment. In this paper, weprovide an initial step towards this effort and report on an exploratory studythat investigated how the OSS communities currently reported, discussed,negotiated, and eventually addressed usability and UX issues. We conductedin-depth qualitative analysis of selected issue tracking threads from three OSSprojects hosted on GitHub. Our findings indicated that discussions aboutusability and UX issues in OSS communities were largely influenced by thepersonal opinions and experiences of the participants. Moreover, thecharacteristics of the community may have greatly affected the focus of suchdiscussion.",
    "Article_Subject": "Human-Computer Interaction (cs.HC); Software Engineering (cs.SE)",
    "Article_Date": "2019/02/20",
    "Article_PDF": "https://arxiv.org/pdf/1902.07704"
  }
]